
#include <kernel/kernel_includes.hpp>
#include "dnnl.hpp"
#include "dnnl_types.h"
#include <cstring>
#include <iostream>
// #include "oneDNN_var_init.cpp"

static constexpr void *__stream = &sc::runtime::default_stream;

extern int8_t rn50_backbone_bs4_data[218688];
static constexpr int8_t* __module_data = rn50_backbone_bs4_data;
alignas(64) static int8_t __uninitialized_data[23657544UL];

const int Start_Out_C = 64;
const int Start_Out_H = 112;
const int Start_Out_W = 112;
const int Start_W_H = 7;
const int Start_W_W = 7;
const int Start_I_H = 224;
const int Start_I_W = 224;
const int Start_In_C = 3;

using tag = dnnl::memory::format_tag;
using dt = dnnl::memory::data_type;

static dnnl::engine eng_dnn_ = dnnl::engine(dnnl::engine::kind::cpu, 0);
static dnnl::stream dnn_strm_ = dnnl::stream(eng_dnn_);

static dnnl::memory::dims conv_src_tz_stg1_ = {1, Start_In_C, Start_I_H, Start_I_W};
static dnnl::memory::dims conv_weights_tz_stg1_ = {Start_Out_C, Start_In_C, Start_W_H, Start_W_W};
static dnnl::memory::dims conv_bias_tz_stg1_ = {Start_Out_C};
static dnnl::memory::dims conv_dst_tz_stg1_ = {1, Start_Out_C, Start_Out_H, Start_Out_W};
static dnnl::memory::dims conv_strides_stg1_ = {2, 2};
static dnnl::memory::dims conv_padding_stg1_ = {3, 3};
static dnnl::memory::dims maxpool_dst_tz_ = {1, 64, 56, 56};
static dnnl::memory::dims maxpool_kernel_sz_ = {3,3};
static dnnl::memory::dims maxpool_strides_sz_ = {2,2};
static dnnl::memory::dims maxpool_padding_sz_ = {1,1};

static int8_t* conv_weights_ptr_stg1_ = (int8_t*) aligned_alloc(size_t(64), 64*3*7*7*sizeof(int8_t));
static float* conv_bias_ptr_stg1_ = (float*) aligned_alloc(size_t(64), 64*sizeof(float));

static int8_t* fc_weights_ptr_end_ = (int8_t*) aligned_alloc(size_t(64), 2097152*sizeof(int8_t));
static float* fc_bias_ptr_end_ = (float*) aligned_alloc(size_t(64), 1000*sizeof(float));


static dnnl::convolution_forward conv_forward_prim_;
static dnnl::pooling_forward pool_forward_prim_;
static dnnl::memory::desc scratchpad_md_prim_;

static dnnl::inner_product_forward fc_forward_prim_;
static dnnl::pooling_forward avg_pool_forward_prim_;
static dnnl::reorder fc_input_reorder;
static dnnl::memory::desc post_scratchpad_md_prim_, reorder_scratchpad_md_8;

static dnnl::memory conv_weights_memory, conv_bias_memory;

static dnnl::memory fc_weights_memory;
static dnnl::memory fc_bias_memory;


static bool init_onednn = false;

static dnnl::memory::dims fc_src_tz_ = {4, 2048, 1, 1};
static dnnl::memory::dims fc_weights_tz_ = {1000, 2048, 1, 1};
static dnnl::memory::dims fc_bias_tz_ = {1000};
static dnnl::memory::dims fc_dst_tz_ = {4, 1000};

static dnnl::memory::dims avgpool_src_tz_ = {4, 2048, 7, 7};
static dnnl::memory::dims avgpool_dst_tz_ = {4, 2048, 1, 1};
static dnnl::memory::dims avgpool_kernel_sz_ = {7,7};
static dnnl::memory::dims avgpool_strides_sz_ = {2,2};
static dnnl::memory::dims avgpool_padding_sz_ = {0,0};

static void runStart_Server(int tid, int8_t* input_pointer, int8_t* conv_out_pointer, int8_t* output_pointer, void* conv_scratch_ptr){
  dnnl::memory conv_src_memory = dnnl::memory({{conv_src_tz_stg1_}, dt::s8, tag::nhwc}, eng_dnn_,input_pointer);
  dnnl::memory conv_dst_memory = dnnl::memory({{conv_dst_tz_stg1_}, dt::s8, tag::nhwc}, eng_dnn_,conv_out_pointer);
  dnnl::memory pool_dst_memory = dnnl::memory({{maxpool_dst_tz_}, dt::s8, tag::nhwc}, eng_dnn_,output_pointer);
  dnnl::memory conv_scratch_memory = dnnl::memory(scratchpad_md_prim_, eng_dnn_,conv_scratch_ptr);
  dnnl::memory conv_weights_memory = dnnl::memory({{conv_weights_tz_stg1_}, dt::s8, tag::Adcb16a}, eng_dnn_,conv_weights_ptr_stg1_);
  dnnl::memory conv_bias_memory = dnnl::memory({{conv_bias_tz_stg1_}, dt::f32, tag::a}, eng_dnn_,conv_bias_ptr_stg1_);

  conv_forward_prim_.execute(dnn_strm_, {{DNNL_ARG_SRC, conv_src_memory},
                               {DNNL_ARG_WEIGHTS, conv_weights_memory},
                               {DNNL_ARG_BIAS, conv_bias_memory},
                               {DNNL_ARG_DST, conv_dst_memory},
                               {DNNL_ARG_SCRATCHPAD, conv_scratch_memory}});
  // printf("Running %d, %d, %d, %d, %d, %d, %d, %d, %d\n", tid, conv_out_pointer[0], conv_out_pointer[1],
  //                                                             conv_out_pointer[2], conv_out_pointer[3],
  //                                                             conv_out_pointer[4], conv_out_pointer[5],
  //                                                             conv_out_pointer[6], conv_out_pointer[7]);
  pool_forward_prim_.execute(dnn_strm_, {{DNNL_ARG_SRC, conv_dst_memory},
                               {DNNL_ARG_DST, pool_dst_memory}});
}

static void runEnd(int8_t* middle_out, int8_t* avg_pool_output, float* final_out, void* fc_scratch_ptr, int8_t* fc_src_mem)
{

  dnnl::memory avg_pool_src_memory_ = dnnl::memory({{avgpool_src_tz_}, dt::s8, tag::nhwc}, eng_dnn_,middle_out);
  dnnl::memory avg_pool_dst_memory_ = dnnl::memory({{avgpool_dst_tz_}, dt::s8, tag::nhwc}, eng_dnn_,avg_pool_output);
  dnnl::memory fc_src_memory_ = dnnl::memory({{fc_src_tz_}, dt::s8, tag::nhwc}, eng_dnn_,fc_src_mem);
  dnnl::memory fc_dst_memory_ = dnnl::memory({{fc_dst_tz_}, dt::f32, tag::nc}, eng_dnn_,final_out);
  dnnl::memory fc_scratch_memory = dnnl::memory(post_scratchpad_md_prim_, eng_dnn_, fc_scratch_ptr);
  dnnl::memory fc_bias_memory = dnnl::memory({{fc_bias_tz_}, dt::f32, tag::a}, eng_dnn_, fc_bias_ptr_end_);
  dnnl::memory fc_weights_memory = dnnl::memory({{fc_weights_tz_}, dt::s8, tag::ABcd16b64a4b}, eng_dnn_, fc_weights_ptr_end_);

  avg_pool_forward_prim_.execute(dnn_strm_, {{DNNL_ARG_SRC, avg_pool_src_memory_},
                         {DNNL_ARG_DST, avg_pool_dst_memory_}});

  fc_input_reorder.execute(dnn_strm_,{{DNNL_ARG_SRC, avg_pool_dst_memory_},
                            {DNNL_ARG_DST, fc_src_memory_}});

  fc_forward_prim_.execute(dnn_strm_, {{DNNL_ARG_SRC, fc_src_memory_},
                        {DNNL_ARG_WEIGHTS, fc_weights_memory},
                        {DNNL_ARG_BIAS, fc_bias_memory},
                        {DNNL_ARG_DST, fc_dst_memory_},
                        {DNNL_ARG_SCRATCHPAD, fc_scratch_memory}});

}

static void prepareOneDNN(float* conv1_weight, float* conv1_bias,float* fc_weight, float* fc_bias){
    if (init_onednn){
      return;
    }

    auto user_weights_memory = dnnl::memory({{conv_weights_tz_stg1_}, dt::f32, tag::oihw}, eng_dnn_);

    memcpy(user_weights_memory.get_data_handle(), conv1_weight, Start_Out_C*Start_In_C*Start_W_H*Start_W_W*sizeof(float));
    auto user_bias_memory = dnnl::memory({{conv_bias_tz_stg1_}, dt::f32, tag::x}, eng_dnn_);
    memcpy(user_bias_memory.get_data_handle(), conv1_bias, Start_Out_C*sizeof(float));

    conv_weights_memory = dnnl::memory({{conv_weights_tz_stg1_}, dt::s8, tag::Adcb16a}, eng_dnn_);
    conv_bias_memory = dnnl::memory({{conv_bias_tz_stg1_}, dt::f32, tag::a}, eng_dnn_);

    const float post_scale = 1.f;
    const std::vector<float> weight_scales = {post_scale/0.0006816235836595297f,
                                            post_scale/0.0005305774975568056f,
                                            post_scale/0.00016325304750353098f,
                                            post_scale/0.0002625430643092841f,
                                            post_scale/0.001501173130236566f,
                                            post_scale/0.0002946545137092471f,
                                            post_scale/0.0013540860963985324f,
                                            post_scale/0.0012125875800848007f,
                                            post_scale/0.0018035992980003357f,
                                            post_scale/0.00025723729049786925f,
                                            post_scale/0.001094487844966352f,
                                            post_scale/0.00026009505381807685f,
                                            post_scale/0.0008863380062393844f,
                                            post_scale/1.1920928955078125e-07f,
                                            post_scale/0.0024081964511424303f,
                                            post_scale/0.0015865263994783163f,
                                            post_scale/0.0004841082845814526f,
                                            post_scale/0.001560483011417091f,
                                            post_scale/0.0025746244937181473f,
                                            post_scale/0.000310599833028391f,
                                            post_scale/0.002417005831375718f,
                                            post_scale/0.0015911447117105126f,
                                            post_scale/0.0022614472545683384f,
                                            post_scale/0.00043826879118569195f,
                                            post_scale/0.0007691492792218924f,
                                            post_scale/0.00020982741261832416f,
                                            post_scale/0.0012938278960064054f,
                                            post_scale/0.0012921467423439026f,
                                            post_scale/0.0004248563782311976f,
                                            post_scale/0.00024047742772381753f,
                                            post_scale/0.0005666522774845362f,
                                            post_scale/0.00013184541603550315f,
                                            post_scale/0.0002759526832960546f,
                                            post_scale/0.0038828933611512184f,
                                            post_scale/0.00014129547344055027f,
                                            post_scale/0.00030801387038081884f,
                                            post_scale/0.0002745217061601579f,
                                            post_scale/0.00030328892171382904f,
                                            post_scale/0.0010830751853063703f,
                                            post_scale/0.0011779471533372998f,
                                            post_scale/0.00022047704260330647f,
                                            post_scale/0.001532222144305706f,
                                            post_scale/0.0002601104788482189f,
                                            post_scale/0.00037946386146359146f,
                                            post_scale/0.0001750480878399685f,
                                            post_scale/0.0008486405131407082f,
                                            post_scale/0.0015950539382174611f,
                                            post_scale/0.0004155198694206774f,
                                            post_scale/0.0008059836691245437f,
                                            post_scale/0.0017546059098094702f,
                                            post_scale/0.001436483347788453f,
                                            post_scale/0.000660675170365721f,
                                            post_scale/0.00042748029227368534f,
                                            post_scale/0.0012573313433676958f,
                                            post_scale/0.0011386079713702202f,
                                            post_scale/0.000577236816752702f,
                                            post_scale/0.0005883735720999539f,
                                            post_scale/0.00015980478201527148f,
                                            post_scale/0.00045653333654627204f,
                                            post_scale/0.00031122786458581686f,
                                            post_scale/0.0006546518416143954f,
                                            post_scale/0.0009724263800308108f,
                                            post_scale/0.00027550148661248386f,
                                            post_scale/0.0025447772350162268f};

    const float in_scale = 0.02070588245987892;
    const std::vector<float> conv_scales = {in_scale*0.0006816235836595297f,
                                            in_scale*0.0005305774975568056f,
                                            in_scale*0.00016325304750353098f,
                                            in_scale*0.0002625430643092841f,
                                            in_scale*0.001501173130236566f,
                                            in_scale*0.0002946545137092471f,
                                            in_scale*0.0013540860963985324f,
                                            in_scale*0.0012125875800848007f,
                                            in_scale*0.0018035992980003357f,
                                            in_scale*0.00025723729049786925f,
                                            in_scale*0.001094487844966352f,
                                            in_scale*0.00026009505381807685f,
                                            in_scale*0.0008863380062393844f,
                                            in_scale*1.1920928955078125e-07f,
                                            in_scale*0.0024081964511424303f,
                                            in_scale*0.0015865263994783163f,
                                            in_scale*0.0004841082845814526f,
                                            in_scale*0.001560483011417091f,
                                            in_scale*0.0025746244937181473f,
                                            in_scale*0.000310599833028391f,
                                            in_scale*0.002417005831375718f,
                                            in_scale*0.0015911447117105126f,
                                            in_scale*0.0022614472545683384f,
                                            in_scale*0.00043826879118569195f,
                                            in_scale*0.0007691492792218924f,
                                            in_scale*0.00020982741261832416f,
                                            in_scale*0.0012938278960064054f,
                                            in_scale*0.0012921467423439026f,
                                            in_scale*0.0004248563782311976f,
                                            in_scale*0.00024047742772381753f,
                                            in_scale*0.0005666522774845362f,
                                            in_scale*0.00013184541603550315f,
                                            in_scale*0.0002759526832960546f,
                                            in_scale*0.0038828933611512184f,
                                            in_scale*0.00014129547344055027f,
                                            in_scale*0.00030801387038081884f,
                                            in_scale*0.0002745217061601579f,
                                            in_scale*0.00030328892171382904f,
                                            in_scale*0.0010830751853063703f,
                                            in_scale*0.0011779471533372998f,
                                            in_scale*0.00022047704260330647f,
                                            in_scale*0.001532222144305706f,
                                            in_scale*0.0002601104788482189f,
                                            in_scale*0.00037946386146359146f,
                                            in_scale*0.0001750480878399685f,
                                            in_scale*0.0008486405131407082f,
                                            in_scale*0.0015950539382174611f,
                                            in_scale*0.0004155198694206774f,
                                            in_scale*0.0008059836691245437f,
                                            in_scale*0.0017546059098094702f,
                                            in_scale*0.001436483347788453f,
                                            in_scale*0.000660675170365721f,
                                            in_scale*0.00042748029227368534f,
                                            in_scale*0.0012573313433676958f,
                                            in_scale*0.0011386079713702202f,
                                            in_scale*0.000577236816752702f,
                                            in_scale*0.0005883735720999539f,
                                            in_scale*0.00015980478201527148f,
                                            in_scale*0.00045653333654627204f,
                                            in_scale*0.00031122786458581686f,
                                            in_scale*0.0006546518416143954f,
                                            in_scale*0.0009724263800308108f,
                                            in_scale*0.00027550148661248386f,
                                            in_scale*0.0025447772350162268f};

    const std::vector<float> bias_scales = {1/(in_scale*0.0006816235836595297f),
                                            1/(in_scale*0.0005305774975568056f),
                                            1/(in_scale*0.00016325304750353098f),
                                            1/(in_scale*0.0002625430643092841f),
                                            1/(in_scale*0.001501173130236566f),
                                            1/(in_scale*0.0002946545137092471f),
                                            1/(in_scale*0.0013540860963985324f),
                                            1/(in_scale*0.0012125875800848007f),
                                            1/(in_scale*0.0018035992980003357f),
                                            1/(in_scale*0.00025723729049786925f),
                                            1/(in_scale*0.001094487844966352f),
                                            1/(in_scale*0.00026009505381807685f),
                                            1/(in_scale*0.0008863380062393844f),
                                            1/(in_scale*1.1920928955078125e-07f),
                                            1/(in_scale*0.0024081964511424303f),
                                            1/(in_scale*0.0015865263994783163f),
                                            1/(in_scale*0.0004841082845814526f),
                                            1/(in_scale*0.001560483011417091f),
                                            1/(in_scale*0.0025746244937181473f),
                                            1/(in_scale*0.000310599833028391f),
                                            1/(in_scale*0.002417005831375718f),
                                            1/(in_scale*0.0015911447117105126f),
                                            1/(in_scale*0.0022614472545683384f),
                                            1/(in_scale*0.00043826879118569195f),
                                            1/(in_scale*0.0007691492792218924f),
                                            1/(in_scale*0.00020982741261832416f),
                                            1/(in_scale*0.0012938278960064054f),
                                            1/(in_scale*0.0012921467423439026f),
                                            1/(in_scale*0.0004248563782311976f),
                                            1/(in_scale*0.00024047742772381753f),
                                            1/(in_scale*0.0005666522774845362f),
                                            1/(in_scale*0.00013184541603550315f),
                                            1/(in_scale*0.0002759526832960546f),
                                            1/(in_scale*0.0038828933611512184f),
                                            1/(in_scale*0.00014129547344055027f),
                                            1/(in_scale*0.00030801387038081884f),
                                            1/(in_scale*0.0002745217061601579f),
                                            1/(in_scale*0.00030328892171382904f),
                                            1/(in_scale*0.0010830751853063703f),
                                            1/(in_scale*0.0011779471533372998f),
                                            1/(in_scale*0.00022047704260330647f),
                                            1/(in_scale*0.001532222144305706f),
                                            1/(in_scale*0.0002601104788482189f),
                                            1/(in_scale*0.00037946386146359146f),
                                            1/(in_scale*0.0001750480878399685f),
                                            1/(in_scale*0.0008486405131407082f),
                                            1/(in_scale*0.0015950539382174611f),
                                            1/(in_scale*0.0004155198694206774f),
                                            1/(in_scale*0.0008059836691245437f),
                                            1/(in_scale*0.0017546059098094702f),
                                            1/(in_scale*0.001436483347788453f),
                                            1/(in_scale*0.000660675170365721f),
                                            1/(in_scale*0.00042748029227368534f),
                                            1/(in_scale*0.0012573313433676958f),
                                            1/(in_scale*0.0011386079713702202f),
                                            1/(in_scale*0.000577236816752702f),
                                            1/(in_scale*0.0005883735720999539f),
                                            1/(in_scale*0.00015980478201527148f),
                                            1/(in_scale*0.00045653333654627204f),
                                            1/(in_scale*0.00031122786458581686f),
                                            1/(in_scale*0.0006546518416143954f),
                                            1/(in_scale*0.0009724263800308108f),
                                            1/(in_scale*0.00027550148661248386f),
                                            1/(in_scale*0.0025447772350162268f)};

    

    const int weight_mask = 1;
    const int bias_mask = 1;
    const int conv_mask = 2;

    dnnl::primitive_attr weight_attr;
    weight_attr.set_output_scales(weight_mask, weight_scales);
    auto weight_reorder_pd = dnnl::reorder::primitive_desc(eng_dnn_, user_weights_memory.get_desc(),
                                                           eng_dnn_, conv_weights_memory.get_desc(), weight_attr);
    auto weight_reorder = dnnl::reorder(weight_reorder_pd);
    weight_reorder.execute(dnn_strm_, user_weights_memory, conv_weights_memory);

    dnnl::primitive_attr bias_attr;
    bias_attr.set_output_scales(bias_mask, bias_scales);
    auto bias_reorder_pd = dnnl::reorder::primitive_desc(eng_dnn_, user_bias_memory.get_desc(),
                                                         eng_dnn_, conv_bias_memory.get_desc(), bias_attr);
    auto bias_reorder = dnnl::reorder(bias_reorder_pd);
    bias_reorder.execute(dnn_strm_, user_bias_memory, conv_bias_memory);

    auto conv_src_md = dnnl::memory::desc({conv_src_tz_stg1_}, dt::s8, tag::any);
    auto conv_bias_md = dnnl::memory::desc({conv_bias_tz_stg1_}, dt::f32, tag::any);
    auto conv_weights_md = dnnl::memory::desc({conv_weights_tz_stg1_}, dt::s8, tag::Adcb16a);
    auto conv_dst_md = dnnl::memory::desc({conv_dst_tz_stg1_}, dt::s8, tag::nhwc);

    memcpy(conv_weights_ptr_stg1_, conv_weights_memory.get_data_handle(), conv_weights_md.get_size());
    memcpy(conv_bias_ptr_stg1_, conv_bias_memory.get_data_handle(), 64*sizeof(float));

    auto conv_desc = dnnl::convolution_forward::desc(dnnl::prop_kind::forward_inference,
            dnnl::algorithm::convolution_direct, conv_src_md, conv_weights_md, 
            conv_bias_md, conv_dst_md, conv_strides_stg1_, conv_padding_stg1_, conv_padding_stg1_);
    
    dnnl::primitive_attr conv_attr;
    conv_attr.set_output_scales(conv_mask, conv_scales);
    conv_attr.set_scratchpad_mode(dnnl::scratchpad_mode::user);

    const float ops_scale = 1./0.05720944702625275;
    const float ops_alpha = 0.f; // SKip?
    const float ops_beta = 0.f;
    dnnl::post_ops ops;
    ops.append_eltwise(ops_scale, dnnl::algorithm::eltwise_relu, ops_alpha, ops_beta);
    conv_attr.set_post_ops(ops);

    auto conv_prim_desc = dnnl::convolution_forward::primitive_desc(conv_desc, conv_attr, eng_dnn_);
    scratchpad_md_prim_ = conv_prim_desc.scratchpad_desc();

    conv_forward_prim_ = dnnl::convolution_forward(conv_prim_desc);

    auto pool_dst_md = dnnl::memory::desc({maxpool_dst_tz_}, dt::s8, tag::any);
    auto pool_desc = dnnl::pooling_forward::desc(dnnl::prop_kind::forward_inference,
            dnnl::algorithm::pooling_max, conv_dst_md, pool_dst_md,
            maxpool_strides_sz_, maxpool_kernel_sz_, maxpool_padding_sz_, maxpool_padding_sz_);
    auto pool_pd = dnnl::pooling_forward::primitive_desc(pool_desc, eng_dnn_);
    
    pool_forward_prim_ = dnnl::pooling_forward(pool_pd);

    // Post Backbone

    dnnl::memory avg_pool_dst_memory_ = dnnl::memory({{avgpool_dst_tz_}, dt::s8, tag::nhwc}, eng_dnn_);
    dnnl::memory fc_src_memory_ = dnnl::memory({{fc_src_tz_}, dt::s8, tag::nhwc}, eng_dnn_);
      
    const int fc_weight_mask = 1;
    const int fc_bias_mask = 1;
    const int fc_mask = 2;
    
    auto avg_pool_src_md = dnnl::memory::desc({avgpool_src_tz_}, dt::s8, tag::nhwc); 
    auto avg_pool_dst_md = dnnl::memory::desc({avgpool_dst_tz_}, dt::s8, tag::nhwc);
   
    auto avg_pool_desc = dnnl::pooling_forward::desc(dnnl::prop_kind::forward_inference,
            dnnl::algorithm::pooling_avg_exclude_padding, avg_pool_src_md, avg_pool_dst_md,
            avgpool_strides_sz_, avgpool_kernel_sz_, avgpool_padding_sz_, avgpool_padding_sz_);
    dnnl::primitive_attr avg_pool_attr;
    avg_pool_attr.set_output_scales(0,{0.18475806713104248});
    auto avg_pool_pd = dnnl::pooling_forward::primitive_desc(avg_pool_desc, eng_dnn_);


    avg_pool_forward_prim_ = dnnl::pooling_forward(avg_pool_pd);

    auto fc_src_md = dnnl::memory::desc({fc_src_tz_}, dt::s8, tag::any);
   
    auto fc_weights_md = dnnl::memory::desc({fc_weights_tz_}, dt::s8, tag::any);
 
    auto fc_bias_md = dnnl::memory::desc({fc_bias_tz_}, dt::f32, tag::any);
   
    auto fc_dst_md = dnnl::memory::desc({fc_dst_tz_}, dt::f32, tag::any);

    

    dnnl::primitive_attr fc_attr;
    fc_attr.set_output_scales(0,{1/0.18475806713104248});
   
    auto input_pd = dnnl::reorder::primitive_desc(eng_dnn_, avg_pool_dst_memory_.get_desc(),
                                                           eng_dnn_, fc_src_memory_.get_desc(),fc_attr);
    auto input_reorder = dnnl::reorder(input_pd);
    
    reorder_scratchpad_md_8 = input_pd.scratchpad_desc();
  
    fc_input_reorder = input_reorder;

    
    auto fc_user_weights_memory = dnnl::memory({{fc_weights_tz_}, dt::f32, tag::oihw}, eng_dnn_);
    memcpy(fc_user_weights_memory.get_data_handle(), fc_weight, 2048*1000*sizeof(float));
    auto fc_user_bias_memory = dnnl::memory({fc_bias_tz_, dt::f32, tag::x}, eng_dnn_);
    memcpy(fc_user_bias_memory.get_data_handle(), fc_bias, 1000*sizeof(float));
    
    const float post_scale_fc = 1.f;
    
    
    std::vector<float> fc_weight_scales = {post_scale_fc/0.00227380497381091f,
                                post_scale_fc/0.00276129716075956f,
                                post_scale_fc/0.0021945871412754f,
                                post_scale_fc/0.00212413328699767f,
                                post_scale_fc/0.0021686281543225f,
                                post_scale_fc/0.00226533785462379f,
                                post_scale_fc/0.00220444053411483f,
                                post_scale_fc/0.00189413060434162f,
                                post_scale_fc/0.00216874736361205f,
                                post_scale_fc/0.00201521744020283f,
                                post_scale_fc/0.00204910663887858f,
                                post_scale_fc/0.00237903092056512f,
                                post_scale_fc/0.00246293842792511f,
                                post_scale_fc/0.00250550871714949f,
                                post_scale_fc/0.0022863105405122f,
                                post_scale_fc/0.00180005235597491f,
                                post_scale_fc/0.00197727303020656f,
                                post_scale_fc/0.00226230616681277f,
                                post_scale_fc/0.0017212979728356f,
                                post_scale_fc/0.00265374663285911f,
                                post_scale_fc/0.00192045583389699f,
                                post_scale_fc/0.00205211713910102f,
                                post_scale_fc/0.00182974606286734f,
                                post_scale_fc/0.00202154810540378f,
                                post_scale_fc/0.00187521078623831f,
                                post_scale_fc/0.00184317701496183f,
                                post_scale_fc/0.00175985926762223f,
                                post_scale_fc/0.00204556202515959f,
                                post_scale_fc/0.00167550111655145f,
                                post_scale_fc/0.00208604405634105f,
                                post_scale_fc/0.00179914804175496f,
                                post_scale_fc/0.0017520097317174f,
                                post_scale_fc/0.00176897412165999f,
                                post_scale_fc/0.00188135122880339f,
                                post_scale_fc/0.00195123464800417f,
                                post_scale_fc/0.00196795188821852f,
                                post_scale_fc/0.00198700255714356f,
                                post_scale_fc/0.00185475393664091f,
                                post_scale_fc/0.00165263214148581f,
                                post_scale_fc/0.00172241579275578f,
                                post_scale_fc/0.00141988263931125f,
                                post_scale_fc/0.00176076241768896f,
                                post_scale_fc/0.00171943509485572f,
                                post_scale_fc/0.00171268451958894f,
                                post_scale_fc/0.00151844171341508f,
                                post_scale_fc/0.00187701731920242f,
                                post_scale_fc/0.00178259541280567f,
                                post_scale_fc/0.00205727014690637f,
                                post_scale_fc/0.00148176809307187f,
                                post_scale_fc/0.00182503531686961f,
                                post_scale_fc/0.0019412855617702f,
                                post_scale_fc/0.00202398817054927f,
                                post_scale_fc/0.00178466341458261f,
                                post_scale_fc/0.00197330070659518f,
                                post_scale_fc/0.00187695783097296f,
                                post_scale_fc/0.00194332562386989f,
                                post_scale_fc/0.00235910736955702f,
                                post_scale_fc/0.00227136840112507f,
                                post_scale_fc/0.00227734283544123f,
                                post_scale_fc/0.0015944829210639f,
                                post_scale_fc/0.00183581921737641f,
                                post_scale_fc/0.00243455148302018f,
                                post_scale_fc/0.00220791669562459f,
                                post_scale_fc/0.00191340572200715f,
                                post_scale_fc/0.00174400256946682f,
                                post_scale_fc/0.00203129136934876f,
                                post_scale_fc/0.00189180159941315f,
                                post_scale_fc/0.00187943095806986f,
                                post_scale_fc/0.00188917643390595f,
                                post_scale_fc/0.00241161580197513f,
                                post_scale_fc/0.00243983883410692f,
                                post_scale_fc/0.00179454823955893f,
                                post_scale_fc/0.0023817594628781f,
                                post_scale_fc/0.0026810101699084f,
                                post_scale_fc/0.0024981542956084f,
                                post_scale_fc/0.00206015328876674f,
                                post_scale_fc/0.00223715207539498f,
                                post_scale_fc/0.00233510066755116f,
                                post_scale_fc/0.00154552375897765f,
                                post_scale_fc/0.00182720355223864f,
                                post_scale_fc/0.00213516131043434f,
                                post_scale_fc/0.00164286722429096f,
                                post_scale_fc/0.00148240220732986f,
                                post_scale_fc/0.00247566308826208f,
                                post_scale_fc/0.00229545659385621f,
                                post_scale_fc/0.00176346860826015f,
                                post_scale_fc/0.00160409545060247f,
                                post_scale_fc/0.00245161750353872f,
                                post_scale_fc/0.00219946936704218f,
                                post_scale_fc/0.00170665839686989f,
                                post_scale_fc/0.00194122560787945f,
                                post_scale_fc/0.00192826520651578f,
                                post_scale_fc/0.00186766497790813f,
                                post_scale_fc/0.00184476177673786f,
                                post_scale_fc/0.00214149896055459f,
                                post_scale_fc/0.00197509303689003f,
                                post_scale_fc/0.00190958485472947f,
                                post_scale_fc/0.00170947448350489f,
                                post_scale_fc/0.00223785825073719f,
                                post_scale_fc/0.00140368286520242f,
                                post_scale_fc/0.0017365327803418f,
                                post_scale_fc/0.00235727499239146f,
                                post_scale_fc/0.00217136996798217f,
                                post_scale_fc/0.00184407876804471f,
                                post_scale_fc/0.00185165810398757f,
                                post_scale_fc/0.00310709001496434f,
                                post_scale_fc/0.00155488646123558f,
                                post_scale_fc/0.00235862960107624f,
                                post_scale_fc/0.00232213828712701f,
                                post_scale_fc/0.00214348337613046f,
                                post_scale_fc/0.00285129551775753f,
                                post_scale_fc/0.00259913643822073f,
                                post_scale_fc/0.00188678503036499f,
                                post_scale_fc/0.00202960358001291f,
                                post_scale_fc/0.00159880332648754f,
                                post_scale_fc/0.00368959014303982f,
                                post_scale_fc/0.0028271316550672f,
                                post_scale_fc/0.00248113158158957f,
                                post_scale_fc/0.00270411605015397f,
                                post_scale_fc/0.00226276786997914f,
                                post_scale_fc/0.00230042054317891f,
                                post_scale_fc/0.00259487703442573f,
                                post_scale_fc/0.00267121312208473f,
                                post_scale_fc/0.0021359717939049f,
                                post_scale_fc/0.00230317329987883f,
                                post_scale_fc/0.0018723786342889f,
                                post_scale_fc/0.00151497067417949f,
                                post_scale_fc/0.00160945684183388f,
                                post_scale_fc/0.00205510878004133f,
                                post_scale_fc/0.00208002096042037f,
                                post_scale_fc/0.00224806484766304f,
                                post_scale_fc/0.00191838189493864f,
                                post_scale_fc/0.00203480338677763f,
                                post_scale_fc/0.00169039471074938f,
                                post_scale_fc/0.00189313618466258f,
                                post_scale_fc/0.00173437292687594f,
                                post_scale_fc/0.00191510887816548f,
                                post_scale_fc/0.00181348028127104f,
                                post_scale_fc/0.00241745426319539f,
                                post_scale_fc/0.00140874262433499f,
                                post_scale_fc/0.00168895116075873f,
                                post_scale_fc/0.00190620205830782f,
                                post_scale_fc/0.00176185136660933f,
                                post_scale_fc/0.00155976612586528f,
                                post_scale_fc/0.00181939115282148f,
                                post_scale_fc/0.00175112159922719f,
                                post_scale_fc/0.00187609624117612f,
                                post_scale_fc/0.00160327181220054f,
                                post_scale_fc/0.00175550312269479f,
                                post_scale_fc/0.00220991251990199f,
                                post_scale_fc/0.00169767113402485f,
                                post_scale_fc/0.00191905698738992f,
                                post_scale_fc/0.00162297906354069f,
                                post_scale_fc/0.00178079027682542f,
                                post_scale_fc/0.00136614008806645f,
                                post_scale_fc/0.00157284981105476f,
                                post_scale_fc/0.00189219915773719f,
                                post_scale_fc/0.00185522926039993f,
                                post_scale_fc/0.00200293585658073f,
                                post_scale_fc/0.00144843710586428f,
                                post_scale_fc/0.00180994358379393f,
                                post_scale_fc/0.00171777443028986f,
                                post_scale_fc/0.00164927332662045f,
                                post_scale_fc/0.00159280956722795f,
                                post_scale_fc/0.00296406634151935f,
                                post_scale_fc/0.00150055170524865f,
                                post_scale_fc/0.00143491942435503f,
                                post_scale_fc/0.00135562592186033f,
                                post_scale_fc/0.00160850270185619f,
                                post_scale_fc/0.00175338389817625f,
                                post_scale_fc/0.00186567031778395f,
                                post_scale_fc/0.00179093040060251f,
                                post_scale_fc/0.00160077004693448f,
                                post_scale_fc/0.00161464768461883f,
                                post_scale_fc/0.00160517508629709f,
                                post_scale_fc/0.00142407929524779f,
                                post_scale_fc/0.00160076573956757f,
                                post_scale_fc/0.00174003967549651f,
                                post_scale_fc/0.00280921231023967f,
                                post_scale_fc/0.00182566954754292f,
                                post_scale_fc/0.00185128115117549f,
                                post_scale_fc/0.0017074286006391f,
                                post_scale_fc/0.00178550404962152f,
                                post_scale_fc/0.0022542888764292f,
                                post_scale_fc/0.00229900423437356f,
                                post_scale_fc/0.0018454446690157f,
                                post_scale_fc/0.00152663758490234f,
                                post_scale_fc/0.00165379280224442f,
                                post_scale_fc/0.00168062304146587f,
                                post_scale_fc/0.00194011931307613f,
                                post_scale_fc/0.00161389063578099f,
                                post_scale_fc/0.0019143606768921f,
                                post_scale_fc/0.00166649161837995f,
                                post_scale_fc/0.00160103966481983f,
                                post_scale_fc/0.00146010669413954f,
                                post_scale_fc/0.00145310978405177f,
                                post_scale_fc/0.00167770928237587f,
                                post_scale_fc/0.00142037658952176f,
                                post_scale_fc/0.00183380278758704f,
                                post_scale_fc/0.00184967962559312f,
                                post_scale_fc/0.00134795578196644f,
                                post_scale_fc/0.00160580035299062f,
                                post_scale_fc/0.00144138792529702f,
                                post_scale_fc/0.00178216863423585f,
                                post_scale_fc/0.0014596777036786f,
                                post_scale_fc/0.0015519387088716f,
                                post_scale_fc/0.00232749222777783f,
                                post_scale_fc/0.00178632594179362f,
                                post_scale_fc/0.00199006008915603f,
                                post_scale_fc/0.00211840355768799f,
                                post_scale_fc/0.00287890876643359f,
                                post_scale_fc/0.00166211277246475f,
                                post_scale_fc/0.00168912461958825f,
                                post_scale_fc/0.00178041774779558f,
                                post_scale_fc/0.00167344301007688f,
                                post_scale_fc/0.00158783781807869f,
                                post_scale_fc/0.00182641600258648f,
                                post_scale_fc/0.00204286398366093f,
                                post_scale_fc/0.00174577604047954f,
                                post_scale_fc/0.00197520037181675f,
                                post_scale_fc/0.00170922989491373f,
                                post_scale_fc/0.00191432028077542f,
                                post_scale_fc/0.0017963167047128f,
                                post_scale_fc/0.00180150067899376f,
                                post_scale_fc/0.00174359721131622f,
                                post_scale_fc/0.00184341345448046f,
                                post_scale_fc/0.00164247886277735f,
                                post_scale_fc/0.0018386070150882f,
                                post_scale_fc/0.00201458577066659f,
                                post_scale_fc/0.00213947403244674f,
                                post_scale_fc/0.00165432097855955f,
                                post_scale_fc/0.00172128656413406f,
                                post_scale_fc/0.00135096861049532f,
                                post_scale_fc/0.00193144485820084f,
                                post_scale_fc/0.00177033059298992f,
                                post_scale_fc/0.00148737418930977f,
                                post_scale_fc/0.00172317621763795f,
                                post_scale_fc/0.00206282804720103f,
                                post_scale_fc/0.00178454630076885f,
                                post_scale_fc/0.00174994149710983f,
                                post_scale_fc/0.00171817967202514f,
                                post_scale_fc/0.0017694963607937f,
                                post_scale_fc/0.00168888038024306f,
                                post_scale_fc/0.00153189909178763f,
                                post_scale_fc/0.00160436821170151f,
                                post_scale_fc/0.00182847899850457f,
                                post_scale_fc/0.00188812508713454f,
                                post_scale_fc/0.00145273783709853f,
                                post_scale_fc/0.00141829170752316f,
                                post_scale_fc/0.00188264262396842f,
                                post_scale_fc/0.00137655285652726f,
                                post_scale_fc/0.00195315689779818f,
                                post_scale_fc/0.00150350388139486f,
                                post_scale_fc/0.0018896113615483f,
                                post_scale_fc/0.00176461122464388f,
                                post_scale_fc/0.00174249673727899f,
                                post_scale_fc/0.00173693581018596f,
                                post_scale_fc/0.0013462376082316f,
                                post_scale_fc/0.00159559992607682f,
                                post_scale_fc/0.00167639984283596f,
                                post_scale_fc/0.00158776831813156f,
                                post_scale_fc/0.00178036466240882f,
                                post_scale_fc/0.00150549504905939f,
                                post_scale_fc/0.00144919601734727f,
                                post_scale_fc/0.00151322188321501f,
                                post_scale_fc/0.00182829028926789f,
                                post_scale_fc/0.00206678477115929f,
                                post_scale_fc/0.00163474597502499f,
                                post_scale_fc/0.00167773687280714f,
                                post_scale_fc/0.00174027553293854f,
                                post_scale_fc/0.00184615643229335f,
                                post_scale_fc/0.0021469322964549f,
                                post_scale_fc/0.00177943077869713f,
                                post_scale_fc/0.00207145139575004f,
                                post_scale_fc/0.00155303499195724f,
                                post_scale_fc/0.00160651456099003f,
                                post_scale_fc/0.00163724564481526f,
                                post_scale_fc/0.00149630079977214f,
                                post_scale_fc/0.00140780839137732f,
                                post_scale_fc/0.00173935480415821f,
                                post_scale_fc/0.00137331429868936f,
                                post_scale_fc/0.00226180627942085f,
                                post_scale_fc/0.00224515260197222f,
                                post_scale_fc/0.00162510038353502f,
                                post_scale_fc/0.00254597445018589f,
                                post_scale_fc/0.00253262720070779f,
                                post_scale_fc/0.00210423558019101f,
                                post_scale_fc/0.00260076345875859f,
                                post_scale_fc/0.00176997226662933f,
                                post_scale_fc/0.00192126911133527f,
                                post_scale_fc/0.00167852418962866f,
                                post_scale_fc/0.0019117840565741f,
                                post_scale_fc/0.00224045966751873f,
                                post_scale_fc/0.00184323848225176f,
                                post_scale_fc/0.00203229207545518f,
                                post_scale_fc/0.00183803762774914f,
                                post_scale_fc/0.0020669880323112f,
                                post_scale_fc/0.0018636651802808f,
                                post_scale_fc/0.00197544205002486f,
                                post_scale_fc/0.00182321318425238f,
                                post_scale_fc/0.0020713007543236f,
                                post_scale_fc/0.00196871580556035f,
                                post_scale_fc/0.0024854342918843f,
                                post_scale_fc/0.00181617983616888f,
                                post_scale_fc/0.0024674164596945f,
                                post_scale_fc/0.00256802490912377f,
                                post_scale_fc/0.00273384852334857f,
                                post_scale_fc/0.0020766204688698f,
                                post_scale_fc/0.00189530081115663f,
                                post_scale_fc/0.00211467873305082f,
                                post_scale_fc/0.00182136753574013f,
                                post_scale_fc/0.00135289737954735f,
                                post_scale_fc/0.00163317332044243f,
                                post_scale_fc/0.0020942660048604f,
                                post_scale_fc/0.00207786471582949f,
                                post_scale_fc/0.0022568495478481f,
                                post_scale_fc/0.00183024385478347f,
                                post_scale_fc/0.00239814189262688f,
                                post_scale_fc/0.00181208061985671f,
                                post_scale_fc/0.00190258619841188f,
                                post_scale_fc/0.00200146622955799f,
                                post_scale_fc/0.00193867180496454f,
                                post_scale_fc/0.00181898078881204f,
                                post_scale_fc/0.00156988471280783f,
                                post_scale_fc/0.00174589385278522f,
                                post_scale_fc/0.00201219739392399f,
                                post_scale_fc/0.00216762907803058f,
                                post_scale_fc/0.00191554112825542f,
                                post_scale_fc/0.0017467982834205f,
                                post_scale_fc/0.00218481151387095f,
                                post_scale_fc/0.00184446724597364f,
                                post_scale_fc/0.00162108184304088f,
                                post_scale_fc/0.0022005490027368f,
                                post_scale_fc/0.00185934151522815f,
                                post_scale_fc/0.00199351762421429f,
                                post_scale_fc/0.00194941449444741f,
                                post_scale_fc/0.00173150410410016f,
                                post_scale_fc/0.00182830321136862f,
                                post_scale_fc/0.00189346564002335f,
                                post_scale_fc/0.00208873930387198f,
                                post_scale_fc/0.00187532790005207f,
                                post_scale_fc/0.00235355924814939f,
                                post_scale_fc/0.00251186010427773f,
                                post_scale_fc/0.0025089019909501f,
                                post_scale_fc/0.00177288986742496f,
                                post_scale_fc/0.00234016170725226f,
                                post_scale_fc/0.00197643670253455f,
                                post_scale_fc/0.00223897281102836f,
                                post_scale_fc/0.00176799239125102f,
                                post_scale_fc/0.00188779167365282f,
                                post_scale_fc/0.00206255796365439f,
                                post_scale_fc/0.00247748964466154f,
                                post_scale_fc/0.00191615300718694f,
                                post_scale_fc/0.001792544266209f,
                                post_scale_fc/0.00227756751701235f,
                                post_scale_fc/0.00174876558594405f,
                                post_scale_fc/0.00160153943579643f,
                                post_scale_fc/0.00192522548604756f,
                                post_scale_fc/0.00166801002342253f,
                                post_scale_fc/0.001866843434982f,
                                post_scale_fc/0.00154662155546247f,
                                post_scale_fc/0.00205433135852217f,
                                post_scale_fc/0.0021028893534094f,
                                post_scale_fc/0.00240919645875692f,
                                post_scale_fc/0.0022338880226016f,
                                post_scale_fc/0.00188299675937742f,
                                post_scale_fc/0.00166554015595465f,
                                post_scale_fc/0.001706148032099f,
                                post_scale_fc/0.00164566549938172f,
                                post_scale_fc/0.0018590911058709f,
                                post_scale_fc/0.00183818640653043f,
                                post_scale_fc/0.00237788492813706f,
                                post_scale_fc/0.00191481073852628f,
                                post_scale_fc/0.0019383420003578f,
                                post_scale_fc/0.00189851108007133f,
                                post_scale_fc/0.00210291962139308f,
                                post_scale_fc/0.00160451175179332f,
                                post_scale_fc/0.00195236969739198f,
                                post_scale_fc/0.00167459750082343f,
                                post_scale_fc/0.00191429373808205f,
                                post_scale_fc/0.0020020492374897f,
                                post_scale_fc/0.00161326676607131f,
                                post_scale_fc/0.0018190547125414f,
                                post_scale_fc/0.00188410584814846f,
                                post_scale_fc/0.00203049881383776f,
                                post_scale_fc/0.00223667221143841f,
                                post_scale_fc/0.00209674099460244f,
                                post_scale_fc/0.0020359088666737f,
                                post_scale_fc/0.00201935623772442f,
                                post_scale_fc/0.00221077026799321f,
                                post_scale_fc/0.00190633547026664f,
                                post_scale_fc/0.00177474855445325f,
                                post_scale_fc/0.00185090128798037f,
                                post_scale_fc/0.00283018359914422f,
                                post_scale_fc/0.00172920268960297f,
                                post_scale_fc/0.0019179293885827f,
                                post_scale_fc/0.00236844504252076f,
                                post_scale_fc/0.00219054007902741f,
                                post_scale_fc/0.00267744669690728f,
                                post_scale_fc/0.00289597688242793f,
                                post_scale_fc/0.00202828808687627f,
                                post_scale_fc/0.00188326800707727f,
                                post_scale_fc/0.00263697584159672f,
                                post_scale_fc/0.0023885415866971f,
                                post_scale_fc/0.00226549617946147f,
                                post_scale_fc/0.00230370205827057f,
                                post_scale_fc/0.00198318460024893f,
                                post_scale_fc/0.00166168238501995f,
                                post_scale_fc/0.00190402055159211f,
                                post_scale_fc/0.00259186653420329f,
                                post_scale_fc/0.00238504470326006f,
                                post_scale_fc/0.00163115432951599f,
                                post_scale_fc/0.00148449407424777f,
                                post_scale_fc/0.00216616201214492f,
                                post_scale_fc/0.00227903365157544f,
                                post_scale_fc/0.00227849860675632f,
                                post_scale_fc/0.0033426065929234f,
                                post_scale_fc/0.00237518409267067f,
                                post_scale_fc/0.00177972484380006f,
                                post_scale_fc/0.00283443974331021f,
                                post_scale_fc/0.00276328460313379f,
                                post_scale_fc/0.0026895347982645f,
                                post_scale_fc/0.00249025621451437f,
                                post_scale_fc/0.00204224395565688f,
                                post_scale_fc/0.00232408149167895f,
                                post_scale_fc/0.00189173873513937f,
                                post_scale_fc/0.00172131787985563f,
                                post_scale_fc/0.00228119478560984f,
                                post_scale_fc/0.00179522600956261f,
                                post_scale_fc/0.00208577048033475f,
                                post_scale_fc/0.0029025103431195f,
                                post_scale_fc/0.00205257348716259f,
                                post_scale_fc/0.00207719043828547f,
                                post_scale_fc/0.00277605606243014f,
                                post_scale_fc/0.00293387100100517f,
                                post_scale_fc/0.00366692501120269f,
                                post_scale_fc/0.00154015549924224f,
                                post_scale_fc/0.00200198148377239f,
                                post_scale_fc/0.00188994174823164f,
                                post_scale_fc/0.0028432838153094f,
                                post_scale_fc/0.00247007794678211f,
                                post_scale_fc/0.00216810056008398f,
                                post_scale_fc/0.00179518514778465f,
                                post_scale_fc/0.00205323728732764f,
                                post_scale_fc/0.00247915578074753f,
                                post_scale_fc/0.00196093250997364f,
                                post_scale_fc/0.00227873236872255f,
                                post_scale_fc/0.00192023103591054f,
                                post_scale_fc/0.00225312123075127f,
                                post_scale_fc/0.00204433780163526f,
                                post_scale_fc/0.00279425154440104f,
                                post_scale_fc/0.0024464561138302f,
                                post_scale_fc/0.00212317844852805f,
                                post_scale_fc/0.00240832800045609f,
                                post_scale_fc/0.00260554510168731f,
                                post_scale_fc/0.00253293639980256f,
                                post_scale_fc/0.00280340481549501f,
                                post_scale_fc/0.00195568311028182f,
                                post_scale_fc/0.00212115771137177f,
                                post_scale_fc/0.00198116805404424f,
                                post_scale_fc/0.00166083662770688f,
                                post_scale_fc/0.00246666488237679f,
                                post_scale_fc/0.00272948970086872f,
                                post_scale_fc/0.00189584563486278f,
                                post_scale_fc/0.00195677042938768f,
                                post_scale_fc/0.00275812367908656f,
                                post_scale_fc/0.00254906364716589f,
                                post_scale_fc/0.00265903910622f,
                                post_scale_fc/0.00286629213951528f,
                                post_scale_fc/0.00210646190680563f,
                                post_scale_fc/0.00249965116381645f,
                                post_scale_fc/0.00207792199216783f,
                                post_scale_fc/0.00184900709427893f,
                                post_scale_fc/0.001968071796f,
                                post_scale_fc/0.0024408078752458f,
                                post_scale_fc/0.00205288594588637f,
                                post_scale_fc/0.00237410143017768f,
                                post_scale_fc/0.00171473308000713f,
                                post_scale_fc/0.00316213094629347f,
                                post_scale_fc/0.00145746092312037f,
                                post_scale_fc/0.0020093098282814f,
                                post_scale_fc/0.00201819255016744f,
                                post_scale_fc/0.00144999532494694f,
                                post_scale_fc/0.00198388146236538f,
                                post_scale_fc/0.00201412895694375f,
                                post_scale_fc/0.00159450469072908f,
                                post_scale_fc/0.00245110993273556f,
                                post_scale_fc/0.00225918693467974f,
                                post_scale_fc/0.00266961310990154f,
                                post_scale_fc/0.00393024086952209f,
                                post_scale_fc/0.00242827762849628f,
                                post_scale_fc/0.00247913133352994f,
                                post_scale_fc/0.00202380097471177f,
                                post_scale_fc/0.00231268815696239f,
                                post_scale_fc/0.00219374289736151f,
                                post_scale_fc/0.00220095668919384f,
                                post_scale_fc/0.00186145829502493f,
                                post_scale_fc/0.00171963672619313f,
                                post_scale_fc/0.00222481857053935f,
                                post_scale_fc/0.00197305111214518f,
                                post_scale_fc/0.0022710426710546f,
                                post_scale_fc/0.00220544007606804f,
                                post_scale_fc/0.00227675097994506f,
                                post_scale_fc/0.0024713312741369f,
                                post_scale_fc/0.00210204371251165f,
                                post_scale_fc/0.00228276429697871f,
                                post_scale_fc/0.00221834750846028f,
                                post_scale_fc/0.00189642247278243f,
                                post_scale_fc/0.00300059700384736f,
                                post_scale_fc/0.0023351521231234f,
                                post_scale_fc/0.00223834556527435f,
                                post_scale_fc/0.00185367837548255f,
                                post_scale_fc/0.00169567111879587f,
                                post_scale_fc/0.0020282263867557f,
                                post_scale_fc/0.00201443210244178f,
                                post_scale_fc/0.00321284099481999f,
                                post_scale_fc/0.00213504256680607f,
                                post_scale_fc/0.001592404441908f,
                                post_scale_fc/0.00204032124020159f,
                                post_scale_fc/0.00249219802208244f,
                                post_scale_fc/0.00209611933678388f,
                                post_scale_fc/0.00215063290670514f,
                                post_scale_fc/0.0019387659849599f,
                                post_scale_fc/0.00265639857389032f,
                                post_scale_fc/0.0021613985300064f,
                                post_scale_fc/0.00212164735421538f,
                                post_scale_fc/0.00187859579455107f,
                                post_scale_fc/0.00175356667023152f,
                                post_scale_fc/0.00169870466925203f,
                                post_scale_fc/0.00206679943948984f,
                                post_scale_fc/0.00198687007650733f,
                                post_scale_fc/0.00164531241171062f,
                                post_scale_fc/0.00233347225002944f,
                                post_scale_fc/0.00363705982454121f,
                                post_scale_fc/0.00245634349994361f,
                                post_scale_fc/0.00182601914275437f,
                                post_scale_fc/0.0019087390974164f,
                                post_scale_fc/0.00237506907433271f,
                                post_scale_fc/0.00237695127725601f,
                                post_scale_fc/0.00275911041535437f,
                                post_scale_fc/0.00255021639168262f,
                                post_scale_fc/0.00179510866291821f,
                                post_scale_fc/0.00227887416258454f,
                                post_scale_fc/0.00263619888573884f,
                                post_scale_fc/0.00259410100989043f,
                                post_scale_fc/0.00218834658153355f,
                                post_scale_fc/0.00266179163008928f,
                                post_scale_fc/0.00290350569412112f,
                                post_scale_fc/0.00248509785160422f,
                                post_scale_fc/0.00182168814353644f,
                                post_scale_fc/0.00186321034561842f,
                                post_scale_fc/0.00224497052840888f,
                                post_scale_fc/0.00217848294414579f,
                                post_scale_fc/0.00228785583749413f,
                                post_scale_fc/0.00258980644866824f,
                                post_scale_fc/0.00232384703122079f,
                                post_scale_fc/0.00304048205725848f,
                                post_scale_fc/0.00217924616299569f,
                                post_scale_fc/0.00193749321624636f,
                                post_scale_fc/0.00229281652718782f,
                                post_scale_fc/0.00208604033105075f,
                                post_scale_fc/0.00212690141052007f,
                                post_scale_fc/0.00314504886046052f,
                                post_scale_fc/0.00186429254245013f,
                                post_scale_fc/0.00255918106995522f,
                                post_scale_fc/0.00290748104453086f,
                                post_scale_fc/0.00203401013277471f,
                                post_scale_fc/0.00323416967876255f,
                                post_scale_fc/0.00210816576145589f,
                                post_scale_fc/0.0023302671033889f,
                                post_scale_fc/0.0024798687081784f,
                                post_scale_fc/0.00178731279447674f,
                                post_scale_fc/0.0017893366748467f,
                                post_scale_fc/0.00248434394598007f,
                                post_scale_fc/0.00182808574754744f,
                                post_scale_fc/0.00237280852161347f,
                                post_scale_fc/0.00240111444145441f,
                                post_scale_fc/0.00203824695199728f,
                                post_scale_fc/0.00249841064214706f,
                                post_scale_fc/0.0019625558052212f,
                                post_scale_fc/0.00318012828938663f,
                                post_scale_fc/0.0022335909307003f,
                                post_scale_fc/0.00171474053058773f,
                                post_scale_fc/0.00216643628664314f,
                                post_scale_fc/0.00155677984002977f,
                                post_scale_fc/0.00177534925751388f,
                                post_scale_fc/0.00183719117194414f,
                                post_scale_fc/0.00175246503204107f,
                                post_scale_fc/0.0044563109986484f,
                                post_scale_fc/0.00176297465804964f,
                                post_scale_fc/0.00165702716913074f,
                                post_scale_fc/0.00248482776805758f,
                                post_scale_fc/0.00235392758622765f,
                                post_scale_fc/0.00225751288235187f,
                                post_scale_fc/0.00282271648757159f,
                                post_scale_fc/0.00209256866946816f,
                                post_scale_fc/0.00234413985162973f,
                                post_scale_fc/0.00150976574514061f,
                                post_scale_fc/0.00259015429764986f,
                                post_scale_fc/0.00330797955393791f,
                                post_scale_fc/0.00135345535818487f,
                                post_scale_fc/0.00240114866755902f,
                                post_scale_fc/0.00318259629420936f,
                                post_scale_fc/0.00198164372704923f,
                                post_scale_fc/0.00215690047480165f,
                                post_scale_fc/0.00179972907062619f,
                                post_scale_fc/0.00275643775239586f,
                                post_scale_fc/0.0020660338923335f,
                                post_scale_fc/0.00578146800398826f,
                                post_scale_fc/0.00183471769560128f,
                                post_scale_fc/0.00238805613480508f,
                                post_scale_fc/0.00417285226285457f,
                                post_scale_fc/0.00210732594132423f,
                                post_scale_fc/0.00171622540801763f,
                                post_scale_fc/0.00191407464444637f,
                                post_scale_fc/0.00212195911444723f,
                                post_scale_fc/0.0022712699137628f,
                                post_scale_fc/0.00273464573547244f,
                                post_scale_fc/0.00169114384334534f,
                                post_scale_fc/0.00186147761996835f,
                                post_scale_fc/0.00224705645814538f,
                                post_scale_fc/0.00184636446647346f,
                                post_scale_fc/0.00201024510897696f,
                                post_scale_fc/0.00200690561905503f,
                                post_scale_fc/0.00228176754899323f,
                                post_scale_fc/0.00315204681828618f,
                                post_scale_fc/0.0019847119692713f,
                                post_scale_fc/0.00226551620289683f,
                                post_scale_fc/0.00217244122177362f,
                                post_scale_fc/0.00223000883124768f,
                                post_scale_fc/0.00224500452168285f,
                                post_scale_fc/0.00212041684426367f,
                                post_scale_fc/0.00193466816563159f,
                                post_scale_fc/0.00166088237892836f,
                                post_scale_fc/0.00271178549155592f,
                                post_scale_fc/0.00171118765138089f,
                                post_scale_fc/0.00151388684753328f,
                                post_scale_fc/0.00178832898382097f,
                                post_scale_fc/0.00166956265456974f,
                                post_scale_fc/0.00199061236344277f,
                                post_scale_fc/0.00241334992460906f,
                                post_scale_fc/0.00229916465468704f,
                                post_scale_fc/0.00279636238701641f,
                                post_scale_fc/0.0022711744531989f,
                                post_scale_fc/0.00194922881200909f,
                                post_scale_fc/0.00232420791871845f,
                                post_scale_fc/0.0028739902190864f,
                                post_scale_fc/0.00211476488038897f,
                                post_scale_fc/0.00225583021529018f,
                                post_scale_fc/0.0016526662511751f,
                                post_scale_fc/0.00194803986232727f,
                                post_scale_fc/0.0023809727281332f,
                                post_scale_fc/0.00292756641283631f,
                                post_scale_fc/0.00200345669873058f,
                                post_scale_fc/0.00169874809216707f,
                                post_scale_fc/0.00178563233930617f,
                                post_scale_fc/0.00197020941413939f,
                                post_scale_fc/0.00208938517607748f,
                                post_scale_fc/0.00253145559690892f,
                                post_scale_fc/0.00234960881061851f,
                                post_scale_fc/0.0018707423005253f,
                                post_scale_fc/0.00157278426922857f,
                                post_scale_fc/0.00193510355893522f,
                                post_scale_fc/0.0017722196644172f,
                                post_scale_fc/0.00232567405328154f,
                                post_scale_fc/0.00212915032170712f,
                                post_scale_fc/0.00163731584325432f,
                                post_scale_fc/0.00241859117522835f,
                                post_scale_fc/0.0021908467169851f,
                                post_scale_fc/0.00260530738160014f,
                                post_scale_fc/0.00217398628592491f,
                                post_scale_fc/0.00190005078911781f,
                                post_scale_fc/0.00242758193053305f,
                                post_scale_fc/0.00165101792663335f,
                                post_scale_fc/0.00185853487346321f,
                                post_scale_fc/0.00176426384132355f,
                                post_scale_fc/0.0018990309908986f,
                                post_scale_fc/0.00209580897353589f,
                                post_scale_fc/0.00224685785360634f,
                                post_scale_fc/0.00275767501443624f,
                                post_scale_fc/0.00164664664771407f,
                                post_scale_fc/0.00180674367584288f,
                                post_scale_fc/0.00227510510012507f,
                                post_scale_fc/0.00201213755644857f,
                                post_scale_fc/0.00344277429394423f,
                                post_scale_fc/0.00207265163771808f,
                                post_scale_fc/0.0017688653897494f,
                                post_scale_fc/0.00195470172911882f,
                                post_scale_fc/0.00176204915624111f,
                                post_scale_fc/0.0019983050879091f,
                                post_scale_fc/0.00205031572841107f,
                                post_scale_fc/0.00159256823826581f,
                                post_scale_fc/0.00165684113744646f,
                                post_scale_fc/0.00164969952311366f,
                                post_scale_fc/0.00200045900419354f,
                                post_scale_fc/0.00197013933211565f,
                                post_scale_fc/0.0022674836218357f,
                                post_scale_fc/0.00218598544597625f,
                                post_scale_fc/0.00226586312055587f,
                                post_scale_fc/0.00206865789368748f,
                                post_scale_fc/0.00356585718691349f,
                                post_scale_fc/0.0019755105022341f,
                                post_scale_fc/0.00311614526435732f,
                                post_scale_fc/0.00216384744271636f,
                                post_scale_fc/0.00183811620809137f,
                                post_scale_fc/0.00213912362232804f,
                                post_scale_fc/0.00224972190335392f,
                                post_scale_fc/0.00195866567082703f,
                                post_scale_fc/0.00211755628697574f,
                                post_scale_fc/0.00159794988576322f,
                                post_scale_fc/0.0023316410370171f,
                                post_scale_fc/0.0022115169558674f,
                                post_scale_fc/0.00272747152484953f,
                                post_scale_fc/0.00181745493318885f,
                                post_scale_fc/0.00182366208173334f,
                                post_scale_fc/0.00226789130829274f,
                                post_scale_fc/0.00338768912479281f,
                                post_scale_fc/0.00171551981475204f,
                                post_scale_fc/0.0019521452486515f,
                                post_scale_fc/0.00227167154662311f,
                                post_scale_fc/0.00211142562329769f,
                                post_scale_fc/0.00252817128784954f,
                                post_scale_fc/0.00276511022821068f,
                                post_scale_fc/0.00205451226793229f,
                                post_scale_fc/0.00261727953329682f,
                                post_scale_fc/0.00206659850664436f,
                                post_scale_fc/0.00196980405598878f,
                                post_scale_fc/0.00179315079003572f,
                                post_scale_fc/0.0033456867095083f,
                                post_scale_fc/0.00192409346345812f,
                                post_scale_fc/0.00234094192273914f,
                                post_scale_fc/0.00169258879031986f,
                                post_scale_fc/0.00167121470440179f,
                                post_scale_fc/0.00198900722898542f,
                                post_scale_fc/0.00185921334195882f,
                                post_scale_fc/0.00260688201524317f,
                                post_scale_fc/0.00243259849958121f,
                                post_scale_fc/0.00199602195061743f,
                                post_scale_fc/0.00225037662312388f,
                                post_scale_fc/0.00209766114130616f,
                                post_scale_fc/0.00228457897901535f,
                                post_scale_fc/0.00259153265506029f,
                                post_scale_fc/0.00185632903594523f,
                                post_scale_fc/0.00190604210365563f,
                                post_scale_fc/0.00202557048760354f,
                                post_scale_fc/0.00191448011901229f,
                                post_scale_fc/0.0023406189866364f,
                                post_scale_fc/0.0019396828720346f,
                                post_scale_fc/0.00192890781909227f,
                                post_scale_fc/0.00210989918559789f,
                                post_scale_fc/0.00204224348999559f,
                                post_scale_fc/0.0019594389013946f,
                                post_scale_fc/0.00209293374791741f,
                                post_scale_fc/0.00203690282069146f,
                                post_scale_fc/0.0015879925340414f,
                                post_scale_fc/0.00184804352466017f,
                                post_scale_fc/0.00191176624502986f,
                                post_scale_fc/0.00163238262757658f,
                                post_scale_fc/0.00193511508405208f,
                                post_scale_fc/0.00166031729895621f,
                                post_scale_fc/0.00361558841541409f,
                                post_scale_fc/0.00167956762015819f,
                                post_scale_fc/0.0021192783024162f,
                                post_scale_fc/0.00202689063735306f,
                                post_scale_fc/0.00184074568096548f,
                                post_scale_fc/0.00236637494526803f,
                                post_scale_fc/0.00233529438264668f,
                                post_scale_fc/0.00184578949119895f,
                                post_scale_fc/0.00231261225417256f,
                                post_scale_fc/0.00289369304664433f,
                                post_scale_fc/0.00268775061704218f,
                                post_scale_fc/0.00155028363224118f,
                                post_scale_fc/0.00218705320730805f,
                                post_scale_fc/0.00242934864945709f,
                                post_scale_fc/0.00191826466470956f,
                                post_scale_fc/0.00211014971137046f,
                                post_scale_fc/0.00246789562515914f,
                                post_scale_fc/0.00204663653858006f,
                                post_scale_fc/0.00198838277719914f,
                                post_scale_fc/0.00463508768007159f,
                                post_scale_fc/0.00243761297315359f,
                                post_scale_fc/0.00194274657405912f,
                                post_scale_fc/0.00303290761075913f,
                                post_scale_fc/0.00195377459749579f,
                                post_scale_fc/0.00243469537235796f,
                                post_scale_fc/0.00264217425137758f,
                                post_scale_fc/0.00266873906366527f,
                                post_scale_fc/0.00236693187616765f,
                                post_scale_fc/0.00240744464099407f,
                                post_scale_fc/0.00301293074153363f,
                                post_scale_fc/0.00391360279172658f,
                                post_scale_fc/0.002145417034626f,
                                post_scale_fc/0.00192571757361292f,
                                post_scale_fc/0.00269744708202779f,
                                post_scale_fc/0.00315934419631958f,
                                post_scale_fc/0.00224426575005054f,
                                post_scale_fc/0.0018723455723375f,
                                post_scale_fc/0.00238603446632623f,
                                post_scale_fc/0.00214536441490054f,
                                post_scale_fc/0.00181536190211772f,
                                post_scale_fc/0.00205451250076293f,
                                post_scale_fc/0.00212743086740374f,
                                post_scale_fc/0.00256292126141488f,
                                post_scale_fc/0.00251797819510102f,
                                post_scale_fc/0.0014911942416802f,
                                post_scale_fc/0.00201508798636496f,
                                post_scale_fc/0.00234746350906789f,
                                post_scale_fc/0.00194500351790338f,
                                post_scale_fc/0.00282566272653639f,
                                post_scale_fc/0.00176103378180414f,
                                post_scale_fc/0.00339953345246613f,
                                post_scale_fc/0.00181273382622748f,
                                post_scale_fc/0.00212915148586034f,
                                post_scale_fc/0.00183940900024026f,
                                post_scale_fc/0.00224190764129161f,
                                post_scale_fc/0.00285854353569448f,
                                post_scale_fc/0.00231267698109149f,
                                post_scale_fc/0.00242159469053149f,
                                post_scale_fc/0.00226553226821124f,
                                post_scale_fc/0.00191547232680022f,
                                post_scale_fc/0.00205241818912327f,
                                post_scale_fc/0.00175638997461646f,
                                post_scale_fc/0.00270381942391395f,
                                post_scale_fc/0.0018859093543142f,
                                post_scale_fc/0.00268288701772689f,
                                post_scale_fc/0.00234548584558069f,
                                post_scale_fc/0.00191822578199207f,
                                post_scale_fc/0.00186813226900994f,
                                post_scale_fc/0.0027695894241333f,
                                post_scale_fc/0.00176504394039511f,
                                post_scale_fc/0.00163183535914868f,
                                post_scale_fc/0.00290826358832418f,
                                post_scale_fc/0.00218442408367991f,
                                post_scale_fc/0.00213779578916728f,
                                post_scale_fc/0.00331912096589803f,
                                post_scale_fc/0.00171584880445152f,
                                post_scale_fc/0.00383840571157634f,
                                post_scale_fc/0.00384032214060425f,
                                post_scale_fc/0.00210095639340579f,
                                post_scale_fc/0.00191184412688016f,
                                post_scale_fc/0.00212015444412827f,
                                post_scale_fc/0.00187981675844639f,
                                post_scale_fc/0.00268462533131241f,
                                post_scale_fc/0.00315822893753647f,
                                post_scale_fc/0.00180805369745939f,
                                post_scale_fc/0.00193846225738525f,
                                post_scale_fc/0.00203489046543836f,
                                post_scale_fc/0.00198656297288835f,
                                post_scale_fc/0.00153718155343085f,
                                post_scale_fc/0.00202228967100381f,
                                post_scale_fc/0.00169703492429107f,
                                post_scale_fc/0.00394117645919323f,
                                post_scale_fc/0.00317592383362352f,
                                post_scale_fc/0.00328714144416153f,
                                post_scale_fc/0.00333709572441875f,
                                post_scale_fc/0.00214883754961192f,
                                post_scale_fc/0.00242167944088578f,
                                post_scale_fc/0.00190275255590677f,
                                post_scale_fc/0.00466032279655337f,
                                post_scale_fc/0.00267692445777356f,
                                post_scale_fc/0.00253167888149619f,
                                post_scale_fc/0.00228986656293272f,
                                post_scale_fc/0.00329640228301286f,
                                post_scale_fc/0.00320884934626519f,
                                post_scale_fc/0.0020452591124922f,
                                post_scale_fc/0.00246208626776933f,
                                post_scale_fc/0.00224645435810089f,
                                post_scale_fc/0.00223849271424114f,
                                post_scale_fc/0.00200690934434533f,
                                post_scale_fc/0.00174108438659459f,
                                post_scale_fc/0.00185273552779108f,
                                post_scale_fc/0.00240103318355977f,
                                post_scale_fc/0.00190464686602354f,
                                post_scale_fc/0.0019472079584375f,
                                post_scale_fc/0.0021951210219413f,
                                post_scale_fc/0.00297502661123871f,
                                post_scale_fc/0.00339040951803326f,
                                post_scale_fc/0.00247981632128357f,
                                post_scale_fc/0.00362138031050562f,
                                post_scale_fc/0.0022784189786762f,
                                post_scale_fc/0.00198276154696941f,
                                post_scale_fc/0.00249466323293745f,
                                post_scale_fc/0.00162394437938928f,
                                post_scale_fc/0.00193656235933303f,
                                post_scale_fc/0.00192566134501248f,
                                post_scale_fc/0.0038460623472929f,
                                post_scale_fc/0.00183368159923702f,
                                post_scale_fc/0.00179789715912193f,
                                post_scale_fc/0.00203241547569632f,
                                post_scale_fc/0.00228171772323548f,
                                post_scale_fc/0.00225571822375059f,
                                post_scale_fc/0.00259172613732516f,
                                post_scale_fc/0.00229148473590612f,
                                post_scale_fc/0.00164745410438627f,
                                post_scale_fc/0.00245929043740034f,
                                post_scale_fc/0.00241900375112891f,
                                post_scale_fc/0.00279543595388531f,
                                post_scale_fc/0.00270285760052502f,
                                post_scale_fc/0.00168569420929998f,
                                post_scale_fc/0.00151216506492346f,
                                post_scale_fc/0.00219536223448812f,
                                post_scale_fc/0.00200520176440477f,
                                post_scale_fc/0.00178698345553129f,
                                post_scale_fc/0.00326062832027673f,
                                post_scale_fc/0.00242430088110268f,
                                post_scale_fc/0.00291381543502211f,
                                post_scale_fc/0.00225287186913192f,
                                post_scale_fc/0.00287016900256276f,
                                post_scale_fc/0.00232223095372319f,
                                post_scale_fc/0.0022382098250091f,
                                post_scale_fc/0.00246563018299639f,
                                post_scale_fc/0.00245226360857486f,
                                post_scale_fc/0.00313904695212841f,
                                post_scale_fc/0.00248649273999035f,
                                post_scale_fc/0.00217115832492709f,
                                post_scale_fc/0.00252142688259482f,
                                post_scale_fc/0.00312265125103294f,
                                post_scale_fc/0.00224291929043829f,
                                post_scale_fc/0.00195017899386584f,
                                post_scale_fc/0.00176159490365535f,
                                post_scale_fc/0.00222711148671805f,
                                post_scale_fc/0.00250628544017672f,
                                post_scale_fc/0.00251064309850335f,
                                post_scale_fc/0.00189737894106656f,
                                post_scale_fc/0.00156293658073991f,
                                post_scale_fc/0.00271065277047455f,
                                post_scale_fc/0.00177337031345814f,
                                post_scale_fc/0.00177155272103846f,
                                post_scale_fc/0.0019618400838226f,
                                post_scale_fc/0.0020773340947926f,
                                post_scale_fc/0.00222243182361125f,
                                post_scale_fc/0.00189561047591269f,
                                post_scale_fc/0.00262672360986471f,
                                post_scale_fc/0.00207616342231631f,
                                post_scale_fc/0.00186561339069157f,
                                post_scale_fc/0.00184982572682201f,
                                post_scale_fc/0.00269384356215596f,
                                post_scale_fc/0.00280993711203336f,
                                post_scale_fc/0.00247844075784087f,
                                post_scale_fc/0.0024635512381792f,
                                post_scale_fc/0.00222483836114406f,
                                post_scale_fc/0.00258312909863889f,
                                post_scale_fc/0.00246577127836644f,
                                post_scale_fc/0.00222072377800941f,
                                post_scale_fc/0.00164023239631205f,
                                post_scale_fc/0.00186130951624363f,
                                post_scale_fc/0.00213983166031539f,
                                post_scale_fc/0.00209297589026391f,
                                post_scale_fc/0.00257288943976163f,
                                post_scale_fc/0.00222503044642508f,
                                post_scale_fc/0.00337271019816398f,
                                post_scale_fc/0.00300134485587477f,
                                post_scale_fc/0.00238478020764887f,
                                post_scale_fc/0.00265213404782116f,
                                post_scale_fc/0.00347232981584966f,
                                post_scale_fc/0.00235541886650025f,
                                post_scale_fc/0.00225467793643474f,
                                post_scale_fc/0.0027637593448162f,
                                post_scale_fc/0.00238223164342343f,
                                post_scale_fc/0.00157080520875751f,
                                post_scale_fc/0.00327736581675708f,
                                post_scale_fc/0.00232435879297554f,
                                post_scale_fc/0.0022538264747709f,
                                post_scale_fc/0.00176513579208403f,
                                post_scale_fc/0.00208830437622964f,
                                post_scale_fc/0.00358790764585137f,
                                post_scale_fc/0.00240409513935446f,
                                post_scale_fc/0.00168346124701201f,
                                post_scale_fc/0.00162452540826052f,
                                post_scale_fc/0.00224283430725336f,
                                post_scale_fc/0.00242280843667686f,
                                post_scale_fc/0.002370415488258f,
                                post_scale_fc/0.00245956308208405f,
                                post_scale_fc/0.00234555639326572f,
                                post_scale_fc/0.00283148512244224f,
                                post_scale_fc/0.00174820038955658f,
                                post_scale_fc/0.00249198195524513f,
                                post_scale_fc/0.00210990943014621f,
                                post_scale_fc/0.0019511777209118f,
                                post_scale_fc/0.00188935827463865f,
                                post_scale_fc/0.00192921736743301f,
                                post_scale_fc/0.00244033988565206f,
                                post_scale_fc/0.00222765794023871f,
                                post_scale_fc/0.00204103579744696f,
                                post_scale_fc/0.00275558186694979f,
                                post_scale_fc/0.00204080156981945f,
                                post_scale_fc/0.00231120688840746f,
                                post_scale_fc/0.00246676709502935f,
                                post_scale_fc/0.00211023981682956f,
                                post_scale_fc/0.00234567653387784f,
                                post_scale_fc/0.00192438776139169f,
                                post_scale_fc/0.00236339983530342f,
                                post_scale_fc/0.00236061634495854f,
                                post_scale_fc/0.00221207714639604f,
                                post_scale_fc/0.00232370081357657f,
                                post_scale_fc/0.00274417200125753f,
                                post_scale_fc/0.00257563823834061f,
                                post_scale_fc/0.00196836469694972f,
                                post_scale_fc/0.00294900848530232f,
                                post_scale_fc/0.00322553888f};
    
    
    
    
    
    

    const float in_scale_fc = 0.18475806713104248;

    std::vector<float> fc_scales(1000);
    std::vector<float> fc_bias_scales(1000);


    for(int i=0;i<1000;i++)
    {
        fc_scales[i] = in_scale_fc*(1/fc_weight_scales[i]);
        
    }
    for(int j=0;j<1000;j++)
    {
        fc_bias_scales[j] = 1/fc_scales[j];
    }
    
  
    
    auto matmul_d = dnnl::inner_product_forward::desc(dnnl::prop_kind::forward_inference,fc_src_md, fc_weights_md, fc_bias_md, fc_dst_md);

    dnnl::primitive_attr fc_dst_attr;
    fc_dst_attr.set_output_scales(2, fc_scales);
    fc_dst_attr.set_scratchpad_mode(dnnl::scratchpad_mode::user);
   


    fc_bias_memory = dnnl::memory({fc_bias_tz_, dt::f32, tag::a}, eng_dnn_);
    dnnl::primitive_attr fc_bias_attr;
    fc_bias_attr.set_output_scales(fc_bias_mask,fc_bias_scales);
    auto fc_bias_reorder_pd = dnnl::reorder::primitive_desc(eng_dnn_, fc_user_bias_memory.get_desc(),
                                                         eng_dnn_, fc_bias_memory.get_desc(), fc_bias_attr);
    auto fc_bias_reorder = dnnl::reorder(fc_bias_reorder_pd);
    fc_bias_reorder.execute(dnn_strm_, fc_user_bias_memory, fc_bias_memory);

   
    auto fc_prim_desc = dnnl::inner_product_forward::primitive_desc(matmul_d, fc_dst_attr,eng_dnn_);
    post_scratchpad_md_prim_ = fc_prim_desc.scratchpad_desc();
    fc_weights_memory = dnnl::memory(fc_prim_desc.weights_desc(), eng_dnn_);

    dnnl::primitive_attr fc_weight_attr;
    fc_weight_attr.set_output_scales(fc_weight_mask,fc_weight_scales);
    auto fc_weight_reorder_pd = dnnl::reorder::primitive_desc(eng_dnn_, fc_user_weights_memory.get_desc(),
                                                           eng_dnn_, fc_weights_memory.get_desc(), fc_weight_attr);
    auto fc_weight_reorder = dnnl::reorder(fc_weight_reorder_pd);
    fc_weight_reorder.execute(dnn_strm_, fc_user_weights_memory, fc_weights_memory);

    fc_forward_prim_ = dnnl::inner_product_forward(fc_prim_desc);
    memcpy(fc_weights_ptr_end_, fc_weights_memory.get_data_handle(), fc_weights_memory.get_desc().get_size());
    memcpy(fc_bias_ptr_end_, fc_bias_memory.get_data_handle(), 1000*sizeof(float));

    init_onednn = true;
}


static void __init_const_globals(int8_t* __restrict__ backbone_output, int64_t* __restrict__ input_pointers, float* __restrict__ res2a_weight_b, float* __restrict__ res2a_bias_b, float* __restrict__ res2a_weight_0, float* __restrict__ res2a_bias_0, float* __restrict__ res2a_weight_1, float* __restrict__ res2a_bias_1, float* __restrict__ res2a_weight_2, float* __restrict__ res2a_bias_2, float* __restrict__ res2b_weight_0, float* __restrict__ res2b_bias_0, float* __restrict__ res2b_weight_1, float* __restrict__ res2b_bias_1, float* __restrict__ res2b_weight_2, float* __restrict__ res2b_bias_2, float* __restrict__ res2c_weight_0, float* __restrict__ res2c_bias_0, float* __restrict__ res2c_weight_1, float* __restrict__ res2c_bias_1, float* __restrict__ res2c_weight_2, float* __restrict__ res2c_bias_2, float* __restrict__ res3a_weight_b, float* __restrict__ res3a_bias_b, float* __restrict__ res3a_weight_0, float* __restrict__ res3a_bias_0, float* __restrict__ res3a_weight_1, float* __restrict__ res3a_bias_1, float* __restrict__ res3a_weight_2, float* __restrict__ res3a_bias_2, float* __restrict__ res3b_weight_0, float* __restrict__ res3b_bias_0, float* __restrict__ res3b_weight_1, float* __restrict__ res3b_bias_1, float* __restrict__ res3b_weight_2, float* __restrict__ res3b_bias_2, float* __restrict__ res3c_weight_0, float* __restrict__ res3c_bias_0, float* __restrict__ res3c_weight_1, float* __restrict__ res3c_bias_1, float* __restrict__ res3c_weight_2, float* __restrict__ res3c_bias_2, float* __restrict__ res3d_weight_0, float* __restrict__ res3d_bias_0, float* __restrict__ res3d_weight_1, float* __restrict__ res3d_bias_1, float* __restrict__ res3d_weight_2, float* __restrict__ res3d_bias_2, float* __restrict__ res4a_weight_b, float* __restrict__ res4a_bias_b, float* __restrict__ res4a_weight_0, float* __restrict__ res4a_bias_0, float* __restrict__ res4a_weight_1, float* __restrict__ res4a_bias_1, float* __restrict__ res4a_weight_2, float* __restrict__ res4a_bias_2, float* __restrict__ res4b_weight_0, float* __restrict__ res4b_bias_0, float* __restrict__ res4b_weight_1, float* __restrict__ res4b_bias_1, float* __restrict__ res4b_weight_2, float* __restrict__ res4b_bias_2, float* __restrict__ res4c_weight_0, float* __restrict__ res4c_bias_0, float* __restrict__ res4c_weight_1, float* __restrict__ res4c_bias_1, float* __restrict__ res4c_weight_2, float* __restrict__ res4c_bias_2, float* __restrict__ res4d_weight_0, float* __restrict__ res4d_bias_0, float* __restrict__ res4d_weight_1, float* __restrict__ res4d_bias_1, float* __restrict__ res4d_weight_2, float* __restrict__ res4d_bias_2, float* __restrict__ res4e_weight_0, float* __restrict__ res4e_bias_0, float* __restrict__ res4e_weight_1, float* __restrict__ res4e_bias_1, float* __restrict__ res4e_weight_2, float* __restrict__ res4e_bias_2, float* __restrict__ res4f_weight_0, float* __restrict__ res4f_bias_0, float* __restrict__ res4f_weight_1, float* __restrict__ res4f_bias_1, float* __restrict__ res4f_weight_2, float* __restrict__ res4f_bias_2, float* __restrict__ res5a_weight_b, float* __restrict__ res5a_bias_b, float* __restrict__ res5a_weight_0, float* __restrict__ res5a_bias_0, float* __restrict__ res5a_weight_1, float* __restrict__ res5a_bias_1, float* __restrict__ res5a_weight_2, float* __restrict__ res5a_bias_2, float* __restrict__ res5b_weight_0, float* __restrict__ res5b_bias_0, float* __restrict__ res5b_weight_1, float* __restrict__ res5b_bias_1, float* __restrict__ res5b_weight_2, float* __restrict__ res5b_bias_2, float* __restrict__ res5c_weight_0, float* __restrict__ res5c_bias_0, float* __restrict__ res5c_weight_1, float* __restrict__ res5c_bias_1, float* __restrict__ res5c_weight_2, float* __restrict__ res5c_bias_2) noexcept __attribute__((nonnull (1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106)));
static bool batchwise_4_fused_res2a_conv_b_cast_mul_add_cast_res2a_conv_0_cast_mul_add_cast_relu_res2a_conv_1_cast_mul_add_cast_relu_res2a_conv_2_cast_mul_add_cast_add_relu_res2b_conv_0_cast_mul_add_cast_relu_res2b_conv_1_cast_mul_add_cast_relu_res2b_conv_2_cast_mul_add_cast_add_relu_res2c_conv_0_cast_mul_add_cast_relu_res2c_conv_1_cast_mul_add_cast_relu_res2c_conv_2_cast_mul_add_cast_add_relu_res3a_conv_b_cast_mul_add_cast_res3a_conv_0_cast_mul_add_cast_relu_res3a_conv_1_cast_mul_add_cast_relu_res3a_conv_2_cast_mul_add_cast_add_relu_res3b_conv_0_cast_mul_add_cast_relu_res3b_conv_1_cast_mul_add_cast_relu_res3b_conv_2_cast_mul_add_cast_add_relu_res3c_conv_0_cast_mul_add_cast_relu_res3c_conv_1_cast_mul_add_cast_relu_res3c_conv_2_cast_mul_add_cast_add_relu_res3d_conv_0_cast_mul_add_cast_relu_res3d_conv_1_cast_mul_add_cast_relu_res3d_conv_2_cast_mul_add_cast_add_relu__684(int8_t* __restrict__ __outs_0, int64_t* __restrict__ input_pointers, int8_t* __restrict__ __ins_1, float* __restrict__ __ins_2, float* __restrict__ __ins_3, int8_t* __restrict__ __ins_4, float* __restrict__ __ins_5, float* __restrict__ __ins_6, int8_t* __restrict__ __ins_7, float* __restrict__ __ins_8, float* __restrict__ __ins_9, int8_t* __restrict__ __ins_10, float* __restrict__ __ins_11, float* __restrict__ __ins_12, int8_t* __restrict__ __ins_13, float* __restrict__ __ins_14, float* __restrict__ __ins_15, int8_t* __restrict__ __ins_16, float* __restrict__ __ins_17, float* __restrict__ __ins_18, int8_t* __restrict__ __ins_19, float* __restrict__ __ins_20, float* __restrict__ __ins_21, int8_t* __restrict__ __ins_22, float* __restrict__ __ins_23, float* __restrict__ __ins_24, int8_t* __restrict__ __ins_25, float* __restrict__ __ins_26, float* __restrict__ __ins_27, int8_t* __restrict__ __ins_28, float* __restrict__ __ins_29, float* __restrict__ __ins_30, int8_t* __restrict__ __ins_31, float* __restrict__ __ins_32, float* __restrict__ __ins_33, int8_t* __restrict__ __ins_34, float* __restrict__ __ins_35, float* __restrict__ __ins_36, int8_t* __restrict__ __ins_37, float* __restrict__ __ins_38, float* __restrict__ __ins_39, int8_t* __restrict__ __ins_40, float* __restrict__ __ins_41, float* __restrict__ __ins_42, int8_t* __restrict__ __ins_43, float* __restrict__ __ins_44, float* __restrict__ __ins_45, int8_t* __restrict__ __ins_46, float* __restrict__ __ins_47, float* __restrict__ __ins_48, int8_t* __restrict__ __ins_49, float* __restrict__ __ins_50, float* __restrict__ __ins_51, int8_t* __restrict__ __ins_52, float* __restrict__ __ins_53, float* __restrict__ __ins_54, int8_t* __restrict__ __ins_55, float* __restrict__ __ins_56, float* __restrict__ __ins_57, int8_t* __restrict__ __ins_58, float* __restrict__ __ins_59, float* __restrict__ __ins_60, int8_t* __restrict__ __ins_61, float* __restrict__ __ins_62, float* __restrict__ __ins_63, int8_t* __restrict__ __ins_64, float* __restrict__ __ins_65, float* __restrict__ __ins_66, int8_t* __restrict__ __ins_67, float* __restrict__ __ins_68, float* __restrict__ __ins_69) noexcept __attribute__((nonnull (1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71)));
static bool batchwise_2_fused_res4a_conv_b_cast_mul_add_cast_res4a_conv_0_cast_mul_add_cast_relu_res4a_conv_1_cast_mul_add_cast_relu_res4a_conv_2_cast_mul_add_cast_add_relu_res4b_conv_0_cast_mul_add_cast_relu_res4b_conv_1_cast_mul_add_cast_relu_res4b_conv_2_cast_mul_add_cast_add_relu_res4c_conv_0_cast_mul_add_cast_relu_res4c_conv_1_cast_mul_add_cast_relu_res4c_conv_2_cast_mul_add_cast_add_relu_res4d_conv_0_cast_mul_add_cast_relu_res4d_conv_1_cast_mul_add_cast_relu_res4d_conv_2_cast_mul_add_cast_add_relu_res4e_conv_0_cast_mul_add_cast_relu_res4e_conv_1_cast_mul_add_cast_relu_res4e_conv_2_cast_mul_add_cast_add_relu_res4f_conv_0_cast_mul_add_cast_relu_res4f_conv_1_cast_mul_add_cast_relu_res4f_conv_2_cast_mul_add_cast_add_relu__685(int8_t* __restrict__ __outs_0, int8_t* __restrict__ __ins_0, int8_t* __restrict__ __ins_1, float* __restrict__ __ins_2, float* __restrict__ __ins_3, int8_t* __restrict__ __ins_4, float* __restrict__ __ins_5, float* __restrict__ __ins_6, int8_t* __restrict__ __ins_7, float* __restrict__ __ins_8, float* __restrict__ __ins_9, int8_t* __restrict__ __ins_10, float* __restrict__ __ins_11, float* __restrict__ __ins_12, int8_t* __restrict__ __ins_13, float* __restrict__ __ins_14, float* __restrict__ __ins_15, int8_t* __restrict__ __ins_16, float* __restrict__ __ins_17, float* __restrict__ __ins_18, int8_t* __restrict__ __ins_19, float* __restrict__ __ins_20, float* __restrict__ __ins_21, int8_t* __restrict__ __ins_22, float* __restrict__ __ins_23, float* __restrict__ __ins_24, int8_t* __restrict__ __ins_25, float* __restrict__ __ins_26, float* __restrict__ __ins_27, int8_t* __restrict__ __ins_28, float* __restrict__ __ins_29, float* __restrict__ __ins_30, int8_t* __restrict__ __ins_31, float* __restrict__ __ins_32, float* __restrict__ __ins_33, int8_t* __restrict__ __ins_34, float* __restrict__ __ins_35, float* __restrict__ __ins_36, int8_t* __restrict__ __ins_37, float* __restrict__ __ins_38, float* __restrict__ __ins_39, int8_t* __restrict__ __ins_40, float* __restrict__ __ins_41, float* __restrict__ __ins_42, int8_t* __restrict__ __ins_43, float* __restrict__ __ins_44, float* __restrict__ __ins_45, int8_t* __restrict__ __ins_46, float* __restrict__ __ins_47, float* __restrict__ __ins_48, int8_t* __restrict__ __ins_49, float* __restrict__ __ins_50, float* __restrict__ __ins_51, int8_t* __restrict__ __ins_52, float* __restrict__ __ins_53, float* __restrict__ __ins_54, int8_t* __restrict__ __ins_55, float* __restrict__ __ins_56, float* __restrict__ __ins_57) noexcept __attribute__((nonnull (1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59)));
static bool res5a_conv_b_cast_mul_add_cast__683(int8_t* __restrict__ __outs_0, int8_t* __restrict__ __ins_0, int8_t* __restrict__ __ins_1, float* __restrict__ __ins_2, float* __restrict__ __ins_3) noexcept __attribute__((nonnull (1,2,3,4,5)));
static bool res5a_conv_0_cast_mul_add_cast_relu_reorder__682(int8_t* __restrict__ __outs_0, int8_t* __restrict__ __ins_0, int8_t* __restrict__ __ins_1, float* __restrict__ __ins_2, float* __restrict__ __ins_3) noexcept __attribute__((nonnull (1,2,3,4,5)));
static bool res5a_conv_1_cast_mul_add_cast_relu_reorder__681(int8_t* __restrict__ __outs_0, int8_t* __restrict__ __ins_0, int8_t* __restrict__ __ins_1, float* __restrict__ __ins_2, float* __restrict__ __ins_3) noexcept __attribute__((nonnull (1,2,3,4,5)));
static bool res5a_conv_2_cast_mul_add_cast_add_relu__680(int8_t* __restrict__ __outs_0, int8_t* __restrict__ __ins_0, int8_t* __restrict__ __ins_1, float* __restrict__ __ins_2, float* __restrict__ __ins_3, int8_t* __restrict__ __ins_4) noexcept __attribute__((nonnull (1,2,3,4,5,6)));
static bool res5b_conv_0_cast_mul_add_cast_relu__679(int8_t* __restrict__ __outs_0, int8_t* __restrict__ __ins_0, int8_t* __restrict__ __ins_1, float* __restrict__ __ins_2, float* __restrict__ __ins_3) noexcept __attribute__((nonnull (1,2,3,4,5)));
static bool res5b_conv_1_cast_mul_add_cast_relu_reorder__678(int8_t* __restrict__ __outs_0, int8_t* __restrict__ __ins_0, int8_t* __restrict__ __ins_1, float* __restrict__ __ins_2, float* __restrict__ __ins_3) noexcept __attribute__((nonnull (1,2,3,4,5)));
static bool res5b_conv_2_cast_mul_add_cast_add_relu__677(int8_t* __restrict__ __outs_0, int8_t* __restrict__ __ins_0, int8_t* __restrict__ __ins_1, float* __restrict__ __ins_2, float* __restrict__ __ins_3, int8_t* __restrict__ __ins_4) noexcept __attribute__((nonnull (1,2,3,4,5,6)));
static bool res5c_conv_0_cast_mul_add_cast_relu_reorder__676(int8_t* __restrict__ __outs_0, int8_t* __restrict__ __ins_0, int8_t* __restrict__ __ins_1, float* __restrict__ __ins_2, float* __restrict__ __ins_3) noexcept __attribute__((nonnull (1,2,3,4,5)));
static bool res5c_conv_1_cast_mul_add_cast_relu__675(int8_t* __restrict__ __outs_0, int8_t* __restrict__ __ins_0, int8_t* __restrict__ __ins_1, float* __restrict__ __ins_2, float* __restrict__ __ins_3) noexcept __attribute__((nonnull (1,2,3,4,5)));
static bool res5c_conv_2_cast_mul_add_cast_add_relu_reorder__674(int8_t* __restrict__ __outs_0, int8_t* __restrict__ __ins_0, int8_t* __restrict__ __ins_1, float* __restrict__ __ins_2, float* __restrict__ __ins_3, int8_t* __restrict__ __ins_4) noexcept __attribute__((nonnull (1,2,3,4,5,6)));
static void reorder__4190_closure_0_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept __attribute__((nonnull (2,4)));
static void mul__5700_closure_1_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept __attribute__((nonnull (2,4)));
static void reorder__4240_closure_2_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept __attribute__((nonnull (2,4)));
static void mul__5760_closure_3_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept __attribute__((nonnull (2,4)));
static void reorder__4290_closure_4_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept __attribute__((nonnull (2,4)));
static void mul__5820_closure_5_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept __attribute__((nonnull (2,4)));
static void reorder__4340_closure_6_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept __attribute__((nonnull (2,4)));
static void mul__5880_closure_7_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept __attribute__((nonnull (2,4)));
static void reorder__4370_closure_8_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept __attribute__((nonnull (2,4)));
static void mul__5900_closure_9_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept __attribute__((nonnull (2,4)));
static void reorder__4400_closure_10_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept __attribute__((nonnull (2,4)));
static void mul__5920_closure_11_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept __attribute__((nonnull (2,4)));
static void reorder__4430_closure_12_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept __attribute__((nonnull (2,4)));
static void mul__5940_closure_13_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept __attribute__((nonnull (2,4)));
static void reorder__4460_closure_14_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept __attribute__((nonnull (2,4)));
static void mul__5960_closure_15_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept __attribute__((nonnull (2,4)));
static void reorder__4490_closure_16_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept __attribute__((nonnull (2,4)));
static void mul__5980_closure_17_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept __attribute__((nonnull (2,4)));
static void reorder__4520_closure_18_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept __attribute__((nonnull (2,4)));
static void mul__6000_closure_19_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept __attribute__((nonnull (2,4)));
static void reorder__4550_closure_20_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept __attribute__((nonnull (2,4)));
static void mul__6020_closure_21_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept __attribute__((nonnull (2,4)));
static void reorder__4580_closure_22_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept __attribute__((nonnull (2,4)));
static void mul__6040_closure_23_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept __attribute__((nonnull (2,4)));
static void reorder__4610_closure_24_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept __attribute__((nonnull (2,4)));
static void mul__6060_closure_25_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept __attribute__((nonnull (2,4)));
static void reorder__4640_closure_26_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept __attribute__((nonnull (2,4)));
static void mul__6080_closure_27_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept __attribute__((nonnull (2,4)));
static void reorder__4670_closure_28_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept __attribute__((nonnull (2,4)));
static void mul__6100_closure_29_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept __attribute__((nonnull (2,4)));
static void reorder__4700_closure_30_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept __attribute__((nonnull (2,4)));
static void mul__6120_closure_31_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept __attribute__((nonnull (2,4)));
static void reorder__4730_closure_32_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept __attribute__((nonnull (2,4)));
static void mul__6140_closure_33_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept __attribute__((nonnull (2,4)));
static void reorder__4760_closure_34_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept __attribute__((nonnull (2,4)));
static void mul__6160_closure_35_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept __attribute__((nonnull (2,4)));
static void reorder__4790_closure_36_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept __attribute__((nonnull (2,4)));
static void mul__6180_closure_37_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept __attribute__((nonnull (2,4)));
static void reorder__4820_closure_38_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept __attribute__((nonnull (2,4)));
static void mul__6200_closure_39_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept __attribute__((nonnull (2,4)));
static void reorder__4850_closure_40_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept __attribute__((nonnull (2,4)));
static void mul__6220_closure_41_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept __attribute__((nonnull (2,4)));
static void reorder__4880_closure_42_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept __attribute__((nonnull (2,4)));
static void mul__6240_closure_43_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept __attribute__((nonnull (2,4)));
static void reorder__4910_closure_44_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept __attribute__((nonnull (2,4)));
static void mul__6260_closure_45_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept __attribute__((nonnull (2,4)));
static void reorder__4940_closure_46_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept __attribute__((nonnull (2,4)));
static void mul__6280_closure_47_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept __attribute__((nonnull (2,4)));
static void reorder__4970_closure_48_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept __attribute__((nonnull (2,4)));
static void mul__6300_closure_49_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept __attribute__((nonnull (2,4)));
static void reorder__5000_closure_50_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept __attribute__((nonnull (2,4)));
static void mul__6320_closure_51_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept __attribute__((nonnull (2,4)));
static void reorder__5030_closure_52_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept __attribute__((nonnull (2,4)));
static void mul__6340_closure_53_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept __attribute__((nonnull (2,4)));
static void reorder__5060_closure_54_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept __attribute__((nonnull (2,4)));
static void mul__6360_closure_55_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept __attribute__((nonnull (2,4)));
static void reorder__5090_closure_56_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept __attribute__((nonnull (2,4)));
static void mul__6380_closure_57_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept __attribute__((nonnull (2,4)));
static void reorder__5120_closure_58_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept __attribute__((nonnull (2,4)));
static void mul__6400_closure_59_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept __attribute__((nonnull (2,4)));
static void reorder__5150_closure_60_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept __attribute__((nonnull (2,4)));
static void mul__6420_closure_61_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept __attribute__((nonnull (2,4)));
static void reorder__5180_closure_62_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept __attribute__((nonnull (2,4)));
static void mul__6440_closure_63_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept __attribute__((nonnull (2,4)));
static void reorder__5210_closure_64_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept __attribute__((nonnull (2,4)));
static void mul__6460_closure_65_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept __attribute__((nonnull (2,4)));
static void reorder__5240_closure_66_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept __attribute__((nonnull (2,4)));
static void mul__6480_closure_67_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept __attribute__((nonnull (2,4)));
static void reorder__5270_closure_68_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept __attribute__((nonnull (2,4)));
static void mul__6500_closure_69_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept __attribute__((nonnull (2,4)));
static void reorder__5300_closure_70_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept __attribute__((nonnull (2,4)));
static void mul__6520_closure_71_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept __attribute__((nonnull (2,4)));
static void reorder__5330_closure_72_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept __attribute__((nonnull (2,4)));
static void mul__6540_closure_73_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept __attribute__((nonnull (2,4)));
static void reorder__5370_closure_74_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept __attribute__((nonnull (2,4)));
static void mul__6580_closure_75_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept __attribute__((nonnull (2,4)));
static void reorder__5400_closure_76_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept __attribute__((nonnull (2,4)));
static void mul__6600_closure_77_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept __attribute__((nonnull (2,4)));
static void reorder__5430_closure_78_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept __attribute__((nonnull (2,4)));
static void mul__6620_closure_79_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept __attribute__((nonnull (2,4)));
static void reorder__5460_closure_80_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept __attribute__((nonnull (2,4)));
static void mul__6640_closure_81_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept __attribute__((nonnull (2,4)));
static void reorder__5490_closure_82_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept __attribute__((nonnull (2,4)));
static void mul__6660_closure_83_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept __attribute__((nonnull (2,4)));
static void reorder__5520_closure_84_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept __attribute__((nonnull (2,4)));
static void mul__6680_closure_85_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept __attribute__((nonnull (2,4)));
static void reorder__5550_closure_86_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept __attribute__((nonnull (2,4)));
static void mul__6700_closure_87_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept __attribute__((nonnull (2,4)));
static void reorder__5580_closure_88_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept __attribute__((nonnull (2,4)));
static void mul__6720_closure_89_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept __attribute__((nonnull (2,4)));
static void reorder__4410_closure_90_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept __attribute__((nonnull (2,4)));
static void mul__5930_closure_91_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept __attribute__((nonnull (2,4)));
static void reorder__4440_closure_92_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept __attribute__((nonnull (2,4)));
static void mul__5950_closure_93_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept __attribute__((nonnull (2,4)));
static void reorder__4500_closure_94_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept __attribute__((nonnull (2,4)));
static void mul__5990_closure_95_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept __attribute__((nonnull (2,4)));
static void reorder__4530_closure_96_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept __attribute__((nonnull (2,4)));
static void mul__6010_closure_97_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept __attribute__((nonnull (2,4)));
static void reorder__4590_closure_98_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept __attribute__((nonnull (2,4)));
static void mul__6050_closure_99_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept __attribute__((nonnull (2,4)));
static void reorder__4620_closure_100_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept __attribute__((nonnull (2,4)));
static void mul__6070_closure_101_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept __attribute__((nonnull (2,4)));
static void reorder__4680_closure_102_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept __attribute__((nonnull (2,4)));
static void mul__6110_closure_103_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept __attribute__((nonnull (2,4)));
static void reorder__4710_closure_104_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept __attribute__((nonnull (2,4)));
static void mul__6130_closure_105_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept __attribute__((nonnull (2,4)));
static void reorder__4200_closure_106_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept __attribute__((nonnull (2,4)));
static void mul__5710_closure_107_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept __attribute__((nonnull (2,4)));
static void reorder__4250_closure_108_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept __attribute__((nonnull (2,4)));
static void mul__5770_closure_109_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept __attribute__((nonnull (2,4)));
static void reorder__4300_closure_110_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept __attribute__((nonnull (2,4)));
static void mul__5830_closure_111_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept __attribute__((nonnull (2,4)));
static void reorder__4350_closure_112_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept __attribute__((nonnull (2,4)));
static void mul__5890_closure_113_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept __attribute__((nonnull (2,4)));
static void reorder__4800_closure_114_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept __attribute__((nonnull (2,4)));
static void mul__6190_closure_115_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept __attribute__((nonnull (2,4)));
static void reorder__4830_closure_116_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept __attribute__((nonnull (2,4)));
static void mul__6210_closure_117_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept __attribute__((nonnull (2,4)));
static void reorder__4890_closure_118_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept __attribute__((nonnull (2,4)));
static void mul__6250_closure_119_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept __attribute__((nonnull (2,4)));
static void reorder__4920_closure_120_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept __attribute__((nonnull (2,4)));
static void mul__6270_closure_121_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept __attribute__((nonnull (2,4)));
static void reorder__4980_closure_122_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept __attribute__((nonnull (2,4)));
static void mul__6310_closure_123_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept __attribute__((nonnull (2,4)));
static void reorder__5010_closure_124_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept __attribute__((nonnull (2,4)));
static void mul__6330_closure_125_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept __attribute__((nonnull (2,4)));
static void reorder__5070_closure_126_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept __attribute__((nonnull (2,4)));
static void mul__6370_closure_127_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept __attribute__((nonnull (2,4)));
static void reorder__5100_closure_128_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept __attribute__((nonnull (2,4)));
static void mul__6390_closure_129_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept __attribute__((nonnull (2,4)));
static void reorder__5160_closure_130_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept __attribute__((nonnull (2,4)));
static void mul__6430_closure_131_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept __attribute__((nonnull (2,4)));
static void reorder__5190_closure_132_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept __attribute__((nonnull (2,4)));
static void mul__6450_closure_133_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept __attribute__((nonnull (2,4)));
static void reorder__5250_closure_134_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept __attribute__((nonnull (2,4)));
static void mul__6490_closure_135_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept __attribute__((nonnull (2,4)));
static void reorder__5280_closure_136_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept __attribute__((nonnull (2,4)));
static void mul__6510_closure_137_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept __attribute__((nonnull (2,4)));
static void reorder__4380_closure_138_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept __attribute__((nonnull (2,4)));
static void mul__5910_closure_139_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept __attribute__((nonnull (2,4)));
static void reorder__4470_closure_140_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept __attribute__((nonnull (2,4)));
static void mul__5970_closure_141_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept __attribute__((nonnull (2,4)));
static void reorder__4560_closure_142_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept __attribute__((nonnull (2,4)));
static void mul__6030_closure_143_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept __attribute__((nonnull (2,4)));
static void reorder__4650_closure_144_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept __attribute__((nonnull (2,4)));
static void mul__6090_closure_145_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept __attribute__((nonnull (2,4)));
static void reorder__4740_closure_146_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept __attribute__((nonnull (2,4)));
static void mul__6150_closure_147_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept __attribute__((nonnull (2,4)));
static void reorder__5380_closure_148_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept __attribute__((nonnull (2,4)));
static void mul__6590_closure_149_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept __attribute__((nonnull (2,4)));
static void reorder__5440_closure_150_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept __attribute__((nonnull (2,4)));
static void mul__6630_closure_151_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept __attribute__((nonnull (2,4)));
static void reorder__5470_closure_152_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept __attribute__((nonnull (2,4)));
static void mul__6650_closure_153_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept __attribute__((nonnull (2,4)));
static void reorder__5530_closure_154_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept __attribute__((nonnull (2,4)));
static void mul__6690_closure_155_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept __attribute__((nonnull (2,4)));
static void reorder__5560_closure_156_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept __attribute__((nonnull (2,4)));
static void mul__6710_closure_157_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept __attribute__((nonnull (2,4)));
static void reorder__4770_closure_158_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept __attribute__((nonnull (2,4)));
static void mul__6170_closure_159_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept __attribute__((nonnull (2,4)));
static void reorder__4860_closure_160_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept __attribute__((nonnull (2,4)));
static void mul__6230_closure_161_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept __attribute__((nonnull (2,4)));
static void reorder__4950_closure_162_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept __attribute__((nonnull (2,4)));
static void mul__6290_closure_163_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept __attribute__((nonnull (2,4)));
static void reorder__5040_closure_164_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept __attribute__((nonnull (2,4)));
static void mul__6350_closure_165_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept __attribute__((nonnull (2,4)));
static void reorder__5130_closure_166_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept __attribute__((nonnull (2,4)));
static void mul__6410_closure_167_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept __attribute__((nonnull (2,4)));
static void reorder__5220_closure_168_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept __attribute__((nonnull (2,4)));
static void mul__6470_closure_169_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept __attribute__((nonnull (2,4)));
static void reorder__5310_closure_170_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept __attribute__((nonnull (2,4)));
static void mul__6530_closure_171_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept __attribute__((nonnull (2,4)));
static void reorder__5340_closure_172_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept __attribute__((nonnull (2,4)));
static void mul__6550_closure_173_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept __attribute__((nonnull (2,4)));
static void reorder__5410_closure_174_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept __attribute__((nonnull (2,4)));
static void mul__6610_closure_175_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept __attribute__((nonnull (2,4)));
static void reorder__5500_closure_176_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept __attribute__((nonnull (2,4)));
static void mul__6670_closure_177_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept __attribute__((nonnull (2,4)));
static void reorder__5590_closure_178_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept __attribute__((nonnull (2,4)));
static void mul__6730_closure_179_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept __attribute__((nonnull (2,4)));
static void mul__1100_closure_180_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept __attribute__((nonnull (2,4)));
static void cast__1110_closure_181_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept __attribute__((nonnull (2,4)));
static void reorder__4210_closure_182_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept __attribute__((nonnull (2,4)));
static void mul__1070_closure_183_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept __attribute__((nonnull (2,4)));
static void cast__1080_closure_184_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept __attribute__((nonnull (2,4)));
static void reorder__4180_closure_185_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept __attribute__((nonnull (2,4)));
static void mul__1160_closure_186_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept __attribute__((nonnull (2,4)));
static void cast__1170_closure_187_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept __attribute__((nonnull (2,4)));
static void reorder__4230_closure_188_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept __attribute__((nonnull (2,4)));
static void mul__1250_closure_189_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept __attribute__((nonnull (2,4)));
static void cast__1260_closure_190_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept __attribute__((nonnull (2,4)));
static void reorder__4280_closure_191_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept __attribute__((nonnull (2,4)));
static void mul__1340_closure_192_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept __attribute__((nonnull (2,4)));
static void cast__1350_closure_193_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept __attribute__((nonnull (2,4)));
static void reorder__4330_closure_194_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept __attribute__((nonnull (2,4)));
static void mul__1190_closure_195_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept __attribute__((nonnull (2,4)));
static void cast__1200_closure_196_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept __attribute__((nonnull (2,4)));
static void reorder__4260_closure_197_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept __attribute__((nonnull (2,4)));
static void mul__1280_closure_198_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept __attribute__((nonnull (2,4)));
static void cast__1290_closure_199_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept __attribute__((nonnull (2,4)));
static void reorder__4310_closure_200_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept __attribute__((nonnull (2,4)));
static void mul__1400_closure_201_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept __attribute__((nonnull (2,4)));
static void cast__1410_closure_202_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept __attribute__((nonnull (2,4)));
static void reorder__4390_closure_203_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept __attribute__((nonnull (2,4)));
static void mul__1130_closure_204_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept __attribute__((nonnull (2,4)));
static void cast__1140_closure_205_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept __attribute__((nonnull (2,4)));
static void reorder__4220_closure_206_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept __attribute__((nonnull (2,4)));
static void mul__1220_closure_207_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept __attribute__((nonnull (2,4)));
static void cast__1230_closure_208_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept __attribute__((nonnull (2,4)));
static void reorder__4270_closure_209_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept __attribute__((nonnull (2,4)));
static void mul__1310_closure_210_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept __attribute__((nonnull (2,4)));
static void cast__1320_closure_211_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept __attribute__((nonnull (2,4)));
static void reorder__4320_closure_212_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept __attribute__((nonnull (2,4)));
static void mul__1460_closure_213_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept __attribute__((nonnull (2,4)));
static void cast__1470_closure_214_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept __attribute__((nonnull (2,4)));
static void reorder__4450_closure_215_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept __attribute__((nonnull (2,4)));
static void mul__1550_closure_216_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept __attribute__((nonnull (2,4)));
static void cast__1560_closure_217_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept __attribute__((nonnull (2,4)));
static void reorder__4540_closure_218_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept __attribute__((nonnull (2,4)));
static void mul__1640_closure_219_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept __attribute__((nonnull (2,4)));
static void cast__1650_closure_220_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept __attribute__((nonnull (2,4)));
static void reorder__4630_closure_221_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept __attribute__((nonnull (2,4)));
static void mul__1730_closure_222_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept __attribute__((nonnull (2,4)));
static void cast__1740_closure_223_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept __attribute__((nonnull (2,4)));
static void reorder__4720_closure_224_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept __attribute__((nonnull (2,4)));
static void mul__1490_closure_225_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept __attribute__((nonnull (2,4)));
static void cast__1500_closure_226_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept __attribute__((nonnull (2,4)));
static void reorder__4480_closure_227_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept __attribute__((nonnull (2,4)));
static void mul__1580_closure_228_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept __attribute__((nonnull (2,4)));
static void cast__1590_closure_229_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept __attribute__((nonnull (2,4)));
static void reorder__4570_closure_230_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept __attribute__((nonnull (2,4)));
static void mul__1670_closure_231_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept __attribute__((nonnull (2,4)));
static void cast__1680_closure_232_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept __attribute__((nonnull (2,4)));
static void reorder__4660_closure_233_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept __attribute__((nonnull (2,4)));
static void mul__1370_closure_234_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept __attribute__((nonnull (2,4)));
static void cast__1380_closure_235_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept __attribute__((nonnull (2,4)));
static void reorder__4360_closure_236_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept __attribute__((nonnull (2,4)));
static void mul__1790_closure_237_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept __attribute__((nonnull (2,4)));
static void cast__1800_closure_238_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept __attribute__((nonnull (2,4)));
static void reorder__4780_closure_239_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept __attribute__((nonnull (2,4)));
static void mul__1430_closure_240_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept __attribute__((nonnull (2,4)));
static void cast__1440_closure_241_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept __attribute__((nonnull (2,4)));
static void reorder__4420_closure_242_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept __attribute__((nonnull (2,4)));
static void mul__1520_closure_243_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept __attribute__((nonnull (2,4)));
static void cast__1530_closure_244_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept __attribute__((nonnull (2,4)));
static void reorder__4510_closure_245_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept __attribute__((nonnull (2,4)));
static void mul__1610_closure_246_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept __attribute__((nonnull (2,4)));
static void cast__1620_closure_247_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept __attribute__((nonnull (2,4)));
static void reorder__4600_closure_248_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept __attribute__((nonnull (2,4)));
static void mul__1700_closure_249_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept __attribute__((nonnull (2,4)));
static void cast__1710_closure_250_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept __attribute__((nonnull (2,4)));
static void reorder__4690_closure_251_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept __attribute__((nonnull (2,4)));
static void mul__1850_closure_252_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept __attribute__((nonnull (2,4)));
static void cast__1860_closure_253_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept __attribute__((nonnull (2,4)));
static void reorder__4840_closure_254_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept __attribute__((nonnull (2,4)));
static void mul__1940_closure_255_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept __attribute__((nonnull (2,4)));
static void cast__1950_closure_256_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept __attribute__((nonnull (2,4)));
static void reorder__4930_closure_257_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept __attribute__((nonnull (2,4)));
static void mul__2030_closure_258_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept __attribute__((nonnull (2,4)));
static void cast__2040_closure_259_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept __attribute__((nonnull (2,4)));
static void reorder__5020_closure_260_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept __attribute__((nonnull (2,4)));
static void mul__2120_closure_261_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept __attribute__((nonnull (2,4)));
static void cast__2130_closure_262_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept __attribute__((nonnull (2,4)));
static void reorder__5110_closure_263_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept __attribute__((nonnull (2,4)));
static void mul__2210_closure_264_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept __attribute__((nonnull (2,4)));
static void cast__2220_closure_265_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept __attribute__((nonnull (2,4)));
static void reorder__5200_closure_266_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept __attribute__((nonnull (2,4)));
static void mul__2300_closure_267_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept __attribute__((nonnull (2,4)));
static void cast__2310_closure_268_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept __attribute__((nonnull (2,4)));
static void reorder__5290_closure_269_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept __attribute__((nonnull (2,4)));
static void mul__1880_closure_270_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept __attribute__((nonnull (2,4)));
static void cast__1890_closure_271_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept __attribute__((nonnull (2,4)));
static void reorder__4870_closure_272_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept __attribute__((nonnull (2,4)));
static void mul__1970_closure_273_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept __attribute__((nonnull (2,4)));
static void cast__1980_closure_274_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept __attribute__((nonnull (2,4)));
static void reorder__4960_closure_275_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept __attribute__((nonnull (2,4)));
static void mul__2060_closure_276_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept __attribute__((nonnull (2,4)));
static void cast__2070_closure_277_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept __attribute__((nonnull (2,4)));
static void reorder__5050_closure_278_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept __attribute__((nonnull (2,4)));
static void mul__2150_closure_279_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept __attribute__((nonnull (2,4)));
static void cast__2160_closure_280_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept __attribute__((nonnull (2,4)));
static void reorder__5140_closure_281_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept __attribute__((nonnull (2,4)));
static void mul__2240_closure_282_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept __attribute__((nonnull (2,4)));
static void cast__2250_closure_283_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept __attribute__((nonnull (2,4)));
static void reorder__5230_closure_284_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept __attribute__((nonnull (2,4)));
static void mul__1760_closure_285_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept __attribute__((nonnull (2,4)));
static void cast__1770_closure_286_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept __attribute__((nonnull (2,4)));
static void reorder__4750_closure_287_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept __attribute__((nonnull (2,4)));
static void mul__2360_closure_288_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept __attribute__((nonnull (2,4)));
static void cast__2370_closure_289_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept __attribute__((nonnull (2,4)));
static void reorder__5350_closure_290_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept __attribute__((nonnull (2,4)));
static void mul__1820_closure_291_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept __attribute__((nonnull (2,4)));
static void cast__1830_closure_292_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept __attribute__((nonnull (2,4)));
static void reorder__4810_closure_293_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept __attribute__((nonnull (2,4)));
static void mul__1910_closure_294_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept __attribute__((nonnull (2,4)));
static void cast__1920_closure_295_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept __attribute__((nonnull (2,4)));
static void reorder__4900_closure_296_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept __attribute__((nonnull (2,4)));
static void mul__2000_closure_297_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept __attribute__((nonnull (2,4)));
static void cast__2010_closure_298_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept __attribute__((nonnull (2,4)));
static void reorder__4990_closure_299_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept __attribute__((nonnull (2,4)));
static void mul__2090_closure_300_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept __attribute__((nonnull (2,4)));
static void cast__2100_closure_301_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept __attribute__((nonnull (2,4)));
static void reorder__5080_closure_302_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept __attribute__((nonnull (2,4)));
static void mul__2180_closure_303_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept __attribute__((nonnull (2,4)));
static void cast__2190_closure_304_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept __attribute__((nonnull (2,4)));
static void reorder__5170_closure_305_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept __attribute__((nonnull (2,4)));
static void mul__2270_closure_306_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept __attribute__((nonnull (2,4)));
static void cast__2280_closure_307_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept __attribute__((nonnull (2,4)));
static void reorder__5260_closure_308_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept __attribute__((nonnull (2,4)));
static void mul__2420_closure_309_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept __attribute__((nonnull (2,4)));
static void cast__2430_closure_310_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept __attribute__((nonnull (2,4)));
static void reorder__5390_closure_311_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept __attribute__((nonnull (2,4)));
static void mul__2510_closure_312_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept __attribute__((nonnull (2,4)));
static void cast__2520_closure_313_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept __attribute__((nonnull (2,4)));
static void reorder__5480_closure_314_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept __attribute__((nonnull (2,4)));
static void mul__2600_closure_315_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept __attribute__((nonnull (2,4)));
static void cast__2610_closure_316_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept __attribute__((nonnull (2,4)));
static void reorder__5570_closure_317_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept __attribute__((nonnull (2,4)));
static void mul__2450_closure_318_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept __attribute__((nonnull (2,4)));
static void cast__2460_closure_319_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept __attribute__((nonnull (2,4)));
static void reorder__5420_closure_320_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept __attribute__((nonnull (2,4)));
static void mul__2540_closure_321_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept __attribute__((nonnull (2,4)));
static void cast__2550_closure_322_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept __attribute__((nonnull (2,4)));
static void reorder__5510_closure_323_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept __attribute__((nonnull (2,4)));
static void mul__2330_closure_324_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept __attribute__((nonnull (2,4)));
static void cast__2340_closure_325_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept __attribute__((nonnull (2,4)));
static void reorder__5320_closure_326_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept __attribute__((nonnull (2,4)));
static void mul__2390_closure_327_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept __attribute__((nonnull (2,4)));
static void cast__2400_closure_328_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept __attribute__((nonnull (2,4)));
static void reorder__5360_closure_329_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept __attribute__((nonnull (2,4)));
static void mul__2480_closure_330_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept __attribute__((nonnull (2,4)));
static void cast__2490_closure_331_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept __attribute__((nonnull (2,4)));
static void reorder__5450_closure_332_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept __attribute__((nonnull (2,4)));
static void mul__2570_closure_333_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept __attribute__((nonnull (2,4)));
static void cast__2580_closure_334_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept __attribute__((nonnull (2,4)));
static void reorder__5540_closure_335_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept __attribute__((nonnull (2,4)));
static void batchwise_4_fused_res2a_conv_b_cast_mul_add_cast_res2a_conv_0_cast_mul_add_cast_relu_res2a_conv_1_cast_mul_add_cast_relu_res2a_conv_2_cast_mul_add_cast_add_relu_res2b_conv_0_cast_mul_add_cast_relu_res2b_conv_1_cast_mul_add_cast_relu_res2b_conv_2_cast_mul_add_cast_add_relu_res2c_conv_0_cast_mul_add_cast_relu_res2c_conv_1_cast_mul_add_cast_relu_res2c_conv_2_cast_mul_add_cast_add_relu_res3a_conv_b_cast_mul_add_cast_res3a_conv_0_cast_mul_add_cast_relu_res3a_conv_1_cast_mul_add_cast_relu_res3a_conv_2_cast_mul_add_cast_add_relu_res3b_conv_0_cast_mul_add_cast_relu_res3b_conv_1_cast_mul_add_cast_relu_res3b_conv_2_cast_mul_add_cast_add_relu_res3c_conv_0_cast_mul_add_cast_relu_res3c_conv_1_cast_mul_add_cast_relu_res3c_conv_2_cast_mul_add_cast_add_relu_res3d_conv_0_cast_mul_add_cast_relu_res3d_conv_1_cast_mul_add_cast_relu_res3d_conv_2_cast_mul_add_cast_add_relu__6840_closure_336_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept __attribute__((nonnull (2,4)));
static bool res2a_conv_b_cast_mul_add_cast__4(int8_t* __restrict__ __outs_0, int8_t* __restrict__ __ins_0, int8_t* __restrict__ __ins_1, float* __restrict__ __ins_2, float* __restrict__ __ins_3) noexcept __attribute__((nonnull (1,2,3,4,5)));
static bool res2a_conv_0_cast_mul_add_cast_relu__8(int8_t* __restrict__ __outs_0, int8_t* __restrict__ __ins_0, int8_t* __restrict__ __ins_1, float* __restrict__ __ins_2, float* __restrict__ __ins_3) noexcept __attribute__((nonnull (1,2,3,4,5)));
static bool res2a_conv_1_cast_mul_add_cast_relu__12(int8_t* __restrict__ __outs_0, int8_t* __restrict__ __ins_0, int8_t* __restrict__ __ins_1, float* __restrict__ __ins_2, float* __restrict__ __ins_3) noexcept __attribute__((nonnull (1,2,3,4,5)));
static bool res2a_conv_2_cast_mul_add_cast_add_relu__16(int8_t* __restrict__ __outs_0, int8_t* __restrict__ __ins_0, int8_t* __restrict__ __ins_1, float* __restrict__ __ins_2, float* __restrict__ __ins_3, int8_t* __restrict__ __ins_4) noexcept __attribute__((nonnull (1,2,3,4,5,6)));
static bool res2b_conv_0_cast_mul_add_cast_relu__20(int8_t* __restrict__ __outs_0, int8_t* __restrict__ __ins_0, int8_t* __restrict__ __ins_1, float* __restrict__ __ins_2, float* __restrict__ __ins_3) noexcept __attribute__((nonnull (1,2,3,4,5)));
static bool res2b_conv_1_cast_mul_add_cast_relu__24(int8_t* __restrict__ __outs_0, int8_t* __restrict__ __ins_0, int8_t* __restrict__ __ins_1, float* __restrict__ __ins_2, float* __restrict__ __ins_3) noexcept __attribute__((nonnull (1,2,3,4,5)));
static bool res2b_conv_2_cast_mul_add_cast_add_relu__28(int8_t* __restrict__ __outs_0, int8_t* __restrict__ __ins_0, int8_t* __restrict__ __ins_1, float* __restrict__ __ins_2, float* __restrict__ __ins_3, int8_t* __restrict__ __ins_4) noexcept __attribute__((nonnull (1,2,3,4,5,6)));
static bool res2c_conv_0_cast_mul_add_cast_relu__32(int8_t* __restrict__ __outs_0, int8_t* __restrict__ __ins_0, int8_t* __restrict__ __ins_1, float* __restrict__ __ins_2, float* __restrict__ __ins_3) noexcept __attribute__((nonnull (1,2,3,4,5)));
static bool res2c_conv_1_cast_mul_add_cast_relu__36(int8_t* __restrict__ __outs_0, int8_t* __restrict__ __ins_0, int8_t* __restrict__ __ins_1, float* __restrict__ __ins_2, float* __restrict__ __ins_3) noexcept __attribute__((nonnull (1,2,3,4,5)));
static bool res2c_conv_2_cast_mul_add_cast_add_relu__40(int8_t* __restrict__ __outs_0, int8_t* __restrict__ __ins_0, int8_t* __restrict__ __ins_1, float* __restrict__ __ins_2, float* __restrict__ __ins_3, int8_t* __restrict__ __ins_4) noexcept __attribute__((nonnull (1,2,3,4,5,6)));
static bool res3a_conv_b_cast_mul_add_cast__44(int8_t* __restrict__ __outs_0, int8_t* __restrict__ __ins_0, int8_t* __restrict__ __ins_1, float* __restrict__ __ins_2, float* __restrict__ __ins_3) noexcept __attribute__((nonnull (1,2,3,4,5)));
static bool res3a_conv_0_cast_mul_add_cast_relu__48(int8_t* __restrict__ __outs_0, int8_t* __restrict__ __ins_0, int8_t* __restrict__ __ins_1, float* __restrict__ __ins_2, float* __restrict__ __ins_3) noexcept __attribute__((nonnull (1,2,3,4,5)));
static bool res3a_conv_1_cast_mul_add_cast_relu__52(int8_t* __restrict__ __outs_0, int8_t* __restrict__ __ins_0, int8_t* __restrict__ __ins_1, float* __restrict__ __ins_2, float* __restrict__ __ins_3) noexcept __attribute__((nonnull (1,2,3,4,5)));
static bool res3a_conv_2_cast_mul_add_cast_add_relu__56(int8_t* __restrict__ __outs_0, int8_t* __restrict__ __ins_0, int8_t* __restrict__ __ins_1, float* __restrict__ __ins_2, float* __restrict__ __ins_3, int8_t* __restrict__ __ins_4) noexcept __attribute__((nonnull (1,2,3,4,5,6)));
static bool res3b_conv_0_cast_mul_add_cast_relu__60(int8_t* __restrict__ __outs_0, int8_t* __restrict__ __ins_0, int8_t* __restrict__ __ins_1, float* __restrict__ __ins_2, float* __restrict__ __ins_3) noexcept __attribute__((nonnull (1,2,3,4,5)));
static bool res3b_conv_1_cast_mul_add_cast_relu__64(int8_t* __restrict__ __outs_0, int8_t* __restrict__ __ins_0, int8_t* __restrict__ __ins_1, float* __restrict__ __ins_2, float* __restrict__ __ins_3) noexcept __attribute__((nonnull (1,2,3,4,5)));
static bool res3b_conv_2_cast_mul_add_cast_add_relu__68(int8_t* __restrict__ __outs_0, int8_t* __restrict__ __ins_0, int8_t* __restrict__ __ins_1, float* __restrict__ __ins_2, float* __restrict__ __ins_3, int8_t* __restrict__ __ins_4) noexcept __attribute__((nonnull (1,2,3,4,5,6)));
static bool res3c_conv_0_cast_mul_add_cast_relu__72(int8_t* __restrict__ __outs_0, int8_t* __restrict__ __ins_0, int8_t* __restrict__ __ins_1, float* __restrict__ __ins_2, float* __restrict__ __ins_3) noexcept __attribute__((nonnull (1,2,3,4,5)));
static bool res3c_conv_1_cast_mul_add_cast_relu__76(int8_t* __restrict__ __outs_0, int8_t* __restrict__ __ins_0, int8_t* __restrict__ __ins_1, float* __restrict__ __ins_2, float* __restrict__ __ins_3) noexcept __attribute__((nonnull (1,2,3,4,5)));
static bool res3c_conv_2_cast_mul_add_cast_add_relu__80(int8_t* __restrict__ __outs_0, int8_t* __restrict__ __ins_0, int8_t* __restrict__ __ins_1, float* __restrict__ __ins_2, float* __restrict__ __ins_3, int8_t* __restrict__ __ins_4) noexcept __attribute__((nonnull (1,2,3,4,5,6)));
static bool res3d_conv_0_cast_mul_add_cast_relu__84(int8_t* __restrict__ __outs_0, int8_t* __restrict__ __ins_0, int8_t* __restrict__ __ins_1, float* __restrict__ __ins_2, float* __restrict__ __ins_3) noexcept __attribute__((nonnull (1,2,3,4,5)));
static bool res3d_conv_1_cast_mul_add_cast_relu__88(int8_t* __restrict__ __outs_0, int8_t* __restrict__ __ins_0, int8_t* __restrict__ __ins_1, float* __restrict__ __ins_2, float* __restrict__ __ins_3) noexcept __attribute__((nonnull (1,2,3,4,5)));
static bool res3d_conv_2_cast_mul_add_cast_add_relu__93(int8_t* __restrict__ __outs_0, int8_t* __restrict__ __ins_0, int8_t* __restrict__ __ins_1, float* __restrict__ __ins_2, float* __restrict__ __ins_3, int8_t* __restrict__ __ins_4) noexcept __attribute__((nonnull (1,2,3,4,5,6)));
extern "C" void* memset(void* ptr, int32_t v, uint64_t len) noexcept;
static void batchwise_2_fused_res4a_conv_b_cast_mul_add_cast_res4a_conv_0_cast_mul_add_cast_relu_res4a_conv_1_cast_mul_add_cast_relu_res4a_conv_2_cast_mul_add_cast_add_relu_res4b_conv_0_cast_mul_add_cast_relu_res4b_conv_1_cast_mul_add_cast_relu_res4b_conv_2_cast_mul_add_cast_add_relu_res4c_conv_0_cast_mul_add_cast_relu_res4c_conv_1_cast_mul_add_cast_relu_res4c_conv_2_cast_mul_add_cast_add_relu_res4d_conv_0_cast_mul_add_cast_relu_res4d_conv_1_cast_mul_add_cast_relu_res4d_conv_2_cast_mul_add_cast_add_relu_res4e_conv_0_cast_mul_add_cast_relu_res4e_conv_1_cast_mul_add_cast_relu_res4e_conv_2_cast_mul_add_cast_add_relu_res4f_conv_0_cast_mul_add_cast_relu_res4f_conv_1_cast_mul_add_cast_relu_res4f_conv_2_cast_mul_add_cast_add_relu__6850_closure_337_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept __attribute__((nonnull (2,4)));
static bool res4a_conv_b_cast_mul_add_cast__4(int8_t* __restrict__ __outs_0, int8_t* __restrict__ __ins_0, int8_t* __restrict__ __ins_1, float* __restrict__ __ins_2, float* __restrict__ __ins_3) noexcept __attribute__((nonnull (1,2,3,4,5)));
static bool res4a_conv_0_cast_mul_add_cast_relu__8(int8_t* __restrict__ __outs_0, int8_t* __restrict__ __ins_0, int8_t* __restrict__ __ins_1, float* __restrict__ __ins_2, float* __restrict__ __ins_3) noexcept __attribute__((nonnull (1,2,3,4,5)));
static bool res4a_conv_1_cast_mul_add_cast_relu__12(int8_t* __restrict__ __outs_0, int8_t* __restrict__ __ins_0, int8_t* __restrict__ __ins_1, float* __restrict__ __ins_2, float* __restrict__ __ins_3) noexcept __attribute__((nonnull (1,2,3,4,5)));
static bool res4a_conv_2_cast_mul_add_cast_add_relu__16(int8_t* __restrict__ __outs_0, int8_t* __restrict__ __ins_0, int8_t* __restrict__ __ins_1, float* __restrict__ __ins_2, float* __restrict__ __ins_3, int8_t* __restrict__ __ins_4) noexcept __attribute__((nonnull (1,2,3,4,5,6)));
static bool res4b_conv_0_cast_mul_add_cast_relu__20(int8_t* __restrict__ __outs_0, int8_t* __restrict__ __ins_0, int8_t* __restrict__ __ins_1, float* __restrict__ __ins_2, float* __restrict__ __ins_3) noexcept __attribute__((nonnull (1,2,3,4,5)));
static bool res4b_conv_1_cast_mul_add_cast_relu__24(int8_t* __restrict__ __outs_0, int8_t* __restrict__ __ins_0, int8_t* __restrict__ __ins_1, float* __restrict__ __ins_2, float* __restrict__ __ins_3) noexcept __attribute__((nonnull (1,2,3,4,5)));
static bool res4b_conv_2_cast_mul_add_cast_add_relu__28(int8_t* __restrict__ __outs_0, int8_t* __restrict__ __ins_0, int8_t* __restrict__ __ins_1, float* __restrict__ __ins_2, float* __restrict__ __ins_3, int8_t* __restrict__ __ins_4) noexcept __attribute__((nonnull (1,2,3,4,5,6)));
static bool res4c_conv_0_cast_mul_add_cast_relu__32(int8_t* __restrict__ __outs_0, int8_t* __restrict__ __ins_0, int8_t* __restrict__ __ins_1, float* __restrict__ __ins_2, float* __restrict__ __ins_3) noexcept __attribute__((nonnull (1,2,3,4,5)));
static bool res4c_conv_1_cast_mul_add_cast_relu__36(int8_t* __restrict__ __outs_0, int8_t* __restrict__ __ins_0, int8_t* __restrict__ __ins_1, float* __restrict__ __ins_2, float* __restrict__ __ins_3) noexcept __attribute__((nonnull (1,2,3,4,5)));
static bool res4c_conv_2_cast_mul_add_cast_add_relu__40(int8_t* __restrict__ __outs_0, int8_t* __restrict__ __ins_0, int8_t* __restrict__ __ins_1, float* __restrict__ __ins_2, float* __restrict__ __ins_3, int8_t* __restrict__ __ins_4) noexcept __attribute__((nonnull (1,2,3,4,5,6)));
static bool res4d_conv_0_cast_mul_add_cast_relu__44(int8_t* __restrict__ __outs_0, int8_t* __restrict__ __ins_0, int8_t* __restrict__ __ins_1, float* __restrict__ __ins_2, float* __restrict__ __ins_3) noexcept __attribute__((nonnull (1,2,3,4,5)));
static bool res4d_conv_1_cast_mul_add_cast_relu__48(int8_t* __restrict__ __outs_0, int8_t* __restrict__ __ins_0, int8_t* __restrict__ __ins_1, float* __restrict__ __ins_2, float* __restrict__ __ins_3) noexcept __attribute__((nonnull (1,2,3,4,5)));
static bool res4d_conv_2_cast_mul_add_cast_add_relu__52(int8_t* __restrict__ __outs_0, int8_t* __restrict__ __ins_0, int8_t* __restrict__ __ins_1, float* __restrict__ __ins_2, float* __restrict__ __ins_3, int8_t* __restrict__ __ins_4) noexcept __attribute__((nonnull (1,2,3,4,5,6)));
static bool res4e_conv_0_cast_mul_add_cast_relu__56(int8_t* __restrict__ __outs_0, int8_t* __restrict__ __ins_0, int8_t* __restrict__ __ins_1, float* __restrict__ __ins_2, float* __restrict__ __ins_3) noexcept __attribute__((nonnull (1,2,3,4,5)));
static bool res4e_conv_1_cast_mul_add_cast_relu__60(int8_t* __restrict__ __outs_0, int8_t* __restrict__ __ins_0, int8_t* __restrict__ __ins_1, float* __restrict__ __ins_2, float* __restrict__ __ins_3) noexcept __attribute__((nonnull (1,2,3,4,5)));
static bool res4e_conv_2_cast_mul_add_cast_add_relu__64(int8_t* __restrict__ __outs_0, int8_t* __restrict__ __ins_0, int8_t* __restrict__ __ins_1, float* __restrict__ __ins_2, float* __restrict__ __ins_3, int8_t* __restrict__ __ins_4) noexcept __attribute__((nonnull (1,2,3,4,5,6)));
static bool res4f_conv_0_cast_mul_add_cast_relu__68(int8_t* __restrict__ __outs_0, int8_t* __restrict__ __ins_0, int8_t* __restrict__ __ins_1, float* __restrict__ __ins_2, float* __restrict__ __ins_3) noexcept __attribute__((nonnull (1,2,3,4,5)));
static bool res4f_conv_1_cast_mul_add_cast_relu__72(int8_t* __restrict__ __outs_0, int8_t* __restrict__ __ins_0, int8_t* __restrict__ __ins_1, float* __restrict__ __ins_2, float* __restrict__ __ins_3) noexcept __attribute__((nonnull (1,2,3,4,5)));
static bool res4f_conv_2_cast_mul_add_cast_add_relu__77(int8_t* __restrict__ __outs_0, int8_t* __restrict__ __ins_0, int8_t* __restrict__ __ins_1, float* __restrict__ __ins_2, float* __restrict__ __ins_3, int8_t* __restrict__ __ins_4) noexcept __attribute__((nonnull (1,2,3,4,5,6)));
static void res5a_conv_b_cast_mul_add_cast__6830_closure_338_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept __attribute__((nonnull (2,4)));
static void res5a_conv_b_cast_mul_add_cast__6830_closure_339_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept __attribute__((nonnull (2,4)));
static void res5a_conv_0_cast_mul_add_cast_relu_reorder__6820_closure_340_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept __attribute__((nonnull (2,4)));
static void res5a_conv_0_cast_mul_add_cast_relu_reorder__6820_closure_341_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept __attribute__((nonnull (2,4)));
static void res5a_conv_1_cast_mul_add_cast_relu_reorder__6810_closure_342_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept __attribute__((nonnull (2,4)));
static void res5a_conv_2_cast_mul_add_cast_add_relu__6800_closure_343_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept __attribute__((nonnull (2,4)));
static void res5b_conv_0_cast_mul_add_cast_relu__6790_closure_344_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept __attribute__((nonnull (2,4)));
static void res5b_conv_0_cast_mul_add_cast_relu__6790_closure_345_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept __attribute__((nonnull (2,4)));
static void res5b_conv_1_cast_mul_add_cast_relu_reorder__6780_closure_346_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept __attribute__((nonnull (2,4)));
static void res5b_conv_2_cast_mul_add_cast_add_relu__6770_closure_347_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept __attribute__((nonnull (2,4)));
static void res5c_conv_0_cast_mul_add_cast_relu_reorder__6760_closure_348_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept __attribute__((nonnull (2,4)));
static void res5c_conv_0_cast_mul_add_cast_relu_reorder__6760_closure_349_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept __attribute__((nonnull (2,4)));
static void res5c_conv_1_cast_mul_add_cast_relu__6750_closure_350_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept __attribute__((nonnull (2,4)));
static void res5c_conv_2_cast_mul_add_cast_add_relu_reorder__6740_closure_351_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept __attribute__((nonnull (2,4)));
static bool reorder__419(float* __restrict__ __outs_0, float* __restrict__ __ins_0) noexcept __attribute__((nonnull (1,2)));
static bool mul__570(float* __restrict__ __outs_0, float* __restrict__ __ins_0, float* __restrict__ __ins_1) noexcept __attribute__((nonnull (1,2,3)));
static bool mul__572(float* __restrict__ __outs_0, float* __restrict__ __ins_0, float* __restrict__ __ins_1) noexcept __attribute__((nonnull (1,2,3)));
static bool mul__574(float* __restrict__ __outs_0, float* __restrict__ __ins_0, float* __restrict__ __ins_1) noexcept __attribute__((nonnull (1,2,3)));
static bool reorder__424(float* __restrict__ __outs_0, float* __restrict__ __ins_0) noexcept __attribute__((nonnull (1,2)));
static bool mul__576(float* __restrict__ __outs_0, float* __restrict__ __ins_0, float* __restrict__ __ins_1) noexcept __attribute__((nonnull (1,2,3)));
static bool mul__578(float* __restrict__ __outs_0, float* __restrict__ __ins_0, float* __restrict__ __ins_1) noexcept __attribute__((nonnull (1,2,3)));
static bool mul__580(float* __restrict__ __outs_0, float* __restrict__ __ins_0, float* __restrict__ __ins_1) noexcept __attribute__((nonnull (1,2,3)));
static bool reorder__429(float* __restrict__ __outs_0, float* __restrict__ __ins_0) noexcept __attribute__((nonnull (1,2)));
static bool mul__582(float* __restrict__ __outs_0, float* __restrict__ __ins_0, float* __restrict__ __ins_1) noexcept __attribute__((nonnull (1,2,3)));
static bool mul__584(float* __restrict__ __outs_0, float* __restrict__ __ins_0, float* __restrict__ __ins_1) noexcept __attribute__((nonnull (1,2,3)));
static bool mul__586(float* __restrict__ __outs_0, float* __restrict__ __ins_0, float* __restrict__ __ins_1) noexcept __attribute__((nonnull (1,2,3)));
static bool reorder__434(float* __restrict__ __outs_0, float* __restrict__ __ins_0) noexcept __attribute__((nonnull (1,2)));
static bool mul__588(float* __restrict__ __outs_0, float* __restrict__ __ins_0, float* __restrict__ __ins_1) noexcept __attribute__((nonnull (1,2,3)));
static bool reorder__437(float* __restrict__ __outs_0, float* __restrict__ __ins_0) noexcept __attribute__((nonnull (1,2)));
static bool mul__590(float* __restrict__ __outs_0, float* __restrict__ __ins_0, float* __restrict__ __ins_1) noexcept __attribute__((nonnull (1,2,3)));
static bool reorder__440(float* __restrict__ __outs_0, float* __restrict__ __ins_0) noexcept __attribute__((nonnull (1,2)));
static bool mul__592(float* __restrict__ __outs_0, float* __restrict__ __ins_0, float* __restrict__ __ins_1) noexcept __attribute__((nonnull (1,2,3)));
static bool reorder__443(float* __restrict__ __outs_0, float* __restrict__ __ins_0) noexcept __attribute__((nonnull (1,2)));
static bool mul__594(float* __restrict__ __outs_0, float* __restrict__ __ins_0, float* __restrict__ __ins_1) noexcept __attribute__((nonnull (1,2,3)));
static bool reorder__446(float* __restrict__ __outs_0, float* __restrict__ __ins_0) noexcept __attribute__((nonnull (1,2)));
static bool mul__596(float* __restrict__ __outs_0, float* __restrict__ __ins_0, float* __restrict__ __ins_1) noexcept __attribute__((nonnull (1,2,3)));
static bool reorder__449(float* __restrict__ __outs_0, float* __restrict__ __ins_0) noexcept __attribute__((nonnull (1,2)));
static bool mul__598(float* __restrict__ __outs_0, float* __restrict__ __ins_0, float* __restrict__ __ins_1) noexcept __attribute__((nonnull (1,2,3)));
static bool reorder__452(float* __restrict__ __outs_0, float* __restrict__ __ins_0) noexcept __attribute__((nonnull (1,2)));
static bool mul__600(float* __restrict__ __outs_0, float* __restrict__ __ins_0, float* __restrict__ __ins_1) noexcept __attribute__((nonnull (1,2,3)));
static bool reorder__455(float* __restrict__ __outs_0, float* __restrict__ __ins_0) noexcept __attribute__((nonnull (1,2)));
static bool mul__602(float* __restrict__ __outs_0, float* __restrict__ __ins_0, float* __restrict__ __ins_1) noexcept __attribute__((nonnull (1,2,3)));
static bool reorder__458(float* __restrict__ __outs_0, float* __restrict__ __ins_0) noexcept __attribute__((nonnull (1,2)));
static bool mul__604(float* __restrict__ __outs_0, float* __restrict__ __ins_0, float* __restrict__ __ins_1) noexcept __attribute__((nonnull (1,2,3)));
static bool reorder__461(float* __restrict__ __outs_0, float* __restrict__ __ins_0) noexcept __attribute__((nonnull (1,2)));
static bool mul__606(float* __restrict__ __outs_0, float* __restrict__ __ins_0, float* __restrict__ __ins_1) noexcept __attribute__((nonnull (1,2,3)));
static bool reorder__464(float* __restrict__ __outs_0, float* __restrict__ __ins_0) noexcept __attribute__((nonnull (1,2)));
static bool mul__608(float* __restrict__ __outs_0, float* __restrict__ __ins_0, float* __restrict__ __ins_1) noexcept __attribute__((nonnull (1,2,3)));
static bool reorder__467(float* __restrict__ __outs_0, float* __restrict__ __ins_0) noexcept __attribute__((nonnull (1,2)));
static bool mul__610(float* __restrict__ __outs_0, float* __restrict__ __ins_0, float* __restrict__ __ins_1) noexcept __attribute__((nonnull (1,2,3)));
static bool reorder__470(float* __restrict__ __outs_0, float* __restrict__ __ins_0) noexcept __attribute__((nonnull (1,2)));
static bool mul__612(float* __restrict__ __outs_0, float* __restrict__ __ins_0, float* __restrict__ __ins_1) noexcept __attribute__((nonnull (1,2,3)));
static bool reorder__473(float* __restrict__ __outs_0, float* __restrict__ __ins_0) noexcept __attribute__((nonnull (1,2)));
static bool mul__614(float* __restrict__ __outs_0, float* __restrict__ __ins_0, float* __restrict__ __ins_1) noexcept __attribute__((nonnull (1,2,3)));
static bool reorder__476(float* __restrict__ __outs_0, float* __restrict__ __ins_0) noexcept __attribute__((nonnull (1,2)));
static bool mul__616(float* __restrict__ __outs_0, float* __restrict__ __ins_0, float* __restrict__ __ins_1) noexcept __attribute__((nonnull (1,2,3)));
static bool reorder__479(float* __restrict__ __outs_0, float* __restrict__ __ins_0) noexcept __attribute__((nonnull (1,2)));
static bool mul__618(float* __restrict__ __outs_0, float* __restrict__ __ins_0, float* __restrict__ __ins_1) noexcept __attribute__((nonnull (1,2,3)));
static bool reorder__482(float* __restrict__ __outs_0, float* __restrict__ __ins_0) noexcept __attribute__((nonnull (1,2)));
static bool mul__620(float* __restrict__ __outs_0, float* __restrict__ __ins_0, float* __restrict__ __ins_1) noexcept __attribute__((nonnull (1,2,3)));
static bool reorder__485(float* __restrict__ __outs_0, float* __restrict__ __ins_0) noexcept __attribute__((nonnull (1,2)));
static bool mul__622(float* __restrict__ __outs_0, float* __restrict__ __ins_0, float* __restrict__ __ins_1) noexcept __attribute__((nonnull (1,2,3)));
static bool reorder__488(float* __restrict__ __outs_0, float* __restrict__ __ins_0) noexcept __attribute__((nonnull (1,2)));
static bool mul__624(float* __restrict__ __outs_0, float* __restrict__ __ins_0, float* __restrict__ __ins_1) noexcept __attribute__((nonnull (1,2,3)));
static bool reorder__491(float* __restrict__ __outs_0, float* __restrict__ __ins_0) noexcept __attribute__((nonnull (1,2)));
static bool mul__626(float* __restrict__ __outs_0, float* __restrict__ __ins_0, float* __restrict__ __ins_1) noexcept __attribute__((nonnull (1,2,3)));
static bool reorder__494(float* __restrict__ __outs_0, float* __restrict__ __ins_0) noexcept __attribute__((nonnull (1,2)));
static bool mul__628(float* __restrict__ __outs_0, float* __restrict__ __ins_0, float* __restrict__ __ins_1) noexcept __attribute__((nonnull (1,2,3)));
static bool reorder__497(float* __restrict__ __outs_0, float* __restrict__ __ins_0) noexcept __attribute__((nonnull (1,2)));
static bool mul__630(float* __restrict__ __outs_0, float* __restrict__ __ins_0, float* __restrict__ __ins_1) noexcept __attribute__((nonnull (1,2,3)));
static bool reorder__500(float* __restrict__ __outs_0, float* __restrict__ __ins_0) noexcept __attribute__((nonnull (1,2)));
static bool mul__632(float* __restrict__ __outs_0, float* __restrict__ __ins_0, float* __restrict__ __ins_1) noexcept __attribute__((nonnull (1,2,3)));
static bool reorder__503(float* __restrict__ __outs_0, float* __restrict__ __ins_0) noexcept __attribute__((nonnull (1,2)));
static bool mul__634(float* __restrict__ __outs_0, float* __restrict__ __ins_0, float* __restrict__ __ins_1) noexcept __attribute__((nonnull (1,2,3)));
static bool reorder__506(float* __restrict__ __outs_0, float* __restrict__ __ins_0) noexcept __attribute__((nonnull (1,2)));
static bool mul__636(float* __restrict__ __outs_0, float* __restrict__ __ins_0, float* __restrict__ __ins_1) noexcept __attribute__((nonnull (1,2,3)));
static bool reorder__509(float* __restrict__ __outs_0, float* __restrict__ __ins_0) noexcept __attribute__((nonnull (1,2)));
static bool mul__638(float* __restrict__ __outs_0, float* __restrict__ __ins_0, float* __restrict__ __ins_1) noexcept __attribute__((nonnull (1,2,3)));
static bool reorder__512(float* __restrict__ __outs_0, float* __restrict__ __ins_0) noexcept __attribute__((nonnull (1,2)));
static bool mul__640(float* __restrict__ __outs_0, float* __restrict__ __ins_0, float* __restrict__ __ins_1) noexcept __attribute__((nonnull (1,2,3)));
static bool reorder__515(float* __restrict__ __outs_0, float* __restrict__ __ins_0) noexcept __attribute__((nonnull (1,2)));
static bool mul__642(float* __restrict__ __outs_0, float* __restrict__ __ins_0, float* __restrict__ __ins_1) noexcept __attribute__((nonnull (1,2,3)));
static bool reorder__518(float* __restrict__ __outs_0, float* __restrict__ __ins_0) noexcept __attribute__((nonnull (1,2)));
static bool mul__644(float* __restrict__ __outs_0, float* __restrict__ __ins_0, float* __restrict__ __ins_1) noexcept __attribute__((nonnull (1,2,3)));
static bool reorder__521(float* __restrict__ __outs_0, float* __restrict__ __ins_0) noexcept __attribute__((nonnull (1,2)));
static bool mul__646(float* __restrict__ __outs_0, float* __restrict__ __ins_0, float* __restrict__ __ins_1) noexcept __attribute__((nonnull (1,2,3)));
static bool reorder__524(float* __restrict__ __outs_0, float* __restrict__ __ins_0) noexcept __attribute__((nonnull (1,2)));
static bool mul__648(float* __restrict__ __outs_0, float* __restrict__ __ins_0, float* __restrict__ __ins_1) noexcept __attribute__((nonnull (1,2,3)));
static bool reorder__527(float* __restrict__ __outs_0, float* __restrict__ __ins_0) noexcept __attribute__((nonnull (1,2)));
static bool mul__650(float* __restrict__ __outs_0, float* __restrict__ __ins_0, float* __restrict__ __ins_1) noexcept __attribute__((nonnull (1,2,3)));
static bool reorder__530(float* __restrict__ __outs_0, float* __restrict__ __ins_0) noexcept __attribute__((nonnull (1,2)));
static bool mul__652(float* __restrict__ __outs_0, float* __restrict__ __ins_0, float* __restrict__ __ins_1) noexcept __attribute__((nonnull (1,2,3)));
static bool reorder__533(float* __restrict__ __outs_0, float* __restrict__ __ins_0) noexcept __attribute__((nonnull (1,2)));
static bool mul__654(float* __restrict__ __outs_0, float* __restrict__ __ins_0, float* __restrict__ __ins_1) noexcept __attribute__((nonnull (1,2,3)));
static bool mul__656(float* __restrict__ __outs_0, float* __restrict__ __ins_0, float* __restrict__ __ins_1) noexcept __attribute__((nonnull (1,2,3)));
static bool reorder__537(float* __restrict__ __outs_0, float* __restrict__ __ins_0) noexcept __attribute__((nonnull (1,2)));
static bool mul__658(float* __restrict__ __outs_0, float* __restrict__ __ins_0, float* __restrict__ __ins_1) noexcept __attribute__((nonnull (1,2,3)));
static bool reorder__540(float* __restrict__ __outs_0, float* __restrict__ __ins_0) noexcept __attribute__((nonnull (1,2)));
static bool mul__660(float* __restrict__ __outs_0, float* __restrict__ __ins_0, float* __restrict__ __ins_1) noexcept __attribute__((nonnull (1,2,3)));
static bool reorder__543(float* __restrict__ __outs_0, float* __restrict__ __ins_0) noexcept __attribute__((nonnull (1,2)));
static bool mul__662(float* __restrict__ __outs_0, float* __restrict__ __ins_0, float* __restrict__ __ins_1) noexcept __attribute__((nonnull (1,2,3)));
static bool reorder__546(float* __restrict__ __outs_0, float* __restrict__ __ins_0) noexcept __attribute__((nonnull (1,2)));
static bool mul__664(float* __restrict__ __outs_0, float* __restrict__ __ins_0, float* __restrict__ __ins_1) noexcept __attribute__((nonnull (1,2,3)));
static bool reorder__549(float* __restrict__ __outs_0, float* __restrict__ __ins_0) noexcept __attribute__((nonnull (1,2)));
static bool mul__666(float* __restrict__ __outs_0, float* __restrict__ __ins_0, float* __restrict__ __ins_1) noexcept __attribute__((nonnull (1,2,3)));
static bool reorder__552(float* __restrict__ __outs_0, float* __restrict__ __ins_0) noexcept __attribute__((nonnull (1,2)));
static bool mul__668(float* __restrict__ __outs_0, float* __restrict__ __ins_0, float* __restrict__ __ins_1) noexcept __attribute__((nonnull (1,2,3)));
static bool reorder__555(float* __restrict__ __outs_0, float* __restrict__ __ins_0) noexcept __attribute__((nonnull (1,2)));
static bool mul__670(float* __restrict__ __outs_0, float* __restrict__ __ins_0, float* __restrict__ __ins_1) noexcept __attribute__((nonnull (1,2,3)));
static bool reorder__558(float* __restrict__ __outs_0, float* __restrict__ __ins_0) noexcept __attribute__((nonnull (1,2)));
static bool mul__672(float* __restrict__ __outs_0, float* __restrict__ __ins_0, float* __restrict__ __ins_1) noexcept __attribute__((nonnull (1,2,3)));
static bool mul__573(float* __restrict__ __outs_0, float* __restrict__ __ins_0, float* __restrict__ __ins_1) noexcept __attribute__((nonnull (1,2,3)));
static bool mul__575(float* __restrict__ __outs_0, float* __restrict__ __ins_0, float* __restrict__ __ins_1) noexcept __attribute__((nonnull (1,2,3)));
static bool mul__579(float* __restrict__ __outs_0, float* __restrict__ __ins_0, float* __restrict__ __ins_1) noexcept __attribute__((nonnull (1,2,3)));
static bool mul__581(float* __restrict__ __outs_0, float* __restrict__ __ins_0, float* __restrict__ __ins_1) noexcept __attribute__((nonnull (1,2,3)));
static bool mul__585(float* __restrict__ __outs_0, float* __restrict__ __ins_0, float* __restrict__ __ins_1) noexcept __attribute__((nonnull (1,2,3)));
static bool mul__587(float* __restrict__ __outs_0, float* __restrict__ __ins_0, float* __restrict__ __ins_1) noexcept __attribute__((nonnull (1,2,3)));
static bool reorder__441(float* __restrict__ __outs_0, float* __restrict__ __ins_0) noexcept __attribute__((nonnull (1,2)));
static bool mul__593(float* __restrict__ __outs_0, float* __restrict__ __ins_0, float* __restrict__ __ins_1) noexcept __attribute__((nonnull (1,2,3)));
static bool reorder__444(float* __restrict__ __outs_0, float* __restrict__ __ins_0) noexcept __attribute__((nonnull (1,2)));
static bool mul__595(float* __restrict__ __outs_0, float* __restrict__ __ins_0, float* __restrict__ __ins_1) noexcept __attribute__((nonnull (1,2,3)));
static bool reorder__450(float* __restrict__ __outs_0, float* __restrict__ __ins_0) noexcept __attribute__((nonnull (1,2)));
static bool mul__599(float* __restrict__ __outs_0, float* __restrict__ __ins_0, float* __restrict__ __ins_1) noexcept __attribute__((nonnull (1,2,3)));
static bool reorder__453(float* __restrict__ __outs_0, float* __restrict__ __ins_0) noexcept __attribute__((nonnull (1,2)));
static bool mul__601(float* __restrict__ __outs_0, float* __restrict__ __ins_0, float* __restrict__ __ins_1) noexcept __attribute__((nonnull (1,2,3)));
static bool reorder__459(float* __restrict__ __outs_0, float* __restrict__ __ins_0) noexcept __attribute__((nonnull (1,2)));
static bool mul__605(float* __restrict__ __outs_0, float* __restrict__ __ins_0, float* __restrict__ __ins_1) noexcept __attribute__((nonnull (1,2,3)));
static bool reorder__462(float* __restrict__ __outs_0, float* __restrict__ __ins_0) noexcept __attribute__((nonnull (1,2)));
static bool mul__607(float* __restrict__ __outs_0, float* __restrict__ __ins_0, float* __restrict__ __ins_1) noexcept __attribute__((nonnull (1,2,3)));
static bool reorder__468(float* __restrict__ __outs_0, float* __restrict__ __ins_0) noexcept __attribute__((nonnull (1,2)));
static bool mul__611(float* __restrict__ __outs_0, float* __restrict__ __ins_0, float* __restrict__ __ins_1) noexcept __attribute__((nonnull (1,2,3)));
static bool reorder__471(float* __restrict__ __outs_0, float* __restrict__ __ins_0) noexcept __attribute__((nonnull (1,2)));
static bool mul__613(float* __restrict__ __outs_0, float* __restrict__ __ins_0, float* __restrict__ __ins_1) noexcept __attribute__((nonnull (1,2,3)));
static bool reorder__420(float* __restrict__ __outs_0, float* __restrict__ __ins_0) noexcept __attribute__((nonnull (1,2)));
static bool mul__571(float* __restrict__ __outs_0, float* __restrict__ __ins_0, float* __restrict__ __ins_1) noexcept __attribute__((nonnull (1,2,3)));
static bool reorder__425(float* __restrict__ __outs_0, float* __restrict__ __ins_0) noexcept __attribute__((nonnull (1,2)));
static bool mul__577(float* __restrict__ __outs_0, float* __restrict__ __ins_0, float* __restrict__ __ins_1) noexcept __attribute__((nonnull (1,2,3)));
static bool reorder__430(float* __restrict__ __outs_0, float* __restrict__ __ins_0) noexcept __attribute__((nonnull (1,2)));
static bool mul__583(float* __restrict__ __outs_0, float* __restrict__ __ins_0, float* __restrict__ __ins_1) noexcept __attribute__((nonnull (1,2,3)));
static bool reorder__435(float* __restrict__ __outs_0, float* __restrict__ __ins_0) noexcept __attribute__((nonnull (1,2)));
static bool mul__589(float* __restrict__ __outs_0, float* __restrict__ __ins_0, float* __restrict__ __ins_1) noexcept __attribute__((nonnull (1,2,3)));
static bool reorder__480(float* __restrict__ __outs_0, float* __restrict__ __ins_0) noexcept __attribute__((nonnull (1,2)));
static bool mul__619(float* __restrict__ __outs_0, float* __restrict__ __ins_0, float* __restrict__ __ins_1) noexcept __attribute__((nonnull (1,2,3)));
static bool reorder__483(float* __restrict__ __outs_0, float* __restrict__ __ins_0) noexcept __attribute__((nonnull (1,2)));
static bool mul__621(float* __restrict__ __outs_0, float* __restrict__ __ins_0, float* __restrict__ __ins_1) noexcept __attribute__((nonnull (1,2,3)));
static bool reorder__489(float* __restrict__ __outs_0, float* __restrict__ __ins_0) noexcept __attribute__((nonnull (1,2)));
static bool mul__625(float* __restrict__ __outs_0, float* __restrict__ __ins_0, float* __restrict__ __ins_1) noexcept __attribute__((nonnull (1,2,3)));
static bool reorder__492(float* __restrict__ __outs_0, float* __restrict__ __ins_0) noexcept __attribute__((nonnull (1,2)));
static bool mul__627(float* __restrict__ __outs_0, float* __restrict__ __ins_0, float* __restrict__ __ins_1) noexcept __attribute__((nonnull (1,2,3)));
static bool reorder__498(float* __restrict__ __outs_0, float* __restrict__ __ins_0) noexcept __attribute__((nonnull (1,2)));
static bool mul__631(float* __restrict__ __outs_0, float* __restrict__ __ins_0, float* __restrict__ __ins_1) noexcept __attribute__((nonnull (1,2,3)));
static bool reorder__501(float* __restrict__ __outs_0, float* __restrict__ __ins_0) noexcept __attribute__((nonnull (1,2)));
static bool mul__633(float* __restrict__ __outs_0, float* __restrict__ __ins_0, float* __restrict__ __ins_1) noexcept __attribute__((nonnull (1,2,3)));
static bool reorder__507(float* __restrict__ __outs_0, float* __restrict__ __ins_0) noexcept __attribute__((nonnull (1,2)));
static bool mul__637(float* __restrict__ __outs_0, float* __restrict__ __ins_0, float* __restrict__ __ins_1) noexcept __attribute__((nonnull (1,2,3)));
static bool reorder__510(float* __restrict__ __outs_0, float* __restrict__ __ins_0) noexcept __attribute__((nonnull (1,2)));
static bool mul__639(float* __restrict__ __outs_0, float* __restrict__ __ins_0, float* __restrict__ __ins_1) noexcept __attribute__((nonnull (1,2,3)));
static bool reorder__516(float* __restrict__ __outs_0, float* __restrict__ __ins_0) noexcept __attribute__((nonnull (1,2)));
static bool mul__643(float* __restrict__ __outs_0, float* __restrict__ __ins_0, float* __restrict__ __ins_1) noexcept __attribute__((nonnull (1,2,3)));
static bool reorder__519(float* __restrict__ __outs_0, float* __restrict__ __ins_0) noexcept __attribute__((nonnull (1,2)));
static bool mul__645(float* __restrict__ __outs_0, float* __restrict__ __ins_0, float* __restrict__ __ins_1) noexcept __attribute__((nonnull (1,2,3)));
static bool reorder__525(float* __restrict__ __outs_0, float* __restrict__ __ins_0) noexcept __attribute__((nonnull (1,2)));
static bool mul__649(float* __restrict__ __outs_0, float* __restrict__ __ins_0, float* __restrict__ __ins_1) noexcept __attribute__((nonnull (1,2,3)));
static bool reorder__528(float* __restrict__ __outs_0, float* __restrict__ __ins_0) noexcept __attribute__((nonnull (1,2)));
static bool mul__651(float* __restrict__ __outs_0, float* __restrict__ __ins_0, float* __restrict__ __ins_1) noexcept __attribute__((nonnull (1,2,3)));
static bool reorder__438(float* __restrict__ __outs_0, float* __restrict__ __ins_0) noexcept __attribute__((nonnull (1,2)));
static bool mul__591(float* __restrict__ __outs_0, float* __restrict__ __ins_0, float* __restrict__ __ins_1) noexcept __attribute__((nonnull (1,2,3)));
static bool reorder__447(float* __restrict__ __outs_0, float* __restrict__ __ins_0) noexcept __attribute__((nonnull (1,2)));
static bool mul__597(float* __restrict__ __outs_0, float* __restrict__ __ins_0, float* __restrict__ __ins_1) noexcept __attribute__((nonnull (1,2,3)));
static bool reorder__456(float* __restrict__ __outs_0, float* __restrict__ __ins_0) noexcept __attribute__((nonnull (1,2)));
static bool mul__603(float* __restrict__ __outs_0, float* __restrict__ __ins_0, float* __restrict__ __ins_1) noexcept __attribute__((nonnull (1,2,3)));
static bool reorder__465(float* __restrict__ __outs_0, float* __restrict__ __ins_0) noexcept __attribute__((nonnull (1,2)));
static bool mul__609(float* __restrict__ __outs_0, float* __restrict__ __ins_0, float* __restrict__ __ins_1) noexcept __attribute__((nonnull (1,2,3)));
static bool reorder__474(float* __restrict__ __outs_0, float* __restrict__ __ins_0) noexcept __attribute__((nonnull (1,2)));
static bool mul__615(float* __restrict__ __outs_0, float* __restrict__ __ins_0, float* __restrict__ __ins_1) noexcept __attribute__((nonnull (1,2,3)));
static bool mul__657(float* __restrict__ __outs_0, float* __restrict__ __ins_0, float* __restrict__ __ins_1) noexcept __attribute__((nonnull (1,2,3)));
static bool reorder__538(float* __restrict__ __outs_0, float* __restrict__ __ins_0) noexcept __attribute__((nonnull (1,2)));
static bool mul__659(float* __restrict__ __outs_0, float* __restrict__ __ins_0, float* __restrict__ __ins_1) noexcept __attribute__((nonnull (1,2,3)));
static bool reorder__544(float* __restrict__ __outs_0, float* __restrict__ __ins_0) noexcept __attribute__((nonnull (1,2)));
static bool mul__663(float* __restrict__ __outs_0, float* __restrict__ __ins_0, float* __restrict__ __ins_1) noexcept __attribute__((nonnull (1,2,3)));
static bool reorder__547(float* __restrict__ __outs_0, float* __restrict__ __ins_0) noexcept __attribute__((nonnull (1,2)));
static bool mul__665(float* __restrict__ __outs_0, float* __restrict__ __ins_0, float* __restrict__ __ins_1) noexcept __attribute__((nonnull (1,2,3)));
static bool reorder__553(float* __restrict__ __outs_0, float* __restrict__ __ins_0) noexcept __attribute__((nonnull (1,2)));
static bool mul__669(float* __restrict__ __outs_0, float* __restrict__ __ins_0, float* __restrict__ __ins_1) noexcept __attribute__((nonnull (1,2,3)));
static bool reorder__556(float* __restrict__ __outs_0, float* __restrict__ __ins_0) noexcept __attribute__((nonnull (1,2)));
static bool mul__671(float* __restrict__ __outs_0, float* __restrict__ __ins_0, float* __restrict__ __ins_1) noexcept __attribute__((nonnull (1,2,3)));
static bool reorder__477(float* __restrict__ __outs_0, float* __restrict__ __ins_0) noexcept __attribute__((nonnull (1,2)));
static bool mul__617(float* __restrict__ __outs_0, float* __restrict__ __ins_0, float* __restrict__ __ins_1) noexcept __attribute__((nonnull (1,2,3)));
static bool reorder__486(float* __restrict__ __outs_0, float* __restrict__ __ins_0) noexcept __attribute__((nonnull (1,2)));
static bool mul__623(float* __restrict__ __outs_0, float* __restrict__ __ins_0, float* __restrict__ __ins_1) noexcept __attribute__((nonnull (1,2,3)));
static bool reorder__495(float* __restrict__ __outs_0, float* __restrict__ __ins_0) noexcept __attribute__((nonnull (1,2)));
static bool mul__629(float* __restrict__ __outs_0, float* __restrict__ __ins_0, float* __restrict__ __ins_1) noexcept __attribute__((nonnull (1,2,3)));
static bool reorder__504(float* __restrict__ __outs_0, float* __restrict__ __ins_0) noexcept __attribute__((nonnull (1,2)));
static bool mul__635(float* __restrict__ __outs_0, float* __restrict__ __ins_0, float* __restrict__ __ins_1) noexcept __attribute__((nonnull (1,2,3)));
static bool reorder__513(float* __restrict__ __outs_0, float* __restrict__ __ins_0) noexcept __attribute__((nonnull (1,2)));
static bool mul__641(float* __restrict__ __outs_0, float* __restrict__ __ins_0, float* __restrict__ __ins_1) noexcept __attribute__((nonnull (1,2,3)));
static bool reorder__522(float* __restrict__ __outs_0, float* __restrict__ __ins_0) noexcept __attribute__((nonnull (1,2)));
static bool mul__647(float* __restrict__ __outs_0, float* __restrict__ __ins_0, float* __restrict__ __ins_1) noexcept __attribute__((nonnull (1,2,3)));
static bool reorder__531(float* __restrict__ __outs_0, float* __restrict__ __ins_0) noexcept __attribute__((nonnull (1,2)));
static bool mul__653(float* __restrict__ __outs_0, float* __restrict__ __ins_0, float* __restrict__ __ins_1) noexcept __attribute__((nonnull (1,2,3)));
static bool reorder__534(float* __restrict__ __outs_0, float* __restrict__ __ins_0) noexcept __attribute__((nonnull (1,2)));
static bool mul__655(float* __restrict__ __outs_0, float* __restrict__ __ins_0, float* __restrict__ __ins_1) noexcept __attribute__((nonnull (1,2,3)));
static bool reorder__541(float* __restrict__ __outs_0, float* __restrict__ __ins_0) noexcept __attribute__((nonnull (1,2)));
static bool mul__661(float* __restrict__ __outs_0, float* __restrict__ __ins_0, float* __restrict__ __ins_1) noexcept __attribute__((nonnull (1,2,3)));
static bool reorder__550(float* __restrict__ __outs_0, float* __restrict__ __ins_0) noexcept __attribute__((nonnull (1,2)));
static bool mul__667(float* __restrict__ __outs_0, float* __restrict__ __ins_0, float* __restrict__ __ins_1) noexcept __attribute__((nonnull (1,2,3)));
static bool reorder__559(float* __restrict__ __outs_0, float* __restrict__ __ins_0) noexcept __attribute__((nonnull (1,2)));
static bool mul__673(float* __restrict__ __outs_0, float* __restrict__ __ins_0, float* __restrict__ __ins_1) noexcept __attribute__((nonnull (1,2,3)));
static bool mul__110(float* __restrict__ __outs_0, float* __restrict__ __ins_0, float* __restrict__ __ins_1) noexcept __attribute__((nonnull (1,2,3)));
static bool cast__111(int8_t* __restrict__ __outs_0, float* __restrict__ __ins_0) noexcept __attribute__((nonnull (1,2)));
static bool reorder__421(int8_t* __restrict__ __outs_0, int8_t* __restrict__ __ins_0) noexcept __attribute__((nonnull (1,2)));
static bool mul__107(float* __restrict__ __outs_0, float* __restrict__ __ins_0, float* __restrict__ __ins_1) noexcept __attribute__((nonnull (1,2,3)));
static bool cast__108(int8_t* __restrict__ __outs_0, float* __restrict__ __ins_0) noexcept __attribute__((nonnull (1,2)));
static bool reorder__418(int8_t* __restrict__ __outs_0, int8_t* __restrict__ __ins_0) noexcept __attribute__((nonnull (1,2)));
static bool mul__116(float* __restrict__ __outs_0, float* __restrict__ __ins_0, float* __restrict__ __ins_1) noexcept __attribute__((nonnull (1,2,3)));
static bool cast__117(int8_t* __restrict__ __outs_0, float* __restrict__ __ins_0) noexcept __attribute__((nonnull (1,2)));
static bool reorder__423(int8_t* __restrict__ __outs_0, int8_t* __restrict__ __ins_0) noexcept __attribute__((nonnull (1,2)));
static bool mul__125(float* __restrict__ __outs_0, float* __restrict__ __ins_0, float* __restrict__ __ins_1) noexcept __attribute__((nonnull (1,2,3)));
static bool cast__126(int8_t* __restrict__ __outs_0, float* __restrict__ __ins_0) noexcept __attribute__((nonnull (1,2)));
static bool reorder__428(int8_t* __restrict__ __outs_0, int8_t* __restrict__ __ins_0) noexcept __attribute__((nonnull (1,2)));
static bool mul__134(float* __restrict__ __outs_0, float* __restrict__ __ins_0, float* __restrict__ __ins_1) noexcept __attribute__((nonnull (1,2,3)));
static bool cast__135(int8_t* __restrict__ __outs_0, float* __restrict__ __ins_0) noexcept __attribute__((nonnull (1,2)));
static bool reorder__433(int8_t* __restrict__ __outs_0, int8_t* __restrict__ __ins_0) noexcept __attribute__((nonnull (1,2)));
static bool mul__119(float* __restrict__ __outs_0, float* __restrict__ __ins_0, float* __restrict__ __ins_1) noexcept __attribute__((nonnull (1,2,3)));
static bool cast__120(int8_t* __restrict__ __outs_0, float* __restrict__ __ins_0) noexcept __attribute__((nonnull (1,2)));
static bool reorder__426(int8_t* __restrict__ __outs_0, int8_t* __restrict__ __ins_0) noexcept __attribute__((nonnull (1,2)));
static bool mul__128(float* __restrict__ __outs_0, float* __restrict__ __ins_0, float* __restrict__ __ins_1) noexcept __attribute__((nonnull (1,2,3)));
static bool cast__129(int8_t* __restrict__ __outs_0, float* __restrict__ __ins_0) noexcept __attribute__((nonnull (1,2)));
static bool reorder__431(int8_t* __restrict__ __outs_0, int8_t* __restrict__ __ins_0) noexcept __attribute__((nonnull (1,2)));
static bool mul__140(float* __restrict__ __outs_0, float* __restrict__ __ins_0, float* __restrict__ __ins_1) noexcept __attribute__((nonnull (1,2,3)));
static bool cast__141(int8_t* __restrict__ __outs_0, float* __restrict__ __ins_0) noexcept __attribute__((nonnull (1,2)));
static bool reorder__439(int8_t* __restrict__ __outs_0, int8_t* __restrict__ __ins_0) noexcept __attribute__((nonnull (1,2)));
static bool mul__113(float* __restrict__ __outs_0, float* __restrict__ __ins_0, float* __restrict__ __ins_1) noexcept __attribute__((nonnull (1,2,3)));
static bool cast__114(int8_t* __restrict__ __outs_0, float* __restrict__ __ins_0) noexcept __attribute__((nonnull (1,2)));
static bool reorder__422(int8_t* __restrict__ __outs_0, int8_t* __restrict__ __ins_0) noexcept __attribute__((nonnull (1,2)));
static bool mul__122(float* __restrict__ __outs_0, float* __restrict__ __ins_0, float* __restrict__ __ins_1) noexcept __attribute__((nonnull (1,2,3)));
static bool cast__123(int8_t* __restrict__ __outs_0, float* __restrict__ __ins_0) noexcept __attribute__((nonnull (1,2)));
static bool reorder__427(int8_t* __restrict__ __outs_0, int8_t* __restrict__ __ins_0) noexcept __attribute__((nonnull (1,2)));
static bool mul__131(float* __restrict__ __outs_0, float* __restrict__ __ins_0, float* __restrict__ __ins_1) noexcept __attribute__((nonnull (1,2,3)));
static bool cast__132(int8_t* __restrict__ __outs_0, float* __restrict__ __ins_0) noexcept __attribute__((nonnull (1,2)));
static bool reorder__432(int8_t* __restrict__ __outs_0, int8_t* __restrict__ __ins_0) noexcept __attribute__((nonnull (1,2)));
static bool mul__146(float* __restrict__ __outs_0, float* __restrict__ __ins_0, float* __restrict__ __ins_1) noexcept __attribute__((nonnull (1,2,3)));
static bool cast__147(int8_t* __restrict__ __outs_0, float* __restrict__ __ins_0) noexcept __attribute__((nonnull (1,2)));
static bool reorder__445(int8_t* __restrict__ __outs_0, int8_t* __restrict__ __ins_0) noexcept __attribute__((nonnull (1,2)));
static bool mul__155(float* __restrict__ __outs_0, float* __restrict__ __ins_0, float* __restrict__ __ins_1) noexcept __attribute__((nonnull (1,2,3)));
static bool cast__156(int8_t* __restrict__ __outs_0, float* __restrict__ __ins_0) noexcept __attribute__((nonnull (1,2)));
static bool reorder__454(int8_t* __restrict__ __outs_0, int8_t* __restrict__ __ins_0) noexcept __attribute__((nonnull (1,2)));
static bool mul__164(float* __restrict__ __outs_0, float* __restrict__ __ins_0, float* __restrict__ __ins_1) noexcept __attribute__((nonnull (1,2,3)));
static bool cast__165(int8_t* __restrict__ __outs_0, float* __restrict__ __ins_0) noexcept __attribute__((nonnull (1,2)));
static bool reorder__463(int8_t* __restrict__ __outs_0, int8_t* __restrict__ __ins_0) noexcept __attribute__((nonnull (1,2)));
static bool mul__173(float* __restrict__ __outs_0, float* __restrict__ __ins_0, float* __restrict__ __ins_1) noexcept __attribute__((nonnull (1,2,3)));
static bool cast__174(int8_t* __restrict__ __outs_0, float* __restrict__ __ins_0) noexcept __attribute__((nonnull (1,2)));
static bool reorder__472(int8_t* __restrict__ __outs_0, int8_t* __restrict__ __ins_0) noexcept __attribute__((nonnull (1,2)));
static bool mul__149(float* __restrict__ __outs_0, float* __restrict__ __ins_0, float* __restrict__ __ins_1) noexcept __attribute__((nonnull (1,2,3)));
static bool cast__150(int8_t* __restrict__ __outs_0, float* __restrict__ __ins_0) noexcept __attribute__((nonnull (1,2)));
static bool reorder__448(int8_t* __restrict__ __outs_0, int8_t* __restrict__ __ins_0) noexcept __attribute__((nonnull (1,2)));
static bool mul__158(float* __restrict__ __outs_0, float* __restrict__ __ins_0, float* __restrict__ __ins_1) noexcept __attribute__((nonnull (1,2,3)));
static bool cast__159(int8_t* __restrict__ __outs_0, float* __restrict__ __ins_0) noexcept __attribute__((nonnull (1,2)));
static bool reorder__457(int8_t* __restrict__ __outs_0, int8_t* __restrict__ __ins_0) noexcept __attribute__((nonnull (1,2)));
static bool mul__167(float* __restrict__ __outs_0, float* __restrict__ __ins_0, float* __restrict__ __ins_1) noexcept __attribute__((nonnull (1,2,3)));
static bool cast__168(int8_t* __restrict__ __outs_0, float* __restrict__ __ins_0) noexcept __attribute__((nonnull (1,2)));
static bool reorder__466(int8_t* __restrict__ __outs_0, int8_t* __restrict__ __ins_0) noexcept __attribute__((nonnull (1,2)));
static bool mul__137(float* __restrict__ __outs_0, float* __restrict__ __ins_0, float* __restrict__ __ins_1) noexcept __attribute__((nonnull (1,2,3)));
static bool cast__138(int8_t* __restrict__ __outs_0, float* __restrict__ __ins_0) noexcept __attribute__((nonnull (1,2)));
static bool reorder__436(int8_t* __restrict__ __outs_0, int8_t* __restrict__ __ins_0) noexcept __attribute__((nonnull (1,2)));
static bool mul__179(float* __restrict__ __outs_0, float* __restrict__ __ins_0, float* __restrict__ __ins_1) noexcept __attribute__((nonnull (1,2,3)));
static bool cast__180(int8_t* __restrict__ __outs_0, float* __restrict__ __ins_0) noexcept __attribute__((nonnull (1,2)));
static bool reorder__478(int8_t* __restrict__ __outs_0, int8_t* __restrict__ __ins_0) noexcept __attribute__((nonnull (1,2)));
static bool mul__143(float* __restrict__ __outs_0, float* __restrict__ __ins_0, float* __restrict__ __ins_1) noexcept __attribute__((nonnull (1,2,3)));
static bool cast__144(int8_t* __restrict__ __outs_0, float* __restrict__ __ins_0) noexcept __attribute__((nonnull (1,2)));
static bool reorder__442(int8_t* __restrict__ __outs_0, int8_t* __restrict__ __ins_0) noexcept __attribute__((nonnull (1,2)));
static bool mul__152(float* __restrict__ __outs_0, float* __restrict__ __ins_0, float* __restrict__ __ins_1) noexcept __attribute__((nonnull (1,2,3)));
static bool cast__153(int8_t* __restrict__ __outs_0, float* __restrict__ __ins_0) noexcept __attribute__((nonnull (1,2)));
static bool reorder__451(int8_t* __restrict__ __outs_0, int8_t* __restrict__ __ins_0) noexcept __attribute__((nonnull (1,2)));
static bool mul__161(float* __restrict__ __outs_0, float* __restrict__ __ins_0, float* __restrict__ __ins_1) noexcept __attribute__((nonnull (1,2,3)));
static bool cast__162(int8_t* __restrict__ __outs_0, float* __restrict__ __ins_0) noexcept __attribute__((nonnull (1,2)));
static bool reorder__460(int8_t* __restrict__ __outs_0, int8_t* __restrict__ __ins_0) noexcept __attribute__((nonnull (1,2)));
static bool mul__170(float* __restrict__ __outs_0, float* __restrict__ __ins_0, float* __restrict__ __ins_1) noexcept __attribute__((nonnull (1,2,3)));
static bool cast__171(int8_t* __restrict__ __outs_0, float* __restrict__ __ins_0) noexcept __attribute__((nonnull (1,2)));
static bool reorder__469(int8_t* __restrict__ __outs_0, int8_t* __restrict__ __ins_0) noexcept __attribute__((nonnull (1,2)));
static bool mul__185(float* __restrict__ __outs_0, float* __restrict__ __ins_0, float* __restrict__ __ins_1) noexcept __attribute__((nonnull (1,2,3)));
static bool cast__186(int8_t* __restrict__ __outs_0, float* __restrict__ __ins_0) noexcept __attribute__((nonnull (1,2)));
static bool reorder__484(int8_t* __restrict__ __outs_0, int8_t* __restrict__ __ins_0) noexcept __attribute__((nonnull (1,2)));
static bool mul__194(float* __restrict__ __outs_0, float* __restrict__ __ins_0, float* __restrict__ __ins_1) noexcept __attribute__((nonnull (1,2,3)));
static bool cast__195(int8_t* __restrict__ __outs_0, float* __restrict__ __ins_0) noexcept __attribute__((nonnull (1,2)));
static bool reorder__493(int8_t* __restrict__ __outs_0, int8_t* __restrict__ __ins_0) noexcept __attribute__((nonnull (1,2)));
static bool mul__203(float* __restrict__ __outs_0, float* __restrict__ __ins_0, float* __restrict__ __ins_1) noexcept __attribute__((nonnull (1,2,3)));
static bool cast__204(int8_t* __restrict__ __outs_0, float* __restrict__ __ins_0) noexcept __attribute__((nonnull (1,2)));
static bool reorder__502(int8_t* __restrict__ __outs_0, int8_t* __restrict__ __ins_0) noexcept __attribute__((nonnull (1,2)));
static bool mul__212(float* __restrict__ __outs_0, float* __restrict__ __ins_0, float* __restrict__ __ins_1) noexcept __attribute__((nonnull (1,2,3)));
static bool cast__213(int8_t* __restrict__ __outs_0, float* __restrict__ __ins_0) noexcept __attribute__((nonnull (1,2)));
static bool reorder__511(int8_t* __restrict__ __outs_0, int8_t* __restrict__ __ins_0) noexcept __attribute__((nonnull (1,2)));
static bool mul__221(float* __restrict__ __outs_0, float* __restrict__ __ins_0, float* __restrict__ __ins_1) noexcept __attribute__((nonnull (1,2,3)));
static bool cast__222(int8_t* __restrict__ __outs_0, float* __restrict__ __ins_0) noexcept __attribute__((nonnull (1,2)));
static bool reorder__520(int8_t* __restrict__ __outs_0, int8_t* __restrict__ __ins_0) noexcept __attribute__((nonnull (1,2)));
static bool mul__230(float* __restrict__ __outs_0, float* __restrict__ __ins_0, float* __restrict__ __ins_1) noexcept __attribute__((nonnull (1,2,3)));
static bool cast__231(int8_t* __restrict__ __outs_0, float* __restrict__ __ins_0) noexcept __attribute__((nonnull (1,2)));
static bool reorder__529(int8_t* __restrict__ __outs_0, int8_t* __restrict__ __ins_0) noexcept __attribute__((nonnull (1,2)));
static bool mul__188(float* __restrict__ __outs_0, float* __restrict__ __ins_0, float* __restrict__ __ins_1) noexcept __attribute__((nonnull (1,2,3)));
static bool cast__189(int8_t* __restrict__ __outs_0, float* __restrict__ __ins_0) noexcept __attribute__((nonnull (1,2)));
static bool reorder__487(int8_t* __restrict__ __outs_0, int8_t* __restrict__ __ins_0) noexcept __attribute__((nonnull (1,2)));
static bool mul__197(float* __restrict__ __outs_0, float* __restrict__ __ins_0, float* __restrict__ __ins_1) noexcept __attribute__((nonnull (1,2,3)));
static bool cast__198(int8_t* __restrict__ __outs_0, float* __restrict__ __ins_0) noexcept __attribute__((nonnull (1,2)));
static bool reorder__496(int8_t* __restrict__ __outs_0, int8_t* __restrict__ __ins_0) noexcept __attribute__((nonnull (1,2)));
static bool mul__206(float* __restrict__ __outs_0, float* __restrict__ __ins_0, float* __restrict__ __ins_1) noexcept __attribute__((nonnull (1,2,3)));
static bool cast__207(int8_t* __restrict__ __outs_0, float* __restrict__ __ins_0) noexcept __attribute__((nonnull (1,2)));
static bool reorder__505(int8_t* __restrict__ __outs_0, int8_t* __restrict__ __ins_0) noexcept __attribute__((nonnull (1,2)));
static bool mul__215(float* __restrict__ __outs_0, float* __restrict__ __ins_0, float* __restrict__ __ins_1) noexcept __attribute__((nonnull (1,2,3)));
static bool cast__216(int8_t* __restrict__ __outs_0, float* __restrict__ __ins_0) noexcept __attribute__((nonnull (1,2)));
static bool reorder__514(int8_t* __restrict__ __outs_0, int8_t* __restrict__ __ins_0) noexcept __attribute__((nonnull (1,2)));
static bool mul__224(float* __restrict__ __outs_0, float* __restrict__ __ins_0, float* __restrict__ __ins_1) noexcept __attribute__((nonnull (1,2,3)));
static bool cast__225(int8_t* __restrict__ __outs_0, float* __restrict__ __ins_0) noexcept __attribute__((nonnull (1,2)));
static bool reorder__523(int8_t* __restrict__ __outs_0, int8_t* __restrict__ __ins_0) noexcept __attribute__((nonnull (1,2)));
static bool mul__176(float* __restrict__ __outs_0, float* __restrict__ __ins_0, float* __restrict__ __ins_1) noexcept __attribute__((nonnull (1,2,3)));
static bool cast__177(int8_t* __restrict__ __outs_0, float* __restrict__ __ins_0) noexcept __attribute__((nonnull (1,2)));
static bool reorder__475(int8_t* __restrict__ __outs_0, int8_t* __restrict__ __ins_0) noexcept __attribute__((nonnull (1,2)));
static bool mul__236(float* __restrict__ __outs_0, float* __restrict__ __ins_0, float* __restrict__ __ins_1) noexcept __attribute__((nonnull (1,2,3)));
static bool cast__237(int8_t* __restrict__ __outs_0, float* __restrict__ __ins_0) noexcept __attribute__((nonnull (1,2)));
static bool reorder__535(int8_t* __restrict__ __outs_0, int8_t* __restrict__ __ins_0) noexcept __attribute__((nonnull (1,2)));
static bool mul__182(float* __restrict__ __outs_0, float* __restrict__ __ins_0, float* __restrict__ __ins_1) noexcept __attribute__((nonnull (1,2,3)));
static bool cast__183(int8_t* __restrict__ __outs_0, float* __restrict__ __ins_0) noexcept __attribute__((nonnull (1,2)));
static bool reorder__481(int8_t* __restrict__ __outs_0, int8_t* __restrict__ __ins_0) noexcept __attribute__((nonnull (1,2)));
static bool mul__191(float* __restrict__ __outs_0, float* __restrict__ __ins_0, float* __restrict__ __ins_1) noexcept __attribute__((nonnull (1,2,3)));
static bool cast__192(int8_t* __restrict__ __outs_0, float* __restrict__ __ins_0) noexcept __attribute__((nonnull (1,2)));
static bool reorder__490(int8_t* __restrict__ __outs_0, int8_t* __restrict__ __ins_0) noexcept __attribute__((nonnull (1,2)));
static bool mul__200(float* __restrict__ __outs_0, float* __restrict__ __ins_0, float* __restrict__ __ins_1) noexcept __attribute__((nonnull (1,2,3)));
static bool cast__201(int8_t* __restrict__ __outs_0, float* __restrict__ __ins_0) noexcept __attribute__((nonnull (1,2)));
static bool reorder__499(int8_t* __restrict__ __outs_0, int8_t* __restrict__ __ins_0) noexcept __attribute__((nonnull (1,2)));
static bool mul__209(float* __restrict__ __outs_0, float* __restrict__ __ins_0, float* __restrict__ __ins_1) noexcept __attribute__((nonnull (1,2,3)));
static bool cast__210(int8_t* __restrict__ __outs_0, float* __restrict__ __ins_0) noexcept __attribute__((nonnull (1,2)));
static bool reorder__508(int8_t* __restrict__ __outs_0, int8_t* __restrict__ __ins_0) noexcept __attribute__((nonnull (1,2)));
static bool mul__218(float* __restrict__ __outs_0, float* __restrict__ __ins_0, float* __restrict__ __ins_1) noexcept __attribute__((nonnull (1,2,3)));
static bool cast__219(int8_t* __restrict__ __outs_0, float* __restrict__ __ins_0) noexcept __attribute__((nonnull (1,2)));
static bool reorder__517(int8_t* __restrict__ __outs_0, int8_t* __restrict__ __ins_0) noexcept __attribute__((nonnull (1,2)));
static bool mul__227(float* __restrict__ __outs_0, float* __restrict__ __ins_0, float* __restrict__ __ins_1) noexcept __attribute__((nonnull (1,2,3)));
static bool cast__228(int8_t* __restrict__ __outs_0, float* __restrict__ __ins_0) noexcept __attribute__((nonnull (1,2)));
static bool reorder__526(int8_t* __restrict__ __outs_0, int8_t* __restrict__ __ins_0) noexcept __attribute__((nonnull (1,2)));
static bool mul__242(float* __restrict__ __outs_0, float* __restrict__ __ins_0, float* __restrict__ __ins_1) noexcept __attribute__((nonnull (1,2,3)));
static bool cast__243(int8_t* __restrict__ __outs_0, float* __restrict__ __ins_0) noexcept __attribute__((nonnull (1,2)));
static bool reorder__539(int8_t* __restrict__ __outs_0, int8_t* __restrict__ __ins_0) noexcept __attribute__((nonnull (1,2)));
static bool mul__251(float* __restrict__ __outs_0, float* __restrict__ __ins_0, float* __restrict__ __ins_1) noexcept __attribute__((nonnull (1,2,3)));
static bool cast__252(int8_t* __restrict__ __outs_0, float* __restrict__ __ins_0) noexcept __attribute__((nonnull (1,2)));
static bool reorder__548(int8_t* __restrict__ __outs_0, int8_t* __restrict__ __ins_0) noexcept __attribute__((nonnull (1,2)));
static bool mul__260(float* __restrict__ __outs_0, float* __restrict__ __ins_0, float* __restrict__ __ins_1) noexcept __attribute__((nonnull (1,2,3)));
static bool cast__261(int8_t* __restrict__ __outs_0, float* __restrict__ __ins_0) noexcept __attribute__((nonnull (1,2)));
static bool reorder__557(int8_t* __restrict__ __outs_0, int8_t* __restrict__ __ins_0) noexcept __attribute__((nonnull (1,2)));
static bool mul__245(float* __restrict__ __outs_0, float* __restrict__ __ins_0, float* __restrict__ __ins_1) noexcept __attribute__((nonnull (1,2,3)));
static bool cast__246(int8_t* __restrict__ __outs_0, float* __restrict__ __ins_0) noexcept __attribute__((nonnull (1,2)));
static bool reorder__542(int8_t* __restrict__ __outs_0, int8_t* __restrict__ __ins_0) noexcept __attribute__((nonnull (1,2)));
static bool mul__254(float* __restrict__ __outs_0, float* __restrict__ __ins_0, float* __restrict__ __ins_1) noexcept __attribute__((nonnull (1,2,3)));
static bool cast__255(int8_t* __restrict__ __outs_0, float* __restrict__ __ins_0) noexcept __attribute__((nonnull (1,2)));
static bool reorder__551(int8_t* __restrict__ __outs_0, int8_t* __restrict__ __ins_0) noexcept __attribute__((nonnull (1,2)));
static bool mul__233(float* __restrict__ __outs_0, float* __restrict__ __ins_0, float* __restrict__ __ins_1) noexcept __attribute__((nonnull (1,2,3)));
static bool cast__234(int8_t* __restrict__ __outs_0, float* __restrict__ __ins_0) noexcept __attribute__((nonnull (1,2)));
static bool reorder__532(int8_t* __restrict__ __outs_0, int8_t* __restrict__ __ins_0) noexcept __attribute__((nonnull (1,2)));
static bool mul__239(float* __restrict__ __outs_0, float* __restrict__ __ins_0, float* __restrict__ __ins_1) noexcept __attribute__((nonnull (1,2,3)));
static bool cast__240(int8_t* __restrict__ __outs_0, float* __restrict__ __ins_0) noexcept __attribute__((nonnull (1,2)));
static bool reorder__536(int8_t* __restrict__ __outs_0, int8_t* __restrict__ __ins_0) noexcept __attribute__((nonnull (1,2)));
static bool mul__248(float* __restrict__ __outs_0, float* __restrict__ __ins_0, float* __restrict__ __ins_1) noexcept __attribute__((nonnull (1,2,3)));
static bool cast__249(int8_t* __restrict__ __outs_0, float* __restrict__ __ins_0) noexcept __attribute__((nonnull (1,2)));
static bool reorder__545(int8_t* __restrict__ __outs_0, int8_t* __restrict__ __ins_0) noexcept __attribute__((nonnull (1,2)));
static bool mul__257(float* __restrict__ __outs_0, float* __restrict__ __ins_0, float* __restrict__ __ins_1) noexcept __attribute__((nonnull (1,2,3)));
static bool cast__258(int8_t* __restrict__ __outs_0, float* __restrict__ __ins_0) noexcept __attribute__((nonnull (1,2)));
static bool reorder__554(int8_t* __restrict__ __outs_0, int8_t* __restrict__ __ins_0) noexcept __attribute__((nonnull (1,2)));
static void reorder__4190_closure_0(uint64_t fused_0fused_0fused_0fused_0_fuseiter_8172___fuseiter_8173_2312___fuseiter_8174_2313___fuseiter_8175_2314___fuseiter_8176_2315, float* __restrict__ __ins_0, float* __restrict__ __outs_0) noexcept __attribute__((nonnull (2,3)));
static void mul__5700_closure_1(uint64_t fused_0fused_0fused_0fused_0__itr_0____itr_1_2316____itr_2_2317____itr_3_2318____itr_4_2319, float* __restrict__ __ins_0, float* __restrict__ __ins_1, float* __restrict__ __outs_0) noexcept __attribute__((nonnull (2,3,4)));
static void reorder__4240_closure_2(uint64_t fused_0fused_0fused_0fused_0_fuseiter_8199___fuseiter_8200_2328___fuseiter_8201_2329___fuseiter_8202_2330___fuseiter_8203_2331, float* __restrict__ __ins_0, float* __restrict__ __outs_0) noexcept __attribute__((nonnull (2,3)));
static void mul__5760_closure_3(uint64_t fused_0fused_0fused_0fused_0__itr_0____itr_1_2332____itr_2_2333____itr_3_2334____itr_4_2335, float* __restrict__ __ins_0, float* __restrict__ __ins_1, float* __restrict__ __outs_0) noexcept __attribute__((nonnull (2,3,4)));
static void reorder__4290_closure_4(uint64_t fused_0fused_0fused_0fused_0_fuseiter_8226___fuseiter_8227_2344___fuseiter_8228_2345___fuseiter_8229_2346___fuseiter_8230_2347, float* __restrict__ __ins_0, float* __restrict__ __outs_0) noexcept __attribute__((nonnull (2,3)));
static void mul__5820_closure_5(uint64_t fused_0fused_0fused_0fused_0__itr_0____itr_1_2348____itr_2_2349____itr_3_2350____itr_4_2351, float* __restrict__ __ins_0, float* __restrict__ __ins_1, float* __restrict__ __outs_0) noexcept __attribute__((nonnull (2,3,4)));
static void reorder__4340_closure_6(uint64_t fused_0fused_0fused_0fused_0_fuseiter_8253___fuseiter_8254_2360___fuseiter_8255_2361___fuseiter_8256_2362___fuseiter_8257_2363, float* __restrict__ __ins_0, float* __restrict__ __outs_0) noexcept __attribute__((nonnull (2,3)));
static void mul__5880_closure_7(uint64_t fused_0fused_0fused_0fused_0__itr_0____itr_1_2364____itr_2_2365____itr_3_2366____itr_4_2367, float* __restrict__ __ins_0, float* __restrict__ __ins_1, float* __restrict__ __outs_0) noexcept __attribute__((nonnull (2,3,4)));
static void reorder__4370_closure_8(uint64_t fused_0fused_0fused_0fused_0_fuseiter_8266___fuseiter_8267_2368___fuseiter_8268_2369___fuseiter_8269_2370___fuseiter_8270_2371, float* __restrict__ __ins_0, float* __restrict__ __outs_0) noexcept __attribute__((nonnull (2,3)));
static void mul__5900_closure_9(uint64_t fused_0fused_0fused_0fused_0__itr_0____itr_1_2372____itr_2_2373____itr_3_2374____itr_4_2375, float* __restrict__ __ins_0, float* __restrict__ __ins_1, float* __restrict__ __outs_0) noexcept __attribute__((nonnull (2,3,4)));
static void reorder__4400_closure_10(uint64_t fused_0fused_0fused_0fused_0_fuseiter_8279___fuseiter_8280_2376___fuseiter_8281_2377___fuseiter_8282_2378___fuseiter_8283_2379, float* __restrict__ __ins_0, float* __restrict__ __outs_0) noexcept __attribute__((nonnull (2,3)));
static void mul__5920_closure_11(uint64_t fused_0fused_0fused_0fused_0__itr_0____itr_1_2380____itr_2_2381____itr_3_2382____itr_4_2383, float* __restrict__ __ins_0, float* __restrict__ __ins_1, float* __restrict__ __outs_0) noexcept __attribute__((nonnull (2,3,4)));
static void reorder__4430_closure_12(uint64_t fused_0fused_0fused_0fused_0_fuseiter_8292___fuseiter_8293_2384___fuseiter_8294_2385___fuseiter_8295_2386___fuseiter_8296_2387, float* __restrict__ __ins_0, float* __restrict__ __outs_0) noexcept __attribute__((nonnull (2,3)));
static void mul__5940_closure_13(uint64_t fused_0fused_0fused_0fused_0__itr_0____itr_1_2388____itr_2_2389____itr_3_2390____itr_4_2391, float* __restrict__ __ins_0, float* __restrict__ __ins_1, float* __restrict__ __outs_0) noexcept __attribute__((nonnull (2,3,4)));
static void reorder__4460_closure_14(uint64_t fused_0fused_0fused_0fused_0_fuseiter_8305___fuseiter_8306_2392___fuseiter_8307_2393___fuseiter_8308_2394___fuseiter_8309_2395, float* __restrict__ __ins_0, float* __restrict__ __outs_0) noexcept __attribute__((nonnull (2,3)));
static void mul__5960_closure_15(uint64_t fused_0fused_0fused_0fused_0__itr_0____itr_1_2396____itr_2_2397____itr_3_2398____itr_4_2399, float* __restrict__ __ins_0, float* __restrict__ __ins_1, float* __restrict__ __outs_0) noexcept __attribute__((nonnull (2,3,4)));
static void reorder__4490_closure_16(uint64_t fused_0fused_0fused_0fused_0_fuseiter_8318___fuseiter_8319_2400___fuseiter_8320_2401___fuseiter_8321_2402___fuseiter_8322_2403, float* __restrict__ __ins_0, float* __restrict__ __outs_0) noexcept __attribute__((nonnull (2,3)));
static void mul__5980_closure_17(uint64_t fused_0fused_0fused_0fused_0__itr_0____itr_1_2404____itr_2_2405____itr_3_2406____itr_4_2407, float* __restrict__ __ins_0, float* __restrict__ __ins_1, float* __restrict__ __outs_0) noexcept __attribute__((nonnull (2,3,4)));
static void reorder__4520_closure_18(uint64_t fused_0fused_0fused_0fused_0_fuseiter_8331___fuseiter_8332_2408___fuseiter_8333_2409___fuseiter_8334_2410___fuseiter_8335_2411, float* __restrict__ __ins_0, float* __restrict__ __outs_0) noexcept __attribute__((nonnull (2,3)));
static void mul__6000_closure_19(uint64_t fused_0fused_0fused_0fused_0__itr_0____itr_1_2412____itr_2_2413____itr_3_2414____itr_4_2415, float* __restrict__ __ins_0, float* __restrict__ __ins_1, float* __restrict__ __outs_0) noexcept __attribute__((nonnull (2,3,4)));
static void reorder__4550_closure_20(uint64_t fused_0fused_0fused_0fused_0_fuseiter_8344___fuseiter_8345_2416___fuseiter_8346_2417___fuseiter_8347_2418___fuseiter_8348_2419, float* __restrict__ __ins_0, float* __restrict__ __outs_0) noexcept __attribute__((nonnull (2,3)));
static void mul__6020_closure_21(uint64_t fused_0fused_0fused_0fused_0__itr_0____itr_1_2420____itr_2_2421____itr_3_2422____itr_4_2423, float* __restrict__ __ins_0, float* __restrict__ __ins_1, float* __restrict__ __outs_0) noexcept __attribute__((nonnull (2,3,4)));
static void reorder__4580_closure_22(uint64_t fused_0fused_0fused_0fused_0_fuseiter_8357___fuseiter_8358_2424___fuseiter_8359_2425___fuseiter_8360_2426___fuseiter_8361_2427, float* __restrict__ __ins_0, float* __restrict__ __outs_0) noexcept __attribute__((nonnull (2,3)));
static void mul__6040_closure_23(uint64_t fused_0fused_0fused_0fused_0__itr_0____itr_1_2428____itr_2_2429____itr_3_2430____itr_4_2431, float* __restrict__ __ins_0, float* __restrict__ __ins_1, float* __restrict__ __outs_0) noexcept __attribute__((nonnull (2,3,4)));
static void reorder__4610_closure_24(uint64_t fused_0fused_0fused_0fused_0_fuseiter_8370___fuseiter_8371_2432___fuseiter_8372_2433___fuseiter_8373_2434___fuseiter_8374_2435, float* __restrict__ __ins_0, float* __restrict__ __outs_0) noexcept __attribute__((nonnull (2,3)));
static void mul__6060_closure_25(uint64_t fused_0fused_0fused_0fused_0__itr_0____itr_1_2436____itr_2_2437____itr_3_2438____itr_4_2439, float* __restrict__ __ins_0, float* __restrict__ __ins_1, float* __restrict__ __outs_0) noexcept __attribute__((nonnull (2,3,4)));
static void reorder__4640_closure_26(uint64_t fused_0fused_0fused_0fused_0_fuseiter_8383___fuseiter_8384_2440___fuseiter_8385_2441___fuseiter_8386_2442___fuseiter_8387_2443, float* __restrict__ __ins_0, float* __restrict__ __outs_0) noexcept __attribute__((nonnull (2,3)));
static void mul__6080_closure_27(uint64_t fused_0fused_0fused_0fused_0__itr_0____itr_1_2444____itr_2_2445____itr_3_2446____itr_4_2447, float* __restrict__ __ins_0, float* __restrict__ __ins_1, float* __restrict__ __outs_0) noexcept __attribute__((nonnull (2,3,4)));
static void reorder__4670_closure_28(uint64_t fused_0fused_0fused_0fused_0_fuseiter_8396___fuseiter_8397_2448___fuseiter_8398_2449___fuseiter_8399_2450___fuseiter_8400_2451, float* __restrict__ __ins_0, float* __restrict__ __outs_0) noexcept __attribute__((nonnull (2,3)));
static void mul__6100_closure_29(uint64_t fused_0fused_0fused_0fused_0__itr_0____itr_1_2452____itr_2_2453____itr_3_2454____itr_4_2455, float* __restrict__ __ins_0, float* __restrict__ __ins_1, float* __restrict__ __outs_0) noexcept __attribute__((nonnull (2,3,4)));
static void reorder__4700_closure_30(uint64_t fused_0fused_0fused_0fused_0_fuseiter_8409___fuseiter_8410_2456___fuseiter_8411_2457___fuseiter_8412_2458___fuseiter_8413_2459, float* __restrict__ __ins_0, float* __restrict__ __outs_0) noexcept __attribute__((nonnull (2,3)));
static void mul__6120_closure_31(uint64_t fused_0fused_0fused_0fused_0__itr_0____itr_1_2460____itr_2_2461____itr_3_2462____itr_4_2463, float* __restrict__ __ins_0, float* __restrict__ __ins_1, float* __restrict__ __outs_0) noexcept __attribute__((nonnull (2,3,4)));
static void reorder__4730_closure_32(uint64_t fused_0fused_0fused_0fused_0_fuseiter_8422___fuseiter_8423_2464___fuseiter_8424_2465___fuseiter_8425_2466___fuseiter_8426_2467, float* __restrict__ __ins_0, float* __restrict__ __outs_0) noexcept __attribute__((nonnull (2,3)));
static void mul__6140_closure_33(uint64_t fused_0fused_0fused_0fused_0__itr_0____itr_1_2468____itr_2_2469____itr_3_2470____itr_4_2471, float* __restrict__ __ins_0, float* __restrict__ __ins_1, float* __restrict__ __outs_0) noexcept __attribute__((nonnull (2,3,4)));
static void reorder__4760_closure_34(uint64_t fused_0fused_0fused_0fused_0_fuseiter_8435___fuseiter_8436_2472___fuseiter_8437_2473___fuseiter_8438_2474___fuseiter_8439_2475, float* __restrict__ __ins_0, float* __restrict__ __outs_0) noexcept __attribute__((nonnull (2,3)));
static void mul__6160_closure_35(uint64_t fused_0fused_0fused_0fused_0__itr_0____itr_1_2476____itr_2_2477____itr_3_2478____itr_4_2479, float* __restrict__ __ins_0, float* __restrict__ __ins_1, float* __restrict__ __outs_0) noexcept __attribute__((nonnull (2,3,4)));
static void reorder__4790_closure_36(uint64_t fused_0fused_0fused_0fused_0_fuseiter_8448___fuseiter_8449_2480___fuseiter_8450_2481___fuseiter_8451_2482___fuseiter_8452_2483, float* __restrict__ __ins_0, float* __restrict__ __outs_0) noexcept __attribute__((nonnull (2,3)));
static void mul__6180_closure_37(uint64_t fused_0fused_0fused_0fused_0__itr_0____itr_1_2484____itr_2_2485____itr_3_2486____itr_4_2487, float* __restrict__ __ins_0, float* __restrict__ __ins_1, float* __restrict__ __outs_0) noexcept __attribute__((nonnull (2,3,4)));
static void reorder__4820_closure_38(uint64_t fused_0fused_0fused_0fused_0_fuseiter_8461___fuseiter_8462_2488___fuseiter_8463_2489___fuseiter_8464_2490___fuseiter_8465_2491, float* __restrict__ __ins_0, float* __restrict__ __outs_0) noexcept __attribute__((nonnull (2,3)));
static void mul__6200_closure_39(uint64_t fused_0fused_0fused_0fused_0__itr_0____itr_1_2492____itr_2_2493____itr_3_2494____itr_4_2495, float* __restrict__ __ins_0, float* __restrict__ __ins_1, float* __restrict__ __outs_0) noexcept __attribute__((nonnull (2,3,4)));
static void reorder__4850_closure_40(uint64_t fused_0fused_0fused_0fused_0_fuseiter_8474___fuseiter_8475_2496___fuseiter_8476_2497___fuseiter_8477_2498___fuseiter_8478_2499, float* __restrict__ __ins_0, float* __restrict__ __outs_0) noexcept __attribute__((nonnull (2,3)));
static void mul__6220_closure_41(uint64_t fused_0fused_0fused_0fused_0__itr_0____itr_1_2500____itr_2_2501____itr_3_2502____itr_4_2503, float* __restrict__ __ins_0, float* __restrict__ __ins_1, float* __restrict__ __outs_0) noexcept __attribute__((nonnull (2,3,4)));
static void reorder__4880_closure_42(uint64_t fused_0fused_0fused_0fused_0_fuseiter_8487___fuseiter_8488_2504___fuseiter_8489_2505___fuseiter_8490_2506___fuseiter_8491_2507, float* __restrict__ __ins_0, float* __restrict__ __outs_0) noexcept __attribute__((nonnull (2,3)));
static void mul__6240_closure_43(uint64_t fused_0fused_0fused_0fused_0__itr_0____itr_1_2508____itr_2_2509____itr_3_2510____itr_4_2511, float* __restrict__ __ins_0, float* __restrict__ __ins_1, float* __restrict__ __outs_0) noexcept __attribute__((nonnull (2,3,4)));
static void reorder__4910_closure_44(uint64_t fused_0fused_0fused_0fused_0_fuseiter_8500___fuseiter_8501_2512___fuseiter_8502_2513___fuseiter_8503_2514___fuseiter_8504_2515, float* __restrict__ __ins_0, float* __restrict__ __outs_0) noexcept __attribute__((nonnull (2,3)));
static void mul__6260_closure_45(uint64_t fused_0fused_0fused_0fused_0__itr_0____itr_1_2516____itr_2_2517____itr_3_2518____itr_4_2519, float* __restrict__ __ins_0, float* __restrict__ __ins_1, float* __restrict__ __outs_0) noexcept __attribute__((nonnull (2,3,4)));
static void reorder__4940_closure_46(uint64_t fused_0fused_0fused_0fused_0_fuseiter_8513___fuseiter_8514_2520___fuseiter_8515_2521___fuseiter_8516_2522___fuseiter_8517_2523, float* __restrict__ __ins_0, float* __restrict__ __outs_0) noexcept __attribute__((nonnull (2,3)));
static void mul__6280_closure_47(uint64_t fused_0fused_0fused_0fused_0__itr_0____itr_1_2524____itr_2_2525____itr_3_2526____itr_4_2527, float* __restrict__ __ins_0, float* __restrict__ __ins_1, float* __restrict__ __outs_0) noexcept __attribute__((nonnull (2,3,4)));
static void reorder__4970_closure_48(uint64_t fused_0fused_0fused_0fused_0_fuseiter_8526___fuseiter_8527_2528___fuseiter_8528_2529___fuseiter_8529_2530___fuseiter_8530_2531, float* __restrict__ __ins_0, float* __restrict__ __outs_0) noexcept __attribute__((nonnull (2,3)));
static void mul__6300_closure_49(uint64_t fused_0fused_0fused_0fused_0__itr_0____itr_1_2532____itr_2_2533____itr_3_2534____itr_4_2535, float* __restrict__ __ins_0, float* __restrict__ __ins_1, float* __restrict__ __outs_0) noexcept __attribute__((nonnull (2,3,4)));
static void reorder__5000_closure_50(uint64_t fused_0fused_0fused_0fused_0_fuseiter_8539___fuseiter_8540_2536___fuseiter_8541_2537___fuseiter_8542_2538___fuseiter_8543_2539, float* __restrict__ __ins_0, float* __restrict__ __outs_0) noexcept __attribute__((nonnull (2,3)));
static void mul__6320_closure_51(uint64_t fused_0fused_0fused_0fused_0__itr_0____itr_1_2540____itr_2_2541____itr_3_2542____itr_4_2543, float* __restrict__ __ins_0, float* __restrict__ __ins_1, float* __restrict__ __outs_0) noexcept __attribute__((nonnull (2,3,4)));
static void reorder__5030_closure_52(uint64_t fused_0fused_0fused_0fused_0_fuseiter_8552___fuseiter_8553_2544___fuseiter_8554_2545___fuseiter_8555_2546___fuseiter_8556_2547, float* __restrict__ __ins_0, float* __restrict__ __outs_0) noexcept __attribute__((nonnull (2,3)));
static void mul__6340_closure_53(uint64_t fused_0fused_0fused_0fused_0__itr_0____itr_1_2548____itr_2_2549____itr_3_2550____itr_4_2551, float* __restrict__ __ins_0, float* __restrict__ __ins_1, float* __restrict__ __outs_0) noexcept __attribute__((nonnull (2,3,4)));
static void reorder__5060_closure_54(uint64_t fused_0fused_0fused_0fused_0_fuseiter_8565___fuseiter_8566_2552___fuseiter_8567_2553___fuseiter_8568_2554___fuseiter_8569_2555, float* __restrict__ __ins_0, float* __restrict__ __outs_0) noexcept __attribute__((nonnull (2,3)));
static void mul__6360_closure_55(uint64_t fused_0fused_0fused_0fused_0__itr_0____itr_1_2556____itr_2_2557____itr_3_2558____itr_4_2559, float* __restrict__ __ins_0, float* __restrict__ __ins_1, float* __restrict__ __outs_0) noexcept __attribute__((nonnull (2,3,4)));
static void reorder__5090_closure_56(uint64_t fused_0fused_0fused_0fused_0_fuseiter_8578___fuseiter_8579_2560___fuseiter_8580_2561___fuseiter_8581_2562___fuseiter_8582_2563, float* __restrict__ __ins_0, float* __restrict__ __outs_0) noexcept __attribute__((nonnull (2,3)));
static void mul__6380_closure_57(uint64_t fused_0fused_0fused_0fused_0__itr_0____itr_1_2564____itr_2_2565____itr_3_2566____itr_4_2567, float* __restrict__ __ins_0, float* __restrict__ __ins_1, float* __restrict__ __outs_0) noexcept __attribute__((nonnull (2,3,4)));
static void reorder__5120_closure_58(uint64_t fused_0fused_0fused_0fused_0_fuseiter_8591___fuseiter_8592_2568___fuseiter_8593_2569___fuseiter_8594_2570___fuseiter_8595_2571, float* __restrict__ __ins_0, float* __restrict__ __outs_0) noexcept __attribute__((nonnull (2,3)));
static void mul__6400_closure_59(uint64_t fused_0fused_0fused_0fused_0__itr_0____itr_1_2572____itr_2_2573____itr_3_2574____itr_4_2575, float* __restrict__ __ins_0, float* __restrict__ __ins_1, float* __restrict__ __outs_0) noexcept __attribute__((nonnull (2,3,4)));
static void reorder__5150_closure_60(uint64_t fused_0fused_0fused_0fused_0_fuseiter_8604___fuseiter_8605_2576___fuseiter_8606_2577___fuseiter_8607_2578___fuseiter_8608_2579, float* __restrict__ __ins_0, float* __restrict__ __outs_0) noexcept __attribute__((nonnull (2,3)));
static void mul__6420_closure_61(uint64_t fused_0fused_0fused_0fused_0__itr_0____itr_1_2580____itr_2_2581____itr_3_2582____itr_4_2583, float* __restrict__ __ins_0, float* __restrict__ __ins_1, float* __restrict__ __outs_0) noexcept __attribute__((nonnull (2,3,4)));
static void reorder__5180_closure_62(uint64_t fused_0fused_0fused_0fused_0_fuseiter_8617___fuseiter_8618_2584___fuseiter_8619_2585___fuseiter_8620_2586___fuseiter_8621_2587, float* __restrict__ __ins_0, float* __restrict__ __outs_0) noexcept __attribute__((nonnull (2,3)));
static void mul__6440_closure_63(uint64_t fused_0fused_0fused_0fused_0__itr_0____itr_1_2588____itr_2_2589____itr_3_2590____itr_4_2591, float* __restrict__ __ins_0, float* __restrict__ __ins_1, float* __restrict__ __outs_0) noexcept __attribute__((nonnull (2,3,4)));
static void reorder__5210_closure_64(uint64_t fused_0fused_0fused_0fused_0_fuseiter_8630___fuseiter_8631_2592___fuseiter_8632_2593___fuseiter_8633_2594___fuseiter_8634_2595, float* __restrict__ __ins_0, float* __restrict__ __outs_0) noexcept __attribute__((nonnull (2,3)));
static void mul__6460_closure_65(uint64_t fused_0fused_0fused_0fused_0__itr_0____itr_1_2596____itr_2_2597____itr_3_2598____itr_4_2599, float* __restrict__ __ins_0, float* __restrict__ __ins_1, float* __restrict__ __outs_0) noexcept __attribute__((nonnull (2,3,4)));
static void reorder__5240_closure_66(uint64_t fused_0fused_0fused_0fused_0_fuseiter_8643___fuseiter_8644_2600___fuseiter_8645_2601___fuseiter_8646_2602___fuseiter_8647_2603, float* __restrict__ __ins_0, float* __restrict__ __outs_0) noexcept __attribute__((nonnull (2,3)));
static void mul__6480_closure_67(uint64_t fused_0fused_0fused_0fused_0__itr_0____itr_1_2604____itr_2_2605____itr_3_2606____itr_4_2607, float* __restrict__ __ins_0, float* __restrict__ __ins_1, float* __restrict__ __outs_0) noexcept __attribute__((nonnull (2,3,4)));
static void reorder__5270_closure_68(uint64_t fused_0fused_0fused_0fused_0_fuseiter_8656___fuseiter_8657_2608___fuseiter_8658_2609___fuseiter_8659_2610___fuseiter_8660_2611, float* __restrict__ __ins_0, float* __restrict__ __outs_0) noexcept __attribute__((nonnull (2,3)));
static void mul__6500_closure_69(uint64_t fused_0fused_0fused_0fused_0__itr_0____itr_1_2612____itr_2_2613____itr_3_2614____itr_4_2615, float* __restrict__ __ins_0, float* __restrict__ __ins_1, float* __restrict__ __outs_0) noexcept __attribute__((nonnull (2,3,4)));
static void reorder__5300_closure_70(uint64_t fused_0fused_0fused_0fused_0_fuseiter_8669___fuseiter_8670_2616___fuseiter_8671_2617___fuseiter_8672_2618___fuseiter_8673_2619, float* __restrict__ __ins_0, float* __restrict__ __outs_0) noexcept __attribute__((nonnull (2,3)));
static void mul__6520_closure_71(uint64_t fused_0fused_0fused_0fused_0__itr_0____itr_1_2620____itr_2_2621____itr_3_2622____itr_4_2623, float* __restrict__ __ins_0, float* __restrict__ __ins_1, float* __restrict__ __outs_0) noexcept __attribute__((nonnull (2,3,4)));
static void reorder__5330_closure_72(uint64_t fused_0fused_0fused_0fused_0_fuseiter_8682___fuseiter_8683_2624___fuseiter_8684_2625___fuseiter_8685_2626___fuseiter_8686_2627, float* __restrict__ __ins_0, float* __restrict__ __outs_0) noexcept __attribute__((nonnull (2,3)));
static void mul__6540_closure_73(uint64_t fused_0fused_0fused_0fused_0__itr_0____itr_1_2628____itr_2_2629____itr_3_2630____itr_4_2631, float* __restrict__ __ins_0, float* __restrict__ __ins_1, float* __restrict__ __outs_0) noexcept __attribute__((nonnull (2,3,4)));
static void reorder__5370_closure_74(uint64_t fused_0fused_0fused_0fused_0_fuseiter_8702___fuseiter_8703_2636___fuseiter_8704_2637___fuseiter_8705_2638___fuseiter_8706_2639, float* __restrict__ __ins_0, float* __restrict__ __outs_0) noexcept __attribute__((nonnull (2,3)));
static void mul__6580_closure_75(uint64_t fused_0fused_0fused_0fused_0__itr_0____itr_1_2640____itr_2_2641____itr_3_2642____itr_4_2643, float* __restrict__ __ins_0, float* __restrict__ __ins_1, float* __restrict__ __outs_0) noexcept __attribute__((nonnull (2,3,4)));
static void reorder__5400_closure_76(uint64_t fused_0fused_0fused_0fused_0_fuseiter_8715___fuseiter_8716_2644___fuseiter_8717_2645___fuseiter_8718_2646___fuseiter_8719_2647, float* __restrict__ __ins_0, float* __restrict__ __outs_0) noexcept __attribute__((nonnull (2,3)));
static void mul__6600_closure_77(uint64_t fused_0fused_0fused_0fused_0__itr_0____itr_1_2648____itr_2_2649____itr_3_2650____itr_4_2651, float* __restrict__ __ins_0, float* __restrict__ __ins_1, float* __restrict__ __outs_0) noexcept __attribute__((nonnull (2,3,4)));
static void reorder__5430_closure_78(uint64_t fused_0fused_0fused_0fused_0_fuseiter_8728___fuseiter_8729_2652___fuseiter_8730_2653___fuseiter_8731_2654___fuseiter_8732_2655, float* __restrict__ __ins_0, float* __restrict__ __outs_0) noexcept __attribute__((nonnull (2,3)));
static void mul__6620_closure_79(uint64_t fused_0fused_0fused_0fused_0__itr_0____itr_1_2656____itr_2_2657____itr_3_2658____itr_4_2659, float* __restrict__ __ins_0, float* __restrict__ __ins_1, float* __restrict__ __outs_0) noexcept __attribute__((nonnull (2,3,4)));
static void reorder__5460_closure_80(uint64_t fused_0fused_0fused_0fused_0_fuseiter_8741___fuseiter_8742_2660___fuseiter_8743_2661___fuseiter_8744_2662___fuseiter_8745_2663, float* __restrict__ __ins_0, float* __restrict__ __outs_0) noexcept __attribute__((nonnull (2,3)));
static void mul__6640_closure_81(uint64_t fused_0fused_0fused_0fused_0__itr_0____itr_1_2664____itr_2_2665____itr_3_2666____itr_4_2667, float* __restrict__ __ins_0, float* __restrict__ __ins_1, float* __restrict__ __outs_0) noexcept __attribute__((nonnull (2,3,4)));
static void reorder__5490_closure_82(uint64_t fused_0fused_0fused_0fused_0_fuseiter_8754___fuseiter_8755_2668___fuseiter_8756_2669___fuseiter_8757_2670___fuseiter_8758_2671, float* __restrict__ __ins_0, float* __restrict__ __outs_0) noexcept __attribute__((nonnull (2,3)));
static void mul__6660_closure_83(uint64_t fused_0fused_0fused_0fused_0__itr_0____itr_1_2672____itr_2_2673____itr_3_2674____itr_4_2675, float* __restrict__ __ins_0, float* __restrict__ __ins_1, float* __restrict__ __outs_0) noexcept __attribute__((nonnull (2,3,4)));
static void reorder__5520_closure_84(uint64_t fused_0fused_0fused_0fused_0_fuseiter_8767___fuseiter_8768_2676___fuseiter_8769_2677___fuseiter_8770_2678___fuseiter_8771_2679, float* __restrict__ __ins_0, float* __restrict__ __outs_0) noexcept __attribute__((nonnull (2,3)));
static void mul__6680_closure_85(uint64_t fused_0fused_0fused_0fused_0__itr_0____itr_1_2680____itr_2_2681____itr_3_2682____itr_4_2683, float* __restrict__ __ins_0, float* __restrict__ __ins_1, float* __restrict__ __outs_0) noexcept __attribute__((nonnull (2,3,4)));
static void reorder__5550_closure_86(uint64_t fused_0fused_0fused_0fused_0_fuseiter_8780___fuseiter_8781_2684___fuseiter_8782_2685___fuseiter_8783_2686___fuseiter_8784_2687, float* __restrict__ __ins_0, float* __restrict__ __outs_0) noexcept __attribute__((nonnull (2,3)));
static void mul__6700_closure_87(uint64_t fused_0fused_0fused_0fused_0__itr_0____itr_1_2688____itr_2_2689____itr_3_2690____itr_4_2691, float* __restrict__ __ins_0, float* __restrict__ __ins_1, float* __restrict__ __outs_0) noexcept __attribute__((nonnull (2,3,4)));
static void reorder__5580_closure_88(uint64_t fused_0fused_0fused_0fused_0_fuseiter_8793___fuseiter_8794_2692___fuseiter_8795_2693___fuseiter_8796_2694___fuseiter_8797_2695, float* __restrict__ __ins_0, float* __restrict__ __outs_0) noexcept __attribute__((nonnull (2,3)));
static void mul__6720_closure_89(uint64_t fused_0fused_0fused_0fused_0__itr_0____itr_1_2696____itr_2_2697____itr_3_2698____itr_4_2699, float* __restrict__ __ins_0, float* __restrict__ __ins_1, float* __restrict__ __outs_0) noexcept __attribute__((nonnull (2,3,4)));
static void reorder__4410_closure_90(uint64_t fused_0fused_0fused_0fused_0_fuseiter_8848___fuseiter_8849_2724___fuseiter_8850_2725___fuseiter_8851_2726___fuseiter_8852_2727, float* __restrict__ __ins_0, float* __restrict__ __outs_0) noexcept __attribute__((nonnull (2,3)));
static void mul__5930_closure_91(uint64_t fused_0fused_0fused_0fused_0__itr_0____itr_1_2728____itr_2_2729____itr_3_2730____itr_4_2731, float* __restrict__ __ins_0, float* __restrict__ __ins_1, float* __restrict__ __outs_0) noexcept __attribute__((nonnull (2,3,4)));
static void reorder__4440_closure_92(uint64_t fused_0fused_0fused_0fused_0_fuseiter_8861___fuseiter_8862_2732___fuseiter_8863_2733___fuseiter_8864_2734___fuseiter_8865_2735, float* __restrict__ __ins_0, float* __restrict__ __outs_0) noexcept __attribute__((nonnull (2,3)));
static void mul__5950_closure_93(uint64_t fused_0fused_0fused_0fused_0__itr_0____itr_1_2736____itr_2_2737____itr_3_2738____itr_4_2739, float* __restrict__ __ins_0, float* __restrict__ __ins_1, float* __restrict__ __outs_0) noexcept __attribute__((nonnull (2,3,4)));
static void reorder__4500_closure_94(uint64_t fused_0fused_0fused_0fused_0_fuseiter_8874___fuseiter_8875_2740___fuseiter_8876_2741___fuseiter_8877_2742___fuseiter_8878_2743, float* __restrict__ __ins_0, float* __restrict__ __outs_0) noexcept __attribute__((nonnull (2,3)));
static void mul__5990_closure_95(uint64_t fused_0fused_0fused_0fused_0__itr_0____itr_1_2744____itr_2_2745____itr_3_2746____itr_4_2747, float* __restrict__ __ins_0, float* __restrict__ __ins_1, float* __restrict__ __outs_0) noexcept __attribute__((nonnull (2,3,4)));
static void reorder__4530_closure_96(uint64_t fused_0fused_0fused_0fused_0_fuseiter_8887___fuseiter_8888_2748___fuseiter_8889_2749___fuseiter_8890_2750___fuseiter_8891_2751, float* __restrict__ __ins_0, float* __restrict__ __outs_0) noexcept __attribute__((nonnull (2,3)));
static void mul__6010_closure_97(uint64_t fused_0fused_0fused_0fused_0__itr_0____itr_1_2752____itr_2_2753____itr_3_2754____itr_4_2755, float* __restrict__ __ins_0, float* __restrict__ __ins_1, float* __restrict__ __outs_0) noexcept __attribute__((nonnull (2,3,4)));
static void reorder__4590_closure_98(uint64_t fused_0fused_0fused_0fused_0_fuseiter_8900___fuseiter_8901_2756___fuseiter_8902_2757___fuseiter_8903_2758___fuseiter_8904_2759, float* __restrict__ __ins_0, float* __restrict__ __outs_0) noexcept __attribute__((nonnull (2,3)));
static void mul__6050_closure_99(uint64_t fused_0fused_0fused_0fused_0__itr_0____itr_1_2760____itr_2_2761____itr_3_2762____itr_4_2763, float* __restrict__ __ins_0, float* __restrict__ __ins_1, float* __restrict__ __outs_0) noexcept __attribute__((nonnull (2,3,4)));
static void reorder__4620_closure_100(uint64_t fused_0fused_0fused_0fused_0_fuseiter_8913___fuseiter_8914_2764___fuseiter_8915_2765___fuseiter_8916_2766___fuseiter_8917_2767, float* __restrict__ __ins_0, float* __restrict__ __outs_0) noexcept __attribute__((nonnull (2,3)));
static void mul__6070_closure_101(uint64_t fused_0fused_0fused_0fused_0__itr_0____itr_1_2768____itr_2_2769____itr_3_2770____itr_4_2771, float* __restrict__ __ins_0, float* __restrict__ __ins_1, float* __restrict__ __outs_0) noexcept __attribute__((nonnull (2,3,4)));
static void reorder__4680_closure_102(uint64_t fused_0fused_0fused_0fused_0_fuseiter_8926___fuseiter_8927_2772___fuseiter_8928_2773___fuseiter_8929_2774___fuseiter_8930_2775, float* __restrict__ __ins_0, float* __restrict__ __outs_0) noexcept __attribute__((nonnull (2,3)));
static void mul__6110_closure_103(uint64_t fused_0fused_0fused_0fused_0__itr_0____itr_1_2776____itr_2_2777____itr_3_2778____itr_4_2779, float* __restrict__ __ins_0, float* __restrict__ __ins_1, float* __restrict__ __outs_0) noexcept __attribute__((nonnull (2,3,4)));
static void reorder__4710_closure_104(uint64_t fused_0fused_0fused_0fused_0_fuseiter_8939___fuseiter_8940_2780___fuseiter_8941_2781___fuseiter_8942_2782___fuseiter_8943_2783, float* __restrict__ __ins_0, float* __restrict__ __outs_0) noexcept __attribute__((nonnull (2,3)));
static void mul__6130_closure_105(uint64_t fused_0fused_0fused_0fused_0__itr_0____itr_1_2784____itr_2_2785____itr_3_2786____itr_4_2787, float* __restrict__ __ins_0, float* __restrict__ __ins_1, float* __restrict__ __outs_0) noexcept __attribute__((nonnull (2,3,4)));
static void reorder__4200_closure_106(uint64_t fused_0fused_0fused_0fused_0_fuseiter_8952___fuseiter_8953_2788___fuseiter_8954_2789___fuseiter_8955_2790___fuseiter_8956_2791, float* __restrict__ __ins_0, float* __restrict__ __outs_0) noexcept __attribute__((nonnull (2,3)));
static void mul__5710_closure_107(uint64_t fused_0fused_0fused_0fused_0__itr_0____itr_1_2792____itr_2_2793____itr_3_2794____itr_4_2795, float* __restrict__ __ins_0, float* __restrict__ __ins_1, float* __restrict__ __outs_0) noexcept __attribute__((nonnull (2,3,4)));
static void reorder__4250_closure_108(uint64_t fused_0fused_0fused_0fused_0_fuseiter_8965___fuseiter_8966_2796___fuseiter_8967_2797___fuseiter_8968_2798___fuseiter_8969_2799, float* __restrict__ __ins_0, float* __restrict__ __outs_0) noexcept __attribute__((nonnull (2,3)));
static void mul__5770_closure_109(uint64_t fused_0fused_0fused_0fused_0__itr_0____itr_1_2800____itr_2_2801____itr_3_2802____itr_4_2803, float* __restrict__ __ins_0, float* __restrict__ __ins_1, float* __restrict__ __outs_0) noexcept __attribute__((nonnull (2,3,4)));
static void reorder__4300_closure_110(uint64_t fused_0fused_0fused_0fused_0_fuseiter_8978___fuseiter_8979_2804___fuseiter_8980_2805___fuseiter_8981_2806___fuseiter_8982_2807, float* __restrict__ __ins_0, float* __restrict__ __outs_0) noexcept __attribute__((nonnull (2,3)));
static void mul__5830_closure_111(uint64_t fused_0fused_0fused_0fused_0__itr_0____itr_1_2808____itr_2_2809____itr_3_2810____itr_4_2811, float* __restrict__ __ins_0, float* __restrict__ __ins_1, float* __restrict__ __outs_0) noexcept __attribute__((nonnull (2,3,4)));
static void reorder__4350_closure_112(uint64_t fused_0fused_0fused_0fused_0_fuseiter_8991___fuseiter_8992_2812___fuseiter_8993_2813___fuseiter_8994_2814___fuseiter_8995_2815, float* __restrict__ __ins_0, float* __restrict__ __outs_0) noexcept __attribute__((nonnull (2,3)));
static void mul__5890_closure_113(uint64_t fused_0fused_0fused_0fused_0__itr_0____itr_1_2816____itr_2_2817____itr_3_2818____itr_4_2819, float* __restrict__ __ins_0, float* __restrict__ __ins_1, float* __restrict__ __outs_0) noexcept __attribute__((nonnull (2,3,4)));
static void reorder__4800_closure_114(uint64_t fused_0fused_0fused_0fused_0_fuseiter_9004___fuseiter_9005_2820___fuseiter_9006_2821___fuseiter_9007_2822___fuseiter_9008_2823, float* __restrict__ __ins_0, float* __restrict__ __outs_0) noexcept __attribute__((nonnull (2,3)));
static void mul__6190_closure_115(uint64_t fused_0fused_0fused_0fused_0__itr_0____itr_1_2824____itr_2_2825____itr_3_2826____itr_4_2827, float* __restrict__ __ins_0, float* __restrict__ __ins_1, float* __restrict__ __outs_0) noexcept __attribute__((nonnull (2,3,4)));
static void reorder__4830_closure_116(uint64_t fused_0fused_0fused_0fused_0_fuseiter_9017___fuseiter_9018_2828___fuseiter_9019_2829___fuseiter_9020_2830___fuseiter_9021_2831, float* __restrict__ __ins_0, float* __restrict__ __outs_0) noexcept __attribute__((nonnull (2,3)));
static void mul__6210_closure_117(uint64_t fused_0fused_0fused_0fused_0__itr_0____itr_1_2832____itr_2_2833____itr_3_2834____itr_4_2835, float* __restrict__ __ins_0, float* __restrict__ __ins_1, float* __restrict__ __outs_0) noexcept __attribute__((nonnull (2,3,4)));
static void reorder__4890_closure_118(uint64_t fused_0fused_0fused_0fused_0_fuseiter_9030___fuseiter_9031_2836___fuseiter_9032_2837___fuseiter_9033_2838___fuseiter_9034_2839, float* __restrict__ __ins_0, float* __restrict__ __outs_0) noexcept __attribute__((nonnull (2,3)));
static void mul__6250_closure_119(uint64_t fused_0fused_0fused_0fused_0__itr_0____itr_1_2840____itr_2_2841____itr_3_2842____itr_4_2843, float* __restrict__ __ins_0, float* __restrict__ __ins_1, float* __restrict__ __outs_0) noexcept __attribute__((nonnull (2,3,4)));
static void reorder__4920_closure_120(uint64_t fused_0fused_0fused_0fused_0_fuseiter_9043___fuseiter_9044_2844___fuseiter_9045_2845___fuseiter_9046_2846___fuseiter_9047_2847, float* __restrict__ __ins_0, float* __restrict__ __outs_0) noexcept __attribute__((nonnull (2,3)));
static void mul__6270_closure_121(uint64_t fused_0fused_0fused_0fused_0__itr_0____itr_1_2848____itr_2_2849____itr_3_2850____itr_4_2851, float* __restrict__ __ins_0, float* __restrict__ __ins_1, float* __restrict__ __outs_0) noexcept __attribute__((nonnull (2,3,4)));
static void reorder__4980_closure_122(uint64_t fused_0fused_0fused_0fused_0_fuseiter_9056___fuseiter_9057_2852___fuseiter_9058_2853___fuseiter_9059_2854___fuseiter_9060_2855, float* __restrict__ __ins_0, float* __restrict__ __outs_0) noexcept __attribute__((nonnull (2,3)));
static void mul__6310_closure_123(uint64_t fused_0fused_0fused_0fused_0__itr_0____itr_1_2856____itr_2_2857____itr_3_2858____itr_4_2859, float* __restrict__ __ins_0, float* __restrict__ __ins_1, float* __restrict__ __outs_0) noexcept __attribute__((nonnull (2,3,4)));
static void reorder__5010_closure_124(uint64_t fused_0fused_0fused_0fused_0_fuseiter_9069___fuseiter_9070_2860___fuseiter_9071_2861___fuseiter_9072_2862___fuseiter_9073_2863, float* __restrict__ __ins_0, float* __restrict__ __outs_0) noexcept __attribute__((nonnull (2,3)));
static void mul__6330_closure_125(uint64_t fused_0fused_0fused_0fused_0__itr_0____itr_1_2864____itr_2_2865____itr_3_2866____itr_4_2867, float* __restrict__ __ins_0, float* __restrict__ __ins_1, float* __restrict__ __outs_0) noexcept __attribute__((nonnull (2,3,4)));
static void reorder__5070_closure_126(uint64_t fused_0fused_0fused_0fused_0_fuseiter_9082___fuseiter_9083_2868___fuseiter_9084_2869___fuseiter_9085_2870___fuseiter_9086_2871, float* __restrict__ __ins_0, float* __restrict__ __outs_0) noexcept __attribute__((nonnull (2,3)));
static void mul__6370_closure_127(uint64_t fused_0fused_0fused_0fused_0__itr_0____itr_1_2872____itr_2_2873____itr_3_2874____itr_4_2875, float* __restrict__ __ins_0, float* __restrict__ __ins_1, float* __restrict__ __outs_0) noexcept __attribute__((nonnull (2,3,4)));
static void reorder__5100_closure_128(uint64_t fused_0fused_0fused_0fused_0_fuseiter_9095___fuseiter_9096_2876___fuseiter_9097_2877___fuseiter_9098_2878___fuseiter_9099_2879, float* __restrict__ __ins_0, float* __restrict__ __outs_0) noexcept __attribute__((nonnull (2,3)));
static void mul__6390_closure_129(uint64_t fused_0fused_0fused_0fused_0__itr_0____itr_1_2880____itr_2_2881____itr_3_2882____itr_4_2883, float* __restrict__ __ins_0, float* __restrict__ __ins_1, float* __restrict__ __outs_0) noexcept __attribute__((nonnull (2,3,4)));
static void reorder__5160_closure_130(uint64_t fused_0fused_0fused_0fused_0_fuseiter_9108___fuseiter_9109_2884___fuseiter_9110_2885___fuseiter_9111_2886___fuseiter_9112_2887, float* __restrict__ __ins_0, float* __restrict__ __outs_0) noexcept __attribute__((nonnull (2,3)));
static void mul__6430_closure_131(uint64_t fused_0fused_0fused_0fused_0__itr_0____itr_1_2888____itr_2_2889____itr_3_2890____itr_4_2891, float* __restrict__ __ins_0, float* __restrict__ __ins_1, float* __restrict__ __outs_0) noexcept __attribute__((nonnull (2,3,4)));
static void reorder__5190_closure_132(uint64_t fused_0fused_0fused_0fused_0_fuseiter_9121___fuseiter_9122_2892___fuseiter_9123_2893___fuseiter_9124_2894___fuseiter_9125_2895, float* __restrict__ __ins_0, float* __restrict__ __outs_0) noexcept __attribute__((nonnull (2,3)));
static void mul__6450_closure_133(uint64_t fused_0fused_0fused_0fused_0__itr_0____itr_1_2896____itr_2_2897____itr_3_2898____itr_4_2899, float* __restrict__ __ins_0, float* __restrict__ __ins_1, float* __restrict__ __outs_0) noexcept __attribute__((nonnull (2,3,4)));
static void reorder__5250_closure_134(uint64_t fused_0fused_0fused_0fused_0_fuseiter_9134___fuseiter_9135_2900___fuseiter_9136_2901___fuseiter_9137_2902___fuseiter_9138_2903, float* __restrict__ __ins_0, float* __restrict__ __outs_0) noexcept __attribute__((nonnull (2,3)));
static void mul__6490_closure_135(uint64_t fused_0fused_0fused_0fused_0__itr_0____itr_1_2904____itr_2_2905____itr_3_2906____itr_4_2907, float* __restrict__ __ins_0, float* __restrict__ __ins_1, float* __restrict__ __outs_0) noexcept __attribute__((nonnull (2,3,4)));
static void reorder__5280_closure_136(uint64_t fused_0fused_0fused_0fused_0_fuseiter_9147___fuseiter_9148_2908___fuseiter_9149_2909___fuseiter_9150_2910___fuseiter_9151_2911, float* __restrict__ __ins_0, float* __restrict__ __outs_0) noexcept __attribute__((nonnull (2,3)));
static void mul__6510_closure_137(uint64_t fused_0fused_0fused_0fused_0__itr_0____itr_1_2912____itr_2_2913____itr_3_2914____itr_4_2915, float* __restrict__ __ins_0, float* __restrict__ __ins_1, float* __restrict__ __outs_0) noexcept __attribute__((nonnull (2,3,4)));
static void reorder__4380_closure_138(uint64_t fused_0fused_0fused_0fused_0_fuseiter_9160___fuseiter_9161_2916___fuseiter_9162_2917___fuseiter_9163_2918___fuseiter_9164_2919, float* __restrict__ __ins_0, float* __restrict__ __outs_0) noexcept __attribute__((nonnull (2,3)));
static void mul__5910_closure_139(uint64_t fused_0fused_0fused_0fused_0__itr_0____itr_1_2920____itr_2_2921____itr_3_2922____itr_4_2923, float* __restrict__ __ins_0, float* __restrict__ __ins_1, float* __restrict__ __outs_0) noexcept __attribute__((nonnull (2,3,4)));
static void reorder__4470_closure_140(uint64_t fused_0fused_0fused_0fused_0_fuseiter_9173___fuseiter_9174_2924___fuseiter_9175_2925___fuseiter_9176_2926___fuseiter_9177_2927, float* __restrict__ __ins_0, float* __restrict__ __outs_0) noexcept __attribute__((nonnull (2,3)));
static void mul__5970_closure_141(uint64_t fused_0fused_0fused_0fused_0__itr_0____itr_1_2928____itr_2_2929____itr_3_2930____itr_4_2931, float* __restrict__ __ins_0, float* __restrict__ __ins_1, float* __restrict__ __outs_0) noexcept __attribute__((nonnull (2,3,4)));
static void reorder__4560_closure_142(uint64_t fused_0fused_0fused_0fused_0_fuseiter_9186___fuseiter_9187_2932___fuseiter_9188_2933___fuseiter_9189_2934___fuseiter_9190_2935, float* __restrict__ __ins_0, float* __restrict__ __outs_0) noexcept __attribute__((nonnull (2,3)));
static void mul__6030_closure_143(uint64_t fused_0fused_0fused_0fused_0__itr_0____itr_1_2936____itr_2_2937____itr_3_2938____itr_4_2939, float* __restrict__ __ins_0, float* __restrict__ __ins_1, float* __restrict__ __outs_0) noexcept __attribute__((nonnull (2,3,4)));
static void reorder__4650_closure_144(uint64_t fused_0fused_0fused_0fused_0_fuseiter_9199___fuseiter_9200_2940___fuseiter_9201_2941___fuseiter_9202_2942___fuseiter_9203_2943, float* __restrict__ __ins_0, float* __restrict__ __outs_0) noexcept __attribute__((nonnull (2,3)));
static void mul__6090_closure_145(uint64_t fused_0fused_0fused_0fused_0__itr_0____itr_1_2944____itr_2_2945____itr_3_2946____itr_4_2947, float* __restrict__ __ins_0, float* __restrict__ __ins_1, float* __restrict__ __outs_0) noexcept __attribute__((nonnull (2,3,4)));
static void reorder__4740_closure_146(uint64_t fused_0fused_0fused_0fused_0_fuseiter_9212___fuseiter_9213_2948___fuseiter_9214_2949___fuseiter_9215_2950___fuseiter_9216_2951, float* __restrict__ __ins_0, float* __restrict__ __outs_0) noexcept __attribute__((nonnull (2,3)));
static void mul__6150_closure_147(uint64_t fused_0fused_0fused_0fused_0__itr_0____itr_1_2952____itr_2_2953____itr_3_2954____itr_4_2955, float* __restrict__ __ins_0, float* __restrict__ __ins_1, float* __restrict__ __outs_0) noexcept __attribute__((nonnull (2,3,4)));
static void reorder__5380_closure_148(uint64_t fused_0fused_0fused_0fused_0_fuseiter_9232___fuseiter_9233_2960___fuseiter_9234_2961___fuseiter_9235_2962___fuseiter_9236_2963, float* __restrict__ __ins_0, float* __restrict__ __outs_0) noexcept __attribute__((nonnull (2,3)));
static void mul__6590_closure_149(uint64_t fused_0fused_0fused_0fused_0__itr_0____itr_1_2964____itr_2_2965____itr_3_2966____itr_4_2967, float* __restrict__ __ins_0, float* __restrict__ __ins_1, float* __restrict__ __outs_0) noexcept __attribute__((nonnull (2,3,4)));
static void reorder__5440_closure_150(uint64_t fused_0fused_0fused_0fused_0_fuseiter_9245___fuseiter_9246_2968___fuseiter_9247_2969___fuseiter_9248_2970___fuseiter_9249_2971, float* __restrict__ __ins_0, float* __restrict__ __outs_0) noexcept __attribute__((nonnull (2,3)));
static void mul__6630_closure_151(uint64_t fused_0fused_0fused_0fused_0__itr_0____itr_1_2972____itr_2_2973____itr_3_2974____itr_4_2975, float* __restrict__ __ins_0, float* __restrict__ __ins_1, float* __restrict__ __outs_0) noexcept __attribute__((nonnull (2,3,4)));
static void reorder__5470_closure_152(uint64_t fused_0fused_0fused_0fused_0_fuseiter_9258___fuseiter_9259_2976___fuseiter_9260_2977___fuseiter_9261_2978___fuseiter_9262_2979, float* __restrict__ __ins_0, float* __restrict__ __outs_0) noexcept __attribute__((nonnull (2,3)));
static void mul__6650_closure_153(uint64_t fused_0fused_0fused_0fused_0__itr_0____itr_1_2980____itr_2_2981____itr_3_2982____itr_4_2983, float* __restrict__ __ins_0, float* __restrict__ __ins_1, float* __restrict__ __outs_0) noexcept __attribute__((nonnull (2,3,4)));
static void reorder__5530_closure_154(uint64_t fused_0fused_0fused_0fused_0_fuseiter_9271___fuseiter_9272_2984___fuseiter_9273_2985___fuseiter_9274_2986___fuseiter_9275_2987, float* __restrict__ __ins_0, float* __restrict__ __outs_0) noexcept __attribute__((nonnull (2,3)));
static void mul__6690_closure_155(uint64_t fused_0fused_0fused_0fused_0__itr_0____itr_1_2988____itr_2_2989____itr_3_2990____itr_4_2991, float* __restrict__ __ins_0, float* __restrict__ __ins_1, float* __restrict__ __outs_0) noexcept __attribute__((nonnull (2,3,4)));
static void reorder__5560_closure_156(uint64_t fused_0fused_0fused_0fused_0_fuseiter_9284___fuseiter_9285_2992___fuseiter_9286_2993___fuseiter_9287_2994___fuseiter_9288_2995, float* __restrict__ __ins_0, float* __restrict__ __outs_0) noexcept __attribute__((nonnull (2,3)));
static void mul__6710_closure_157(uint64_t fused_0fused_0fused_0fused_0__itr_0____itr_1_2996____itr_2_2997____itr_3_2998____itr_4_2999, float* __restrict__ __ins_0, float* __restrict__ __ins_1, float* __restrict__ __outs_0) noexcept __attribute__((nonnull (2,3,4)));
static void reorder__4770_closure_158(uint64_t fused_0fused_0fused_0fused_0_fuseiter_9297___fuseiter_9298_3000___fuseiter_9299_3001___fuseiter_9300_3002___fuseiter_9301_3003, float* __restrict__ __ins_0, float* __restrict__ __outs_0) noexcept __attribute__((nonnull (2,3)));
static void mul__6170_closure_159(uint64_t fused_0fused_0fused_0fused_0__itr_0____itr_1_3004____itr_2_3005____itr_3_3006____itr_4_3007, float* __restrict__ __ins_0, float* __restrict__ __ins_1, float* __restrict__ __outs_0) noexcept __attribute__((nonnull (2,3,4)));
static void reorder__4860_closure_160(uint64_t fused_0fused_0fused_0fused_0_fuseiter_9310___fuseiter_9311_3008___fuseiter_9312_3009___fuseiter_9313_3010___fuseiter_9314_3011, float* __restrict__ __ins_0, float* __restrict__ __outs_0) noexcept __attribute__((nonnull (2,3)));
static void mul__6230_closure_161(uint64_t fused_0fused_0fused_0fused_0__itr_0____itr_1_3012____itr_2_3013____itr_3_3014____itr_4_3015, float* __restrict__ __ins_0, float* __restrict__ __ins_1, float* __restrict__ __outs_0) noexcept __attribute__((nonnull (2,3,4)));
static void reorder__4950_closure_162(uint64_t fused_0fused_0fused_0fused_0_fuseiter_9323___fuseiter_9324_3016___fuseiter_9325_3017___fuseiter_9326_3018___fuseiter_9327_3019, float* __restrict__ __ins_0, float* __restrict__ __outs_0) noexcept __attribute__((nonnull (2,3)));
static void mul__6290_closure_163(uint64_t fused_0fused_0fused_0fused_0__itr_0____itr_1_3020____itr_2_3021____itr_3_3022____itr_4_3023, float* __restrict__ __ins_0, float* __restrict__ __ins_1, float* __restrict__ __outs_0) noexcept __attribute__((nonnull (2,3,4)));
static void reorder__5040_closure_164(uint64_t fused_0fused_0fused_0fused_0_fuseiter_9336___fuseiter_9337_3024___fuseiter_9338_3025___fuseiter_9339_3026___fuseiter_9340_3027, float* __restrict__ __ins_0, float* __restrict__ __outs_0) noexcept __attribute__((nonnull (2,3)));
static void mul__6350_closure_165(uint64_t fused_0fused_0fused_0fused_0__itr_0____itr_1_3028____itr_2_3029____itr_3_3030____itr_4_3031, float* __restrict__ __ins_0, float* __restrict__ __ins_1, float* __restrict__ __outs_0) noexcept __attribute__((nonnull (2,3,4)));
static void reorder__5130_closure_166(uint64_t fused_0fused_0fused_0fused_0_fuseiter_9349___fuseiter_9350_3032___fuseiter_9351_3033___fuseiter_9352_3034___fuseiter_9353_3035, float* __restrict__ __ins_0, float* __restrict__ __outs_0) noexcept __attribute__((nonnull (2,3)));
static void mul__6410_closure_167(uint64_t fused_0fused_0fused_0fused_0__itr_0____itr_1_3036____itr_2_3037____itr_3_3038____itr_4_3039, float* __restrict__ __ins_0, float* __restrict__ __ins_1, float* __restrict__ __outs_0) noexcept __attribute__((nonnull (2,3,4)));
static void reorder__5220_closure_168(uint64_t fused_0fused_0fused_0fused_0_fuseiter_9362___fuseiter_9363_3040___fuseiter_9364_3041___fuseiter_9365_3042___fuseiter_9366_3043, float* __restrict__ __ins_0, float* __restrict__ __outs_0) noexcept __attribute__((nonnull (2,3)));
static void mul__6470_closure_169(uint64_t fused_0fused_0fused_0fused_0__itr_0____itr_1_3044____itr_2_3045____itr_3_3046____itr_4_3047, float* __restrict__ __ins_0, float* __restrict__ __ins_1, float* __restrict__ __outs_0) noexcept __attribute__((nonnull (2,3,4)));
static void reorder__5310_closure_170(uint64_t fused_0fused_0fused_0fused_0_fuseiter_9375___fuseiter_9376_3048___fuseiter_9377_3049___fuseiter_9378_3050___fuseiter_9379_3051, float* __restrict__ __ins_0, float* __restrict__ __outs_0) noexcept __attribute__((nonnull (2,3)));
static void mul__6530_closure_171(uint64_t fused_0fused_0fused_0fused_0__itr_0____itr_1_3052____itr_2_3053____itr_3_3054____itr_4_3055, float* __restrict__ __ins_0, float* __restrict__ __ins_1, float* __restrict__ __outs_0) noexcept __attribute__((nonnull (2,3,4)));
static void reorder__5340_closure_172(uint64_t fused_0fused_0fused_0fused_0_fuseiter_9388___fuseiter_9389_3056___fuseiter_9390_3057___fuseiter_9391_3058___fuseiter_9392_3059, float* __restrict__ __ins_0, float* __restrict__ __outs_0) noexcept __attribute__((nonnull (2,3)));
static void mul__6550_closure_173(uint64_t fused_0fused_0fused_0fused_0__itr_0____itr_1_3060____itr_2_3061____itr_3_3062____itr_4_3063, float* __restrict__ __ins_0, float* __restrict__ __ins_1, float* __restrict__ __outs_0) noexcept __attribute__((nonnull (2,3,4)));
static void reorder__5410_closure_174(uint64_t fused_0fused_0fused_0fused_0_fuseiter_9401___fuseiter_9402_3064___fuseiter_9403_3065___fuseiter_9404_3066___fuseiter_9405_3067, float* __restrict__ __ins_0, float* __restrict__ __outs_0) noexcept __attribute__((nonnull (2,3)));
static void mul__6610_closure_175(uint64_t fused_0fused_0fused_0fused_0__itr_0____itr_1_3068____itr_2_3069____itr_3_3070____itr_4_3071, float* __restrict__ __ins_0, float* __restrict__ __ins_1, float* __restrict__ __outs_0) noexcept __attribute__((nonnull (2,3,4)));
static void reorder__5500_closure_176(uint64_t fused_0fused_0fused_0fused_0_fuseiter_9414___fuseiter_9415_3072___fuseiter_9416_3073___fuseiter_9417_3074___fuseiter_9418_3075, float* __restrict__ __ins_0, float* __restrict__ __outs_0) noexcept __attribute__((nonnull (2,3)));
static void mul__6670_closure_177(uint64_t fused_0fused_0fused_0fused_0__itr_0____itr_1_3076____itr_2_3077____itr_3_3078____itr_4_3079, float* __restrict__ __ins_0, float* __restrict__ __ins_1, float* __restrict__ __outs_0) noexcept __attribute__((nonnull (2,3,4)));
static void reorder__5590_closure_178(uint64_t fused_0fused_0fused_0fused_0_fuseiter_9427___fuseiter_9428_3080___fuseiter_9429_3081___fuseiter_9430_3082___fuseiter_9431_3083, float* __restrict__ __ins_0, float* __restrict__ __outs_0) noexcept __attribute__((nonnull (2,3)));
static void mul__6730_closure_179(uint64_t fused_0fused_0fused_0fused_0__itr_0____itr_1_3084____itr_2_3085____itr_3_3086____itr_4_3087, float* __restrict__ __ins_0, float* __restrict__ __ins_1, float* __restrict__ __outs_0) noexcept __attribute__((nonnull (2,3,4)));
static void mul__1100_closure_180(uint64_t fused_0fused_0__itr_0____itr_1_3088____itr_2_3089, float* __restrict__ __ins_0, float* __restrict__ __ins_1, float* __restrict__ __outs_0) noexcept __attribute__((nonnull (2,3,4)));
static void cast__1110_closure_181(uint64_t fused_0fused_0__itr_0____itr_1_3090____itr_2_3091, float* __restrict__ __ins_0, int8_t* __restrict__ __outs_0) noexcept __attribute__((nonnull (2,3)));
static void reorder__4210_closure_182(uint64_t fused_0fused_0fused_0fused_0fused_0_fuseiter_9450___fuseiter_9451_3092___fuseiter_9452_3093___fuseiter_9453_3094___fuseiter_9454_3095___fuseiter_9455_3096, int8_t* __restrict__ __ins_0, int8_t* __restrict__ __outs_0) noexcept __attribute__((nonnull (2,3)));
static void mul__1070_closure_183(uint64_t fused_0fused_0__itr_0____itr_1_3097____itr_2_3098, float* __restrict__ __ins_0, float* __restrict__ __ins_1, float* __restrict__ __outs_0) noexcept __attribute__((nonnull (2,3,4)));
static void cast__1080_closure_184(uint64_t fused_0fused_0__itr_0____itr_1_3099____itr_2_3100, float* __restrict__ __ins_0, int8_t* __restrict__ __outs_0) noexcept __attribute__((nonnull (2,3)));
static void reorder__4180_closure_185(uint64_t fused_0fused_0fused_0fused_0_fuseiter_9467___fuseiter_9468_3101___fuseiter_9469_3102___fuseiter_9470_3103___fuseiter_9471_3104, int8_t* __restrict__ __ins_0, int8_t* __restrict__ __outs_0) noexcept __attribute__((nonnull (2,3)));
static void mul__1160_closure_186(uint64_t fused_0fused_0__itr_0____itr_1_3105____itr_2_3106, float* __restrict__ __ins_0, float* __restrict__ __ins_1, float* __restrict__ __outs_0) noexcept __attribute__((nonnull (2,3,4)));
static void cast__1170_closure_187(uint64_t fused_0fused_0__itr_0____itr_1_3107____itr_2_3108, float* __restrict__ __ins_0, int8_t* __restrict__ __outs_0) noexcept __attribute__((nonnull (2,3)));
static void reorder__4230_closure_188(uint64_t fused_0fused_0fused_0fused_0_fuseiter_9484___fuseiter_9485_3109___fuseiter_9486_3110___fuseiter_9487_3111___fuseiter_9488_3112, int8_t* __restrict__ __ins_0, int8_t* __restrict__ __outs_0) noexcept __attribute__((nonnull (2,3)));
static void mul__1250_closure_189(uint64_t fused_0fused_0__itr_0____itr_1_3113____itr_2_3114, float* __restrict__ __ins_0, float* __restrict__ __ins_1, float* __restrict__ __outs_0) noexcept __attribute__((nonnull (2,3,4)));
static void cast__1260_closure_190(uint64_t fused_0fused_0__itr_0____itr_1_3115____itr_2_3116, float* __restrict__ __ins_0, int8_t* __restrict__ __outs_0) noexcept __attribute__((nonnull (2,3)));
static void reorder__4280_closure_191(uint64_t fused_0fused_0fused_0fused_0_fuseiter_9501___fuseiter_9502_3117___fuseiter_9503_3118___fuseiter_9504_3119___fuseiter_9505_3120, int8_t* __restrict__ __ins_0, int8_t* __restrict__ __outs_0) noexcept __attribute__((nonnull (2,3)));
static void mul__1340_closure_192(uint64_t fused_0fused_0__itr_0____itr_1_3121____itr_2_3122, float* __restrict__ __ins_0, float* __restrict__ __ins_1, float* __restrict__ __outs_0) noexcept __attribute__((nonnull (2,3,4)));
static void cast__1350_closure_193(uint64_t fused_0fused_0__itr_0____itr_1_3123____itr_2_3124, float* __restrict__ __ins_0, int8_t* __restrict__ __outs_0) noexcept __attribute__((nonnull (2,3)));
static void reorder__4330_closure_194(uint64_t fused_0fused_0fused_0fused_0_fuseiter_9518___fuseiter_9519_3125___fuseiter_9520_3126___fuseiter_9521_3127___fuseiter_9522_3128, int8_t* __restrict__ __ins_0, int8_t* __restrict__ __outs_0) noexcept __attribute__((nonnull (2,3)));
static void mul__1190_closure_195(uint64_t fused_0fused_0__itr_0____itr_1_3129____itr_2_3130, float* __restrict__ __ins_0, float* __restrict__ __ins_1, float* __restrict__ __outs_0) noexcept __attribute__((nonnull (2,3,4)));
static void cast__1200_closure_196(uint64_t fused_0fused_0__itr_0____itr_1_3131____itr_2_3132, float* __restrict__ __ins_0, int8_t* __restrict__ __outs_0) noexcept __attribute__((nonnull (2,3)));
static void reorder__4260_closure_197(uint64_t fused_0fused_0fused_0fused_0_fuseiter_9535___fuseiter_9536_3133___fuseiter_9537_3134___fuseiter_9538_3135___fuseiter_9539_3136, int8_t* __restrict__ __ins_0, int8_t* __restrict__ __outs_0) noexcept __attribute__((nonnull (2,3)));
static void mul__1280_closure_198(uint64_t fused_0fused_0__itr_0____itr_1_3137____itr_2_3138, float* __restrict__ __ins_0, float* __restrict__ __ins_1, float* __restrict__ __outs_0) noexcept __attribute__((nonnull (2,3,4)));
static void cast__1290_closure_199(uint64_t fused_0fused_0__itr_0____itr_1_3139____itr_2_3140, float* __restrict__ __ins_0, int8_t* __restrict__ __outs_0) noexcept __attribute__((nonnull (2,3)));
static void reorder__4310_closure_200(uint64_t fused_0fused_0fused_0fused_0_fuseiter_9552___fuseiter_9553_3141___fuseiter_9554_3142___fuseiter_9555_3143___fuseiter_9556_3144, int8_t* __restrict__ __ins_0, int8_t* __restrict__ __outs_0) noexcept __attribute__((nonnull (2,3)));
static void mul__1400_closure_201(uint64_t fused_0fused_0__itr_0____itr_1_3145____itr_2_3146, float* __restrict__ __ins_0, float* __restrict__ __ins_1, float* __restrict__ __outs_0) noexcept __attribute__((nonnull (2,3,4)));
static void cast__1410_closure_202(uint64_t fused_0fused_0__itr_0____itr_1_3147____itr_2_3148, float* __restrict__ __ins_0, int8_t* __restrict__ __outs_0) noexcept __attribute__((nonnull (2,3)));
static void reorder__4390_closure_203(uint64_t fused_0fused_0fused_0fused_0_fuseiter_9569___fuseiter_9570_3149___fuseiter_9571_3150___fuseiter_9572_3151___fuseiter_9573_3152, int8_t* __restrict__ __ins_0, int8_t* __restrict__ __outs_0) noexcept __attribute__((nonnull (2,3)));
static void mul__1130_closure_204(uint64_t fused_0fused_0__itr_0____itr_1_3153____itr_2_3154, float* __restrict__ __ins_0, float* __restrict__ __ins_1, float* __restrict__ __outs_0) noexcept __attribute__((nonnull (2,3,4)));
static void cast__1140_closure_205(uint64_t fused_0fused_0__itr_0____itr_1_3155____itr_2_3156, float* __restrict__ __ins_0, int8_t* __restrict__ __outs_0) noexcept __attribute__((nonnull (2,3)));
static void reorder__4220_closure_206(uint64_t fused_0fused_0fused_0fused_0_fuseiter_9586___fuseiter_9587_3157___fuseiter_9588_3158___fuseiter_9589_3159___fuseiter_9590_3160, int8_t* __restrict__ __ins_0, int8_t* __restrict__ __outs_0) noexcept __attribute__((nonnull (2,3)));
static void mul__1220_closure_207(uint64_t fused_0fused_0__itr_0____itr_1_3161____itr_2_3162, float* __restrict__ __ins_0, float* __restrict__ __ins_1, float* __restrict__ __outs_0) noexcept __attribute__((nonnull (2,3,4)));
static void cast__1230_closure_208(uint64_t fused_0fused_0__itr_0____itr_1_3163____itr_2_3164, float* __restrict__ __ins_0, int8_t* __restrict__ __outs_0) noexcept __attribute__((nonnull (2,3)));
static void reorder__4270_closure_209(uint64_t fused_0fused_0fused_0fused_0_fuseiter_9603___fuseiter_9604_3165___fuseiter_9605_3166___fuseiter_9606_3167___fuseiter_9607_3168, int8_t* __restrict__ __ins_0, int8_t* __restrict__ __outs_0) noexcept __attribute__((nonnull (2,3)));
static void mul__1310_closure_210(uint64_t fused_0fused_0__itr_0____itr_1_3169____itr_2_3170, float* __restrict__ __ins_0, float* __restrict__ __ins_1, float* __restrict__ __outs_0) noexcept __attribute__((nonnull (2,3,4)));
static void cast__1320_closure_211(uint64_t fused_0fused_0__itr_0____itr_1_3171____itr_2_3172, float* __restrict__ __ins_0, int8_t* __restrict__ __outs_0) noexcept __attribute__((nonnull (2,3)));
static void reorder__4320_closure_212(uint64_t fused_0fused_0fused_0fused_0_fuseiter_9620___fuseiter_9621_3173___fuseiter_9622_3174___fuseiter_9623_3175___fuseiter_9624_3176, int8_t* __restrict__ __ins_0, int8_t* __restrict__ __outs_0) noexcept __attribute__((nonnull (2,3)));
static void mul__1460_closure_213(uint64_t fused_0fused_0__itr_0____itr_1_3177____itr_2_3178, float* __restrict__ __ins_0, float* __restrict__ __ins_1, float* __restrict__ __outs_0) noexcept __attribute__((nonnull (2,3,4)));
static void cast__1470_closure_214(uint64_t fused_0fused_0__itr_0____itr_1_3179____itr_2_3180, float* __restrict__ __ins_0, int8_t* __restrict__ __outs_0) noexcept __attribute__((nonnull (2,3)));
static void reorder__4450_closure_215(uint64_t fused_0fused_0fused_0fused_0_fuseiter_9637___fuseiter_9638_3181___fuseiter_9639_3182___fuseiter_9640_3183___fuseiter_9641_3184, int8_t* __restrict__ __ins_0, int8_t* __restrict__ __outs_0) noexcept __attribute__((nonnull (2,3)));
static void mul__1550_closure_216(uint64_t fused_0fused_0__itr_0____itr_1_3185____itr_2_3186, float* __restrict__ __ins_0, float* __restrict__ __ins_1, float* __restrict__ __outs_0) noexcept __attribute__((nonnull (2,3,4)));
static void cast__1560_closure_217(uint64_t fused_0fused_0__itr_0____itr_1_3187____itr_2_3188, float* __restrict__ __ins_0, int8_t* __restrict__ __outs_0) noexcept __attribute__((nonnull (2,3)));
static void reorder__4540_closure_218(uint64_t fused_0fused_0fused_0fused_0_fuseiter_9654___fuseiter_9655_3189___fuseiter_9656_3190___fuseiter_9657_3191___fuseiter_9658_3192, int8_t* __restrict__ __ins_0, int8_t* __restrict__ __outs_0) noexcept __attribute__((nonnull (2,3)));
static void mul__1640_closure_219(uint64_t fused_0fused_0__itr_0____itr_1_3193____itr_2_3194, float* __restrict__ __ins_0, float* __restrict__ __ins_1, float* __restrict__ __outs_0) noexcept __attribute__((nonnull (2,3,4)));
static void cast__1650_closure_220(uint64_t fused_0fused_0__itr_0____itr_1_3195____itr_2_3196, float* __restrict__ __ins_0, int8_t* __restrict__ __outs_0) noexcept __attribute__((nonnull (2,3)));
static void reorder__4630_closure_221(uint64_t fused_0fused_0fused_0fused_0_fuseiter_9671___fuseiter_9672_3197___fuseiter_9673_3198___fuseiter_9674_3199___fuseiter_9675_3200, int8_t* __restrict__ __ins_0, int8_t* __restrict__ __outs_0) noexcept __attribute__((nonnull (2,3)));
static void mul__1730_closure_222(uint64_t fused_0fused_0__itr_0____itr_1_3201____itr_2_3202, float* __restrict__ __ins_0, float* __restrict__ __ins_1, float* __restrict__ __outs_0) noexcept __attribute__((nonnull (2,3,4)));
static void cast__1740_closure_223(uint64_t fused_0fused_0__itr_0____itr_1_3203____itr_2_3204, float* __restrict__ __ins_0, int8_t* __restrict__ __outs_0) noexcept __attribute__((nonnull (2,3)));
static void reorder__4720_closure_224(uint64_t fused_0fused_0fused_0fused_0_fuseiter_9688___fuseiter_9689_3205___fuseiter_9690_3206___fuseiter_9691_3207___fuseiter_9692_3208, int8_t* __restrict__ __ins_0, int8_t* __restrict__ __outs_0) noexcept __attribute__((nonnull (2,3)));
static void mul__1490_closure_225(uint64_t fused_0fused_0__itr_0____itr_1_3209____itr_2_3210, float* __restrict__ __ins_0, float* __restrict__ __ins_1, float* __restrict__ __outs_0) noexcept __attribute__((nonnull (2,3,4)));
static void cast__1500_closure_226(uint64_t fused_0fused_0__itr_0____itr_1_3211____itr_2_3212, float* __restrict__ __ins_0, int8_t* __restrict__ __outs_0) noexcept __attribute__((nonnull (2,3)));
static void reorder__4480_closure_227(uint64_t fused_0fused_0fused_0fused_0_fuseiter_9705___fuseiter_9706_3213___fuseiter_9707_3214___fuseiter_9708_3215___fuseiter_9709_3216, int8_t* __restrict__ __ins_0, int8_t* __restrict__ __outs_0) noexcept __attribute__((nonnull (2,3)));
static void mul__1580_closure_228(uint64_t fused_0fused_0__itr_0____itr_1_3217____itr_2_3218, float* __restrict__ __ins_0, float* __restrict__ __ins_1, float* __restrict__ __outs_0) noexcept __attribute__((nonnull (2,3,4)));
static void cast__1590_closure_229(uint64_t fused_0fused_0__itr_0____itr_1_3219____itr_2_3220, float* __restrict__ __ins_0, int8_t* __restrict__ __outs_0) noexcept __attribute__((nonnull (2,3)));
static void reorder__4570_closure_230(uint64_t fused_0fused_0fused_0fused_0_fuseiter_9722___fuseiter_9723_3221___fuseiter_9724_3222___fuseiter_9725_3223___fuseiter_9726_3224, int8_t* __restrict__ __ins_0, int8_t* __restrict__ __outs_0) noexcept __attribute__((nonnull (2,3)));
static void mul__1670_closure_231(uint64_t fused_0fused_0__itr_0____itr_1_3225____itr_2_3226, float* __restrict__ __ins_0, float* __restrict__ __ins_1, float* __restrict__ __outs_0) noexcept __attribute__((nonnull (2,3,4)));
static void cast__1680_closure_232(uint64_t fused_0fused_0__itr_0____itr_1_3227____itr_2_3228, float* __restrict__ __ins_0, int8_t* __restrict__ __outs_0) noexcept __attribute__((nonnull (2,3)));
static void reorder__4660_closure_233(uint64_t fused_0fused_0fused_0fused_0_fuseiter_9739___fuseiter_9740_3229___fuseiter_9741_3230___fuseiter_9742_3231___fuseiter_9743_3232, int8_t* __restrict__ __ins_0, int8_t* __restrict__ __outs_0) noexcept __attribute__((nonnull (2,3)));
static void mul__1370_closure_234(uint64_t fused_0fused_0__itr_0____itr_1_3233____itr_2_3234, float* __restrict__ __ins_0, float* __restrict__ __ins_1, float* __restrict__ __outs_0) noexcept __attribute__((nonnull (2,3,4)));
static void cast__1380_closure_235(uint64_t fused_0fused_0__itr_0____itr_1_3235____itr_2_3236, float* __restrict__ __ins_0, int8_t* __restrict__ __outs_0) noexcept __attribute__((nonnull (2,3)));
static void reorder__4360_closure_236(uint64_t fused_0_fuseiter_9756___fuseiter_9757_3237, int8_t* __restrict__ __ins_0, int8_t* __restrict__ __outs_0) noexcept __attribute__((nonnull (2,3)));
static void mul__1790_closure_237(uint64_t fused_0fused_0__itr_0____itr_1_3238____itr_2_3239, float* __restrict__ __ins_0, float* __restrict__ __ins_1, float* __restrict__ __outs_0) noexcept __attribute__((nonnull (2,3,4)));
static void cast__1800_closure_238(uint64_t fused_0fused_0__itr_0____itr_1_3240____itr_2_3241, float* __restrict__ __ins_0, int8_t* __restrict__ __outs_0) noexcept __attribute__((nonnull (2,3)));
static void reorder__4780_closure_239(uint64_t fused_0_fuseiter_9773___fuseiter_9774_3242, int8_t* __restrict__ __ins_0, int8_t* __restrict__ __outs_0) noexcept __attribute__((nonnull (2,3)));
static void mul__1430_closure_240(uint64_t fused_0fused_0__itr_0____itr_1_3243____itr_2_3244, float* __restrict__ __ins_0, float* __restrict__ __ins_1, float* __restrict__ __outs_0) noexcept __attribute__((nonnull (2,3,4)));
static void cast__1440_closure_241(uint64_t fused_0fused_0__itr_0____itr_1_3245____itr_2_3246, float* __restrict__ __ins_0, int8_t* __restrict__ __outs_0) noexcept __attribute__((nonnull (2,3)));
static void reorder__4420_closure_242(uint64_t fused_0fused_0fused_0_fuseiter_9790___fuseiter_9791_3247___fuseiter_9792_3248___fuseiter_9793_3249, int8_t* __restrict__ __ins_0, int8_t* __restrict__ __outs_0) noexcept __attribute__((nonnull (2,3)));
static void mul__1520_closure_243(uint64_t fused_0fused_0__itr_0____itr_1_3250____itr_2_3251, float* __restrict__ __ins_0, float* __restrict__ __ins_1, float* __restrict__ __outs_0) noexcept __attribute__((nonnull (2,3,4)));
static void cast__1530_closure_244(uint64_t fused_0fused_0__itr_0____itr_1_3252____itr_2_3253, float* __restrict__ __ins_0, int8_t* __restrict__ __outs_0) noexcept __attribute__((nonnull (2,3)));
static void reorder__4510_closure_245(uint64_t fused_0fused_0fused_0_fuseiter_9807___fuseiter_9808_3254___fuseiter_9809_3255___fuseiter_9810_3256, int8_t* __restrict__ __ins_0, int8_t* __restrict__ __outs_0) noexcept __attribute__((nonnull (2,3)));
static void mul__1610_closure_246(uint64_t fused_0fused_0__itr_0____itr_1_3257____itr_2_3258, float* __restrict__ __ins_0, float* __restrict__ __ins_1, float* __restrict__ __outs_0) noexcept __attribute__((nonnull (2,3,4)));
static void cast__1620_closure_247(uint64_t fused_0fused_0__itr_0____itr_1_3259____itr_2_3260, float* __restrict__ __ins_0, int8_t* __restrict__ __outs_0) noexcept __attribute__((nonnull (2,3)));
static void reorder__4600_closure_248(uint64_t fused_0fused_0fused_0_fuseiter_9824___fuseiter_9825_3261___fuseiter_9826_3262___fuseiter_9827_3263, int8_t* __restrict__ __ins_0, int8_t* __restrict__ __outs_0) noexcept __attribute__((nonnull (2,3)));
static void mul__1700_closure_249(uint64_t fused_0fused_0__itr_0____itr_1_3264____itr_2_3265, float* __restrict__ __ins_0, float* __restrict__ __ins_1, float* __restrict__ __outs_0) noexcept __attribute__((nonnull (2,3,4)));
static void cast__1710_closure_250(uint64_t fused_0fused_0__itr_0____itr_1_3266____itr_2_3267, float* __restrict__ __ins_0, int8_t* __restrict__ __outs_0) noexcept __attribute__((nonnull (2,3)));
static void reorder__4690_closure_251(uint64_t fused_0fused_0fused_0_fuseiter_9841___fuseiter_9842_3268___fuseiter_9843_3269___fuseiter_9844_3270, int8_t* __restrict__ __ins_0, int8_t* __restrict__ __outs_0) noexcept __attribute__((nonnull (2,3)));
static void mul__1850_closure_252(uint64_t fused_0fused_0__itr_0____itr_1_3271____itr_2_3272, float* __restrict__ __ins_0, float* __restrict__ __ins_1, float* __restrict__ __outs_0) noexcept __attribute__((nonnull (2,3,4)));
static void cast__1860_closure_253(uint64_t fused_0fused_0__itr_0____itr_1_3273____itr_2_3274, float* __restrict__ __ins_0, int8_t* __restrict__ __outs_0) noexcept __attribute__((nonnull (2,3)));
static void reorder__4840_closure_254(uint64_t fused_0_fuseiter_9858___fuseiter_9859_3275, int8_t* __restrict__ __ins_0, int8_t* __restrict__ __outs_0) noexcept __attribute__((nonnull (2,3)));
static void mul__1940_closure_255(uint64_t fused_0fused_0__itr_0____itr_1_3276____itr_2_3277, float* __restrict__ __ins_0, float* __restrict__ __ins_1, float* __restrict__ __outs_0) noexcept __attribute__((nonnull (2,3,4)));
static void cast__1950_closure_256(uint64_t fused_0fused_0__itr_0____itr_1_3278____itr_2_3279, float* __restrict__ __ins_0, int8_t* __restrict__ __outs_0) noexcept __attribute__((nonnull (2,3)));
static void reorder__4930_closure_257(uint64_t fused_0_fuseiter_9875___fuseiter_9876_3280, int8_t* __restrict__ __ins_0, int8_t* __restrict__ __outs_0) noexcept __attribute__((nonnull (2,3)));
static void mul__2030_closure_258(uint64_t fused_0fused_0__itr_0____itr_1_3281____itr_2_3282, float* __restrict__ __ins_0, float* __restrict__ __ins_1, float* __restrict__ __outs_0) noexcept __attribute__((nonnull (2,3,4)));
static void cast__2040_closure_259(uint64_t fused_0fused_0__itr_0____itr_1_3283____itr_2_3284, float* __restrict__ __ins_0, int8_t* __restrict__ __outs_0) noexcept __attribute__((nonnull (2,3)));
static void reorder__5020_closure_260(uint64_t fused_0_fuseiter_9892___fuseiter_9893_3285, int8_t* __restrict__ __ins_0, int8_t* __restrict__ __outs_0) noexcept __attribute__((nonnull (2,3)));
static void mul__2120_closure_261(uint64_t fused_0fused_0__itr_0____itr_1_3286____itr_2_3287, float* __restrict__ __ins_0, float* __restrict__ __ins_1, float* __restrict__ __outs_0) noexcept __attribute__((nonnull (2,3,4)));
static void cast__2130_closure_262(uint64_t fused_0fused_0__itr_0____itr_1_3288____itr_2_3289, float* __restrict__ __ins_0, int8_t* __restrict__ __outs_0) noexcept __attribute__((nonnull (2,3)));
static void reorder__5110_closure_263(uint64_t fused_0_fuseiter_9909___fuseiter_9910_3290, int8_t* __restrict__ __ins_0, int8_t* __restrict__ __outs_0) noexcept __attribute__((nonnull (2,3)));
static void mul__2210_closure_264(uint64_t fused_0fused_0__itr_0____itr_1_3291____itr_2_3292, float* __restrict__ __ins_0, float* __restrict__ __ins_1, float* __restrict__ __outs_0) noexcept __attribute__((nonnull (2,3,4)));
static void cast__2220_closure_265(uint64_t fused_0fused_0__itr_0____itr_1_3293____itr_2_3294, float* __restrict__ __ins_0, int8_t* __restrict__ __outs_0) noexcept __attribute__((nonnull (2,3)));
static void reorder__5200_closure_266(uint64_t fused_0_fuseiter_9926___fuseiter_9927_3295, int8_t* __restrict__ __ins_0, int8_t* __restrict__ __outs_0) noexcept __attribute__((nonnull (2,3)));
static void mul__2300_closure_267(uint64_t fused_0fused_0__itr_0____itr_1_3296____itr_2_3297, float* __restrict__ __ins_0, float* __restrict__ __ins_1, float* __restrict__ __outs_0) noexcept __attribute__((nonnull (2,3,4)));
static void cast__2310_closure_268(uint64_t fused_0fused_0__itr_0____itr_1_3298____itr_2_3299, float* __restrict__ __ins_0, int8_t* __restrict__ __outs_0) noexcept __attribute__((nonnull (2,3)));
static void reorder__5290_closure_269(uint64_t fused_0_fuseiter_9943___fuseiter_9944_3300, int8_t* __restrict__ __ins_0, int8_t* __restrict__ __outs_0) noexcept __attribute__((nonnull (2,3)));
static void mul__1880_closure_270(uint64_t fused_0fused_0__itr_0____itr_1_3301____itr_2_3302, float* __restrict__ __ins_0, float* __restrict__ __ins_1, float* __restrict__ __outs_0) noexcept __attribute__((nonnull (2,3,4)));
static void cast__1890_closure_271(uint64_t fused_0fused_0__itr_0____itr_1_3303____itr_2_3304, float* __restrict__ __ins_0, int8_t* __restrict__ __outs_0) noexcept __attribute__((nonnull (2,3)));
static void reorder__4870_closure_272(uint64_t fused_0_fuseiter_9960___fuseiter_9961_3305, int8_t* __restrict__ __ins_0, int8_t* __restrict__ __outs_0) noexcept __attribute__((nonnull (2,3)));
static void mul__1970_closure_273(uint64_t fused_0fused_0__itr_0____itr_1_3306____itr_2_3307, float* __restrict__ __ins_0, float* __restrict__ __ins_1, float* __restrict__ __outs_0) noexcept __attribute__((nonnull (2,3,4)));
static void cast__1980_closure_274(uint64_t fused_0fused_0__itr_0____itr_1_3308____itr_2_3309, float* __restrict__ __ins_0, int8_t* __restrict__ __outs_0) noexcept __attribute__((nonnull (2,3)));
static void reorder__4960_closure_275(uint64_t fused_0_fuseiter_9977___fuseiter_9978_3310, int8_t* __restrict__ __ins_0, int8_t* __restrict__ __outs_0) noexcept __attribute__((nonnull (2,3)));
static void mul__2060_closure_276(uint64_t fused_0fused_0__itr_0____itr_1_3311____itr_2_3312, float* __restrict__ __ins_0, float* __restrict__ __ins_1, float* __restrict__ __outs_0) noexcept __attribute__((nonnull (2,3,4)));
static void cast__2070_closure_277(uint64_t fused_0fused_0__itr_0____itr_1_3313____itr_2_3314, float* __restrict__ __ins_0, int8_t* __restrict__ __outs_0) noexcept __attribute__((nonnull (2,3)));
static void reorder__5050_closure_278(uint64_t fused_0_fuseiter_9994___fuseiter_9995_3315, int8_t* __restrict__ __ins_0, int8_t* __restrict__ __outs_0) noexcept __attribute__((nonnull (2,3)));
static void mul__2150_closure_279(uint64_t fused_0fused_0__itr_0____itr_1_3316____itr_2_3317, float* __restrict__ __ins_0, float* __restrict__ __ins_1, float* __restrict__ __outs_0) noexcept __attribute__((nonnull (2,3,4)));
static void cast__2160_closure_280(uint64_t fused_0fused_0__itr_0____itr_1_3318____itr_2_3319, float* __restrict__ __ins_0, int8_t* __restrict__ __outs_0) noexcept __attribute__((nonnull (2,3)));
static void reorder__5140_closure_281(uint64_t fused_0_fuseiter_10011___fuseiter_10012_3320, int8_t* __restrict__ __ins_0, int8_t* __restrict__ __outs_0) noexcept __attribute__((nonnull (2,3)));
static void mul__2240_closure_282(uint64_t fused_0fused_0__itr_0____itr_1_3321____itr_2_3322, float* __restrict__ __ins_0, float* __restrict__ __ins_1, float* __restrict__ __outs_0) noexcept __attribute__((nonnull (2,3,4)));
static void cast__2250_closure_283(uint64_t fused_0fused_0__itr_0____itr_1_3323____itr_2_3324, float* __restrict__ __ins_0, int8_t* __restrict__ __outs_0) noexcept __attribute__((nonnull (2,3)));
static void reorder__5230_closure_284(uint64_t fused_0_fuseiter_10028___fuseiter_10029_3325, int8_t* __restrict__ __ins_0, int8_t* __restrict__ __outs_0) noexcept __attribute__((nonnull (2,3)));
static void mul__1760_closure_285(uint64_t fused_0fused_0__itr_0____itr_1_3326____itr_2_3327, float* __restrict__ __ins_0, float* __restrict__ __ins_1, float* __restrict__ __outs_0) noexcept __attribute__((nonnull (2,3,4)));
static void cast__1770_closure_286(uint64_t fused_0fused_0__itr_0____itr_1_3328____itr_2_3329, float* __restrict__ __ins_0, int8_t* __restrict__ __outs_0) noexcept __attribute__((nonnull (2,3)));
static void reorder__4750_closure_287(uint64_t fused_0_fuseiter_10045___fuseiter_10046_3330, int8_t* __restrict__ __ins_0, int8_t* __restrict__ __outs_0) noexcept __attribute__((nonnull (2,3)));
static void mul__2360_closure_288(uint64_t fused_0fused_0__itr_0____itr_1_3331____itr_2_3332, float* __restrict__ __ins_0, float* __restrict__ __ins_1, float* __restrict__ __outs_0) noexcept __attribute__((nonnull (2,3,4)));
static void cast__2370_closure_289(uint64_t fused_0fused_0__itr_0____itr_1_3333____itr_2_3334, float* __restrict__ __ins_0, int8_t* __restrict__ __outs_0) noexcept __attribute__((nonnull (2,3)));
static void reorder__5350_closure_290(uint64_t fused_0fused_0fused_0fused_0_fuseiter_10062___fuseiter_10063_3335___fuseiter_10064_3336___fuseiter_10065_3337___fuseiter_10066_3338, int8_t* __restrict__ __ins_0, int8_t* __restrict__ __outs_0) noexcept __attribute__((nonnull (2,3)));
static void mul__1820_closure_291(uint64_t fused_0fused_0__itr_0____itr_1_3339____itr_2_3340, float* __restrict__ __ins_0, float* __restrict__ __ins_1, float* __restrict__ __outs_0) noexcept __attribute__((nonnull (2,3,4)));
static void cast__1830_closure_292(uint64_t fused_0fused_0__itr_0____itr_1_3341____itr_2_3342, float* __restrict__ __ins_0, int8_t* __restrict__ __outs_0) noexcept __attribute__((nonnull (2,3)));
static void reorder__4810_closure_293(uint64_t fused_0fused_0_fuseiter_10079___fuseiter_10080_3343___fuseiter_10081_3344, int8_t* __restrict__ __ins_0, int8_t* __restrict__ __outs_0) noexcept __attribute__((nonnull (2,3)));
static void mul__1910_closure_294(uint64_t fused_0fused_0__itr_0____itr_1_3345____itr_2_3346, float* __restrict__ __ins_0, float* __restrict__ __ins_1, float* __restrict__ __outs_0) noexcept __attribute__((nonnull (2,3,4)));
static void cast__1920_closure_295(uint64_t fused_0fused_0__itr_0____itr_1_3347____itr_2_3348, float* __restrict__ __ins_0, int8_t* __restrict__ __outs_0) noexcept __attribute__((nonnull (2,3)));
static void reorder__4900_closure_296(uint64_t fused_0fused_0_fuseiter_10096___fuseiter_10097_3349___fuseiter_10098_3350, int8_t* __restrict__ __ins_0, int8_t* __restrict__ __outs_0) noexcept __attribute__((nonnull (2,3)));
static void mul__2000_closure_297(uint64_t fused_0fused_0__itr_0____itr_1_3351____itr_2_3352, float* __restrict__ __ins_0, float* __restrict__ __ins_1, float* __restrict__ __outs_0) noexcept __attribute__((nonnull (2,3,4)));
static void cast__2010_closure_298(uint64_t fused_0fused_0__itr_0____itr_1_3353____itr_2_3354, float* __restrict__ __ins_0, int8_t* __restrict__ __outs_0) noexcept __attribute__((nonnull (2,3)));
static void reorder__4990_closure_299(uint64_t fused_0fused_0_fuseiter_10113___fuseiter_10114_3355___fuseiter_10115_3356, int8_t* __restrict__ __ins_0, int8_t* __restrict__ __outs_0) noexcept __attribute__((nonnull (2,3)));
static void mul__2090_closure_300(uint64_t fused_0fused_0__itr_0____itr_1_3357____itr_2_3358, float* __restrict__ __ins_0, float* __restrict__ __ins_1, float* __restrict__ __outs_0) noexcept __attribute__((nonnull (2,3,4)));
static void cast__2100_closure_301(uint64_t fused_0fused_0__itr_0____itr_1_3359____itr_2_3360, float* __restrict__ __ins_0, int8_t* __restrict__ __outs_0) noexcept __attribute__((nonnull (2,3)));
static void reorder__5080_closure_302(uint64_t fused_0fused_0_fuseiter_10130___fuseiter_10131_3361___fuseiter_10132_3362, int8_t* __restrict__ __ins_0, int8_t* __restrict__ __outs_0) noexcept __attribute__((nonnull (2,3)));
static void mul__2180_closure_303(uint64_t fused_0fused_0__itr_0____itr_1_3363____itr_2_3364, float* __restrict__ __ins_0, float* __restrict__ __ins_1, float* __restrict__ __outs_0) noexcept __attribute__((nonnull (2,3,4)));
static void cast__2190_closure_304(uint64_t fused_0fused_0__itr_0____itr_1_3365____itr_2_3366, float* __restrict__ __ins_0, int8_t* __restrict__ __outs_0) noexcept __attribute__((nonnull (2,3)));
static void reorder__5170_closure_305(uint64_t fused_0fused_0_fuseiter_10147___fuseiter_10148_3367___fuseiter_10149_3368, int8_t* __restrict__ __ins_0, int8_t* __restrict__ __outs_0) noexcept __attribute__((nonnull (2,3)));
static void mul__2270_closure_306(uint64_t fused_0fused_0__itr_0____itr_1_3369____itr_2_3370, float* __restrict__ __ins_0, float* __restrict__ __ins_1, float* __restrict__ __outs_0) noexcept __attribute__((nonnull (2,3,4)));
static void cast__2280_closure_307(uint64_t fused_0fused_0__itr_0____itr_1_3371____itr_2_3372, float* __restrict__ __ins_0, int8_t* __restrict__ __outs_0) noexcept __attribute__((nonnull (2,3)));
static void reorder__5260_closure_308(uint64_t fused_0fused_0_fuseiter_10164___fuseiter_10165_3373___fuseiter_10166_3374, int8_t* __restrict__ __ins_0, int8_t* __restrict__ __outs_0) noexcept __attribute__((nonnull (2,3)));
static void mul__2420_closure_309(uint64_t fused_0fused_0__itr_0____itr_1_3375____itr_2_3376, float* __restrict__ __ins_0, float* __restrict__ __ins_1, float* __restrict__ __outs_0) noexcept __attribute__((nonnull (2,3,4)));
static void cast__2430_closure_310(uint64_t fused_0fused_0__itr_0____itr_1_3377____itr_2_3378, float* __restrict__ __ins_0, int8_t* __restrict__ __outs_0) noexcept __attribute__((nonnull (2,3)));
static void reorder__5390_closure_311(uint64_t fused_0fused_0fused_0fused_0_fuseiter_10181___fuseiter_10182_3379___fuseiter_10183_3380___fuseiter_10184_3381___fuseiter_10185_3382, int8_t* __restrict__ __ins_0, int8_t* __restrict__ __outs_0) noexcept __attribute__((nonnull (2,3)));
static void mul__2510_closure_312(uint64_t fused_0fused_0__itr_0____itr_1_3383____itr_2_3384, float* __restrict__ __ins_0, float* __restrict__ __ins_1, float* __restrict__ __outs_0) noexcept __attribute__((nonnull (2,3,4)));
static void cast__2520_closure_313(uint64_t fused_0fused_0__itr_0____itr_1_3385____itr_2_3386, float* __restrict__ __ins_0, int8_t* __restrict__ __outs_0) noexcept __attribute__((nonnull (2,3)));
static void reorder__5480_closure_314(uint64_t fused_0fused_0fused_0fused_0_fuseiter_10198___fuseiter_10199_3387___fuseiter_10200_3388___fuseiter_10201_3389___fuseiter_10202_3390, int8_t* __restrict__ __ins_0, int8_t* __restrict__ __outs_0) noexcept __attribute__((nonnull (2,3)));
static void mul__2600_closure_315(uint64_t fused_0fused_0__itr_0____itr_1_3391____itr_2_3392, float* __restrict__ __ins_0, float* __restrict__ __ins_1, float* __restrict__ __outs_0) noexcept __attribute__((nonnull (2,3,4)));
static void cast__2610_closure_316(uint64_t fused_0fused_0__itr_0____itr_1_3393____itr_2_3394, float* __restrict__ __ins_0, int8_t* __restrict__ __outs_0) noexcept __attribute__((nonnull (2,3)));
static void reorder__5570_closure_317(uint64_t fused_0_fuseiter_10215___fuseiter_10216_3395, int8_t* __restrict__ __ins_0, int8_t* __restrict__ __outs_0) noexcept __attribute__((nonnull (2,3)));
static void mul__2450_closure_318(uint64_t fused_0fused_0__itr_0____itr_1_3396____itr_2_3397, float* __restrict__ __ins_0, float* __restrict__ __ins_1, float* __restrict__ __outs_0) noexcept __attribute__((nonnull (2,3,4)));
static void cast__2460_closure_319(uint64_t fused_0fused_0__itr_0____itr_1_3398____itr_2_3399, float* __restrict__ __ins_0, int8_t* __restrict__ __outs_0) noexcept __attribute__((nonnull (2,3)));
static void reorder__5420_closure_320(uint64_t fused_0_fuseiter_10232___fuseiter_10233_3400, int8_t* __restrict__ __ins_0, int8_t* __restrict__ __outs_0) noexcept __attribute__((nonnull (2,3)));
static void mul__2540_closure_321(uint64_t fused_0fused_0__itr_0____itr_1_3401____itr_2_3402, float* __restrict__ __ins_0, float* __restrict__ __ins_1, float* __restrict__ __outs_0) noexcept __attribute__((nonnull (2,3,4)));
static void cast__2550_closure_322(uint64_t fused_0fused_0__itr_0____itr_1_3403____itr_2_3404, float* __restrict__ __ins_0, int8_t* __restrict__ __outs_0) noexcept __attribute__((nonnull (2,3)));
static void reorder__5510_closure_323(uint64_t fused_0fused_0fused_0fused_0_fuseiter_10249___fuseiter_10250_3405___fuseiter_10251_3406___fuseiter_10252_3407___fuseiter_10253_3408, int8_t* __restrict__ __ins_0, int8_t* __restrict__ __outs_0) noexcept __attribute__((nonnull (2,3)));
static void mul__2330_closure_324(uint64_t fused_0fused_0__itr_0____itr_1_3409____itr_2_3410, float* __restrict__ __ins_0, float* __restrict__ __ins_1, float* __restrict__ __outs_0) noexcept __attribute__((nonnull (2,3,4)));
static void cast__2340_closure_325(uint64_t fused_0fused_0__itr_0____itr_1_3411____itr_2_3412, float* __restrict__ __ins_0, int8_t* __restrict__ __outs_0) noexcept __attribute__((nonnull (2,3)));
static void reorder__5320_closure_326(uint64_t fused_0_fuseiter_10266___fuseiter_10267_3413, int8_t* __restrict__ __ins_0, int8_t* __restrict__ __outs_0) noexcept __attribute__((nonnull (2,3)));
static void mul__2390_closure_327(uint64_t fused_0fused_0__itr_0____itr_1_3414____itr_2_3415, float* __restrict__ __ins_0, float* __restrict__ __ins_1, float* __restrict__ __outs_0) noexcept __attribute__((nonnull (2,3,4)));
static void cast__2400_closure_328(uint64_t fused_0fused_0__itr_0____itr_1_3416____itr_2_3417, float* __restrict__ __ins_0, int8_t* __restrict__ __outs_0) noexcept __attribute__((nonnull (2,3)));
static void reorder__5360_closure_329(uint64_t fused_0fused_0_fuseiter_10283___fuseiter_10284_3418___fuseiter_10285_3419, int8_t* __restrict__ __ins_0, int8_t* __restrict__ __outs_0) noexcept __attribute__((nonnull (2,3)));
static void mul__2480_closure_330(uint64_t fused_0fused_0__itr_0____itr_1_3420____itr_2_3421, float* __restrict__ __ins_0, float* __restrict__ __ins_1, float* __restrict__ __outs_0) noexcept __attribute__((nonnull (2,3,4)));
static void cast__2490_closure_331(uint64_t fused_0fused_0__itr_0____itr_1_3422____itr_2_3423, float* __restrict__ __ins_0, int8_t* __restrict__ __outs_0) noexcept __attribute__((nonnull (2,3)));
static void reorder__5450_closure_332(uint64_t fused_0_fuseiter_10300___fuseiter_10301_3424, int8_t* __restrict__ __ins_0, int8_t* __restrict__ __outs_0) noexcept __attribute__((nonnull (2,3)));
static void mul__2570_closure_333(uint64_t fused_0fused_0__itr_0____itr_1_3425____itr_2_3426, float* __restrict__ __ins_0, float* __restrict__ __ins_1, float* __restrict__ __outs_0) noexcept __attribute__((nonnull (2,3,4)));
static void cast__2580_closure_334(uint64_t fused_0fused_0__itr_0____itr_1_3427____itr_2_3428, float* __restrict__ __ins_0, int8_t* __restrict__ __outs_0) noexcept __attribute__((nonnull (2,3)));
static void reorder__5540_closure_335(uint64_t fused_0fused_0_fuseiter_10317___fuseiter_10318_3429___fuseiter_10319_3430, int8_t* __restrict__ __ins_0, int8_t* __restrict__ __outs_0) noexcept __attribute__((nonnull (2,3)));
static void batchwise_4_fused_res2a_conv_b_cast_mul_add_cast_res2a_conv_0_cast_mul_add_cast_relu_res2a_conv_1_cast_mul_add_cast_relu_res2a_conv_2_cast_mul_add_cast_add_relu_res2b_conv_0_cast_mul_add_cast_relu_res2b_conv_1_cast_mul_add_cast_relu_res2b_conv_2_cast_mul_add_cast_add_relu_res2c_conv_0_cast_mul_add_cast_relu_res2c_conv_1_cast_mul_add_cast_relu_res2c_conv_2_cast_mul_add_cast_add_relu_res3a_conv_b_cast_mul_add_cast_res3a_conv_0_cast_mul_add_cast_relu_res3a_conv_1_cast_mul_add_cast_relu_res3a_conv_2_cast_mul_add_cast_add_relu_res3b_conv_0_cast_mul_add_cast_relu_res3b_conv_1_cast_mul_add_cast_relu_res3b_conv_2_cast_mul_add_cast_add_relu_res3c_conv_0_cast_mul_add_cast_relu_res3c_conv_1_cast_mul_add_cast_relu_res3c_conv_2_cast_mul_add_cast_add_relu_res3d_conv_0_cast_mul_add_cast_relu_res3d_conv_1_cast_mul_add_cast_relu_res3d_conv_2_cast_mul_add_cast_add_relu__6840_closure_336(uint64_t __batchwise_iter_0, int64_t* __restrict__ input_pointers, int8_t* __restrict__ __ins_1, float* __restrict__ __ins_2, float* __restrict__ __ins_3, int8_t* __restrict__ __ins_4, float* __restrict__ __ins_5, float* __restrict__ __ins_6, int8_t* __restrict__ __ins_7, float* __restrict__ __ins_8, float* __restrict__ __ins_9, int8_t* __restrict__ __ins_10, float* __restrict__ __ins_11, float* __restrict__ __ins_12, int8_t* __restrict__ __ins_13, float* __restrict__ __ins_14, float* __restrict__ __ins_15, int8_t* __restrict__ __ins_16, float* __restrict__ __ins_17, float* __restrict__ __ins_18, int8_t* __restrict__ __ins_19, float* __restrict__ __ins_20, float* __restrict__ __ins_21, int8_t* __restrict__ __ins_22, float* __restrict__ __ins_23, float* __restrict__ __ins_24, int8_t* __restrict__ __ins_25, float* __restrict__ __ins_26, float* __restrict__ __ins_27, int8_t* __restrict__ __ins_28, float* __restrict__ __ins_29, float* __restrict__ __ins_30, int8_t* __restrict__ __ins_31, float* __restrict__ __ins_32, float* __restrict__ __ins_33, int8_t* __restrict__ __ins_34, float* __restrict__ __ins_35, float* __restrict__ __ins_36, int8_t* __restrict__ __ins_37, float* __restrict__ __ins_38, float* __restrict__ __ins_39, int8_t* __restrict__ __ins_40, float* __restrict__ __ins_41, float* __restrict__ __ins_42, int8_t* __restrict__ __ins_43, float* __restrict__ __ins_44, float* __restrict__ __ins_45, int8_t* __restrict__ __ins_46, float* __restrict__ __ins_47, float* __restrict__ __ins_48, int8_t* __restrict__ __ins_49, float* __restrict__ __ins_50, float* __restrict__ __ins_51, int8_t* __restrict__ __ins_52, float* __restrict__ __ins_53, float* __restrict__ __ins_54, int8_t* __restrict__ __ins_55, float* __restrict__ __ins_56, float* __restrict__ __ins_57, int8_t* __restrict__ __ins_58, float* __restrict__ __ins_59, float* __restrict__ __ins_60, int8_t* __restrict__ __ins_61, float* __restrict__ __ins_62, float* __restrict__ __ins_63, int8_t* __restrict__ __ins_64, float* __restrict__ __ins_65, float* __restrict__ __ins_66, int8_t* __restrict__ __outs_0, int8_t* __restrict__ __ins_67, float* __restrict__ __ins_68, float* __restrict__ __ins_69) noexcept __attribute__((nonnull (2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72)));
static void batchwise_2_fused_res4a_conv_b_cast_mul_add_cast_res4a_conv_0_cast_mul_add_cast_relu_res4a_conv_1_cast_mul_add_cast_relu_res4a_conv_2_cast_mul_add_cast_add_relu_res4b_conv_0_cast_mul_add_cast_relu_res4b_conv_1_cast_mul_add_cast_relu_res4b_conv_2_cast_mul_add_cast_add_relu_res4c_conv_0_cast_mul_add_cast_relu_res4c_conv_1_cast_mul_add_cast_relu_res4c_conv_2_cast_mul_add_cast_add_relu_res4d_conv_0_cast_mul_add_cast_relu_res4d_conv_1_cast_mul_add_cast_relu_res4d_conv_2_cast_mul_add_cast_add_relu_res4e_conv_0_cast_mul_add_cast_relu_res4e_conv_1_cast_mul_add_cast_relu_res4e_conv_2_cast_mul_add_cast_add_relu_res4f_conv_0_cast_mul_add_cast_relu_res4f_conv_1_cast_mul_add_cast_relu_res4f_conv_2_cast_mul_add_cast_add_relu__6850_closure_337(uint64_t __batchwise_iter_0, int8_t* __restrict__ __ins_0, int8_t* __restrict__ __ins_1, float* __restrict__ __ins_2, float* __restrict__ __ins_3, int8_t* __restrict__ __ins_4, float* __restrict__ __ins_5, float* __restrict__ __ins_6, int8_t* __restrict__ __ins_7, float* __restrict__ __ins_8, float* __restrict__ __ins_9, int8_t* __restrict__ __ins_10, float* __restrict__ __ins_11, float* __restrict__ __ins_12, int8_t* __restrict__ __ins_13, float* __restrict__ __ins_14, float* __restrict__ __ins_15, int8_t* __restrict__ __ins_16, float* __restrict__ __ins_17, float* __restrict__ __ins_18, int8_t* __restrict__ __ins_19, float* __restrict__ __ins_20, float* __restrict__ __ins_21, int8_t* __restrict__ __ins_22, float* __restrict__ __ins_23, float* __restrict__ __ins_24, int8_t* __restrict__ __ins_25, float* __restrict__ __ins_26, float* __restrict__ __ins_27, int8_t* __restrict__ __ins_28, float* __restrict__ __ins_29, float* __restrict__ __ins_30, int8_t* __restrict__ __ins_31, float* __restrict__ __ins_32, float* __restrict__ __ins_33, int8_t* __restrict__ __ins_34, float* __restrict__ __ins_35, float* __restrict__ __ins_36, int8_t* __restrict__ __ins_37, float* __restrict__ __ins_38, float* __restrict__ __ins_39, int8_t* __restrict__ __ins_40, float* __restrict__ __ins_41, float* __restrict__ __ins_42, int8_t* __restrict__ __ins_43, float* __restrict__ __ins_44, float* __restrict__ __ins_45, int8_t* __restrict__ __ins_46, float* __restrict__ __ins_47, float* __restrict__ __ins_48, int8_t* __restrict__ __ins_49, float* __restrict__ __ins_50, float* __restrict__ __ins_51, int8_t* __restrict__ __ins_52, float* __restrict__ __ins_53, float* __restrict__ __ins_54, int8_t* __restrict__ __outs_0, int8_t* __restrict__ __ins_55, float* __restrict__ __ins_56, float* __restrict__ __ins_57) noexcept __attribute__((nonnull (2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60)));
static void res5a_conv_b_cast_mul_add_cast__6830_closure_338(uint64_t n, int8_t* __restrict__ __ins_0, int8_t* __restrict__ input_tmp) noexcept __attribute__((nonnull (2,3)));
static void res5a_conv_b_cast_mul_add_cast__6830_closure_339(uint64_t fused_0fused_0fused_0oc_i__k_3515__n_3516__n_i_3517, int8_t* __restrict__ input_tmp, int8_t* __restrict__ __ins_1, float* __restrict__ __ins_2, float* __restrict__ __ins_3, int8_t* __restrict__ __outs_0) noexcept __attribute__((nonnull (2,3,4,5,6)));
static void res5a_conv_0_cast_mul_add_cast_relu_reorder__6820_closure_340(uint64_t n, int8_t* __restrict__ __outs_0) noexcept __attribute__((nonnull (2)));
static void res5a_conv_0_cast_mul_add_cast_relu_reorder__6820_closure_341(uint64_t fused_0fused_0k__n_3518__n_i_3519, int8_t* __restrict__ __ins_0, int8_t* __restrict__ __ins_1, float* __restrict__ __ins_2, float* __restrict__ __ins_3, int8_t* __restrict__ __outs_0) noexcept __attribute__((nonnull (2,3,4,5,6)));
static void res5a_conv_1_cast_mul_add_cast_relu_reorder__6810_closure_342(uint64_t fused_0fused_0fused_0oc_i__n_3520__n_i_3521__k_o_3522, int8_t* __restrict__ __ins_0, int8_t* __restrict__ __ins_1, float* __restrict__ __ins_2, float* __restrict__ __ins_3, int8_t* __restrict__ __outs_0) noexcept __attribute__((nonnull (2,3,4,5,6)));
static void res5a_conv_2_cast_mul_add_cast_add_relu__6800_closure_343(uint64_t fused_0fused_0n__n_i_3523__k_3524, int8_t* __restrict__ __ins_0, int8_t* __restrict__ __ins_1, float* __restrict__ __ins_2, float* __restrict__ __ins_3, int8_t* __restrict__ __ins_4, int8_t* __restrict__ __outs_0) noexcept __attribute__((nonnull (2,3,4,5,6,7)));
static void res5b_conv_0_cast_mul_add_cast_relu__6790_closure_344(uint64_t n, int8_t* __restrict__ __outs_0) noexcept __attribute__((nonnull (2)));
static void res5b_conv_0_cast_mul_add_cast_relu__6790_closure_345(uint64_t fused_0fused_0n__n_i_3525__k_3526, int8_t* __restrict__ __ins_0, int8_t* __restrict__ __ins_1, float* __restrict__ __ins_2, float* __restrict__ __ins_3, int8_t* __restrict__ __outs_0) noexcept __attribute__((nonnull (2,3,4,5,6)));
static void res5b_conv_1_cast_mul_add_cast_relu_reorder__6780_closure_346(uint64_t fused_0fused_0fused_0oc_i__n_3527__n_i_3528__k_o_3529, int8_t* __restrict__ __ins_0, int8_t* __restrict__ __ins_1, float* __restrict__ __ins_2, float* __restrict__ __ins_3, int8_t* __restrict__ __outs_0) noexcept __attribute__((nonnull (2,3,4,5,6)));
static void res5b_conv_2_cast_mul_add_cast_add_relu__6770_closure_347(uint64_t fused_0fused_0k__n_3530__n_i_3531, int8_t* __restrict__ __ins_0, int8_t* __restrict__ __ins_1, float* __restrict__ __ins_2, float* __restrict__ __ins_3, int8_t* __restrict__ __ins_4, int8_t* __restrict__ __outs_0) noexcept __attribute__((nonnull (2,3,4,5,6,7)));
static void res5c_conv_0_cast_mul_add_cast_relu_reorder__6760_closure_348(uint64_t n, int8_t* __restrict__ __outs_0) noexcept __attribute__((nonnull (2)));
static void res5c_conv_0_cast_mul_add_cast_relu_reorder__6760_closure_349(uint64_t fused_0fused_0n__n_i_3532__k_3533, int8_t* __restrict__ __ins_0, int8_t* __restrict__ __ins_1, float* __restrict__ __ins_2, float* __restrict__ __ins_3, int8_t* __restrict__ __outs_0) noexcept __attribute__((nonnull (2,3,4,5,6)));
static void res5c_conv_1_cast_mul_add_cast_relu__6750_closure_350(uint64_t fused_0fused_0fused_0oc_i__n_3534__n_i_3535__k_o_3536, int8_t* __restrict__ __ins_0, int8_t* __restrict__ __ins_1, float* __restrict__ __ins_2, float* __restrict__ __ins_3, int8_t* __restrict__ __outs_0) noexcept __attribute__((nonnull (2,3,4,5,6)));
static void res5c_conv_2_cast_mul_add_cast_add_relu_reorder__6740_closure_351(uint64_t fused_0fused_0n__n_i_3537__k_3538, int8_t* __restrict__ __ins_0, int8_t* __restrict__ __ins_1, float* __restrict__ __ins_2, float* __restrict__ __ins_3, int8_t* __restrict__ __ins_4, int8_t* __restrict__ __outs_0) noexcept __attribute__((nonnull (2,3,4,5,6,7)));


extern "C" void rn50_backbone_bs4(int8_t* __restrict__ backbone_output, int64_t* __restrict__ input_pointers, float* __restrict__ final_out, float* __restrict__ res2a_weight_b, float* __restrict__ res2a_bias_b, float* __restrict__ res2a_weight_0, float* __restrict__ res2a_bias_0, float* __restrict__ res2a_weight_1, float* __restrict__ res2a_bias_1, float* __restrict__ res2a_weight_2, float* __restrict__ res2a_bias_2, float* __restrict__ res2b_weight_0, float* __restrict__ res2b_bias_0, float* __restrict__ res2b_weight_1, float* __restrict__ res2b_bias_1, float* __restrict__ res2b_weight_2, float* __restrict__ res2b_bias_2, float* __restrict__ res2c_weight_0, float* __restrict__ res2c_bias_0, float* __restrict__ res2c_weight_1, float* __restrict__ res2c_bias_1, float* __restrict__ res2c_weight_2, float* __restrict__ res2c_bias_2, float* __restrict__ res3a_weight_b, float* __restrict__ res3a_bias_b, float* __restrict__ res3a_weight_0, float* __restrict__ res3a_bias_0, float* __restrict__ res3a_weight_1, float* __restrict__ res3a_bias_1, float* __restrict__ res3a_weight_2, float* __restrict__ res3a_bias_2, float* __restrict__ res3b_weight_0, float* __restrict__ res3b_bias_0, float* __restrict__ res3b_weight_1, float* __restrict__ res3b_bias_1, float* __restrict__ res3b_weight_2, float* __restrict__ res3b_bias_2, float* __restrict__ res3c_weight_0, float* __restrict__ res3c_bias_0, float* __restrict__ res3c_weight_1, float* __restrict__ res3c_bias_1, float* __restrict__ res3c_weight_2, float* __restrict__ res3c_bias_2, float* __restrict__ res3d_weight_0, float* __restrict__ res3d_bias_0, float* __restrict__ res3d_weight_1, float* __restrict__ res3d_bias_1, float* __restrict__ res3d_weight_2, float* __restrict__ res3d_bias_2, float* __restrict__ res4a_weight_b, float* __restrict__ res4a_bias_b, float* __restrict__ res4a_weight_0, float* __restrict__ res4a_bias_0, float* __restrict__ res4a_weight_1, float* __restrict__ res4a_bias_1, float* __restrict__ res4a_weight_2, float* __restrict__ res4a_bias_2, float* __restrict__ res4b_weight_0, float* __restrict__ res4b_bias_0, float* __restrict__ res4b_weight_1, float* __restrict__ res4b_bias_1, float* __restrict__ res4b_weight_2, float* __restrict__ res4b_bias_2, float* __restrict__ res4c_weight_0, float* __restrict__ res4c_bias_0, float* __restrict__ res4c_weight_1, float* __restrict__ res4c_bias_1, float* __restrict__ res4c_weight_2, float* __restrict__ res4c_bias_2, float* __restrict__ res4d_weight_0, float* __restrict__ res4d_bias_0, float* __restrict__ res4d_weight_1, float* __restrict__ res4d_bias_1, float* __restrict__ res4d_weight_2, float* __restrict__ res4d_bias_2, float* __restrict__ res4e_weight_0, float* __restrict__ res4e_bias_0, float* __restrict__ res4e_weight_1, float* __restrict__ res4e_bias_1, float* __restrict__ res4e_weight_2, float* __restrict__ res4e_bias_2, float* __restrict__ res4f_weight_0, float* __restrict__ res4f_bias_0, float* __restrict__ res4f_weight_1, float* __restrict__ res4f_bias_1, float* __restrict__ res4f_weight_2, float* __restrict__ res4f_bias_2, float* __restrict__ res5a_weight_b, float* __restrict__ res5a_bias_b, float* __restrict__ res5a_weight_0, float* __restrict__ res5a_bias_0, float* __restrict__ res5a_weight_1, float* __restrict__ res5a_bias_1, float* __restrict__ res5a_weight_2, float* __restrict__ res5a_bias_2, float* __restrict__ res5b_weight_0, float* __restrict__ res5b_bias_0, float* __restrict__ res5b_weight_1, float* __restrict__ res5b_bias_1, float* __restrict__ res5b_weight_2, float* __restrict__ res5b_bias_2, float* __restrict__ res5c_weight_0, float* __restrict__ res5c_bias_0, float* __restrict__ res5c_weight_1, float* __restrict__ res5c_bias_1, float* __restrict__ res5c_weight_2, float* __restrict__ res5c_bias_2) noexcept{
  bool& is_init = *(bool*)(__module_data + 0);
  int8_t* folded_const_261 = (int8_t*)&__uninitialized_data[216064UL];
  float* folded_const_156 = (float*)&__uninitialized_data[0UL];
  float* folded_const_222 = (float*)&__uninitialized_data[111616UL];
  int8_t* folded_const_260 = (int8_t*)&__uninitialized_data[211968UL];
  float* folded_const_157 = (float*)&__uninitialized_data[1024UL];
  float* folded_const_208 = (float*)&__uninitialized_data[105984UL];
  int8_t* folded_const_268 = (int8_t*)&__uninitialized_data[347136UL];
  float* folded_const_158 = (float*)&__uninitialized_data[1280UL];
  float* folded_const_209 = (float*)&__uninitialized_data[106240UL];
  int8_t* folded_const_262 = (int8_t*)&__uninitialized_data[232448UL];
  float* folded_const_159 = (float*)&__uninitialized_data[1536UL];
  float* folded_const_223 = (float*)&__uninitialized_data[112640UL];
  int8_t* folded_const_265 = (int8_t*)&__uninitialized_data[281600UL];
  float* folded_const_160 = (float*)&__uninitialized_data[2560UL];
  float* folded_const_210 = (float*)&__uninitialized_data[106496UL];
  int8_t* folded_const_269 = (int8_t*)&__uninitialized_data[384000UL];
  float* folded_const_161 = (float*)&__uninitialized_data[2816UL];
  float* folded_const_211 = (float*)&__uninitialized_data[106752UL];
  int8_t* folded_const_263 = (int8_t*)&__uninitialized_data[248832UL];
  float* folded_const_162 = (float*)&__uninitialized_data[3072UL];
  float* folded_const_224 = (float*)&__uninitialized_data[113664UL];
  int8_t* folded_const_266 = (int8_t*)&__uninitialized_data[297984UL];
  float* folded_const_163 = (float*)&__uninitialized_data[4096UL];
  float* folded_const_212 = (float*)&__uninitialized_data[107008UL];
  int8_t* folded_const_270 = (int8_t*)&__uninitialized_data[420864UL];
  float* folded_const_164 = (float*)&__uninitialized_data[4352UL];
  float* folded_const_213 = (float*)&__uninitialized_data[107264UL];
  int8_t* folded_const_264 = (int8_t*)&__uninitialized_data[265216UL];
  float* folded_const_165 = (float*)&__uninitialized_data[4608UL];
  float* folded_const_225 = (float*)&__uninitialized_data[114688UL];
  int8_t* folded_const_278 = (int8_t*)&__uninitialized_data[916480UL];
  float* folded_const_166 = (float*)&__uninitialized_data[5632UL];
  float* folded_const_238 = (float*)&__uninitialized_data[128000UL];
  int8_t* folded_const_267 = (int8_t*)&__uninitialized_data[314368UL];
  float* folded_const_167 = (float*)&__uninitialized_data[7680UL];
  float* folded_const_214 = (float*)&__uninitialized_data[107520UL];
  int8_t* folded_const_280 = (int8_t*)&__uninitialized_data[1178624UL];
  float* folded_const_168 = (float*)&__uninitialized_data[8192UL];
  float* folded_const_215 = (float*)&__uninitialized_data[108032UL];
  int8_t* folded_const_271 = (int8_t*)&__uninitialized_data[457728UL];
  float* folded_const_169 = (float*)&__uninitialized_data[8704UL];
  float* folded_const_239 = (float*)&__uninitialized_data[130048UL];
  int8_t* folded_const_275 = (int8_t*)&__uninitialized_data[719872UL];
  float* folded_const_170 = (float*)&__uninitialized_data[10752UL];
  float* folded_const_216 = (float*)&__uninitialized_data[108544UL];
  int8_t* folded_const_281 = (int8_t*)&__uninitialized_data[1326080UL];
  float* folded_const_171 = (float*)&__uninitialized_data[11264UL];
  float* folded_const_217 = (float*)&__uninitialized_data[109056UL];
  int8_t* folded_const_272 = (int8_t*)&__uninitialized_data[523264UL];
  float* folded_const_172 = (float*)&__uninitialized_data[11776UL];
  float* folded_const_240 = (float*)&__uninitialized_data[132096UL];
  int8_t* folded_const_276 = (int8_t*)&__uninitialized_data[785408UL];
  float* folded_const_173 = (float*)&__uninitialized_data[13824UL];
  float* folded_const_218 = (float*)&__uninitialized_data[109568UL];
  int8_t* folded_const_282 = (int8_t*)&__uninitialized_data[1473536UL];
  float* folded_const_174 = (float*)&__uninitialized_data[14336UL];
  float* folded_const_219 = (float*)&__uninitialized_data[110080UL];
  int8_t* folded_const_273 = (int8_t*)&__uninitialized_data[588800UL];
  float* folded_const_175 = (float*)&__uninitialized_data[14848UL];
  float* folded_const_241 = (float*)&__uninitialized_data[134144UL];
  int8_t* folded_const_277 = (int8_t*)&__uninitialized_data[850944UL];
  float* folded_const_176 = (float*)&__uninitialized_data[16896UL];
  float* folded_const_220 = (float*)&__uninitialized_data[110592UL];
  int8_t* folded_const_283 = (int8_t*)&__uninitialized_data[1620992UL];
  float* folded_const_177 = (float*)&__uninitialized_data[17408UL];
  float* folded_const_221 = (float*)&__uninitialized_data[111104UL];
  int8_t* folded_const_274 = (int8_t*)&__uninitialized_data[654336UL];
  float* folded_const_178 = (float*)&__uninitialized_data[17920UL];
  float* folded_const_242 = (float*)&__uninitialized_data[136192UL];
  int8_t* folded_const_295 = (int8_t*)&__uninitialized_data[4652032UL];
  float* folded_const_179 = (float*)&__uninitialized_data[19968UL];
  float* folded_const_249 = (float*)&__uninitialized_data[150528UL];
  int8_t* folded_const_279 = (int8_t*)&__uninitialized_data[1047552UL];
  float* folded_const_180 = (float*)&__uninitialized_data[24064UL];
  float* folded_const_226 = (float*)&__uninitialized_data[115712UL];
  int8_t* folded_const_297 = (int8_t*)&__uninitialized_data[5700608UL];
  float* folded_const_181 = (float*)&__uninitialized_data[25088UL];
  float* folded_const_227 = (float*)&__uninitialized_data[116736UL];
  int8_t* folded_const_284 = (int8_t*)&__uninitialized_data[1768448UL];
  float* folded_const_182 = (float*)&__uninitialized_data[26112UL];
  float* folded_const_250 = (float*)&__uninitialized_data[154624UL];
  int8_t* folded_const_290 = (int8_t*)&__uninitialized_data[3341312UL];
  float* folded_const_183 = (float*)&__uninitialized_data[30208UL];
  float* folded_const_228 = (float*)&__uninitialized_data[117760UL];
  int8_t* folded_const_298 = (int8_t*)&__uninitialized_data[6290432UL];
  float* folded_const_184 = (float*)&__uninitialized_data[31232UL];
  float* folded_const_229 = (float*)&__uninitialized_data[118784UL];
  int8_t* folded_const_285 = (int8_t*)&__uninitialized_data[2030592UL];
  float* folded_const_185 = (float*)&__uninitialized_data[32256UL];
  float* folded_const_251 = (float*)&__uninitialized_data[158720UL];
  int8_t* folded_const_291 = (int8_t*)&__uninitialized_data[3603456UL];
  float* folded_const_186 = (float*)&__uninitialized_data[36352UL];
  float* folded_const_230 = (float*)&__uninitialized_data[119808UL];
  int8_t* folded_const_299 = (int8_t*)&__uninitialized_data[6880256UL];
  float* folded_const_187 = (float*)&__uninitialized_data[37376UL];
  float* folded_const_231 = (float*)&__uninitialized_data[120832UL];
  int8_t* folded_const_286 = (int8_t*)&__uninitialized_data[2292736UL];
  float* folded_const_188 = (float*)&__uninitialized_data[38400UL];
  float* folded_const_252 = (float*)&__uninitialized_data[162816UL];
  int8_t* folded_const_292 = (int8_t*)&__uninitialized_data[3865600UL];
  float* folded_const_189 = (float*)&__uninitialized_data[42496UL];
  float* folded_const_232 = (float*)&__uninitialized_data[121856UL];
  int8_t* folded_const_300 = (int8_t*)&__uninitialized_data[7470080UL];
  float* folded_const_190 = (float*)&__uninitialized_data[43520UL];
  float* folded_const_233 = (float*)&__uninitialized_data[122880UL];
  int8_t* folded_const_287 = (int8_t*)&__uninitialized_data[2554880UL];
  float* folded_const_191 = (float*)&__uninitialized_data[44544UL];
  float* folded_const_253 = (float*)&__uninitialized_data[166912UL];
  int8_t* folded_const_293 = (int8_t*)&__uninitialized_data[4127744UL];
  float* folded_const_192 = (float*)&__uninitialized_data[48640UL];
  float* folded_const_234 = (float*)&__uninitialized_data[123904UL];
  int8_t* folded_const_301 = (int8_t*)&__uninitialized_data[8059904UL];
  float* folded_const_193 = (float*)&__uninitialized_data[49664UL];
  float* folded_const_235 = (float*)&__uninitialized_data[124928UL];
  int8_t* folded_const_288 = (int8_t*)&__uninitialized_data[2817024UL];
  float* folded_const_194 = (float*)&__uninitialized_data[50688UL];
  float* folded_const_254 = (float*)&__uninitialized_data[171008UL];
  int8_t* folded_const_294 = (int8_t*)&__uninitialized_data[4389888UL];
  float* folded_const_195 = (float*)&__uninitialized_data[54784UL];
  float* folded_const_236 = (float*)&__uninitialized_data[125952UL];
  int8_t* folded_const_302 = (int8_t*)&__uninitialized_data[8649728UL];
  float* folded_const_196 = (float*)&__uninitialized_data[55808UL];
  float* folded_const_237 = (float*)&__uninitialized_data[126976UL];
  int8_t* folded_const_289 = (int8_t*)&__uninitialized_data[3079168UL];
  float* folded_const_197 = (float*)&__uninitialized_data[56832UL];
  float* folded_const_255 = (float*)&__uninitialized_data[175104UL];
  int8_t* folded_const_308 = (int8_t*)&__uninitialized_data[14482432UL];
  float* folded_const_198 = (float*)&__uninitialized_data[60928UL];
  float* folded_const_256 = (float*)&__uninitialized_data[179200UL];
  int8_t* folded_const_296 = (int8_t*)&__uninitialized_data[5176320UL];
  float* folded_const_199 = (float*)&__uninitialized_data[69120UL];
  float* folded_const_243 = (float*)&__uninitialized_data[138240UL];
  int8_t* folded_const_309 = (int8_t*)&__uninitialized_data[16579584UL];
  float* folded_const_200 = (float*)&__uninitialized_data[71168UL];
  float* folded_const_244 = (float*)&__uninitialized_data[140288UL];
  int8_t* folded_const_303 = (int8_t*)&__uninitialized_data[9239552UL];
  float* folded_const_201 = (float*)&__uninitialized_data[73216UL];
  float* folded_const_257 = (float*)&__uninitialized_data[187392UL];
  int8_t* folded_const_306 = (int8_t*)&__uninitialized_data[12385280UL];
  float* folded_const_202 = (float*)&__uninitialized_data[81408UL];
  float* folded_const_245 = (float*)&__uninitialized_data[142336UL];
  int8_t* folded_const_310 = (int8_t*)&__uninitialized_data[18938880UL];
  float* folded_const_203 = (float*)&__uninitialized_data[83456UL];
  float* folded_const_246 = (float*)&__uninitialized_data[144384UL];
  int8_t* folded_const_304 = (int8_t*)&__uninitialized_data[10288128UL];
  float* folded_const_204 = (float*)&__uninitialized_data[85504UL];
  float* folded_const_258 = (float*)&__uninitialized_data[195584UL];
  int8_t* folded_const_307 = (int8_t*)&__uninitialized_data[13433856UL];
  float* folded_const_205 = (float*)&__uninitialized_data[93696UL];
  float* folded_const_247 = (float*)&__uninitialized_data[146432UL];
  int8_t* folded_const_311 = (int8_t*)&__uninitialized_data[21298176UL];
  float* folded_const_206 = (float*)&__uninitialized_data[95744UL];
  float* folded_const_248 = (float*)&__uninitialized_data[148480UL];
  int8_t* folded_const_305 = (int8_t*)&__uninitialized_data[11336704UL];
  float* folded_const_207 = (float*)&__uninitialized_data[97792UL];
  float* folded_const_259 = (float*)&__uninitialized_data[203776UL];
  int8_t* __rescheduled_0 = (int8_t*)sc_aligned_malloc(__stream, 86638592UL);
  if (!is_init) {
    __init_const_globals(backbone_output, input_pointers, res2a_weight_b, res2a_bias_b, res2a_weight_0, res2a_bias_0, res2a_weight_1, res2a_bias_1, res2a_weight_2, res2a_bias_2, res2b_weight_0, res2b_bias_0, res2b_weight_1, res2b_bias_1, res2b_weight_2, res2b_bias_2, res2c_weight_0, res2c_bias_0, res2c_weight_1, res2c_bias_1, res2c_weight_2, res2c_bias_2, res3a_weight_b, res3a_bias_b, res3a_weight_0, res3a_bias_0, res3a_weight_1, res3a_bias_1, res3a_weight_2, res3a_bias_2, res3b_weight_0, res3b_bias_0, res3b_weight_1, res3b_bias_1, res3b_weight_2, res3b_bias_2, res3c_weight_0, res3c_bias_0, res3c_weight_1, res3c_bias_1, res3c_weight_2, res3c_bias_2, res3d_weight_0, res3d_bias_0, res3d_weight_1, res3d_bias_1, res3d_weight_2, res3d_bias_2, res4a_weight_b, res4a_bias_b, res4a_weight_0, res4a_bias_0, res4a_weight_1, res4a_bias_1, res4a_weight_2, res4a_bias_2, res4b_weight_0, res4b_bias_0, res4b_weight_1, res4b_bias_1, res4b_weight_2, res4b_bias_2, res4c_weight_0, res4c_bias_0, res4c_weight_1, res4c_bias_1, res4c_weight_2, res4c_bias_2, res4d_weight_0, res4d_bias_0, res4d_weight_1, res4d_bias_1, res4d_weight_2, res4d_bias_2, res4e_weight_0, res4e_bias_0, res4e_weight_1, res4e_bias_1, res4e_weight_2, res4e_bias_2, res4f_weight_0, res4f_bias_0, res4f_weight_1, res4f_bias_1, res4f_weight_2, res4f_bias_2, res5a_weight_b, res5a_bias_b, res5a_weight_0, res5a_bias_0, res5a_weight_1, res5a_bias_1, res5a_weight_2, res5a_bias_2, res5b_weight_0, res5b_bias_0, res5b_weight_1, res5b_bias_1, res5b_weight_2, res5b_bias_2, res5c_weight_0, res5c_bias_0, res5c_weight_1, res5c_bias_1, res5c_weight_2, res5c_bias_2);
  }
  // [s8 [4, 1, 8, 28, 28, 64] @ A1aBCD64b]
  int8_t* buffer_611 = (int8_t*)&__rescheduled_0[0UL];
  batchwise_4_fused_res2a_conv_b_cast_mul_add_cast_res2a_conv_0_cast_mul_add_cast_relu_res2a_conv_1_cast_mul_add_cast_relu_res2a_conv_2_cast_mul_add_cast_add_relu_res2b_conv_0_cast_mul_add_cast_relu_res2b_conv_1_cast_mul_add_cast_relu_res2b_conv_2_cast_mul_add_cast_add_relu_res2c_conv_0_cast_mul_add_cast_relu_res2c_conv_1_cast_mul_add_cast_relu_res2c_conv_2_cast_mul_add_cast_add_relu_res3a_conv_b_cast_mul_add_cast_res3a_conv_0_cast_mul_add_cast_relu_res3a_conv_1_cast_mul_add_cast_relu_res3a_conv_2_cast_mul_add_cast_add_relu_res3b_conv_0_cast_mul_add_cast_relu_res3b_conv_1_cast_mul_add_cast_relu_res3b_conv_2_cast_mul_add_cast_add_relu_res3c_conv_0_cast_mul_add_cast_relu_res3c_conv_1_cast_mul_add_cast_relu_res3c_conv_2_cast_mul_add_cast_add_relu_res3d_conv_0_cast_mul_add_cast_relu_res3d_conv_1_cast_mul_add_cast_relu_res3d_conv_2_cast_mul_add_cast_add_relu__684(buffer_611, input_pointers, folded_const_261, folded_const_156, folded_const_222, folded_const_260, folded_const_157, folded_const_208, folded_const_268, folded_const_158, folded_const_209, folded_const_262, folded_const_159, folded_const_223, folded_const_265, folded_const_160, folded_const_210, folded_const_269, folded_const_161, folded_const_211, folded_const_263, folded_const_162, folded_const_224, folded_const_266, folded_const_163, folded_const_212, folded_const_270, folded_const_164, folded_const_213, folded_const_264, folded_const_165, folded_const_225, folded_const_278, folded_const_166, folded_const_238, folded_const_267, folded_const_167, folded_const_214, folded_const_280, folded_const_168, folded_const_215, folded_const_271, folded_const_169, folded_const_239, folded_const_275, folded_const_170, folded_const_216, folded_const_281, folded_const_171, folded_const_217, folded_const_272, folded_const_172, folded_const_240, folded_const_276, folded_const_173, folded_const_218, folded_const_282, folded_const_174, folded_const_219, folded_const_273, folded_const_175, folded_const_241, folded_const_277, folded_const_176, folded_const_220, folded_const_283, folded_const_177, folded_const_221, folded_const_274, folded_const_178, folded_const_242);
  // [s8 [2, 2, 16, 14, 14, 64] @ A2aBCD64b]
  int8_t* buffer_612 = (int8_t*)&__rescheduled_0[42467328UL];
  batchwise_2_fused_res4a_conv_b_cast_mul_add_cast_res4a_conv_0_cast_mul_add_cast_relu_res4a_conv_1_cast_mul_add_cast_relu_res4a_conv_2_cast_mul_add_cast_add_relu_res4b_conv_0_cast_mul_add_cast_relu_res4b_conv_1_cast_mul_add_cast_relu_res4b_conv_2_cast_mul_add_cast_add_relu_res4c_conv_0_cast_mul_add_cast_relu_res4c_conv_1_cast_mul_add_cast_relu_res4c_conv_2_cast_mul_add_cast_add_relu_res4d_conv_0_cast_mul_add_cast_relu_res4d_conv_1_cast_mul_add_cast_relu_res4d_conv_2_cast_mul_add_cast_add_relu_res4e_conv_0_cast_mul_add_cast_relu_res4e_conv_1_cast_mul_add_cast_relu_res4e_conv_2_cast_mul_add_cast_add_relu_res4f_conv_0_cast_mul_add_cast_relu_res4f_conv_1_cast_mul_add_cast_relu_res4f_conv_2_cast_mul_add_cast_add_relu__685(buffer_612, &buffer_611[0UL], folded_const_295, folded_const_179, folded_const_249, folded_const_279, folded_const_180, folded_const_226, folded_const_297, folded_const_181, folded_const_227, folded_const_284, folded_const_182, folded_const_250, folded_const_290, folded_const_183, folded_const_228, folded_const_298, folded_const_184, folded_const_229, folded_const_285, folded_const_185, folded_const_251, folded_const_291, folded_const_186, folded_const_230, folded_const_299, folded_const_187, folded_const_231, folded_const_286, folded_const_188, folded_const_252, folded_const_292, folded_const_189, folded_const_232, folded_const_300, folded_const_190, folded_const_233, folded_const_287, folded_const_191, folded_const_253, folded_const_293, folded_const_192, folded_const_234, folded_const_301, folded_const_193, folded_const_235, folded_const_288, folded_const_194, folded_const_254, folded_const_294, folded_const_195, folded_const_236, folded_const_302, folded_const_196, folded_const_237, folded_const_289, folded_const_197, folded_const_255);
  // [s8 [4, 1, 4, 7, 7, 512] @ A1aBCD512b]
  int8_t* buffer_613 = (int8_t*)&__rescheduled_0[0UL];
  res5a_conv_b_cast_mul_add_cast__683(buffer_613, &buffer_612[0UL], folded_const_308, folded_const_198, folded_const_256);
  // [s8 [4, 1, 8, 16, 16, 64] @ A1aBCD64b]
  int8_t* buffer_614 = (int8_t*)&__rescheduled_0[53084160UL];
  res5a_conv_0_cast_mul_add_cast_relu_reorder__682(buffer_614, &buffer_612[0UL], folded_const_296, folded_const_199, folded_const_243);
  // [s8 [4, 1, 1, 7, 7, 512] @ A1aBCD512b]
  int8_t* buffer_615 = (int8_t*)&__rescheduled_0[42467328UL];
  res5a_conv_1_cast_mul_add_cast_relu_reorder__681(buffer_615, buffer_614, folded_const_309, folded_const_200, folded_const_244);
  res5a_conv_2_cast_mul_add_cast_add_relu__680(buffer_613, buffer_615, folded_const_303, folded_const_201, folded_const_257, buffer_613);
  res5b_conv_0_cast_mul_add_cast_relu__679(buffer_615, buffer_613, folded_const_306, folded_const_202, folded_const_245);
  res5b_conv_1_cast_mul_add_cast_relu_reorder__678(buffer_614, buffer_615, folded_const_310, folded_const_203, folded_const_246);
  res5b_conv_2_cast_mul_add_cast_add_relu__677(buffer_613, buffer_614, folded_const_304, folded_const_204, folded_const_258, buffer_613);
  res5c_conv_0_cast_mul_add_cast_relu_reorder__676(buffer_615, buffer_613, folded_const_307, folded_const_205, folded_const_247);
  res5c_conv_1_cast_mul_add_cast_relu__675(buffer_614, buffer_615, folded_const_311, folded_const_206, folded_const_248);
  int8_t* avg_pool_in = (int8_t*)&__rescheduled_0[10000000UL];
  res5c_conv_2_cast_mul_add_cast_add_relu_reorder__674(avg_pool_in, buffer_614, folded_const_305, folded_const_207, folded_const_259, buffer_613);

  int8_t* avg_pool_out = (int8_t*)&__rescheduled_0[10401408UL];
  int8_t* fc_src_mem = (int8_t*)&__rescheduled_0[0UL];

  void* fc_scratch_ptr = (int8_t*)&__rescheduled_0[3387391UL];
 
  runEnd(avg_pool_in,avg_pool_out,final_out,fc_scratch_ptr,fc_src_mem);  
  
  sc_aligned_free(__stream, __rescheduled_0);
}

static bool reorder__419(float* __restrict__ __outs_0, float* __restrict__ __ins_0) noexcept{
  generic_val __tempargs0[2UL];
  __tempargs0[0UL] = __ins_0;
  __tempargs0[1UL] = __outs_0;
  sc_parallel_call_cpu_with_env((void*)&reorder__4190_closure_0_0wrapper, __stream, __module_data, 0UL, 4UL, 1UL, __tempargs0);
  return true;
}

static bool mul__570(float* __restrict__ __outs_0, float* __restrict__ __ins_0, float* __restrict__ __ins_1) noexcept{
  generic_val __tempargs1[3UL];
  __tempargs1[0UL] = __ins_0;
  __tempargs1[1UL] = __ins_1;
  __tempargs1[2UL] = __outs_0;
  sc_parallel_call_cpu_with_env((void*)&mul__5700_closure_1_0wrapper, __stream, __module_data, 0UL, 4UL, 1UL, __tempargs1);
  return true;
}

static bool mul__572(float* __restrict__ __outs_0, float* __restrict__ __ins_0, float* __restrict__ __ins_1) noexcept{
  for (uint64_t _fuseiter_8190 = 0UL; _fuseiter_8190 < 64UL; _fuseiter_8190 += 16UL) {
    vec_f32x16 __cached_0;
    __cached_0 = vec_f32x16::load(&__ins_0[_fuseiter_8190]);
    float __cached_1;
    __cached_1 = __ins_1[0];
    vec_f32x16 __cached_2;
    __cached_2 = (__cached_0 * vec_f32x16(__cached_1));
    vec_f32x16::store(__cached_2, &__outs_0[_fuseiter_8190]);
  }
  return true;
}

static bool mul__574(float* __restrict__ __outs_0, float* __restrict__ __ins_0, float* __restrict__ __ins_1) noexcept{
  for (uint64_t _fuseiter_8197 = 0UL; _fuseiter_8197 < 64UL; _fuseiter_8197 += 16UL) {
    vec_f32x16 __cached_0;
    __cached_0 = vec_f32x16::load(&__ins_0[_fuseiter_8197]);
    float __cached_1;
    __cached_1 = __ins_1[0];
    vec_f32x16 __cached_2;
    __cached_2 = (__cached_0 * vec_f32x16(__cached_1));
    vec_f32x16::store(__cached_2, &__outs_0[_fuseiter_8197]);
  }
  return true;
}

static bool reorder__424(float* __restrict__ __outs_0, float* __restrict__ __ins_0) noexcept{
  generic_val __tempargs2[2UL];
  __tempargs2[0UL] = __ins_0;
  __tempargs2[1UL] = __outs_0;
  sc_parallel_call_cpu_with_env((void*)&reorder__4240_closure_2_0wrapper, __stream, __module_data, 0UL, 4UL, 1UL, __tempargs2);
  return true;
}

static bool mul__576(float* __restrict__ __outs_0, float* __restrict__ __ins_0, float* __restrict__ __ins_1) noexcept{
  generic_val __tempargs3[3UL];
  __tempargs3[0UL] = __ins_0;
  __tempargs3[1UL] = __ins_1;
  __tempargs3[2UL] = __outs_0;
  sc_parallel_call_cpu_with_env((void*)&mul__5760_closure_3_0wrapper, __stream, __module_data, 0UL, 4UL, 1UL, __tempargs3);
  return true;
}

static bool mul__578(float* __restrict__ __outs_0, float* __restrict__ __ins_0, float* __restrict__ __ins_1) noexcept{
  for (uint64_t _fuseiter_8217 = 0UL; _fuseiter_8217 < 64UL; _fuseiter_8217 += 16UL) {
    vec_f32x16 __cached_0;
    __cached_0 = vec_f32x16::load(&__ins_0[_fuseiter_8217]);
    float __cached_1;
    __cached_1 = __ins_1[0];
    vec_f32x16 __cached_2;
    __cached_2 = (__cached_0 * vec_f32x16(__cached_1));
    vec_f32x16::store(__cached_2, &__outs_0[_fuseiter_8217]);
  }
  return true;
}

static bool mul__580(float* __restrict__ __outs_0, float* __restrict__ __ins_0, float* __restrict__ __ins_1) noexcept{
  for (uint64_t _fuseiter_8224 = 0UL; _fuseiter_8224 < 64UL; _fuseiter_8224 += 16UL) {
    vec_f32x16 __cached_0;
    __cached_0 = vec_f32x16::load(&__ins_0[_fuseiter_8224]);
    float __cached_1;
    __cached_1 = __ins_1[0];
    vec_f32x16 __cached_2;
    __cached_2 = (__cached_0 * vec_f32x16(__cached_1));
    vec_f32x16::store(__cached_2, &__outs_0[_fuseiter_8224]);
  }
  return true;
}

static bool reorder__429(float* __restrict__ __outs_0, float* __restrict__ __ins_0) noexcept{
  generic_val __tempargs4[2UL];
  __tempargs4[0UL] = __ins_0;
  __tempargs4[1UL] = __outs_0;
  sc_parallel_call_cpu_with_env((void*)&reorder__4290_closure_4_0wrapper, __stream, __module_data, 0UL, 4UL, 1UL, __tempargs4);
  return true;
}

static bool mul__582(float* __restrict__ __outs_0, float* __restrict__ __ins_0, float* __restrict__ __ins_1) noexcept{
  generic_val __tempargs5[3UL];
  __tempargs5[0UL] = __ins_0;
  __tempargs5[1UL] = __ins_1;
  __tempargs5[2UL] = __outs_0;
  sc_parallel_call_cpu_with_env((void*)&mul__5820_closure_5_0wrapper, __stream, __module_data, 0UL, 4UL, 1UL, __tempargs5);
  return true;
}

static bool mul__584(float* __restrict__ __outs_0, float* __restrict__ __ins_0, float* __restrict__ __ins_1) noexcept{
  for (uint64_t _fuseiter_8244 = 0UL; _fuseiter_8244 < 64UL; _fuseiter_8244 += 16UL) {
    vec_f32x16 __cached_0;
    __cached_0 = vec_f32x16::load(&__ins_0[_fuseiter_8244]);
    float __cached_1;
    __cached_1 = __ins_1[0];
    vec_f32x16 __cached_2;
    __cached_2 = (__cached_0 * vec_f32x16(__cached_1));
    vec_f32x16::store(__cached_2, &__outs_0[_fuseiter_8244]);
  }
  return true;
}

static bool mul__586(float* __restrict__ __outs_0, float* __restrict__ __ins_0, float* __restrict__ __ins_1) noexcept{
  for (uint64_t _fuseiter_8251 = 0UL; _fuseiter_8251 < 64UL; _fuseiter_8251 += 16UL) {
    vec_f32x16 __cached_0;
    __cached_0 = vec_f32x16::load(&__ins_0[_fuseiter_8251]);
    float __cached_1;
    __cached_1 = __ins_1[0];
    vec_f32x16 __cached_2;
    __cached_2 = (__cached_0 * vec_f32x16(__cached_1));
    vec_f32x16::store(__cached_2, &__outs_0[_fuseiter_8251]);
  }
  return true;
}

static bool reorder__434(float* __restrict__ __outs_0, float* __restrict__ __ins_0) noexcept{
  generic_val __tempargs6[2UL];
  __tempargs6[0UL] = __ins_0;
  __tempargs6[1UL] = __outs_0;
  sc_parallel_call_cpu_with_env((void*)&reorder__4340_closure_6_0wrapper, __stream, __module_data, 0UL, 4UL, 1UL, __tempargs6);
  return true;
}

static bool mul__588(float* __restrict__ __outs_0, float* __restrict__ __ins_0, float* __restrict__ __ins_1) noexcept{
  generic_val __tempargs7[3UL];
  __tempargs7[0UL] = __ins_0;
  __tempargs7[1UL] = __ins_1;
  __tempargs7[2UL] = __outs_0;
  sc_parallel_call_cpu_with_env((void*)&mul__5880_closure_7_0wrapper, __stream, __module_data, 0UL, 4UL, 1UL, __tempargs7);
  return true;
}

static bool reorder__437(float* __restrict__ __outs_0, float* __restrict__ __ins_0) noexcept{
  generic_val __tempargs8[2UL];
  __tempargs8[0UL] = __ins_0;
  __tempargs8[1UL] = __outs_0;
  sc_parallel_call_cpu_with_env((void*)&reorder__4370_closure_8_0wrapper, __stream, __module_data, 0UL, 8UL, 1UL, __tempargs8);
  return true;
}

static bool mul__590(float* __restrict__ __outs_0, float* __restrict__ __ins_0, float* __restrict__ __ins_1) noexcept{
  generic_val __tempargs9[3UL];
  __tempargs9[0UL] = __ins_0;
  __tempargs9[1UL] = __ins_1;
  __tempargs9[2UL] = __outs_0;
  sc_parallel_call_cpu_with_env((void*)&mul__5900_closure_9_0wrapper, __stream, __module_data, 0UL, 8UL, 1UL, __tempargs9);
  return true;
}

static bool reorder__440(float* __restrict__ __outs_0, float* __restrict__ __ins_0) noexcept{
  generic_val __tempargs10[2UL];
  __tempargs10[0UL] = __ins_0;
  __tempargs10[1UL] = __outs_0;
  sc_parallel_call_cpu_with_env((void*)&reorder__4400_closure_10_0wrapper, __stream, __module_data, 0UL, 2UL, 1UL, __tempargs10);
  return true;
}

static bool mul__592(float* __restrict__ __outs_0, float* __restrict__ __ins_0, float* __restrict__ __ins_1) noexcept{
  generic_val __tempargs11[3UL];
  __tempargs11[0UL] = __ins_0;
  __tempargs11[1UL] = __ins_1;
  __tempargs11[2UL] = __outs_0;
  sc_parallel_call_cpu_with_env((void*)&mul__5920_closure_11_0wrapper, __stream, __module_data, 0UL, 2UL, 1UL, __tempargs11);
  return true;
}

static bool reorder__443(float* __restrict__ __outs_0, float* __restrict__ __ins_0) noexcept{
  generic_val __tempargs12[2UL];
  __tempargs12[0UL] = __ins_0;
  __tempargs12[1UL] = __outs_0;
  sc_parallel_call_cpu_with_env((void*)&reorder__4430_closure_12_0wrapper, __stream, __module_data, 0UL, 2UL, 1UL, __tempargs12);
  return true;
}

static bool mul__594(float* __restrict__ __outs_0, float* __restrict__ __ins_0, float* __restrict__ __ins_1) noexcept{
  generic_val __tempargs13[3UL];
  __tempargs13[0UL] = __ins_0;
  __tempargs13[1UL] = __ins_1;
  __tempargs13[2UL] = __outs_0;
  sc_parallel_call_cpu_with_env((void*)&mul__5940_closure_13_0wrapper, __stream, __module_data, 0UL, 2UL, 1UL, __tempargs13);
  return true;
}

static bool reorder__446(float* __restrict__ __outs_0, float* __restrict__ __ins_0) noexcept{
  generic_val __tempargs14[2UL];
  __tempargs14[0UL] = __ins_0;
  __tempargs14[1UL] = __outs_0;
  sc_parallel_call_cpu_with_env((void*)&reorder__4460_closure_14_0wrapper, __stream, __module_data, 0UL, 8UL, 1UL, __tempargs14);
  return true;
}

static bool mul__596(float* __restrict__ __outs_0, float* __restrict__ __ins_0, float* __restrict__ __ins_1) noexcept{
  generic_val __tempargs15[3UL];
  __tempargs15[0UL] = __ins_0;
  __tempargs15[1UL] = __ins_1;
  __tempargs15[2UL] = __outs_0;
  sc_parallel_call_cpu_with_env((void*)&mul__5960_closure_15_0wrapper, __stream, __module_data, 0UL, 8UL, 1UL, __tempargs15);
  return true;
}

static bool reorder__449(float* __restrict__ __outs_0, float* __restrict__ __ins_0) noexcept{
  generic_val __tempargs16[2UL];
  __tempargs16[0UL] = __ins_0;
  __tempargs16[1UL] = __outs_0;
  sc_parallel_call_cpu_with_env((void*)&reorder__4490_closure_16_0wrapper, __stream, __module_data, 0UL, 2UL, 1UL, __tempargs16);
  return true;
}

static bool mul__598(float* __restrict__ __outs_0, float* __restrict__ __ins_0, float* __restrict__ __ins_1) noexcept{
  generic_val __tempargs17[3UL];
  __tempargs17[0UL] = __ins_0;
  __tempargs17[1UL] = __ins_1;
  __tempargs17[2UL] = __outs_0;
  sc_parallel_call_cpu_with_env((void*)&mul__5980_closure_17_0wrapper, __stream, __module_data, 0UL, 2UL, 1UL, __tempargs17);
  return true;
}

static bool reorder__452(float* __restrict__ __outs_0, float* __restrict__ __ins_0) noexcept{
  generic_val __tempargs18[2UL];
  __tempargs18[0UL] = __ins_0;
  __tempargs18[1UL] = __outs_0;
  sc_parallel_call_cpu_with_env((void*)&reorder__4520_closure_18_0wrapper, __stream, __module_data, 0UL, 2UL, 1UL, __tempargs18);
  return true;
}

static bool mul__600(float* __restrict__ __outs_0, float* __restrict__ __ins_0, float* __restrict__ __ins_1) noexcept{
  generic_val __tempargs19[3UL];
  __tempargs19[0UL] = __ins_0;
  __tempargs19[1UL] = __ins_1;
  __tempargs19[2UL] = __outs_0;
  sc_parallel_call_cpu_with_env((void*)&mul__6000_closure_19_0wrapper, __stream, __module_data, 0UL, 2UL, 1UL, __tempargs19);
  return true;
}

static bool reorder__455(float* __restrict__ __outs_0, float* __restrict__ __ins_0) noexcept{
  generic_val __tempargs20[2UL];
  __tempargs20[0UL] = __ins_0;
  __tempargs20[1UL] = __outs_0;
  sc_parallel_call_cpu_with_env((void*)&reorder__4550_closure_20_0wrapper, __stream, __module_data, 0UL, 8UL, 1UL, __tempargs20);
  return true;
}

static bool mul__602(float* __restrict__ __outs_0, float* __restrict__ __ins_0, float* __restrict__ __ins_1) noexcept{
  generic_val __tempargs21[3UL];
  __tempargs21[0UL] = __ins_0;
  __tempargs21[1UL] = __ins_1;
  __tempargs21[2UL] = __outs_0;
  sc_parallel_call_cpu_with_env((void*)&mul__6020_closure_21_0wrapper, __stream, __module_data, 0UL, 8UL, 1UL, __tempargs21);
  return true;
}

static bool reorder__458(float* __restrict__ __outs_0, float* __restrict__ __ins_0) noexcept{
  generic_val __tempargs22[2UL];
  __tempargs22[0UL] = __ins_0;
  __tempargs22[1UL] = __outs_0;
  sc_parallel_call_cpu_with_env((void*)&reorder__4580_closure_22_0wrapper, __stream, __module_data, 0UL, 2UL, 1UL, __tempargs22);
  return true;
}

static bool mul__604(float* __restrict__ __outs_0, float* __restrict__ __ins_0, float* __restrict__ __ins_1) noexcept{
  generic_val __tempargs23[3UL];
  __tempargs23[0UL] = __ins_0;
  __tempargs23[1UL] = __ins_1;
  __tempargs23[2UL] = __outs_0;
  sc_parallel_call_cpu_with_env((void*)&mul__6040_closure_23_0wrapper, __stream, __module_data, 0UL, 2UL, 1UL, __tempargs23);
  return true;
}

static bool reorder__461(float* __restrict__ __outs_0, float* __restrict__ __ins_0) noexcept{
  generic_val __tempargs24[2UL];
  __tempargs24[0UL] = __ins_0;
  __tempargs24[1UL] = __outs_0;
  sc_parallel_call_cpu_with_env((void*)&reorder__4610_closure_24_0wrapper, __stream, __module_data, 0UL, 2UL, 1UL, __tempargs24);
  return true;
}

static bool mul__606(float* __restrict__ __outs_0, float* __restrict__ __ins_0, float* __restrict__ __ins_1) noexcept{
  generic_val __tempargs25[3UL];
  __tempargs25[0UL] = __ins_0;
  __tempargs25[1UL] = __ins_1;
  __tempargs25[2UL] = __outs_0;
  sc_parallel_call_cpu_with_env((void*)&mul__6060_closure_25_0wrapper, __stream, __module_data, 0UL, 2UL, 1UL, __tempargs25);
  return true;
}

static bool reorder__464(float* __restrict__ __outs_0, float* __restrict__ __ins_0) noexcept{
  generic_val __tempargs26[2UL];
  __tempargs26[0UL] = __ins_0;
  __tempargs26[1UL] = __outs_0;
  sc_parallel_call_cpu_with_env((void*)&reorder__4640_closure_26_0wrapper, __stream, __module_data, 0UL, 8UL, 1UL, __tempargs26);
  return true;
}

static bool mul__608(float* __restrict__ __outs_0, float* __restrict__ __ins_0, float* __restrict__ __ins_1) noexcept{
  generic_val __tempargs27[3UL];
  __tempargs27[0UL] = __ins_0;
  __tempargs27[1UL] = __ins_1;
  __tempargs27[2UL] = __outs_0;
  sc_parallel_call_cpu_with_env((void*)&mul__6080_closure_27_0wrapper, __stream, __module_data, 0UL, 8UL, 1UL, __tempargs27);
  return true;
}

static bool reorder__467(float* __restrict__ __outs_0, float* __restrict__ __ins_0) noexcept{
  generic_val __tempargs28[2UL];
  __tempargs28[0UL] = __ins_0;
  __tempargs28[1UL] = __outs_0;
  sc_parallel_call_cpu_with_env((void*)&reorder__4670_closure_28_0wrapper, __stream, __module_data, 0UL, 2UL, 1UL, __tempargs28);
  return true;
}

static bool mul__610(float* __restrict__ __outs_0, float* __restrict__ __ins_0, float* __restrict__ __ins_1) noexcept{
  generic_val __tempargs29[3UL];
  __tempargs29[0UL] = __ins_0;
  __tempargs29[1UL] = __ins_1;
  __tempargs29[2UL] = __outs_0;
  sc_parallel_call_cpu_with_env((void*)&mul__6100_closure_29_0wrapper, __stream, __module_data, 0UL, 2UL, 1UL, __tempargs29);
  return true;
}

static bool reorder__470(float* __restrict__ __outs_0, float* __restrict__ __ins_0) noexcept{
  generic_val __tempargs30[2UL];
  __tempargs30[0UL] = __ins_0;
  __tempargs30[1UL] = __outs_0;
  sc_parallel_call_cpu_with_env((void*)&reorder__4700_closure_30_0wrapper, __stream, __module_data, 0UL, 2UL, 1UL, __tempargs30);
  return true;
}

static bool mul__612(float* __restrict__ __outs_0, float* __restrict__ __ins_0, float* __restrict__ __ins_1) noexcept{
  generic_val __tempargs31[3UL];
  __tempargs31[0UL] = __ins_0;
  __tempargs31[1UL] = __ins_1;
  __tempargs31[2UL] = __outs_0;
  sc_parallel_call_cpu_with_env((void*)&mul__6120_closure_31_0wrapper, __stream, __module_data, 0UL, 2UL, 1UL, __tempargs31);
  return true;
}

static bool reorder__473(float* __restrict__ __outs_0, float* __restrict__ __ins_0) noexcept{
  generic_val __tempargs32[2UL];
  __tempargs32[0UL] = __ins_0;
  __tempargs32[1UL] = __outs_0;
  sc_parallel_call_cpu_with_env((void*)&reorder__4730_closure_32_0wrapper, __stream, __module_data, 0UL, 8UL, 1UL, __tempargs32);
  return true;
}

static bool mul__614(float* __restrict__ __outs_0, float* __restrict__ __ins_0, float* __restrict__ __ins_1) noexcept{
  generic_val __tempargs33[3UL];
  __tempargs33[0UL] = __ins_0;
  __tempargs33[1UL] = __ins_1;
  __tempargs33[2UL] = __outs_0;
  sc_parallel_call_cpu_with_env((void*)&mul__6140_closure_33_0wrapper, __stream, __module_data, 0UL, 8UL, 1UL, __tempargs33);
  return true;
}

static bool reorder__476(float* __restrict__ __outs_0, float* __restrict__ __ins_0) noexcept{
  generic_val __tempargs34[2UL];
  __tempargs34[0UL] = __ins_0;
  __tempargs34[1UL] = __outs_0;
  sc_parallel_call_cpu_with_env((void*)&reorder__4760_closure_34_0wrapper, __stream, __module_data, 0UL, 16UL, 1UL, __tempargs34);
  return true;
}

static bool mul__616(float* __restrict__ __outs_0, float* __restrict__ __ins_0, float* __restrict__ __ins_1) noexcept{
  generic_val __tempargs35[3UL];
  __tempargs35[0UL] = __ins_0;
  __tempargs35[1UL] = __ins_1;
  __tempargs35[2UL] = __outs_0;
  sc_parallel_call_cpu_with_env((void*)&mul__6160_closure_35_0wrapper, __stream, __module_data, 0UL, 16UL, 1UL, __tempargs35);
  return true;
}

static bool reorder__479(float* __restrict__ __outs_0, float* __restrict__ __ins_0) noexcept{
  generic_val __tempargs36[2UL];
  __tempargs36[0UL] = __ins_0;
  __tempargs36[1UL] = __outs_0;
  sc_parallel_call_cpu_with_env((void*)&reorder__4790_closure_36_0wrapper, __stream, __module_data, 0UL, 4UL, 1UL, __tempargs36);
  return true;
}

static bool mul__618(float* __restrict__ __outs_0, float* __restrict__ __ins_0, float* __restrict__ __ins_1) noexcept{
  generic_val __tempargs37[3UL];
  __tempargs37[0UL] = __ins_0;
  __tempargs37[1UL] = __ins_1;
  __tempargs37[2UL] = __outs_0;
  sc_parallel_call_cpu_with_env((void*)&mul__6180_closure_37_0wrapper, __stream, __module_data, 0UL, 4UL, 1UL, __tempargs37);
  return true;
}

static bool reorder__482(float* __restrict__ __outs_0, float* __restrict__ __ins_0) noexcept{
  generic_val __tempargs38[2UL];
  __tempargs38[0UL] = __ins_0;
  __tempargs38[1UL] = __outs_0;
  sc_parallel_call_cpu_with_env((void*)&reorder__4820_closure_38_0wrapper, __stream, __module_data, 0UL, 4UL, 1UL, __tempargs38);
  return true;
}

static bool mul__620(float* __restrict__ __outs_0, float* __restrict__ __ins_0, float* __restrict__ __ins_1) noexcept{
  generic_val __tempargs39[3UL];
  __tempargs39[0UL] = __ins_0;
  __tempargs39[1UL] = __ins_1;
  __tempargs39[2UL] = __outs_0;
  sc_parallel_call_cpu_with_env((void*)&mul__6200_closure_39_0wrapper, __stream, __module_data, 0UL, 4UL, 1UL, __tempargs39);
  return true;
}

static bool reorder__485(float* __restrict__ __outs_0, float* __restrict__ __ins_0) noexcept{
  generic_val __tempargs40[2UL];
  __tempargs40[0UL] = __ins_0;
  __tempargs40[1UL] = __outs_0;
  sc_parallel_call_cpu_with_env((void*)&reorder__4850_closure_40_0wrapper, __stream, __module_data, 0UL, 16UL, 1UL, __tempargs40);
  return true;
}

static bool mul__622(float* __restrict__ __outs_0, float* __restrict__ __ins_0, float* __restrict__ __ins_1) noexcept{
  generic_val __tempargs41[3UL];
  __tempargs41[0UL] = __ins_0;
  __tempargs41[1UL] = __ins_1;
  __tempargs41[2UL] = __outs_0;
  sc_parallel_call_cpu_with_env((void*)&mul__6220_closure_41_0wrapper, __stream, __module_data, 0UL, 16UL, 1UL, __tempargs41);
  return true;
}

static bool reorder__488(float* __restrict__ __outs_0, float* __restrict__ __ins_0) noexcept{
  generic_val __tempargs42[2UL];
  __tempargs42[0UL] = __ins_0;
  __tempargs42[1UL] = __outs_0;
  sc_parallel_call_cpu_with_env((void*)&reorder__4880_closure_42_0wrapper, __stream, __module_data, 0UL, 4UL, 1UL, __tempargs42);
  return true;
}

static bool mul__624(float* __restrict__ __outs_0, float* __restrict__ __ins_0, float* __restrict__ __ins_1) noexcept{
  generic_val __tempargs43[3UL];
  __tempargs43[0UL] = __ins_0;
  __tempargs43[1UL] = __ins_1;
  __tempargs43[2UL] = __outs_0;
  sc_parallel_call_cpu_with_env((void*)&mul__6240_closure_43_0wrapper, __stream, __module_data, 0UL, 4UL, 1UL, __tempargs43);
  return true;
}

static bool reorder__491(float* __restrict__ __outs_0, float* __restrict__ __ins_0) noexcept{
  generic_val __tempargs44[2UL];
  __tempargs44[0UL] = __ins_0;
  __tempargs44[1UL] = __outs_0;
  sc_parallel_call_cpu_with_env((void*)&reorder__4910_closure_44_0wrapper, __stream, __module_data, 0UL, 4UL, 1UL, __tempargs44);
  return true;
}

static bool mul__626(float* __restrict__ __outs_0, float* __restrict__ __ins_0, float* __restrict__ __ins_1) noexcept{
  generic_val __tempargs45[3UL];
  __tempargs45[0UL] = __ins_0;
  __tempargs45[1UL] = __ins_1;
  __tempargs45[2UL] = __outs_0;
  sc_parallel_call_cpu_with_env((void*)&mul__6260_closure_45_0wrapper, __stream, __module_data, 0UL, 4UL, 1UL, __tempargs45);
  return true;
}

static bool reorder__494(float* __restrict__ __outs_0, float* __restrict__ __ins_0) noexcept{
  generic_val __tempargs46[2UL];
  __tempargs46[0UL] = __ins_0;
  __tempargs46[1UL] = __outs_0;
  sc_parallel_call_cpu_with_env((void*)&reorder__4940_closure_46_0wrapper, __stream, __module_data, 0UL, 16UL, 1UL, __tempargs46);
  return true;
}

static bool mul__628(float* __restrict__ __outs_0, float* __restrict__ __ins_0, float* __restrict__ __ins_1) noexcept{
  generic_val __tempargs47[3UL];
  __tempargs47[0UL] = __ins_0;
  __tempargs47[1UL] = __ins_1;
  __tempargs47[2UL] = __outs_0;
  sc_parallel_call_cpu_with_env((void*)&mul__6280_closure_47_0wrapper, __stream, __module_data, 0UL, 16UL, 1UL, __tempargs47);
  return true;
}

static bool reorder__497(float* __restrict__ __outs_0, float* __restrict__ __ins_0) noexcept{
  generic_val __tempargs48[2UL];
  __tempargs48[0UL] = __ins_0;
  __tempargs48[1UL] = __outs_0;
  sc_parallel_call_cpu_with_env((void*)&reorder__4970_closure_48_0wrapper, __stream, __module_data, 0UL, 4UL, 1UL, __tempargs48);
  return true;
}

static bool mul__630(float* __restrict__ __outs_0, float* __restrict__ __ins_0, float* __restrict__ __ins_1) noexcept{
  generic_val __tempargs49[3UL];
  __tempargs49[0UL] = __ins_0;
  __tempargs49[1UL] = __ins_1;
  __tempargs49[2UL] = __outs_0;
  sc_parallel_call_cpu_with_env((void*)&mul__6300_closure_49_0wrapper, __stream, __module_data, 0UL, 4UL, 1UL, __tempargs49);
  return true;
}

static bool reorder__500(float* __restrict__ __outs_0, float* __restrict__ __ins_0) noexcept{
  generic_val __tempargs50[2UL];
  __tempargs50[0UL] = __ins_0;
  __tempargs50[1UL] = __outs_0;
  sc_parallel_call_cpu_with_env((void*)&reorder__5000_closure_50_0wrapper, __stream, __module_data, 0UL, 4UL, 1UL, __tempargs50);
  return true;
}

static bool mul__632(float* __restrict__ __outs_0, float* __restrict__ __ins_0, float* __restrict__ __ins_1) noexcept{
  generic_val __tempargs51[3UL];
  __tempargs51[0UL] = __ins_0;
  __tempargs51[1UL] = __ins_1;
  __tempargs51[2UL] = __outs_0;
  sc_parallel_call_cpu_with_env((void*)&mul__6320_closure_51_0wrapper, __stream, __module_data, 0UL, 4UL, 1UL, __tempargs51);
  return true;
}

static bool reorder__503(float* __restrict__ __outs_0, float* __restrict__ __ins_0) noexcept{
  generic_val __tempargs52[2UL];
  __tempargs52[0UL] = __ins_0;
  __tempargs52[1UL] = __outs_0;
  sc_parallel_call_cpu_with_env((void*)&reorder__5030_closure_52_0wrapper, __stream, __module_data, 0UL, 16UL, 1UL, __tempargs52);
  return true;
}

static bool mul__634(float* __restrict__ __outs_0, float* __restrict__ __ins_0, float* __restrict__ __ins_1) noexcept{
  generic_val __tempargs53[3UL];
  __tempargs53[0UL] = __ins_0;
  __tempargs53[1UL] = __ins_1;
  __tempargs53[2UL] = __outs_0;
  sc_parallel_call_cpu_with_env((void*)&mul__6340_closure_53_0wrapper, __stream, __module_data, 0UL, 16UL, 1UL, __tempargs53);
  return true;
}

static bool reorder__506(float* __restrict__ __outs_0, float* __restrict__ __ins_0) noexcept{
  generic_val __tempargs54[2UL];
  __tempargs54[0UL] = __ins_0;
  __tempargs54[1UL] = __outs_0;
  sc_parallel_call_cpu_with_env((void*)&reorder__5060_closure_54_0wrapper, __stream, __module_data, 0UL, 4UL, 1UL, __tempargs54);
  return true;
}

static bool mul__636(float* __restrict__ __outs_0, float* __restrict__ __ins_0, float* __restrict__ __ins_1) noexcept{
  generic_val __tempargs55[3UL];
  __tempargs55[0UL] = __ins_0;
  __tempargs55[1UL] = __ins_1;
  __tempargs55[2UL] = __outs_0;
  sc_parallel_call_cpu_with_env((void*)&mul__6360_closure_55_0wrapper, __stream, __module_data, 0UL, 4UL, 1UL, __tempargs55);
  return true;
}

static bool reorder__509(float* __restrict__ __outs_0, float* __restrict__ __ins_0) noexcept{
  generic_val __tempargs56[2UL];
  __tempargs56[0UL] = __ins_0;
  __tempargs56[1UL] = __outs_0;
  sc_parallel_call_cpu_with_env((void*)&reorder__5090_closure_56_0wrapper, __stream, __module_data, 0UL, 4UL, 1UL, __tempargs56);
  return true;
}

static bool mul__638(float* __restrict__ __outs_0, float* __restrict__ __ins_0, float* __restrict__ __ins_1) noexcept{
  generic_val __tempargs57[3UL];
  __tempargs57[0UL] = __ins_0;
  __tempargs57[1UL] = __ins_1;
  __tempargs57[2UL] = __outs_0;
  sc_parallel_call_cpu_with_env((void*)&mul__6380_closure_57_0wrapper, __stream, __module_data, 0UL, 4UL, 1UL, __tempargs57);
  return true;
}

static bool reorder__512(float* __restrict__ __outs_0, float* __restrict__ __ins_0) noexcept{
  generic_val __tempargs58[2UL];
  __tempargs58[0UL] = __ins_0;
  __tempargs58[1UL] = __outs_0;
  sc_parallel_call_cpu_with_env((void*)&reorder__5120_closure_58_0wrapper, __stream, __module_data, 0UL, 16UL, 1UL, __tempargs58);
  return true;
}

static bool mul__640(float* __restrict__ __outs_0, float* __restrict__ __ins_0, float* __restrict__ __ins_1) noexcept{
  generic_val __tempargs59[3UL];
  __tempargs59[0UL] = __ins_0;
  __tempargs59[1UL] = __ins_1;
  __tempargs59[2UL] = __outs_0;
  sc_parallel_call_cpu_with_env((void*)&mul__6400_closure_59_0wrapper, __stream, __module_data, 0UL, 16UL, 1UL, __tempargs59);
  return true;
}

static bool reorder__515(float* __restrict__ __outs_0, float* __restrict__ __ins_0) noexcept{
  generic_val __tempargs60[2UL];
  __tempargs60[0UL] = __ins_0;
  __tempargs60[1UL] = __outs_0;
  sc_parallel_call_cpu_with_env((void*)&reorder__5150_closure_60_0wrapper, __stream, __module_data, 0UL, 4UL, 1UL, __tempargs60);
  return true;
}

static bool mul__642(float* __restrict__ __outs_0, float* __restrict__ __ins_0, float* __restrict__ __ins_1) noexcept{
  generic_val __tempargs61[3UL];
  __tempargs61[0UL] = __ins_0;
  __tempargs61[1UL] = __ins_1;
  __tempargs61[2UL] = __outs_0;
  sc_parallel_call_cpu_with_env((void*)&mul__6420_closure_61_0wrapper, __stream, __module_data, 0UL, 4UL, 1UL, __tempargs61);
  return true;
}

static bool reorder__518(float* __restrict__ __outs_0, float* __restrict__ __ins_0) noexcept{
  generic_val __tempargs62[2UL];
  __tempargs62[0UL] = __ins_0;
  __tempargs62[1UL] = __outs_0;
  sc_parallel_call_cpu_with_env((void*)&reorder__5180_closure_62_0wrapper, __stream, __module_data, 0UL, 4UL, 1UL, __tempargs62);
  return true;
}

static bool mul__644(float* __restrict__ __outs_0, float* __restrict__ __ins_0, float* __restrict__ __ins_1) noexcept{
  generic_val __tempargs63[3UL];
  __tempargs63[0UL] = __ins_0;
  __tempargs63[1UL] = __ins_1;
  __tempargs63[2UL] = __outs_0;
  sc_parallel_call_cpu_with_env((void*)&mul__6440_closure_63_0wrapper, __stream, __module_data, 0UL, 4UL, 1UL, __tempargs63);
  return true;
}

static bool reorder__521(float* __restrict__ __outs_0, float* __restrict__ __ins_0) noexcept{
  generic_val __tempargs64[2UL];
  __tempargs64[0UL] = __ins_0;
  __tempargs64[1UL] = __outs_0;
  sc_parallel_call_cpu_with_env((void*)&reorder__5210_closure_64_0wrapper, __stream, __module_data, 0UL, 16UL, 1UL, __tempargs64);
  return true;
}

static bool mul__646(float* __restrict__ __outs_0, float* __restrict__ __ins_0, float* __restrict__ __ins_1) noexcept{
  generic_val __tempargs65[3UL];
  __tempargs65[0UL] = __ins_0;
  __tempargs65[1UL] = __ins_1;
  __tempargs65[2UL] = __outs_0;
  sc_parallel_call_cpu_with_env((void*)&mul__6460_closure_65_0wrapper, __stream, __module_data, 0UL, 16UL, 1UL, __tempargs65);
  return true;
}

static bool reorder__524(float* __restrict__ __outs_0, float* __restrict__ __ins_0) noexcept{
  generic_val __tempargs66[2UL];
  __tempargs66[0UL] = __ins_0;
  __tempargs66[1UL] = __outs_0;
  sc_parallel_call_cpu_with_env((void*)&reorder__5240_closure_66_0wrapper, __stream, __module_data, 0UL, 4UL, 1UL, __tempargs66);
  return true;
}

static bool mul__648(float* __restrict__ __outs_0, float* __restrict__ __ins_0, float* __restrict__ __ins_1) noexcept{
  generic_val __tempargs67[3UL];
  __tempargs67[0UL] = __ins_0;
  __tempargs67[1UL] = __ins_1;
  __tempargs67[2UL] = __outs_0;
  sc_parallel_call_cpu_with_env((void*)&mul__6480_closure_67_0wrapper, __stream, __module_data, 0UL, 4UL, 1UL, __tempargs67);
  return true;
}

static bool reorder__527(float* __restrict__ __outs_0, float* __restrict__ __ins_0) noexcept{
  generic_val __tempargs68[2UL];
  __tempargs68[0UL] = __ins_0;
  __tempargs68[1UL] = __outs_0;
  sc_parallel_call_cpu_with_env((void*)&reorder__5270_closure_68_0wrapper, __stream, __module_data, 0UL, 4UL, 1UL, __tempargs68);
  return true;
}

static bool mul__650(float* __restrict__ __outs_0, float* __restrict__ __ins_0, float* __restrict__ __ins_1) noexcept{
  generic_val __tempargs69[3UL];
  __tempargs69[0UL] = __ins_0;
  __tempargs69[1UL] = __ins_1;
  __tempargs69[2UL] = __outs_0;
  sc_parallel_call_cpu_with_env((void*)&mul__6500_closure_69_0wrapper, __stream, __module_data, 0UL, 4UL, 1UL, __tempargs69);
  return true;
}

static bool reorder__530(float* __restrict__ __outs_0, float* __restrict__ __ins_0) noexcept{
  generic_val __tempargs70[2UL];
  __tempargs70[0UL] = __ins_0;
  __tempargs70[1UL] = __outs_0;
  sc_parallel_call_cpu_with_env((void*)&reorder__5300_closure_70_0wrapper, __stream, __module_data, 0UL, 16UL, 1UL, __tempargs70);
  return true;
}

static bool mul__652(float* __restrict__ __outs_0, float* __restrict__ __ins_0, float* __restrict__ __ins_1) noexcept{
  generic_val __tempargs71[3UL];
  __tempargs71[0UL] = __ins_0;
  __tempargs71[1UL] = __ins_1;
  __tempargs71[2UL] = __outs_0;
  sc_parallel_call_cpu_with_env((void*)&mul__6520_closure_71_0wrapper, __stream, __module_data, 0UL, 16UL, 1UL, __tempargs71);
  return true;
}

static bool reorder__533(float* __restrict__ __outs_0, float* __restrict__ __ins_0) noexcept{
  generic_val __tempargs72[2UL];
  __tempargs72[0UL] = __ins_0;
  __tempargs72[1UL] = __outs_0;
  sc_parallel_call_cpu_with_env((void*)&reorder__5330_closure_72_0wrapper, __stream, __module_data, 0UL, 4UL, 1UL, __tempargs72);
  return true;
}

static bool mul__654(float* __restrict__ __outs_0, float* __restrict__ __ins_0, float* __restrict__ __ins_1) noexcept{
  generic_val __tempargs73[3UL];
  __tempargs73[0UL] = __ins_0;
  __tempargs73[1UL] = __ins_1;
  __tempargs73[2UL] = __outs_0;
  sc_parallel_call_cpu_with_env((void*)&mul__6540_closure_73_0wrapper, __stream, __module_data, 0UL, 4UL, 1UL, __tempargs73);
  return true;
}

static bool mul__656(float* __restrict__ __outs_0, float* __restrict__ __ins_0, float* __restrict__ __ins_1) noexcept{
  for (uint64_t _fuseiter_8700 = 0UL; _fuseiter_8700 < 512UL; _fuseiter_8700 += 16UL) {
    vec_f32x16 __cached_0;
    __cached_0 = vec_f32x16::load(&__ins_0[_fuseiter_8700]);
    float __cached_1;
    __cached_1 = __ins_1[0];
    vec_f32x16 __cached_2;
    __cached_2 = (__cached_0 * vec_f32x16(__cached_1));
    vec_f32x16::store(__cached_2, &__outs_0[_fuseiter_8700]);
  }
  return true;
}

static bool reorder__537(float* __restrict__ __outs_0, float* __restrict__ __ins_0) noexcept{
  generic_val __tempargs74[2UL];
  __tempargs74[0UL] = __ins_0;
  __tempargs74[1UL] = __outs_0;
  sc_parallel_call_cpu_with_env((void*)&reorder__5370_closure_74_0wrapper, __stream, __module_data, 0UL, 2UL, 1UL, __tempargs74);
  return true;
}

static bool mul__658(float* __restrict__ __outs_0, float* __restrict__ __ins_0, float* __restrict__ __ins_1) noexcept{
  generic_val __tempargs75[3UL];
  __tempargs75[0UL] = __ins_0;
  __tempargs75[1UL] = __ins_1;
  __tempargs75[2UL] = __outs_0;
  sc_parallel_call_cpu_with_env((void*)&mul__6580_closure_75_0wrapper, __stream, __module_data, 0UL, 2UL, 1UL, __tempargs75);
  return true;
}

static bool reorder__540(float* __restrict__ __outs_0, float* __restrict__ __ins_0) noexcept{
  generic_val __tempargs76[2UL];
  __tempargs76[0UL] = __ins_0;
  __tempargs76[1UL] = __outs_0;
  sc_parallel_call_cpu_with_env((void*)&reorder__5400_closure_76_0wrapper, __stream, __module_data, 0UL, 4UL, 1UL, __tempargs76);
  return true;
}

static bool mul__660(float* __restrict__ __outs_0, float* __restrict__ __ins_0, float* __restrict__ __ins_1) noexcept{
  generic_val __tempargs77[3UL];
  __tempargs77[0UL] = __ins_0;
  __tempargs77[1UL] = __ins_1;
  __tempargs77[2UL] = __outs_0;
  sc_parallel_call_cpu_with_env((void*)&mul__6600_closure_77_0wrapper, __stream, __module_data, 0UL, 4UL, 1UL, __tempargs77);
  return true;
}

static bool reorder__543(float* __restrict__ __outs_0, float* __restrict__ __ins_0) noexcept{
  generic_val __tempargs78[2UL];
  __tempargs78[0UL] = __ins_0;
  __tempargs78[1UL] = __outs_0;
  sc_parallel_call_cpu_with_env((void*)&reorder__5430_closure_78_0wrapper, __stream, __module_data, 0UL, 8UL, 1UL, __tempargs78);
  return true;
}

static bool mul__662(float* __restrict__ __outs_0, float* __restrict__ __ins_0, float* __restrict__ __ins_1) noexcept{
  generic_val __tempargs79[3UL];
  __tempargs79[0UL] = __ins_0;
  __tempargs79[1UL] = __ins_1;
  __tempargs79[2UL] = __outs_0;
  sc_parallel_call_cpu_with_env((void*)&mul__6620_closure_79_0wrapper, __stream, __module_data, 0UL, 8UL, 1UL, __tempargs79);
  return true;
}

static bool reorder__546(float* __restrict__ __outs_0, float* __restrict__ __ins_0) noexcept{
  generic_val __tempargs80[2UL];
  __tempargs80[0UL] = __ins_0;
  __tempargs80[1UL] = __outs_0;
  sc_parallel_call_cpu_with_env((void*)&reorder__5460_closure_80_0wrapper, __stream, __module_data, 0UL, 4UL, 1UL, __tempargs80);
  return true;
}

static bool mul__664(float* __restrict__ __outs_0, float* __restrict__ __ins_0, float* __restrict__ __ins_1) noexcept{
  generic_val __tempargs81[3UL];
  __tempargs81[0UL] = __ins_0;
  __tempargs81[1UL] = __ins_1;
  __tempargs81[2UL] = __outs_0;
  sc_parallel_call_cpu_with_env((void*)&mul__6640_closure_81_0wrapper, __stream, __module_data, 0UL, 4UL, 1UL, __tempargs81);
  return true;
}

static bool reorder__549(float* __restrict__ __outs_0, float* __restrict__ __ins_0) noexcept{
  generic_val __tempargs82[2UL];
  __tempargs82[0UL] = __ins_0;
  __tempargs82[1UL] = __outs_0;
  sc_parallel_call_cpu_with_env((void*)&reorder__5490_closure_82_0wrapper, __stream, __module_data, 0UL, 4UL, 1UL, __tempargs82);
  return true;
}

static bool mul__666(float* __restrict__ __outs_0, float* __restrict__ __ins_0, float* __restrict__ __ins_1) noexcept{
  generic_val __tempargs83[3UL];
  __tempargs83[0UL] = __ins_0;
  __tempargs83[1UL] = __ins_1;
  __tempargs83[2UL] = __outs_0;
  sc_parallel_call_cpu_with_env((void*)&mul__6660_closure_83_0wrapper, __stream, __module_data, 0UL, 4UL, 1UL, __tempargs83);
  return true;
}

static bool reorder__552(float* __restrict__ __outs_0, float* __restrict__ __ins_0) noexcept{
  generic_val __tempargs84[2UL];
  __tempargs84[0UL] = __ins_0;
  __tempargs84[1UL] = __outs_0;
  sc_parallel_call_cpu_with_env((void*)&reorder__5520_closure_84_0wrapper, __stream, __module_data, 0UL, 2UL, 1UL, __tempargs84);
  return true;
}

static bool mul__668(float* __restrict__ __outs_0, float* __restrict__ __ins_0, float* __restrict__ __ins_1) noexcept{
  generic_val __tempargs85[3UL];
  __tempargs85[0UL] = __ins_0;
  __tempargs85[1UL] = __ins_1;
  __tempargs85[2UL] = __outs_0;
  sc_parallel_call_cpu_with_env((void*)&mul__6680_closure_85_0wrapper, __stream, __module_data, 0UL, 2UL, 1UL, __tempargs85);
  return true;
}

static bool reorder__555(float* __restrict__ __outs_0, float* __restrict__ __ins_0) noexcept{
  generic_val __tempargs86[2UL];
  __tempargs86[0UL] = __ins_0;
  __tempargs86[1UL] = __outs_0;
  sc_parallel_call_cpu_with_env((void*)&reorder__5550_closure_86_0wrapper, __stream, __module_data, 0UL, 8UL, 1UL, __tempargs86);
  return true;
}

static bool mul__670(float* __restrict__ __outs_0, float* __restrict__ __ins_0, float* __restrict__ __ins_1) noexcept{
  generic_val __tempargs87[3UL];
  __tempargs87[0UL] = __ins_0;
  __tempargs87[1UL] = __ins_1;
  __tempargs87[2UL] = __outs_0;
  sc_parallel_call_cpu_with_env((void*)&mul__6700_closure_87_0wrapper, __stream, __module_data, 0UL, 8UL, 1UL, __tempargs87);
  return true;
}

static bool reorder__558(float* __restrict__ __outs_0, float* __restrict__ __ins_0) noexcept{
  generic_val __tempargs88[2UL];
  __tempargs88[0UL] = __ins_0;
  __tempargs88[1UL] = __outs_0;
  sc_parallel_call_cpu_with_env((void*)&reorder__5580_closure_88_0wrapper, __stream, __module_data, 0UL, 4UL, 1UL, __tempargs88);
  return true;
}

static bool mul__672(float* __restrict__ __outs_0, float* __restrict__ __ins_0, float* __restrict__ __ins_1) noexcept{
  generic_val __tempargs89[3UL];
  __tempargs89[0UL] = __ins_0;
  __tempargs89[1UL] = __ins_1;
  __tempargs89[2UL] = __outs_0;
  sc_parallel_call_cpu_with_env((void*)&mul__6720_closure_89_0wrapper, __stream, __module_data, 0UL, 4UL, 1UL, __tempargs89);
  return true;
}

static bool mul__573(float* __restrict__ __outs_0, float* __restrict__ __ins_0, float* __restrict__ __ins_1) noexcept{
  for (uint64_t _fuseiter_8811 = 0UL; _fuseiter_8811 < 64UL; _fuseiter_8811 += 16UL) {
    vec_f32x16 __cached_0;
    __cached_0 = vec_f32x16::load(&__ins_0[_fuseiter_8811]);
    float __cached_1;
    __cached_1 = __ins_1[0];
    vec_f32x16 __cached_2;
    __cached_2 = (__cached_0 * vec_f32x16(__cached_1));
    vec_f32x16::store(__cached_2, &__outs_0[_fuseiter_8811]);
  }
  return true;
}

static bool mul__575(float* __restrict__ __outs_0, float* __restrict__ __ins_0, float* __restrict__ __ins_1) noexcept{
  for (uint64_t _fuseiter_8818 = 0UL; _fuseiter_8818 < 64UL; _fuseiter_8818 += 16UL) {
    vec_f32x16 __cached_0;
    __cached_0 = vec_f32x16::load(&__ins_0[_fuseiter_8818]);
    float __cached_1;
    __cached_1 = __ins_1[0];
    vec_f32x16 __cached_2;
    __cached_2 = (__cached_0 * vec_f32x16(__cached_1));
    vec_f32x16::store(__cached_2, &__outs_0[_fuseiter_8818]);
  }
  return true;
}

static bool mul__579(float* __restrict__ __outs_0, float* __restrict__ __ins_0, float* __restrict__ __ins_1) noexcept{
  for (uint64_t _fuseiter_8825 = 0UL; _fuseiter_8825 < 64UL; _fuseiter_8825 += 16UL) {
    vec_f32x16 __cached_0;
    __cached_0 = vec_f32x16::load(&__ins_0[_fuseiter_8825]);
    float __cached_1;
    __cached_1 = __ins_1[0];
    vec_f32x16 __cached_2;
    __cached_2 = (__cached_0 * vec_f32x16(__cached_1));
    vec_f32x16::store(__cached_2, &__outs_0[_fuseiter_8825]);
  }
  return true;
}

static bool mul__581(float* __restrict__ __outs_0, float* __restrict__ __ins_0, float* __restrict__ __ins_1) noexcept{
  for (uint64_t _fuseiter_8832 = 0UL; _fuseiter_8832 < 64UL; _fuseiter_8832 += 16UL) {
    vec_f32x16 __cached_0;
    __cached_0 = vec_f32x16::load(&__ins_0[_fuseiter_8832]);
    float __cached_1;
    __cached_1 = __ins_1[0];
    vec_f32x16 __cached_2;
    __cached_2 = (__cached_0 * vec_f32x16(__cached_1));
    vec_f32x16::store(__cached_2, &__outs_0[_fuseiter_8832]);
  }
  return true;
}

static bool mul__585(float* __restrict__ __outs_0, float* __restrict__ __ins_0, float* __restrict__ __ins_1) noexcept{
  for (uint64_t _fuseiter_8839 = 0UL; _fuseiter_8839 < 64UL; _fuseiter_8839 += 16UL) {
    vec_f32x16 __cached_0;
    __cached_0 = vec_f32x16::load(&__ins_0[_fuseiter_8839]);
    float __cached_1;
    __cached_1 = __ins_1[0];
    vec_f32x16 __cached_2;
    __cached_2 = (__cached_0 * vec_f32x16(__cached_1));
    vec_f32x16::store(__cached_2, &__outs_0[_fuseiter_8839]);
  }
  return true;
}

static bool mul__587(float* __restrict__ __outs_0, float* __restrict__ __ins_0, float* __restrict__ __ins_1) noexcept{
  for (uint64_t _fuseiter_8846 = 0UL; _fuseiter_8846 < 64UL; _fuseiter_8846 += 16UL) {
    vec_f32x16 __cached_0;
    __cached_0 = vec_f32x16::load(&__ins_0[_fuseiter_8846]);
    float __cached_1;
    __cached_1 = __ins_1[0];
    vec_f32x16 __cached_2;
    __cached_2 = (__cached_0 * vec_f32x16(__cached_1));
    vec_f32x16::store(__cached_2, &__outs_0[_fuseiter_8846]);
  }
  return true;
}

static bool reorder__441(float* __restrict__ __outs_0, float* __restrict__ __ins_0) noexcept{
  generic_val __tempargs90[2UL];
  __tempargs90[0UL] = __ins_0;
  __tempargs90[1UL] = __outs_0;
  sc_parallel_call_cpu_with_env((void*)&reorder__4410_closure_90_0wrapper, __stream, __module_data, 0UL, 2UL, 1UL, __tempargs90);
  return true;
}

static bool mul__593(float* __restrict__ __outs_0, float* __restrict__ __ins_0, float* __restrict__ __ins_1) noexcept{
  generic_val __tempargs91[3UL];
  __tempargs91[0UL] = __ins_0;
  __tempargs91[1UL] = __ins_1;
  __tempargs91[2UL] = __outs_0;
  sc_parallel_call_cpu_with_env((void*)&mul__5930_closure_91_0wrapper, __stream, __module_data, 0UL, 2UL, 1UL, __tempargs91);
  return true;
}

static bool reorder__444(float* __restrict__ __outs_0, float* __restrict__ __ins_0) noexcept{
  generic_val __tempargs92[2UL];
  __tempargs92[0UL] = __ins_0;
  __tempargs92[1UL] = __outs_0;
  sc_parallel_call_cpu_with_env((void*)&reorder__4440_closure_92_0wrapper, __stream, __module_data, 0UL, 2UL, 1UL, __tempargs92);
  return true;
}

static bool mul__595(float* __restrict__ __outs_0, float* __restrict__ __ins_0, float* __restrict__ __ins_1) noexcept{
  generic_val __tempargs93[3UL];
  __tempargs93[0UL] = __ins_0;
  __tempargs93[1UL] = __ins_1;
  __tempargs93[2UL] = __outs_0;
  sc_parallel_call_cpu_with_env((void*)&mul__5950_closure_93_0wrapper, __stream, __module_data, 0UL, 2UL, 1UL, __tempargs93);
  return true;
}

static bool reorder__450(float* __restrict__ __outs_0, float* __restrict__ __ins_0) noexcept{
  generic_val __tempargs94[2UL];
  __tempargs94[0UL] = __ins_0;
  __tempargs94[1UL] = __outs_0;
  sc_parallel_call_cpu_with_env((void*)&reorder__4500_closure_94_0wrapper, __stream, __module_data, 0UL, 2UL, 1UL, __tempargs94);
  return true;
}

static bool mul__599(float* __restrict__ __outs_0, float* __restrict__ __ins_0, float* __restrict__ __ins_1) noexcept{
  generic_val __tempargs95[3UL];
  __tempargs95[0UL] = __ins_0;
  __tempargs95[1UL] = __ins_1;
  __tempargs95[2UL] = __outs_0;
  sc_parallel_call_cpu_with_env((void*)&mul__5990_closure_95_0wrapper, __stream, __module_data, 0UL, 2UL, 1UL, __tempargs95);
  return true;
}

static bool reorder__453(float* __restrict__ __outs_0, float* __restrict__ __ins_0) noexcept{
  generic_val __tempargs96[2UL];
  __tempargs96[0UL] = __ins_0;
  __tempargs96[1UL] = __outs_0;
  sc_parallel_call_cpu_with_env((void*)&reorder__4530_closure_96_0wrapper, __stream, __module_data, 0UL, 2UL, 1UL, __tempargs96);
  return true;
}

static bool mul__601(float* __restrict__ __outs_0, float* __restrict__ __ins_0, float* __restrict__ __ins_1) noexcept{
  generic_val __tempargs97[3UL];
  __tempargs97[0UL] = __ins_0;
  __tempargs97[1UL] = __ins_1;
  __tempargs97[2UL] = __outs_0;
  sc_parallel_call_cpu_with_env((void*)&mul__6010_closure_97_0wrapper, __stream, __module_data, 0UL, 2UL, 1UL, __tempargs97);
  return true;
}

static bool reorder__459(float* __restrict__ __outs_0, float* __restrict__ __ins_0) noexcept{
  generic_val __tempargs98[2UL];
  __tempargs98[0UL] = __ins_0;
  __tempargs98[1UL] = __outs_0;
  sc_parallel_call_cpu_with_env((void*)&reorder__4590_closure_98_0wrapper, __stream, __module_data, 0UL, 2UL, 1UL, __tempargs98);
  return true;
}

static bool mul__605(float* __restrict__ __outs_0, float* __restrict__ __ins_0, float* __restrict__ __ins_1) noexcept{
  generic_val __tempargs99[3UL];
  __tempargs99[0UL] = __ins_0;
  __tempargs99[1UL] = __ins_1;
  __tempargs99[2UL] = __outs_0;
  sc_parallel_call_cpu_with_env((void*)&mul__6050_closure_99_0wrapper, __stream, __module_data, 0UL, 2UL, 1UL, __tempargs99);
  return true;
}

static bool reorder__462(float* __restrict__ __outs_0, float* __restrict__ __ins_0) noexcept{
  generic_val __tempargs100[2UL];
  __tempargs100[0UL] = __ins_0;
  __tempargs100[1UL] = __outs_0;
  sc_parallel_call_cpu_with_env((void*)&reorder__4620_closure_100_0wrapper, __stream, __module_data, 0UL, 2UL, 1UL, __tempargs100);
  return true;
}

static bool mul__607(float* __restrict__ __outs_0, float* __restrict__ __ins_0, float* __restrict__ __ins_1) noexcept{
  generic_val __tempargs101[3UL];
  __tempargs101[0UL] = __ins_0;
  __tempargs101[1UL] = __ins_1;
  __tempargs101[2UL] = __outs_0;
  sc_parallel_call_cpu_with_env((void*)&mul__6070_closure_101_0wrapper, __stream, __module_data, 0UL, 2UL, 1UL, __tempargs101);
  return true;
}

static bool reorder__468(float* __restrict__ __outs_0, float* __restrict__ __ins_0) noexcept{
  generic_val __tempargs102[2UL];
  __tempargs102[0UL] = __ins_0;
  __tempargs102[1UL] = __outs_0;
  sc_parallel_call_cpu_with_env((void*)&reorder__4680_closure_102_0wrapper, __stream, __module_data, 0UL, 2UL, 1UL, __tempargs102);
  return true;
}

static bool mul__611(float* __restrict__ __outs_0, float* __restrict__ __ins_0, float* __restrict__ __ins_1) noexcept{
  generic_val __tempargs103[3UL];
  __tempargs103[0UL] = __ins_0;
  __tempargs103[1UL] = __ins_1;
  __tempargs103[2UL] = __outs_0;
  sc_parallel_call_cpu_with_env((void*)&mul__6110_closure_103_0wrapper, __stream, __module_data, 0UL, 2UL, 1UL, __tempargs103);
  return true;
}

static bool reorder__471(float* __restrict__ __outs_0, float* __restrict__ __ins_0) noexcept{
  generic_val __tempargs104[2UL];
  __tempargs104[0UL] = __ins_0;
  __tempargs104[1UL] = __outs_0;
  sc_parallel_call_cpu_with_env((void*)&reorder__4710_closure_104_0wrapper, __stream, __module_data, 0UL, 2UL, 1UL, __tempargs104);
  return true;
}

static bool mul__613(float* __restrict__ __outs_0, float* __restrict__ __ins_0, float* __restrict__ __ins_1) noexcept{
  generic_val __tempargs105[3UL];
  __tempargs105[0UL] = __ins_0;
  __tempargs105[1UL] = __ins_1;
  __tempargs105[2UL] = __outs_0;
  sc_parallel_call_cpu_with_env((void*)&mul__6130_closure_105_0wrapper, __stream, __module_data, 0UL, 2UL, 1UL, __tempargs105);
  return true;
}

static bool reorder__420(float* __restrict__ __outs_0, float* __restrict__ __ins_0) noexcept{
  generic_val __tempargs106[2UL];
  __tempargs106[0UL] = __ins_0;
  __tempargs106[1UL] = __outs_0;
  sc_parallel_call_cpu_with_env((void*)&reorder__4200_closure_106_0wrapper, __stream, __module_data, 0UL, 4UL, 1UL, __tempargs106);
  return true;
}

static bool mul__571(float* __restrict__ __outs_0, float* __restrict__ __ins_0, float* __restrict__ __ins_1) noexcept{
  generic_val __tempargs107[3UL];
  __tempargs107[0UL] = __ins_0;
  __tempargs107[1UL] = __ins_1;
  __tempargs107[2UL] = __outs_0;
  sc_parallel_call_cpu_with_env((void*)&mul__5710_closure_107_0wrapper, __stream, __module_data, 0UL, 4UL, 1UL, __tempargs107);
  return true;
}

static bool reorder__425(float* __restrict__ __outs_0, float* __restrict__ __ins_0) noexcept{
  generic_val __tempargs108[2UL];
  __tempargs108[0UL] = __ins_0;
  __tempargs108[1UL] = __outs_0;
  sc_parallel_call_cpu_with_env((void*)&reorder__4250_closure_108_0wrapper, __stream, __module_data, 0UL, 4UL, 1UL, __tempargs108);
  return true;
}

static bool mul__577(float* __restrict__ __outs_0, float* __restrict__ __ins_0, float* __restrict__ __ins_1) noexcept{
  generic_val __tempargs109[3UL];
  __tempargs109[0UL] = __ins_0;
  __tempargs109[1UL] = __ins_1;
  __tempargs109[2UL] = __outs_0;
  sc_parallel_call_cpu_with_env((void*)&mul__5770_closure_109_0wrapper, __stream, __module_data, 0UL, 4UL, 1UL, __tempargs109);
  return true;
}

static bool reorder__430(float* __restrict__ __outs_0, float* __restrict__ __ins_0) noexcept{
  generic_val __tempargs110[2UL];
  __tempargs110[0UL] = __ins_0;
  __tempargs110[1UL] = __outs_0;
  sc_parallel_call_cpu_with_env((void*)&reorder__4300_closure_110_0wrapper, __stream, __module_data, 0UL, 4UL, 1UL, __tempargs110);
  return true;
}

static bool mul__583(float* __restrict__ __outs_0, float* __restrict__ __ins_0, float* __restrict__ __ins_1) noexcept{
  generic_val __tempargs111[3UL];
  __tempargs111[0UL] = __ins_0;
  __tempargs111[1UL] = __ins_1;
  __tempargs111[2UL] = __outs_0;
  sc_parallel_call_cpu_with_env((void*)&mul__5830_closure_111_0wrapper, __stream, __module_data, 0UL, 4UL, 1UL, __tempargs111);
  return true;
}

static bool reorder__435(float* __restrict__ __outs_0, float* __restrict__ __ins_0) noexcept{
  generic_val __tempargs112[2UL];
  __tempargs112[0UL] = __ins_0;
  __tempargs112[1UL] = __outs_0;
  sc_parallel_call_cpu_with_env((void*)&reorder__4350_closure_112_0wrapper, __stream, __module_data, 0UL, 4UL, 1UL, __tempargs112);
  return true;
}

static bool mul__589(float* __restrict__ __outs_0, float* __restrict__ __ins_0, float* __restrict__ __ins_1) noexcept{
  generic_val __tempargs113[3UL];
  __tempargs113[0UL] = __ins_0;
  __tempargs113[1UL] = __ins_1;
  __tempargs113[2UL] = __outs_0;
  sc_parallel_call_cpu_with_env((void*)&mul__5890_closure_113_0wrapper, __stream, __module_data, 0UL, 4UL, 1UL, __tempargs113);
  return true;
}

static bool reorder__480(float* __restrict__ __outs_0, float* __restrict__ __ins_0) noexcept{
  generic_val __tempargs114[2UL];
  __tempargs114[0UL] = __ins_0;
  __tempargs114[1UL] = __outs_0;
  sc_parallel_call_cpu_with_env((void*)&reorder__4800_closure_114_0wrapper, __stream, __module_data, 0UL, 4UL, 1UL, __tempargs114);
  return true;
}

static bool mul__619(float* __restrict__ __outs_0, float* __restrict__ __ins_0, float* __restrict__ __ins_1) noexcept{
  generic_val __tempargs115[3UL];
  __tempargs115[0UL] = __ins_0;
  __tempargs115[1UL] = __ins_1;
  __tempargs115[2UL] = __outs_0;
  sc_parallel_call_cpu_with_env((void*)&mul__6190_closure_115_0wrapper, __stream, __module_data, 0UL, 4UL, 1UL, __tempargs115);
  return true;
}

static bool reorder__483(float* __restrict__ __outs_0, float* __restrict__ __ins_0) noexcept{
  generic_val __tempargs116[2UL];
  __tempargs116[0UL] = __ins_0;
  __tempargs116[1UL] = __outs_0;
  sc_parallel_call_cpu_with_env((void*)&reorder__4830_closure_116_0wrapper, __stream, __module_data, 0UL, 4UL, 1UL, __tempargs116);
  return true;
}

static bool mul__621(float* __restrict__ __outs_0, float* __restrict__ __ins_0, float* __restrict__ __ins_1) noexcept{
  generic_val __tempargs117[3UL];
  __tempargs117[0UL] = __ins_0;
  __tempargs117[1UL] = __ins_1;
  __tempargs117[2UL] = __outs_0;
  sc_parallel_call_cpu_with_env((void*)&mul__6210_closure_117_0wrapper, __stream, __module_data, 0UL, 4UL, 1UL, __tempargs117);
  return true;
}

static bool reorder__489(float* __restrict__ __outs_0, float* __restrict__ __ins_0) noexcept{
  generic_val __tempargs118[2UL];
  __tempargs118[0UL] = __ins_0;
  __tempargs118[1UL] = __outs_0;
  sc_parallel_call_cpu_with_env((void*)&reorder__4890_closure_118_0wrapper, __stream, __module_data, 0UL, 4UL, 1UL, __tempargs118);
  return true;
}

static bool mul__625(float* __restrict__ __outs_0, float* __restrict__ __ins_0, float* __restrict__ __ins_1) noexcept{
  generic_val __tempargs119[3UL];
  __tempargs119[0UL] = __ins_0;
  __tempargs119[1UL] = __ins_1;
  __tempargs119[2UL] = __outs_0;
  sc_parallel_call_cpu_with_env((void*)&mul__6250_closure_119_0wrapper, __stream, __module_data, 0UL, 4UL, 1UL, __tempargs119);
  return true;
}

static bool reorder__492(float* __restrict__ __outs_0, float* __restrict__ __ins_0) noexcept{
  generic_val __tempargs120[2UL];
  __tempargs120[0UL] = __ins_0;
  __tempargs120[1UL] = __outs_0;
  sc_parallel_call_cpu_with_env((void*)&reorder__4920_closure_120_0wrapper, __stream, __module_data, 0UL, 4UL, 1UL, __tempargs120);
  return true;
}

static bool mul__627(float* __restrict__ __outs_0, float* __restrict__ __ins_0, float* __restrict__ __ins_1) noexcept{
  generic_val __tempargs121[3UL];
  __tempargs121[0UL] = __ins_0;
  __tempargs121[1UL] = __ins_1;
  __tempargs121[2UL] = __outs_0;
  sc_parallel_call_cpu_with_env((void*)&mul__6270_closure_121_0wrapper, __stream, __module_data, 0UL, 4UL, 1UL, __tempargs121);
  return true;
}

static bool reorder__498(float* __restrict__ __outs_0, float* __restrict__ __ins_0) noexcept{
  generic_val __tempargs122[2UL];
  __tempargs122[0UL] = __ins_0;
  __tempargs122[1UL] = __outs_0;
  sc_parallel_call_cpu_with_env((void*)&reorder__4980_closure_122_0wrapper, __stream, __module_data, 0UL, 4UL, 1UL, __tempargs122);
  return true;
}

static bool mul__631(float* __restrict__ __outs_0, float* __restrict__ __ins_0, float* __restrict__ __ins_1) noexcept{
  generic_val __tempargs123[3UL];
  __tempargs123[0UL] = __ins_0;
  __tempargs123[1UL] = __ins_1;
  __tempargs123[2UL] = __outs_0;
  sc_parallel_call_cpu_with_env((void*)&mul__6310_closure_123_0wrapper, __stream, __module_data, 0UL, 4UL, 1UL, __tempargs123);
  return true;
}

static bool reorder__501(float* __restrict__ __outs_0, float* __restrict__ __ins_0) noexcept{
  generic_val __tempargs124[2UL];
  __tempargs124[0UL] = __ins_0;
  __tempargs124[1UL] = __outs_0;
  sc_parallel_call_cpu_with_env((void*)&reorder__5010_closure_124_0wrapper, __stream, __module_data, 0UL, 4UL, 1UL, __tempargs124);
  return true;
}

static bool mul__633(float* __restrict__ __outs_0, float* __restrict__ __ins_0, float* __restrict__ __ins_1) noexcept{
  generic_val __tempargs125[3UL];
  __tempargs125[0UL] = __ins_0;
  __tempargs125[1UL] = __ins_1;
  __tempargs125[2UL] = __outs_0;
  sc_parallel_call_cpu_with_env((void*)&mul__6330_closure_125_0wrapper, __stream, __module_data, 0UL, 4UL, 1UL, __tempargs125);
  return true;
}

static bool reorder__507(float* __restrict__ __outs_0, float* __restrict__ __ins_0) noexcept{
  generic_val __tempargs126[2UL];
  __tempargs126[0UL] = __ins_0;
  __tempargs126[1UL] = __outs_0;
  sc_parallel_call_cpu_with_env((void*)&reorder__5070_closure_126_0wrapper, __stream, __module_data, 0UL, 4UL, 1UL, __tempargs126);
  return true;
}

static bool mul__637(float* __restrict__ __outs_0, float* __restrict__ __ins_0, float* __restrict__ __ins_1) noexcept{
  generic_val __tempargs127[3UL];
  __tempargs127[0UL] = __ins_0;
  __tempargs127[1UL] = __ins_1;
  __tempargs127[2UL] = __outs_0;
  sc_parallel_call_cpu_with_env((void*)&mul__6370_closure_127_0wrapper, __stream, __module_data, 0UL, 4UL, 1UL, __tempargs127);
  return true;
}

static bool reorder__510(float* __restrict__ __outs_0, float* __restrict__ __ins_0) noexcept{
  generic_val __tempargs128[2UL];
  __tempargs128[0UL] = __ins_0;
  __tempargs128[1UL] = __outs_0;
  sc_parallel_call_cpu_with_env((void*)&reorder__5100_closure_128_0wrapper, __stream, __module_data, 0UL, 4UL, 1UL, __tempargs128);
  return true;
}

static bool mul__639(float* __restrict__ __outs_0, float* __restrict__ __ins_0, float* __restrict__ __ins_1) noexcept{
  generic_val __tempargs129[3UL];
  __tempargs129[0UL] = __ins_0;
  __tempargs129[1UL] = __ins_1;
  __tempargs129[2UL] = __outs_0;
  sc_parallel_call_cpu_with_env((void*)&mul__6390_closure_129_0wrapper, __stream, __module_data, 0UL, 4UL, 1UL, __tempargs129);
  return true;
}

static bool reorder__516(float* __restrict__ __outs_0, float* __restrict__ __ins_0) noexcept{
  generic_val __tempargs130[2UL];
  __tempargs130[0UL] = __ins_0;
  __tempargs130[1UL] = __outs_0;
  sc_parallel_call_cpu_with_env((void*)&reorder__5160_closure_130_0wrapper, __stream, __module_data, 0UL, 4UL, 1UL, __tempargs130);
  return true;
}

static bool mul__643(float* __restrict__ __outs_0, float* __restrict__ __ins_0, float* __restrict__ __ins_1) noexcept{
  generic_val __tempargs131[3UL];
  __tempargs131[0UL] = __ins_0;
  __tempargs131[1UL] = __ins_1;
  __tempargs131[2UL] = __outs_0;
  sc_parallel_call_cpu_with_env((void*)&mul__6430_closure_131_0wrapper, __stream, __module_data, 0UL, 4UL, 1UL, __tempargs131);
  return true;
}

static bool reorder__519(float* __restrict__ __outs_0, float* __restrict__ __ins_0) noexcept{
  generic_val __tempargs132[2UL];
  __tempargs132[0UL] = __ins_0;
  __tempargs132[1UL] = __outs_0;
  sc_parallel_call_cpu_with_env((void*)&reorder__5190_closure_132_0wrapper, __stream, __module_data, 0UL, 4UL, 1UL, __tempargs132);
  return true;
}

static bool mul__645(float* __restrict__ __outs_0, float* __restrict__ __ins_0, float* __restrict__ __ins_1) noexcept{
  generic_val __tempargs133[3UL];
  __tempargs133[0UL] = __ins_0;
  __tempargs133[1UL] = __ins_1;
  __tempargs133[2UL] = __outs_0;
  sc_parallel_call_cpu_with_env((void*)&mul__6450_closure_133_0wrapper, __stream, __module_data, 0UL, 4UL, 1UL, __tempargs133);
  return true;
}

static bool reorder__525(float* __restrict__ __outs_0, float* __restrict__ __ins_0) noexcept{
  generic_val __tempargs134[2UL];
  __tempargs134[0UL] = __ins_0;
  __tempargs134[1UL] = __outs_0;
  sc_parallel_call_cpu_with_env((void*)&reorder__5250_closure_134_0wrapper, __stream, __module_data, 0UL, 4UL, 1UL, __tempargs134);
  return true;
}

static bool mul__649(float* __restrict__ __outs_0, float* __restrict__ __ins_0, float* __restrict__ __ins_1) noexcept{
  generic_val __tempargs135[3UL];
  __tempargs135[0UL] = __ins_0;
  __tempargs135[1UL] = __ins_1;
  __tempargs135[2UL] = __outs_0;
  sc_parallel_call_cpu_with_env((void*)&mul__6490_closure_135_0wrapper, __stream, __module_data, 0UL, 4UL, 1UL, __tempargs135);
  return true;
}

static bool reorder__528(float* __restrict__ __outs_0, float* __restrict__ __ins_0) noexcept{
  generic_val __tempargs136[2UL];
  __tempargs136[0UL] = __ins_0;
  __tempargs136[1UL] = __outs_0;
  sc_parallel_call_cpu_with_env((void*)&reorder__5280_closure_136_0wrapper, __stream, __module_data, 0UL, 4UL, 1UL, __tempargs136);
  return true;
}

static bool mul__651(float* __restrict__ __outs_0, float* __restrict__ __ins_0, float* __restrict__ __ins_1) noexcept{
  generic_val __tempargs137[3UL];
  __tempargs137[0UL] = __ins_0;
  __tempargs137[1UL] = __ins_1;
  __tempargs137[2UL] = __outs_0;
  sc_parallel_call_cpu_with_env((void*)&mul__6510_closure_137_0wrapper, __stream, __module_data, 0UL, 4UL, 1UL, __tempargs137);
  return true;
}

static bool reorder__438(float* __restrict__ __outs_0, float* __restrict__ __ins_0) noexcept{
  generic_val __tempargs138[2UL];
  __tempargs138[0UL] = __ins_0;
  __tempargs138[1UL] = __outs_0;
  sc_parallel_call_cpu_with_env((void*)&reorder__4380_closure_138_0wrapper, __stream, __module_data, 0UL, 8UL, 1UL, __tempargs138);
  return true;
}

static bool mul__591(float* __restrict__ __outs_0, float* __restrict__ __ins_0, float* __restrict__ __ins_1) noexcept{
  generic_val __tempargs139[3UL];
  __tempargs139[0UL] = __ins_0;
  __tempargs139[1UL] = __ins_1;
  __tempargs139[2UL] = __outs_0;
  sc_parallel_call_cpu_with_env((void*)&mul__5910_closure_139_0wrapper, __stream, __module_data, 0UL, 8UL, 1UL, __tempargs139);
  return true;
}

static bool reorder__447(float* __restrict__ __outs_0, float* __restrict__ __ins_0) noexcept{
  generic_val __tempargs140[2UL];
  __tempargs140[0UL] = __ins_0;
  __tempargs140[1UL] = __outs_0;
  sc_parallel_call_cpu_with_env((void*)&reorder__4470_closure_140_0wrapper, __stream, __module_data, 0UL, 8UL, 1UL, __tempargs140);
  return true;
}

static bool mul__597(float* __restrict__ __outs_0, float* __restrict__ __ins_0, float* __restrict__ __ins_1) noexcept{
  generic_val __tempargs141[3UL];
  __tempargs141[0UL] = __ins_0;
  __tempargs141[1UL] = __ins_1;
  __tempargs141[2UL] = __outs_0;
  sc_parallel_call_cpu_with_env((void*)&mul__5970_closure_141_0wrapper, __stream, __module_data, 0UL, 8UL, 1UL, __tempargs141);
  return true;
}

static bool reorder__456(float* __restrict__ __outs_0, float* __restrict__ __ins_0) noexcept{
  generic_val __tempargs142[2UL];
  __tempargs142[0UL] = __ins_0;
  __tempargs142[1UL] = __outs_0;
  sc_parallel_call_cpu_with_env((void*)&reorder__4560_closure_142_0wrapper, __stream, __module_data, 0UL, 8UL, 1UL, __tempargs142);
  return true;
}

static bool mul__603(float* __restrict__ __outs_0, float* __restrict__ __ins_0, float* __restrict__ __ins_1) noexcept{
  generic_val __tempargs143[3UL];
  __tempargs143[0UL] = __ins_0;
  __tempargs143[1UL] = __ins_1;
  __tempargs143[2UL] = __outs_0;
  sc_parallel_call_cpu_with_env((void*)&mul__6030_closure_143_0wrapper, __stream, __module_data, 0UL, 8UL, 1UL, __tempargs143);
  return true;
}

static bool reorder__465(float* __restrict__ __outs_0, float* __restrict__ __ins_0) noexcept{
  generic_val __tempargs144[2UL];
  __tempargs144[0UL] = __ins_0;
  __tempargs144[1UL] = __outs_0;
  sc_parallel_call_cpu_with_env((void*)&reorder__4650_closure_144_0wrapper, __stream, __module_data, 0UL, 8UL, 1UL, __tempargs144);
  return true;
}

static bool mul__609(float* __restrict__ __outs_0, float* __restrict__ __ins_0, float* __restrict__ __ins_1) noexcept{
  generic_val __tempargs145[3UL];
  __tempargs145[0UL] = __ins_0;
  __tempargs145[1UL] = __ins_1;
  __tempargs145[2UL] = __outs_0;
  sc_parallel_call_cpu_with_env((void*)&mul__6090_closure_145_0wrapper, __stream, __module_data, 0UL, 8UL, 1UL, __tempargs145);
  return true;
}

static bool reorder__474(float* __restrict__ __outs_0, float* __restrict__ __ins_0) noexcept{
  generic_val __tempargs146[2UL];
  __tempargs146[0UL] = __ins_0;
  __tempargs146[1UL] = __outs_0;
  sc_parallel_call_cpu_with_env((void*)&reorder__4740_closure_146_0wrapper, __stream, __module_data, 0UL, 8UL, 1UL, __tempargs146);
  return true;
}

static bool mul__615(float* __restrict__ __outs_0, float* __restrict__ __ins_0, float* __restrict__ __ins_1) noexcept{
  generic_val __tempargs147[3UL];
  __tempargs147[0UL] = __ins_0;
  __tempargs147[1UL] = __ins_1;
  __tempargs147[2UL] = __outs_0;
  sc_parallel_call_cpu_with_env((void*)&mul__6150_closure_147_0wrapper, __stream, __module_data, 0UL, 8UL, 1UL, __tempargs147);
  return true;
}

static bool mul__657(float* __restrict__ __outs_0, float* __restrict__ __ins_0, float* __restrict__ __ins_1) noexcept{
  for (uint64_t _fuseiter_9230 = 0UL; _fuseiter_9230 < 512UL; _fuseiter_9230 += 16UL) {
    vec_f32x16 __cached_0;
    __cached_0 = vec_f32x16::load(&__ins_0[_fuseiter_9230]);
    float __cached_1;
    __cached_1 = __ins_1[0];
    vec_f32x16 __cached_2;
    __cached_2 = (__cached_0 * vec_f32x16(__cached_1));
    vec_f32x16::store(__cached_2, &__outs_0[_fuseiter_9230]);
  }
  return true;
}

static bool reorder__538(float* __restrict__ __outs_0, float* __restrict__ __ins_0) noexcept{
  generic_val __tempargs148[2UL];
  __tempargs148[0UL] = __ins_0;
  __tempargs148[1UL] = __outs_0;
  sc_parallel_call_cpu_with_env((void*)&reorder__5380_closure_148_0wrapper, __stream, __module_data, 0UL, 2UL, 1UL, __tempargs148);
  return true;
}

static bool mul__659(float* __restrict__ __outs_0, float* __restrict__ __ins_0, float* __restrict__ __ins_1) noexcept{
  generic_val __tempargs149[3UL];
  __tempargs149[0UL] = __ins_0;
  __tempargs149[1UL] = __ins_1;
  __tempargs149[2UL] = __outs_0;
  sc_parallel_call_cpu_with_env((void*)&mul__6590_closure_149_0wrapper, __stream, __module_data, 0UL, 2UL, 1UL, __tempargs149);
  return true;
}

static bool reorder__544(float* __restrict__ __outs_0, float* __restrict__ __ins_0) noexcept{
  generic_val __tempargs150[2UL];
  __tempargs150[0UL] = __ins_0;
  __tempargs150[1UL] = __outs_0;
  sc_parallel_call_cpu_with_env((void*)&reorder__5440_closure_150_0wrapper, __stream, __module_data, 0UL, 8UL, 1UL, __tempargs150);
  return true;
}

static bool mul__663(float* __restrict__ __outs_0, float* __restrict__ __ins_0, float* __restrict__ __ins_1) noexcept{
  generic_val __tempargs151[3UL];
  __tempargs151[0UL] = __ins_0;
  __tempargs151[1UL] = __ins_1;
  __tempargs151[2UL] = __outs_0;
  sc_parallel_call_cpu_with_env((void*)&mul__6630_closure_151_0wrapper, __stream, __module_data, 0UL, 8UL, 1UL, __tempargs151);
  return true;
}

static bool reorder__547(float* __restrict__ __outs_0, float* __restrict__ __ins_0) noexcept{
  generic_val __tempargs152[2UL];
  __tempargs152[0UL] = __ins_0;
  __tempargs152[1UL] = __outs_0;
  sc_parallel_call_cpu_with_env((void*)&reorder__5470_closure_152_0wrapper, __stream, __module_data, 0UL, 4UL, 1UL, __tempargs152);
  return true;
}

static bool mul__665(float* __restrict__ __outs_0, float* __restrict__ __ins_0, float* __restrict__ __ins_1) noexcept{
  generic_val __tempargs153[3UL];
  __tempargs153[0UL] = __ins_0;
  __tempargs153[1UL] = __ins_1;
  __tempargs153[2UL] = __outs_0;
  sc_parallel_call_cpu_with_env((void*)&mul__6650_closure_153_0wrapper, __stream, __module_data, 0UL, 4UL, 1UL, __tempargs153);
  return true;
}

static bool reorder__553(float* __restrict__ __outs_0, float* __restrict__ __ins_0) noexcept{
  generic_val __tempargs154[2UL];
  __tempargs154[0UL] = __ins_0;
  __tempargs154[1UL] = __outs_0;
  sc_parallel_call_cpu_with_env((void*)&reorder__5530_closure_154_0wrapper, __stream, __module_data, 0UL, 2UL, 1UL, __tempargs154);
  return true;
}

static bool mul__669(float* __restrict__ __outs_0, float* __restrict__ __ins_0, float* __restrict__ __ins_1) noexcept{
  generic_val __tempargs155[3UL];
  __tempargs155[0UL] = __ins_0;
  __tempargs155[1UL] = __ins_1;
  __tempargs155[2UL] = __outs_0;
  sc_parallel_call_cpu_with_env((void*)&mul__6690_closure_155_0wrapper, __stream, __module_data, 0UL, 2UL, 1UL, __tempargs155);
  return true;
}

static bool reorder__556(float* __restrict__ __outs_0, float* __restrict__ __ins_0) noexcept{
  generic_val __tempargs156[2UL];
  __tempargs156[0UL] = __ins_0;
  __tempargs156[1UL] = __outs_0;
  sc_parallel_call_cpu_with_env((void*)&reorder__5560_closure_156_0wrapper, __stream, __module_data, 0UL, 8UL, 1UL, __tempargs156);
  return true;
}

static bool mul__671(float* __restrict__ __outs_0, float* __restrict__ __ins_0, float* __restrict__ __ins_1) noexcept{
  generic_val __tempargs157[3UL];
  __tempargs157[0UL] = __ins_0;
  __tempargs157[1UL] = __ins_1;
  __tempargs157[2UL] = __outs_0;
  sc_parallel_call_cpu_with_env((void*)&mul__6710_closure_157_0wrapper, __stream, __module_data, 0UL, 8UL, 1UL, __tempargs157);
  return true;
}

static bool reorder__477(float* __restrict__ __outs_0, float* __restrict__ __ins_0) noexcept{
  generic_val __tempargs158[2UL];
  __tempargs158[0UL] = __ins_0;
  __tempargs158[1UL] = __outs_0;
  sc_parallel_call_cpu_with_env((void*)&reorder__4770_closure_158_0wrapper, __stream, __module_data, 0UL, 16UL, 1UL, __tempargs158);
  return true;
}

static bool mul__617(float* __restrict__ __outs_0, float* __restrict__ __ins_0, float* __restrict__ __ins_1) noexcept{
  generic_val __tempargs159[3UL];
  __tempargs159[0UL] = __ins_0;
  __tempargs159[1UL] = __ins_1;
  __tempargs159[2UL] = __outs_0;
  sc_parallel_call_cpu_with_env((void*)&mul__6170_closure_159_0wrapper, __stream, __module_data, 0UL, 16UL, 1UL, __tempargs159);
  return true;
}

static bool reorder__486(float* __restrict__ __outs_0, float* __restrict__ __ins_0) noexcept{
  generic_val __tempargs160[2UL];
  __tempargs160[0UL] = __ins_0;
  __tempargs160[1UL] = __outs_0;
  sc_parallel_call_cpu_with_env((void*)&reorder__4860_closure_160_0wrapper, __stream, __module_data, 0UL, 16UL, 1UL, __tempargs160);
  return true;
}

static bool mul__623(float* __restrict__ __outs_0, float* __restrict__ __ins_0, float* __restrict__ __ins_1) noexcept{
  generic_val __tempargs161[3UL];
  __tempargs161[0UL] = __ins_0;
  __tempargs161[1UL] = __ins_1;
  __tempargs161[2UL] = __outs_0;
  sc_parallel_call_cpu_with_env((void*)&mul__6230_closure_161_0wrapper, __stream, __module_data, 0UL, 16UL, 1UL, __tempargs161);
  return true;
}

static bool reorder__495(float* __restrict__ __outs_0, float* __restrict__ __ins_0) noexcept{
  generic_val __tempargs162[2UL];
  __tempargs162[0UL] = __ins_0;
  __tempargs162[1UL] = __outs_0;
  sc_parallel_call_cpu_with_env((void*)&reorder__4950_closure_162_0wrapper, __stream, __module_data, 0UL, 16UL, 1UL, __tempargs162);
  return true;
}

static bool mul__629(float* __restrict__ __outs_0, float* __restrict__ __ins_0, float* __restrict__ __ins_1) noexcept{
  generic_val __tempargs163[3UL];
  __tempargs163[0UL] = __ins_0;
  __tempargs163[1UL] = __ins_1;
  __tempargs163[2UL] = __outs_0;
  sc_parallel_call_cpu_with_env((void*)&mul__6290_closure_163_0wrapper, __stream, __module_data, 0UL, 16UL, 1UL, __tempargs163);
  return true;
}

static bool reorder__504(float* __restrict__ __outs_0, float* __restrict__ __ins_0) noexcept{
  generic_val __tempargs164[2UL];
  __tempargs164[0UL] = __ins_0;
  __tempargs164[1UL] = __outs_0;
  sc_parallel_call_cpu_with_env((void*)&reorder__5040_closure_164_0wrapper, __stream, __module_data, 0UL, 16UL, 1UL, __tempargs164);
  return true;
}

static bool mul__635(float* __restrict__ __outs_0, float* __restrict__ __ins_0, float* __restrict__ __ins_1) noexcept{
  generic_val __tempargs165[3UL];
  __tempargs165[0UL] = __ins_0;
  __tempargs165[1UL] = __ins_1;
  __tempargs165[2UL] = __outs_0;
  sc_parallel_call_cpu_with_env((void*)&mul__6350_closure_165_0wrapper, __stream, __module_data, 0UL, 16UL, 1UL, __tempargs165);
  return true;
}

static bool reorder__513(float* __restrict__ __outs_0, float* __restrict__ __ins_0) noexcept{
  generic_val __tempargs166[2UL];
  __tempargs166[0UL] = __ins_0;
  __tempargs166[1UL] = __outs_0;
  sc_parallel_call_cpu_with_env((void*)&reorder__5130_closure_166_0wrapper, __stream, __module_data, 0UL, 16UL, 1UL, __tempargs166);
  return true;
}

static bool mul__641(float* __restrict__ __outs_0, float* __restrict__ __ins_0, float* __restrict__ __ins_1) noexcept{
  generic_val __tempargs167[3UL];
  __tempargs167[0UL] = __ins_0;
  __tempargs167[1UL] = __ins_1;
  __tempargs167[2UL] = __outs_0;
  sc_parallel_call_cpu_with_env((void*)&mul__6410_closure_167_0wrapper, __stream, __module_data, 0UL, 16UL, 1UL, __tempargs167);
  return true;
}

static bool reorder__522(float* __restrict__ __outs_0, float* __restrict__ __ins_0) noexcept{
  generic_val __tempargs168[2UL];
  __tempargs168[0UL] = __ins_0;
  __tempargs168[1UL] = __outs_0;
  sc_parallel_call_cpu_with_env((void*)&reorder__5220_closure_168_0wrapper, __stream, __module_data, 0UL, 16UL, 1UL, __tempargs168);
  return true;
}

static bool mul__647(float* __restrict__ __outs_0, float* __restrict__ __ins_0, float* __restrict__ __ins_1) noexcept{
  generic_val __tempargs169[3UL];
  __tempargs169[0UL] = __ins_0;
  __tempargs169[1UL] = __ins_1;
  __tempargs169[2UL] = __outs_0;
  sc_parallel_call_cpu_with_env((void*)&mul__6470_closure_169_0wrapper, __stream, __module_data, 0UL, 16UL, 1UL, __tempargs169);
  return true;
}

static bool reorder__531(float* __restrict__ __outs_0, float* __restrict__ __ins_0) noexcept{
  generic_val __tempargs170[2UL];
  __tempargs170[0UL] = __ins_0;
  __tempargs170[1UL] = __outs_0;
  sc_parallel_call_cpu_with_env((void*)&reorder__5310_closure_170_0wrapper, __stream, __module_data, 0UL, 16UL, 1UL, __tempargs170);
  return true;
}

static bool mul__653(float* __restrict__ __outs_0, float* __restrict__ __ins_0, float* __restrict__ __ins_1) noexcept{
  generic_val __tempargs171[3UL];
  __tempargs171[0UL] = __ins_0;
  __tempargs171[1UL] = __ins_1;
  __tempargs171[2UL] = __outs_0;
  sc_parallel_call_cpu_with_env((void*)&mul__6530_closure_171_0wrapper, __stream, __module_data, 0UL, 16UL, 1UL, __tempargs171);
  return true;
}

static bool reorder__534(float* __restrict__ __outs_0, float* __restrict__ __ins_0) noexcept{
  generic_val __tempargs172[2UL];
  __tempargs172[0UL] = __ins_0;
  __tempargs172[1UL] = __outs_0;
  sc_parallel_call_cpu_with_env((void*)&reorder__5340_closure_172_0wrapper, __stream, __module_data, 0UL, 4UL, 1UL, __tempargs172);
  return true;
}

static bool mul__655(float* __restrict__ __outs_0, float* __restrict__ __ins_0, float* __restrict__ __ins_1) noexcept{
  generic_val __tempargs173[3UL];
  __tempargs173[0UL] = __ins_0;
  __tempargs173[1UL] = __ins_1;
  __tempargs173[2UL] = __outs_0;
  sc_parallel_call_cpu_with_env((void*)&mul__6550_closure_173_0wrapper, __stream, __module_data, 0UL, 4UL, 1UL, __tempargs173);
  return true;
}

static bool reorder__541(float* __restrict__ __outs_0, float* __restrict__ __ins_0) noexcept{
  generic_val __tempargs174[2UL];
  __tempargs174[0UL] = __ins_0;
  __tempargs174[1UL] = __outs_0;
  sc_parallel_call_cpu_with_env((void*)&reorder__5410_closure_174_0wrapper, __stream, __module_data, 0UL, 4UL, 1UL, __tempargs174);
  return true;
}

static bool mul__661(float* __restrict__ __outs_0, float* __restrict__ __ins_0, float* __restrict__ __ins_1) noexcept{
  generic_val __tempargs175[3UL];
  __tempargs175[0UL] = __ins_0;
  __tempargs175[1UL] = __ins_1;
  __tempargs175[2UL] = __outs_0;
  sc_parallel_call_cpu_with_env((void*)&mul__6610_closure_175_0wrapper, __stream, __module_data, 0UL, 4UL, 1UL, __tempargs175);
  return true;
}

static bool reorder__550(float* __restrict__ __outs_0, float* __restrict__ __ins_0) noexcept{
  generic_val __tempargs176[2UL];
  __tempargs176[0UL] = __ins_0;
  __tempargs176[1UL] = __outs_0;
  sc_parallel_call_cpu_with_env((void*)&reorder__5500_closure_176_0wrapper, __stream, __module_data, 0UL, 4UL, 1UL, __tempargs176);
  return true;
}

static bool mul__667(float* __restrict__ __outs_0, float* __restrict__ __ins_0, float* __restrict__ __ins_1) noexcept{
  generic_val __tempargs177[3UL];
  __tempargs177[0UL] = __ins_0;
  __tempargs177[1UL] = __ins_1;
  __tempargs177[2UL] = __outs_0;
  sc_parallel_call_cpu_with_env((void*)&mul__6670_closure_177_0wrapper, __stream, __module_data, 0UL, 4UL, 1UL, __tempargs177);
  return true;
}

static bool reorder__559(float* __restrict__ __outs_0, float* __restrict__ __ins_0) noexcept{
  generic_val __tempargs178[2UL];
  __tempargs178[0UL] = __ins_0;
  __tempargs178[1UL] = __outs_0;
  sc_parallel_call_cpu_with_env((void*)&reorder__5590_closure_178_0wrapper, __stream, __module_data, 0UL, 4UL, 1UL, __tempargs178);
  return true;
}

static bool mul__673(float* __restrict__ __outs_0, float* __restrict__ __ins_0, float* __restrict__ __ins_1) noexcept{
  generic_val __tempargs179[3UL];
  __tempargs179[0UL] = __ins_0;
  __tempargs179[1UL] = __ins_1;
  __tempargs179[2UL] = __outs_0;
  sc_parallel_call_cpu_with_env((void*)&mul__6730_closure_179_0wrapper, __stream, __module_data, 0UL, 4UL, 1UL, __tempargs179);
  return true;
}

static bool mul__110(float* __restrict__ __outs_0, float* __restrict__ __ins_0, float* __restrict__ __ins_1) noexcept{
  generic_val __tempargs180[3UL];
  __tempargs180[0UL] = __ins_0;
  __tempargs180[1UL] = __ins_1;
  __tempargs180[2UL] = __outs_0;
  sc_parallel_call_cpu_with_env((void*)&mul__1100_closure_180_0wrapper, __stream, __module_data, 0UL, 4096UL, 1UL, __tempargs180);
  return true;
}

static bool cast__111(int8_t* __restrict__ __outs_0, float* __restrict__ __ins_0) noexcept{
  generic_val __tempargs181[2UL];
  __tempargs181[0UL] = __ins_0;
  __tempargs181[1UL] = __outs_0;
  sc_parallel_call_cpu_with_env((void*)&cast__1110_closure_181_0wrapper, __stream, __module_data, 0UL, 4096UL, 1UL, __tempargs181);
  return true;
}

static bool reorder__421(int8_t* __restrict__ __outs_0, int8_t* __restrict__ __ins_0) noexcept{
  generic_val __tempargs182[2UL];
  __tempargs182[0UL] = __ins_0;
  __tempargs182[1UL] = __outs_0;
  sc_parallel_call_cpu_with_env((void*)&reorder__4210_closure_182_0wrapper, __stream, __module_data, 0UL, 1024UL, 1UL, __tempargs182);
  return true;
}

static bool mul__107(float* __restrict__ __outs_0, float* __restrict__ __ins_0, float* __restrict__ __ins_1) noexcept{
  generic_val __tempargs183[3UL];
  __tempargs183[0UL] = __ins_0;
  __tempargs183[1UL] = __ins_1;
  __tempargs183[2UL] = __outs_0;
  sc_parallel_call_cpu_with_env((void*)&mul__1070_closure_183_0wrapper, __stream, __module_data, 0UL, 16384UL, 1UL, __tempargs183);
  return true;
}

static bool cast__108(int8_t* __restrict__ __outs_0, float* __restrict__ __ins_0) noexcept{
  generic_val __tempargs184[2UL];
  __tempargs184[0UL] = __ins_0;
  __tempargs184[1UL] = __outs_0;
  sc_parallel_call_cpu_with_env((void*)&cast__1080_closure_184_0wrapper, __stream, __module_data, 0UL, 16384UL, 1UL, __tempargs184);
  return true;
}

static bool reorder__418(int8_t* __restrict__ __outs_0, int8_t* __restrict__ __ins_0) noexcept{
  generic_val __tempargs185[2UL];
  __tempargs185[0UL] = __ins_0;
  __tempargs185[1UL] = __outs_0;
  sc_parallel_call_cpu_with_env((void*)&reorder__4180_closure_185_0wrapper, __stream, __module_data, 0UL, 64UL, 1UL, __tempargs185);
  return true;
}

static bool mul__116(float* __restrict__ __outs_0, float* __restrict__ __ins_0, float* __restrict__ __ins_1) noexcept{
  generic_val __tempargs186[3UL];
  __tempargs186[0UL] = __ins_0;
  __tempargs186[1UL] = __ins_1;
  __tempargs186[2UL] = __outs_0;
  sc_parallel_call_cpu_with_env((void*)&mul__1160_closure_186_0wrapper, __stream, __module_data, 0UL, 16384UL, 1UL, __tempargs186);
  return true;
}

static bool cast__117(int8_t* __restrict__ __outs_0, float* __restrict__ __ins_0) noexcept{
  generic_val __tempargs187[2UL];
  __tempargs187[0UL] = __ins_0;
  __tempargs187[1UL] = __outs_0;
  sc_parallel_call_cpu_with_env((void*)&cast__1170_closure_187_0wrapper, __stream, __module_data, 0UL, 16384UL, 1UL, __tempargs187);
  return true;
}

static bool reorder__423(int8_t* __restrict__ __outs_0, int8_t* __restrict__ __ins_0) noexcept{
  generic_val __tempargs188[2UL];
  __tempargs188[0UL] = __ins_0;
  __tempargs188[1UL] = __outs_0;
  sc_parallel_call_cpu_with_env((void*)&reorder__4230_closure_188_0wrapper, __stream, __module_data, 0UL, 64UL, 1UL, __tempargs188);
  return true;
}

static bool mul__125(float* __restrict__ __outs_0, float* __restrict__ __ins_0, float* __restrict__ __ins_1) noexcept{
  generic_val __tempargs189[3UL];
  __tempargs189[0UL] = __ins_0;
  __tempargs189[1UL] = __ins_1;
  __tempargs189[2UL] = __outs_0;
  sc_parallel_call_cpu_with_env((void*)&mul__1250_closure_189_0wrapper, __stream, __module_data, 0UL, 16384UL, 1UL, __tempargs189);
  return true;
}

static bool cast__126(int8_t* __restrict__ __outs_0, float* __restrict__ __ins_0) noexcept{
  generic_val __tempargs190[2UL];
  __tempargs190[0UL] = __ins_0;
  __tempargs190[1UL] = __outs_0;
  sc_parallel_call_cpu_with_env((void*)&cast__1260_closure_190_0wrapper, __stream, __module_data, 0UL, 16384UL, 1UL, __tempargs190);
  return true;
}

static bool reorder__428(int8_t* __restrict__ __outs_0, int8_t* __restrict__ __ins_0) noexcept{
  generic_val __tempargs191[2UL];
  __tempargs191[0UL] = __ins_0;
  __tempargs191[1UL] = __outs_0;
  sc_parallel_call_cpu_with_env((void*)&reorder__4280_closure_191_0wrapper, __stream, __module_data, 0UL, 64UL, 1UL, __tempargs191);
  return true;
}

static bool mul__134(float* __restrict__ __outs_0, float* __restrict__ __ins_0, float* __restrict__ __ins_1) noexcept{
  generic_val __tempargs192[3UL];
  __tempargs192[0UL] = __ins_0;
  __tempargs192[1UL] = __ins_1;
  __tempargs192[2UL] = __outs_0;
  sc_parallel_call_cpu_with_env((void*)&mul__1340_closure_192_0wrapper, __stream, __module_data, 0UL, 16384UL, 1UL, __tempargs192);
  return true;
}

static bool cast__135(int8_t* __restrict__ __outs_0, float* __restrict__ __ins_0) noexcept{
  generic_val __tempargs193[2UL];
  __tempargs193[0UL] = __ins_0;
  __tempargs193[1UL] = __outs_0;
  sc_parallel_call_cpu_with_env((void*)&cast__1350_closure_193_0wrapper, __stream, __module_data, 0UL, 16384UL, 1UL, __tempargs193);
  return true;
}

static bool reorder__433(int8_t* __restrict__ __outs_0, int8_t* __restrict__ __ins_0) noexcept{
  generic_val __tempargs194[2UL];
  __tempargs194[0UL] = __ins_0;
  __tempargs194[1UL] = __outs_0;
  sc_parallel_call_cpu_with_env((void*)&reorder__4330_closure_194_0wrapper, __stream, __module_data, 0UL, 64UL, 1UL, __tempargs194);
  return true;
}

static bool mul__119(float* __restrict__ __outs_0, float* __restrict__ __ins_0, float* __restrict__ __ins_1) noexcept{
  generic_val __tempargs195[3UL];
  __tempargs195[0UL] = __ins_0;
  __tempargs195[1UL] = __ins_1;
  __tempargs195[2UL] = __outs_0;
  sc_parallel_call_cpu_with_env((void*)&mul__1190_closure_195_0wrapper, __stream, __module_data, 0UL, 16384UL, 1UL, __tempargs195);
  return true;
}

static bool cast__120(int8_t* __restrict__ __outs_0, float* __restrict__ __ins_0) noexcept{
  generic_val __tempargs196[2UL];
  __tempargs196[0UL] = __ins_0;
  __tempargs196[1UL] = __outs_0;
  sc_parallel_call_cpu_with_env((void*)&cast__1200_closure_196_0wrapper, __stream, __module_data, 0UL, 16384UL, 1UL, __tempargs196);
  return true;
}

static bool reorder__426(int8_t* __restrict__ __outs_0, int8_t* __restrict__ __ins_0) noexcept{
  generic_val __tempargs197[2UL];
  __tempargs197[0UL] = __ins_0;
  __tempargs197[1UL] = __outs_0;
  sc_parallel_call_cpu_with_env((void*)&reorder__4260_closure_197_0wrapper, __stream, __module_data, 0UL, 64UL, 1UL, __tempargs197);
  return true;
}

static bool mul__128(float* __restrict__ __outs_0, float* __restrict__ __ins_0, float* __restrict__ __ins_1) noexcept{
  generic_val __tempargs198[3UL];
  __tempargs198[0UL] = __ins_0;
  __tempargs198[1UL] = __ins_1;
  __tempargs198[2UL] = __outs_0;
  sc_parallel_call_cpu_with_env((void*)&mul__1280_closure_198_0wrapper, __stream, __module_data, 0UL, 16384UL, 1UL, __tempargs198);
  return true;
}

static bool cast__129(int8_t* __restrict__ __outs_0, float* __restrict__ __ins_0) noexcept{
  generic_val __tempargs199[2UL];
  __tempargs199[0UL] = __ins_0;
  __tempargs199[1UL] = __outs_0;
  sc_parallel_call_cpu_with_env((void*)&cast__1290_closure_199_0wrapper, __stream, __module_data, 0UL, 16384UL, 1UL, __tempargs199);
  return true;
}

static bool reorder__431(int8_t* __restrict__ __outs_0, int8_t* __restrict__ __ins_0) noexcept{
  generic_val __tempargs200[2UL];
  __tempargs200[0UL] = __ins_0;
  __tempargs200[1UL] = __outs_0;
  sc_parallel_call_cpu_with_env((void*)&reorder__4310_closure_200_0wrapper, __stream, __module_data, 0UL, 64UL, 1UL, __tempargs200);
  return true;
}

static bool mul__140(float* __restrict__ __outs_0, float* __restrict__ __ins_0, float* __restrict__ __ins_1) noexcept{
  generic_val __tempargs201[3UL];
  __tempargs201[0UL] = __ins_0;
  __tempargs201[1UL] = __ins_1;
  __tempargs201[2UL] = __outs_0;
  sc_parallel_call_cpu_with_env((void*)&mul__1400_closure_201_0wrapper, __stream, __module_data, 0UL, 32768UL, 1UL, __tempargs201);
  return true;
}

static bool cast__141(int8_t* __restrict__ __outs_0, float* __restrict__ __ins_0) noexcept{
  generic_val __tempargs202[2UL];
  __tempargs202[0UL] = __ins_0;
  __tempargs202[1UL] = __outs_0;
  sc_parallel_call_cpu_with_env((void*)&cast__1410_closure_202_0wrapper, __stream, __module_data, 0UL, 32768UL, 1UL, __tempargs202);
  return true;
}

static bool reorder__439(int8_t* __restrict__ __outs_0, int8_t* __restrict__ __ins_0) noexcept{
  generic_val __tempargs203[2UL];
  __tempargs203[0UL] = __ins_0;
  __tempargs203[1UL] = __outs_0;
  sc_parallel_call_cpu_with_env((void*)&reorder__4390_closure_203_0wrapper, __stream, __module_data, 0UL, 128UL, 1UL, __tempargs203);
  return true;
}

static bool mul__113(float* __restrict__ __outs_0, float* __restrict__ __ins_0, float* __restrict__ __ins_1) noexcept{
  generic_val __tempargs204[3UL];
  __tempargs204[0UL] = __ins_0;
  __tempargs204[1UL] = __ins_1;
  __tempargs204[2UL] = __outs_0;
  sc_parallel_call_cpu_with_env((void*)&mul__1130_closure_204_0wrapper, __stream, __module_data, 0UL, 12288UL, 1UL, __tempargs204);
  return true;
}

static bool cast__114(int8_t* __restrict__ __outs_0, float* __restrict__ __ins_0) noexcept{
  generic_val __tempargs205[2UL];
  __tempargs205[0UL] = __ins_0;
  __tempargs205[1UL] = __outs_0;
  sc_parallel_call_cpu_with_env((void*)&cast__1140_closure_205_0wrapper, __stream, __module_data, 0UL, 12288UL, 1UL, __tempargs205);
  return true;
}

static bool reorder__422(int8_t* __restrict__ __outs_0, int8_t* __restrict__ __ins_0) noexcept{
  generic_val __tempargs206[2UL];
  __tempargs206[0UL] = __ins_0;
  __tempargs206[1UL] = __outs_0;
  sc_parallel_call_cpu_with_env((void*)&reorder__4220_closure_206_0wrapper, __stream, __module_data, 0UL, 144UL, 1UL, __tempargs206);
  return true;
}

static bool mul__122(float* __restrict__ __outs_0, float* __restrict__ __ins_0, float* __restrict__ __ins_1) noexcept{
  generic_val __tempargs207[3UL];
  __tempargs207[0UL] = __ins_0;
  __tempargs207[1UL] = __ins_1;
  __tempargs207[2UL] = __outs_0;
  sc_parallel_call_cpu_with_env((void*)&mul__1220_closure_207_0wrapper, __stream, __module_data, 0UL, 12288UL, 1UL, __tempargs207);
  return true;
}

static bool cast__123(int8_t* __restrict__ __outs_0, float* __restrict__ __ins_0) noexcept{
  generic_val __tempargs208[2UL];
  __tempargs208[0UL] = __ins_0;
  __tempargs208[1UL] = __outs_0;
  sc_parallel_call_cpu_with_env((void*)&cast__1230_closure_208_0wrapper, __stream, __module_data, 0UL, 12288UL, 1UL, __tempargs208);
  return true;
}

static bool reorder__427(int8_t* __restrict__ __outs_0, int8_t* __restrict__ __ins_0) noexcept{
  generic_val __tempargs209[2UL];
  __tempargs209[0UL] = __ins_0;
  __tempargs209[1UL] = __outs_0;
  sc_parallel_call_cpu_with_env((void*)&reorder__4270_closure_209_0wrapper, __stream, __module_data, 0UL, 144UL, 1UL, __tempargs209);
  return true;
}

static bool mul__131(float* __restrict__ __outs_0, float* __restrict__ __ins_0, float* __restrict__ __ins_1) noexcept{
  generic_val __tempargs210[3UL];
  __tempargs210[0UL] = __ins_0;
  __tempargs210[1UL] = __ins_1;
  __tempargs210[2UL] = __outs_0;
  sc_parallel_call_cpu_with_env((void*)&mul__1310_closure_210_0wrapper, __stream, __module_data, 0UL, 12288UL, 1UL, __tempargs210);
  return true;
}

static bool cast__132(int8_t* __restrict__ __outs_0, float* __restrict__ __ins_0) noexcept{
  generic_val __tempargs211[2UL];
  __tempargs211[0UL] = __ins_0;
  __tempargs211[1UL] = __outs_0;
  sc_parallel_call_cpu_with_env((void*)&cast__1320_closure_211_0wrapper, __stream, __module_data, 0UL, 12288UL, 1UL, __tempargs211);
  return true;
}

static bool reorder__432(int8_t* __restrict__ __outs_0, int8_t* __restrict__ __ins_0) noexcept{
  generic_val __tempargs212[2UL];
  __tempargs212[0UL] = __ins_0;
  __tempargs212[1UL] = __outs_0;
  sc_parallel_call_cpu_with_env((void*)&reorder__4320_closure_212_0wrapper, __stream, __module_data, 0UL, 144UL, 1UL, __tempargs212);
  return true;
}

static bool mul__146(float* __restrict__ __outs_0, float* __restrict__ __ins_0, float* __restrict__ __ins_1) noexcept{
  generic_val __tempargs213[3UL];
  __tempargs213[0UL] = __ins_0;
  __tempargs213[1UL] = __ins_1;
  __tempargs213[2UL] = __outs_0;
  sc_parallel_call_cpu_with_env((void*)&mul__1460_closure_213_0wrapper, __stream, __module_data, 0UL, 65536UL, 1UL, __tempargs213);
  return true;
}

static bool cast__147(int8_t* __restrict__ __outs_0, float* __restrict__ __ins_0) noexcept{
  generic_val __tempargs214[2UL];
  __tempargs214[0UL] = __ins_0;
  __tempargs214[1UL] = __outs_0;
  sc_parallel_call_cpu_with_env((void*)&cast__1470_closure_214_0wrapper, __stream, __module_data, 0UL, 65536UL, 1UL, __tempargs214);
  return true;
}

static bool reorder__445(int8_t* __restrict__ __outs_0, int8_t* __restrict__ __ins_0) noexcept{
  generic_val __tempargs215[2UL];
  __tempargs215[0UL] = __ins_0;
  __tempargs215[1UL] = __outs_0;
  sc_parallel_call_cpu_with_env((void*)&reorder__4450_closure_215_0wrapper, __stream, __module_data, 0UL, 256UL, 1UL, __tempargs215);
  return true;
}

static bool mul__155(float* __restrict__ __outs_0, float* __restrict__ __ins_0, float* __restrict__ __ins_1) noexcept{
  generic_val __tempargs216[3UL];
  __tempargs216[0UL] = __ins_0;
  __tempargs216[1UL] = __ins_1;
  __tempargs216[2UL] = __outs_0;
  sc_parallel_call_cpu_with_env((void*)&mul__1550_closure_216_0wrapper, __stream, __module_data, 0UL, 65536UL, 1UL, __tempargs216);
  return true;
}

static bool cast__156(int8_t* __restrict__ __outs_0, float* __restrict__ __ins_0) noexcept{
  generic_val __tempargs217[2UL];
  __tempargs217[0UL] = __ins_0;
  __tempargs217[1UL] = __outs_0;
  sc_parallel_call_cpu_with_env((void*)&cast__1560_closure_217_0wrapper, __stream, __module_data, 0UL, 65536UL, 1UL, __tempargs217);
  return true;
}

static bool reorder__454(int8_t* __restrict__ __outs_0, int8_t* __restrict__ __ins_0) noexcept{
  generic_val __tempargs218[2UL];
  __tempargs218[0UL] = __ins_0;
  __tempargs218[1UL] = __outs_0;
  sc_parallel_call_cpu_with_env((void*)&reorder__4540_closure_218_0wrapper, __stream, __module_data, 0UL, 256UL, 1UL, __tempargs218);
  return true;
}

static bool mul__164(float* __restrict__ __outs_0, float* __restrict__ __ins_0, float* __restrict__ __ins_1) noexcept{
  generic_val __tempargs219[3UL];
  __tempargs219[0UL] = __ins_0;
  __tempargs219[1UL] = __ins_1;
  __tempargs219[2UL] = __outs_0;
  sc_parallel_call_cpu_with_env((void*)&mul__1640_closure_219_0wrapper, __stream, __module_data, 0UL, 65536UL, 1UL, __tempargs219);
  return true;
}

static bool cast__165(int8_t* __restrict__ __outs_0, float* __restrict__ __ins_0) noexcept{
  generic_val __tempargs220[2UL];
  __tempargs220[0UL] = __ins_0;
  __tempargs220[1UL] = __outs_0;
  sc_parallel_call_cpu_with_env((void*)&cast__1650_closure_220_0wrapper, __stream, __module_data, 0UL, 65536UL, 1UL, __tempargs220);
  return true;
}

static bool reorder__463(int8_t* __restrict__ __outs_0, int8_t* __restrict__ __ins_0) noexcept{
  generic_val __tempargs221[2UL];
  __tempargs221[0UL] = __ins_0;
  __tempargs221[1UL] = __outs_0;
  sc_parallel_call_cpu_with_env((void*)&reorder__4630_closure_221_0wrapper, __stream, __module_data, 0UL, 256UL, 1UL, __tempargs221);
  return true;
}

static bool mul__173(float* __restrict__ __outs_0, float* __restrict__ __ins_0, float* __restrict__ __ins_1) noexcept{
  generic_val __tempargs222[3UL];
  __tempargs222[0UL] = __ins_0;
  __tempargs222[1UL] = __ins_1;
  __tempargs222[2UL] = __outs_0;
  sc_parallel_call_cpu_with_env((void*)&mul__1730_closure_222_0wrapper, __stream, __module_data, 0UL, 65536UL, 1UL, __tempargs222);
  return true;
}

static bool cast__174(int8_t* __restrict__ __outs_0, float* __restrict__ __ins_0) noexcept{
  generic_val __tempargs223[2UL];
  __tempargs223[0UL] = __ins_0;
  __tempargs223[1UL] = __outs_0;
  sc_parallel_call_cpu_with_env((void*)&cast__1740_closure_223_0wrapper, __stream, __module_data, 0UL, 65536UL, 1UL, __tempargs223);
  return true;
}

static bool reorder__472(int8_t* __restrict__ __outs_0, int8_t* __restrict__ __ins_0) noexcept{
  generic_val __tempargs224[2UL];
  __tempargs224[0UL] = __ins_0;
  __tempargs224[1UL] = __outs_0;
  sc_parallel_call_cpu_with_env((void*)&reorder__4720_closure_224_0wrapper, __stream, __module_data, 0UL, 256UL, 1UL, __tempargs224);
  return true;
}

static bool mul__149(float* __restrict__ __outs_0, float* __restrict__ __ins_0, float* __restrict__ __ins_1) noexcept{
  generic_val __tempargs225[3UL];
  __tempargs225[0UL] = __ins_0;
  __tempargs225[1UL] = __ins_1;
  __tempargs225[2UL] = __outs_0;
  sc_parallel_call_cpu_with_env((void*)&mul__1490_closure_225_0wrapper, __stream, __module_data, 0UL, 65536UL, 1UL, __tempargs225);
  return true;
}

static bool cast__150(int8_t* __restrict__ __outs_0, float* __restrict__ __ins_0) noexcept{
  generic_val __tempargs226[2UL];
  __tempargs226[0UL] = __ins_0;
  __tempargs226[1UL] = __outs_0;
  sc_parallel_call_cpu_with_env((void*)&cast__1500_closure_226_0wrapper, __stream, __module_data, 0UL, 65536UL, 1UL, __tempargs226);
  return true;
}

static bool reorder__448(int8_t* __restrict__ __outs_0, int8_t* __restrict__ __ins_0) noexcept{
  generic_val __tempargs227[2UL];
  __tempargs227[0UL] = __ins_0;
  __tempargs227[1UL] = __outs_0;
  sc_parallel_call_cpu_with_env((void*)&reorder__4480_closure_227_0wrapper, __stream, __module_data, 0UL, 256UL, 1UL, __tempargs227);
  return true;
}

static bool mul__158(float* __restrict__ __outs_0, float* __restrict__ __ins_0, float* __restrict__ __ins_1) noexcept{
  generic_val __tempargs228[3UL];
  __tempargs228[0UL] = __ins_0;
  __tempargs228[1UL] = __ins_1;
  __tempargs228[2UL] = __outs_0;
  sc_parallel_call_cpu_with_env((void*)&mul__1580_closure_228_0wrapper, __stream, __module_data, 0UL, 65536UL, 1UL, __tempargs228);
  return true;
}

static bool cast__159(int8_t* __restrict__ __outs_0, float* __restrict__ __ins_0) noexcept{
  generic_val __tempargs229[2UL];
  __tempargs229[0UL] = __ins_0;
  __tempargs229[1UL] = __outs_0;
  sc_parallel_call_cpu_with_env((void*)&cast__1590_closure_229_0wrapper, __stream, __module_data, 0UL, 65536UL, 1UL, __tempargs229);
  return true;
}

static bool reorder__457(int8_t* __restrict__ __outs_0, int8_t* __restrict__ __ins_0) noexcept{
  generic_val __tempargs230[2UL];
  __tempargs230[0UL] = __ins_0;
  __tempargs230[1UL] = __outs_0;
  sc_parallel_call_cpu_with_env((void*)&reorder__4570_closure_230_0wrapper, __stream, __module_data, 0UL, 256UL, 1UL, __tempargs230);
  return true;
}

static bool mul__167(float* __restrict__ __outs_0, float* __restrict__ __ins_0, float* __restrict__ __ins_1) noexcept{
  generic_val __tempargs231[3UL];
  __tempargs231[0UL] = __ins_0;
  __tempargs231[1UL] = __ins_1;
  __tempargs231[2UL] = __outs_0;
  sc_parallel_call_cpu_with_env((void*)&mul__1670_closure_231_0wrapper, __stream, __module_data, 0UL, 65536UL, 1UL, __tempargs231);
  return true;
}

static bool cast__168(int8_t* __restrict__ __outs_0, float* __restrict__ __ins_0) noexcept{
  generic_val __tempargs232[2UL];
  __tempargs232[0UL] = __ins_0;
  __tempargs232[1UL] = __outs_0;
  sc_parallel_call_cpu_with_env((void*)&cast__1680_closure_232_0wrapper, __stream, __module_data, 0UL, 65536UL, 1UL, __tempargs232);
  return true;
}

static bool reorder__466(int8_t* __restrict__ __outs_0, int8_t* __restrict__ __ins_0) noexcept{
  generic_val __tempargs233[2UL];
  __tempargs233[0UL] = __ins_0;
  __tempargs233[1UL] = __outs_0;
  sc_parallel_call_cpu_with_env((void*)&reorder__4660_closure_233_0wrapper, __stream, __module_data, 0UL, 256UL, 1UL, __tempargs233);
  return true;
}

static bool mul__137(float* __restrict__ __outs_0, float* __restrict__ __ins_0, float* __restrict__ __ins_1) noexcept{
  generic_val __tempargs234[3UL];
  __tempargs234[0UL] = __ins_0;
  __tempargs234[1UL] = __ins_1;
  __tempargs234[2UL] = __outs_0;
  sc_parallel_call_cpu_with_env((void*)&mul__1370_closure_234_0wrapper, __stream, __module_data, 0UL, 131072UL, 1UL, __tempargs234);
  return true;
}

static bool cast__138(int8_t* __restrict__ __outs_0, float* __restrict__ __ins_0) noexcept{
  generic_val __tempargs235[2UL];
  __tempargs235[0UL] = __ins_0;
  __tempargs235[1UL] = __outs_0;
  sc_parallel_call_cpu_with_env((void*)&cast__1380_closure_235_0wrapper, __stream, __module_data, 0UL, 131072UL, 1UL, __tempargs235);
  return true;
}

static bool reorder__436(int8_t* __restrict__ __outs_0, int8_t* __restrict__ __ins_0) noexcept{
  generic_val __tempargs236[2UL];
  __tempargs236[0UL] = __ins_0;
  __tempargs236[1UL] = __outs_0;
  sc_parallel_call_cpu_with_env((void*)&reorder__4360_closure_236_0wrapper, __stream, __module_data, 0UL, 32UL, 1UL, __tempargs236);
  return true;
}

static bool mul__179(float* __restrict__ __outs_0, float* __restrict__ __ins_0, float* __restrict__ __ins_1) noexcept{
  generic_val __tempargs237[3UL];
  __tempargs237[0UL] = __ins_0;
  __tempargs237[1UL] = __ins_1;
  __tempargs237[2UL] = __outs_0;
  sc_parallel_call_cpu_with_env((void*)&mul__1790_closure_237_0wrapper, __stream, __module_data, 0UL, 131072UL, 1UL, __tempargs237);
  return true;
}

static bool cast__180(int8_t* __restrict__ __outs_0, float* __restrict__ __ins_0) noexcept{
  generic_val __tempargs238[2UL];
  __tempargs238[0UL] = __ins_0;
  __tempargs238[1UL] = __outs_0;
  sc_parallel_call_cpu_with_env((void*)&cast__1800_closure_238_0wrapper, __stream, __module_data, 0UL, 131072UL, 1UL, __tempargs238);
  return true;
}

static bool reorder__478(int8_t* __restrict__ __outs_0, int8_t* __restrict__ __ins_0) noexcept{
  generic_val __tempargs239[2UL];
  __tempargs239[0UL] = __ins_0;
  __tempargs239[1UL] = __outs_0;
  sc_parallel_call_cpu_with_env((void*)&reorder__4780_closure_239_0wrapper, __stream, __module_data, 0UL, 32UL, 1UL, __tempargs239);
  return true;
}

static bool mul__143(float* __restrict__ __outs_0, float* __restrict__ __ins_0, float* __restrict__ __ins_1) noexcept{
  generic_val __tempargs240[3UL];
  __tempargs240[0UL] = __ins_0;
  __tempargs240[1UL] = __ins_1;
  __tempargs240[2UL] = __outs_0;
  sc_parallel_call_cpu_with_env((void*)&mul__1430_closure_240_0wrapper, __stream, __module_data, 0UL, 49152UL, 1UL, __tempargs240);
  return true;
}

static bool cast__144(int8_t* __restrict__ __outs_0, float* __restrict__ __ins_0) noexcept{
  generic_val __tempargs241[2UL];
  __tempargs241[0UL] = __ins_0;
  __tempargs241[1UL] = __outs_0;
  sc_parallel_call_cpu_with_env((void*)&cast__1440_closure_241_0wrapper, __stream, __module_data, 0UL, 49152UL, 1UL, __tempargs241);
  return true;
}

static bool reorder__442(int8_t* __restrict__ __outs_0, int8_t* __restrict__ __ins_0) noexcept{
  generic_val __tempargs242[2UL];
  __tempargs242[0UL] = __ins_0;
  __tempargs242[1UL] = __outs_0;
  sc_parallel_call_cpu_with_env((void*)&reorder__4420_closure_242_0wrapper, __stream, __module_data, 0UL, 36UL, 1UL, __tempargs242);
  return true;
}

static bool mul__152(float* __restrict__ __outs_0, float* __restrict__ __ins_0, float* __restrict__ __ins_1) noexcept{
  generic_val __tempargs243[3UL];
  __tempargs243[0UL] = __ins_0;
  __tempargs243[1UL] = __ins_1;
  __tempargs243[2UL] = __outs_0;
  sc_parallel_call_cpu_with_env((void*)&mul__1520_closure_243_0wrapper, __stream, __module_data, 0UL, 49152UL, 1UL, __tempargs243);
  return true;
}

static bool cast__153(int8_t* __restrict__ __outs_0, float* __restrict__ __ins_0) noexcept{
  generic_val __tempargs244[2UL];
  __tempargs244[0UL] = __ins_0;
  __tempargs244[1UL] = __outs_0;
  sc_parallel_call_cpu_with_env((void*)&cast__1530_closure_244_0wrapper, __stream, __module_data, 0UL, 49152UL, 1UL, __tempargs244);
  return true;
}

static bool reorder__451(int8_t* __restrict__ __outs_0, int8_t* __restrict__ __ins_0) noexcept{
  generic_val __tempargs245[2UL];
  __tempargs245[0UL] = __ins_0;
  __tempargs245[1UL] = __outs_0;
  sc_parallel_call_cpu_with_env((void*)&reorder__4510_closure_245_0wrapper, __stream, __module_data, 0UL, 36UL, 1UL, __tempargs245);
  return true;
}

static bool mul__161(float* __restrict__ __outs_0, float* __restrict__ __ins_0, float* __restrict__ __ins_1) noexcept{
  generic_val __tempargs246[3UL];
  __tempargs246[0UL] = __ins_0;
  __tempargs246[1UL] = __ins_1;
  __tempargs246[2UL] = __outs_0;
  sc_parallel_call_cpu_with_env((void*)&mul__1610_closure_246_0wrapper, __stream, __module_data, 0UL, 49152UL, 1UL, __tempargs246);
  return true;
}

static bool cast__162(int8_t* __restrict__ __outs_0, float* __restrict__ __ins_0) noexcept{
  generic_val __tempargs247[2UL];
  __tempargs247[0UL] = __ins_0;
  __tempargs247[1UL] = __outs_0;
  sc_parallel_call_cpu_with_env((void*)&cast__1620_closure_247_0wrapper, __stream, __module_data, 0UL, 49152UL, 1UL, __tempargs247);
  return true;
}

static bool reorder__460(int8_t* __restrict__ __outs_0, int8_t* __restrict__ __ins_0) noexcept{
  generic_val __tempargs248[2UL];
  __tempargs248[0UL] = __ins_0;
  __tempargs248[1UL] = __outs_0;
  sc_parallel_call_cpu_with_env((void*)&reorder__4600_closure_248_0wrapper, __stream, __module_data, 0UL, 36UL, 1UL, __tempargs248);
  return true;
}

static bool mul__170(float* __restrict__ __outs_0, float* __restrict__ __ins_0, float* __restrict__ __ins_1) noexcept{
  generic_val __tempargs249[3UL];
  __tempargs249[0UL] = __ins_0;
  __tempargs249[1UL] = __ins_1;
  __tempargs249[2UL] = __outs_0;
  sc_parallel_call_cpu_with_env((void*)&mul__1700_closure_249_0wrapper, __stream, __module_data, 0UL, 49152UL, 1UL, __tempargs249);
  return true;
}

static bool cast__171(int8_t* __restrict__ __outs_0, float* __restrict__ __ins_0) noexcept{
  generic_val __tempargs250[2UL];
  __tempargs250[0UL] = __ins_0;
  __tempargs250[1UL] = __outs_0;
  sc_parallel_call_cpu_with_env((void*)&cast__1710_closure_250_0wrapper, __stream, __module_data, 0UL, 49152UL, 1UL, __tempargs250);
  return true;
}

static bool reorder__469(int8_t* __restrict__ __outs_0, int8_t* __restrict__ __ins_0) noexcept{
  generic_val __tempargs251[2UL];
  __tempargs251[0UL] = __ins_0;
  __tempargs251[1UL] = __outs_0;
  sc_parallel_call_cpu_with_env((void*)&reorder__4690_closure_251_0wrapper, __stream, __module_data, 0UL, 36UL, 1UL, __tempargs251);
  return true;
}

static bool mul__185(float* __restrict__ __outs_0, float* __restrict__ __ins_0, float* __restrict__ __ins_1) noexcept{
  generic_val __tempargs252[3UL];
  __tempargs252[0UL] = __ins_0;
  __tempargs252[1UL] = __ins_1;
  __tempargs252[2UL] = __outs_0;
  sc_parallel_call_cpu_with_env((void*)&mul__1850_closure_252_0wrapper, __stream, __module_data, 0UL, 262144UL, 1UL, __tempargs252);
  return true;
}

static bool cast__186(int8_t* __restrict__ __outs_0, float* __restrict__ __ins_0) noexcept{
  generic_val __tempargs253[2UL];
  __tempargs253[0UL] = __ins_0;
  __tempargs253[1UL] = __outs_0;
  sc_parallel_call_cpu_with_env((void*)&cast__1860_closure_253_0wrapper, __stream, __module_data, 0UL, 262144UL, 1UL, __tempargs253);
  return true;
}

static bool reorder__484(int8_t* __restrict__ __outs_0, int8_t* __restrict__ __ins_0) noexcept{
  generic_val __tempargs254[2UL];
  __tempargs254[0UL] = __ins_0;
  __tempargs254[1UL] = __outs_0;
  sc_parallel_call_cpu_with_env((void*)&reorder__4840_closure_254_0wrapper, __stream, __module_data, 0UL, 64UL, 1UL, __tempargs254);
  return true;
}

static bool mul__194(float* __restrict__ __outs_0, float* __restrict__ __ins_0, float* __restrict__ __ins_1) noexcept{
  generic_val __tempargs255[3UL];
  __tempargs255[0UL] = __ins_0;
  __tempargs255[1UL] = __ins_1;
  __tempargs255[2UL] = __outs_0;
  sc_parallel_call_cpu_with_env((void*)&mul__1940_closure_255_0wrapper, __stream, __module_data, 0UL, 262144UL, 1UL, __tempargs255);
  return true;
}

static bool cast__195(int8_t* __restrict__ __outs_0, float* __restrict__ __ins_0) noexcept{
  generic_val __tempargs256[2UL];
  __tempargs256[0UL] = __ins_0;
  __tempargs256[1UL] = __outs_0;
  sc_parallel_call_cpu_with_env((void*)&cast__1950_closure_256_0wrapper, __stream, __module_data, 0UL, 262144UL, 1UL, __tempargs256);
  return true;
}

static bool reorder__493(int8_t* __restrict__ __outs_0, int8_t* __restrict__ __ins_0) noexcept{
  generic_val __tempargs257[2UL];
  __tempargs257[0UL] = __ins_0;
  __tempargs257[1UL] = __outs_0;
  sc_parallel_call_cpu_with_env((void*)&reorder__4930_closure_257_0wrapper, __stream, __module_data, 0UL, 64UL, 1UL, __tempargs257);
  return true;
}

static bool mul__203(float* __restrict__ __outs_0, float* __restrict__ __ins_0, float* __restrict__ __ins_1) noexcept{
  generic_val __tempargs258[3UL];
  __tempargs258[0UL] = __ins_0;
  __tempargs258[1UL] = __ins_1;
  __tempargs258[2UL] = __outs_0;
  sc_parallel_call_cpu_with_env((void*)&mul__2030_closure_258_0wrapper, __stream, __module_data, 0UL, 262144UL, 1UL, __tempargs258);
  return true;
}

static bool cast__204(int8_t* __restrict__ __outs_0, float* __restrict__ __ins_0) noexcept{
  generic_val __tempargs259[2UL];
  __tempargs259[0UL] = __ins_0;
  __tempargs259[1UL] = __outs_0;
  sc_parallel_call_cpu_with_env((void*)&cast__2040_closure_259_0wrapper, __stream, __module_data, 0UL, 262144UL, 1UL, __tempargs259);
  return true;
}

static bool reorder__502(int8_t* __restrict__ __outs_0, int8_t* __restrict__ __ins_0) noexcept{
  generic_val __tempargs260[2UL];
  __tempargs260[0UL] = __ins_0;
  __tempargs260[1UL] = __outs_0;
  sc_parallel_call_cpu_with_env((void*)&reorder__5020_closure_260_0wrapper, __stream, __module_data, 0UL, 64UL, 1UL, __tempargs260);
  return true;
}

static bool mul__212(float* __restrict__ __outs_0, float* __restrict__ __ins_0, float* __restrict__ __ins_1) noexcept{
  generic_val __tempargs261[3UL];
  __tempargs261[0UL] = __ins_0;
  __tempargs261[1UL] = __ins_1;
  __tempargs261[2UL] = __outs_0;
  sc_parallel_call_cpu_with_env((void*)&mul__2120_closure_261_0wrapper, __stream, __module_data, 0UL, 262144UL, 1UL, __tempargs261);
  return true;
}

static bool cast__213(int8_t* __restrict__ __outs_0, float* __restrict__ __ins_0) noexcept{
  generic_val __tempargs262[2UL];
  __tempargs262[0UL] = __ins_0;
  __tempargs262[1UL] = __outs_0;
  sc_parallel_call_cpu_with_env((void*)&cast__2130_closure_262_0wrapper, __stream, __module_data, 0UL, 262144UL, 1UL, __tempargs262);
  return true;
}

static bool reorder__511(int8_t* __restrict__ __outs_0, int8_t* __restrict__ __ins_0) noexcept{
  generic_val __tempargs263[2UL];
  __tempargs263[0UL] = __ins_0;
  __tempargs263[1UL] = __outs_0;
  sc_parallel_call_cpu_with_env((void*)&reorder__5110_closure_263_0wrapper, __stream, __module_data, 0UL, 64UL, 1UL, __tempargs263);
  return true;
}

static bool mul__221(float* __restrict__ __outs_0, float* __restrict__ __ins_0, float* __restrict__ __ins_1) noexcept{
  generic_val __tempargs264[3UL];
  __tempargs264[0UL] = __ins_0;
  __tempargs264[1UL] = __ins_1;
  __tempargs264[2UL] = __outs_0;
  sc_parallel_call_cpu_with_env((void*)&mul__2210_closure_264_0wrapper, __stream, __module_data, 0UL, 262144UL, 1UL, __tempargs264);
  return true;
}

static bool cast__222(int8_t* __restrict__ __outs_0, float* __restrict__ __ins_0) noexcept{
  generic_val __tempargs265[2UL];
  __tempargs265[0UL] = __ins_0;
  __tempargs265[1UL] = __outs_0;
  sc_parallel_call_cpu_with_env((void*)&cast__2220_closure_265_0wrapper, __stream, __module_data, 0UL, 262144UL, 1UL, __tempargs265);
  return true;
}

static bool reorder__520(int8_t* __restrict__ __outs_0, int8_t* __restrict__ __ins_0) noexcept{
  generic_val __tempargs266[2UL];
  __tempargs266[0UL] = __ins_0;
  __tempargs266[1UL] = __outs_0;
  sc_parallel_call_cpu_with_env((void*)&reorder__5200_closure_266_0wrapper, __stream, __module_data, 0UL, 64UL, 1UL, __tempargs266);
  return true;
}

static bool mul__230(float* __restrict__ __outs_0, float* __restrict__ __ins_0, float* __restrict__ __ins_1) noexcept{
  generic_val __tempargs267[3UL];
  __tempargs267[0UL] = __ins_0;
  __tempargs267[1UL] = __ins_1;
  __tempargs267[2UL] = __outs_0;
  sc_parallel_call_cpu_with_env((void*)&mul__2300_closure_267_0wrapper, __stream, __module_data, 0UL, 262144UL, 1UL, __tempargs267);
  return true;
}

static bool cast__231(int8_t* __restrict__ __outs_0, float* __restrict__ __ins_0) noexcept{
  generic_val __tempargs268[2UL];
  __tempargs268[0UL] = __ins_0;
  __tempargs268[1UL] = __outs_0;
  sc_parallel_call_cpu_with_env((void*)&cast__2310_closure_268_0wrapper, __stream, __module_data, 0UL, 262144UL, 1UL, __tempargs268);
  return true;
}

static bool reorder__529(int8_t* __restrict__ __outs_0, int8_t* __restrict__ __ins_0) noexcept{
  generic_val __tempargs269[2UL];
  __tempargs269[0UL] = __ins_0;
  __tempargs269[1UL] = __outs_0;
  sc_parallel_call_cpu_with_env((void*)&reorder__5290_closure_269_0wrapper, __stream, __module_data, 0UL, 64UL, 1UL, __tempargs269);
  return true;
}

static bool mul__188(float* __restrict__ __outs_0, float* __restrict__ __ins_0, float* __restrict__ __ins_1) noexcept{
  generic_val __tempargs270[3UL];
  __tempargs270[0UL] = __ins_0;
  __tempargs270[1UL] = __ins_1;
  __tempargs270[2UL] = __outs_0;
  sc_parallel_call_cpu_with_env((void*)&mul__1880_closure_270_0wrapper, __stream, __module_data, 0UL, 262144UL, 1UL, __tempargs270);
  return true;
}

static bool cast__189(int8_t* __restrict__ __outs_0, float* __restrict__ __ins_0) noexcept{
  generic_val __tempargs271[2UL];
  __tempargs271[0UL] = __ins_0;
  __tempargs271[1UL] = __outs_0;
  sc_parallel_call_cpu_with_env((void*)&cast__1890_closure_271_0wrapper, __stream, __module_data, 0UL, 262144UL, 1UL, __tempargs271);
  return true;
}

static bool reorder__487(int8_t* __restrict__ __outs_0, int8_t* __restrict__ __ins_0) noexcept{
  generic_val __tempargs272[2UL];
  __tempargs272[0UL] = __ins_0;
  __tempargs272[1UL] = __outs_0;
  sc_parallel_call_cpu_with_env((void*)&reorder__4870_closure_272_0wrapper, __stream, __module_data, 0UL, 64UL, 1UL, __tempargs272);
  return true;
}

static bool mul__197(float* __restrict__ __outs_0, float* __restrict__ __ins_0, float* __restrict__ __ins_1) noexcept{
  generic_val __tempargs273[3UL];
  __tempargs273[0UL] = __ins_0;
  __tempargs273[1UL] = __ins_1;
  __tempargs273[2UL] = __outs_0;
  sc_parallel_call_cpu_with_env((void*)&mul__1970_closure_273_0wrapper, __stream, __module_data, 0UL, 262144UL, 1UL, __tempargs273);
  return true;
}

static bool cast__198(int8_t* __restrict__ __outs_0, float* __restrict__ __ins_0) noexcept{
  generic_val __tempargs274[2UL];
  __tempargs274[0UL] = __ins_0;
  __tempargs274[1UL] = __outs_0;
  sc_parallel_call_cpu_with_env((void*)&cast__1980_closure_274_0wrapper, __stream, __module_data, 0UL, 262144UL, 1UL, __tempargs274);
  return true;
}

static bool reorder__496(int8_t* __restrict__ __outs_0, int8_t* __restrict__ __ins_0) noexcept{
  generic_val __tempargs275[2UL];
  __tempargs275[0UL] = __ins_0;
  __tempargs275[1UL] = __outs_0;
  sc_parallel_call_cpu_with_env((void*)&reorder__4960_closure_275_0wrapper, __stream, __module_data, 0UL, 64UL, 1UL, __tempargs275);
  return true;
}

static bool mul__206(float* __restrict__ __outs_0, float* __restrict__ __ins_0, float* __restrict__ __ins_1) noexcept{
  generic_val __tempargs276[3UL];
  __tempargs276[0UL] = __ins_0;
  __tempargs276[1UL] = __ins_1;
  __tempargs276[2UL] = __outs_0;
  sc_parallel_call_cpu_with_env((void*)&mul__2060_closure_276_0wrapper, __stream, __module_data, 0UL, 262144UL, 1UL, __tempargs276);
  return true;
}

static bool cast__207(int8_t* __restrict__ __outs_0, float* __restrict__ __ins_0) noexcept{
  generic_val __tempargs277[2UL];
  __tempargs277[0UL] = __ins_0;
  __tempargs277[1UL] = __outs_0;
  sc_parallel_call_cpu_with_env((void*)&cast__2070_closure_277_0wrapper, __stream, __module_data, 0UL, 262144UL, 1UL, __tempargs277);
  return true;
}

static bool reorder__505(int8_t* __restrict__ __outs_0, int8_t* __restrict__ __ins_0) noexcept{
  generic_val __tempargs278[2UL];
  __tempargs278[0UL] = __ins_0;
  __tempargs278[1UL] = __outs_0;
  sc_parallel_call_cpu_with_env((void*)&reorder__5050_closure_278_0wrapper, __stream, __module_data, 0UL, 64UL, 1UL, __tempargs278);
  return true;
}

static bool mul__215(float* __restrict__ __outs_0, float* __restrict__ __ins_0, float* __restrict__ __ins_1) noexcept{
  generic_val __tempargs279[3UL];
  __tempargs279[0UL] = __ins_0;
  __tempargs279[1UL] = __ins_1;
  __tempargs279[2UL] = __outs_0;
  sc_parallel_call_cpu_with_env((void*)&mul__2150_closure_279_0wrapper, __stream, __module_data, 0UL, 262144UL, 1UL, __tempargs279);
  return true;
}

static bool cast__216(int8_t* __restrict__ __outs_0, float* __restrict__ __ins_0) noexcept{
  generic_val __tempargs280[2UL];
  __tempargs280[0UL] = __ins_0;
  __tempargs280[1UL] = __outs_0;
  sc_parallel_call_cpu_with_env((void*)&cast__2160_closure_280_0wrapper, __stream, __module_data, 0UL, 262144UL, 1UL, __tempargs280);
  return true;
}

static bool reorder__514(int8_t* __restrict__ __outs_0, int8_t* __restrict__ __ins_0) noexcept{
  generic_val __tempargs281[2UL];
  __tempargs281[0UL] = __ins_0;
  __tempargs281[1UL] = __outs_0;
  sc_parallel_call_cpu_with_env((void*)&reorder__5140_closure_281_0wrapper, __stream, __module_data, 0UL, 64UL, 1UL, __tempargs281);
  return true;
}

static bool mul__224(float* __restrict__ __outs_0, float* __restrict__ __ins_0, float* __restrict__ __ins_1) noexcept{
  generic_val __tempargs282[3UL];
  __tempargs282[0UL] = __ins_0;
  __tempargs282[1UL] = __ins_1;
  __tempargs282[2UL] = __outs_0;
  sc_parallel_call_cpu_with_env((void*)&mul__2240_closure_282_0wrapper, __stream, __module_data, 0UL, 262144UL, 1UL, __tempargs282);
  return true;
}

static bool cast__225(int8_t* __restrict__ __outs_0, float* __restrict__ __ins_0) noexcept{
  generic_val __tempargs283[2UL];
  __tempargs283[0UL] = __ins_0;
  __tempargs283[1UL] = __outs_0;
  sc_parallel_call_cpu_with_env((void*)&cast__2250_closure_283_0wrapper, __stream, __module_data, 0UL, 262144UL, 1UL, __tempargs283);
  return true;
}

static bool reorder__523(int8_t* __restrict__ __outs_0, int8_t* __restrict__ __ins_0) noexcept{
  generic_val __tempargs284[2UL];
  __tempargs284[0UL] = __ins_0;
  __tempargs284[1UL] = __outs_0;
  sc_parallel_call_cpu_with_env((void*)&reorder__5230_closure_284_0wrapper, __stream, __module_data, 0UL, 64UL, 1UL, __tempargs284);
  return true;
}

static bool mul__176(float* __restrict__ __outs_0, float* __restrict__ __ins_0, float* __restrict__ __ins_1) noexcept{
  generic_val __tempargs285[3UL];
  __tempargs285[0UL] = __ins_0;
  __tempargs285[1UL] = __ins_1;
  __tempargs285[2UL] = __outs_0;
  sc_parallel_call_cpu_with_env((void*)&mul__1760_closure_285_0wrapper, __stream, __module_data, 0UL, 524288UL, 1UL, __tempargs285);
  return true;
}

static bool cast__177(int8_t* __restrict__ __outs_0, float* __restrict__ __ins_0) noexcept{
  generic_val __tempargs286[2UL];
  __tempargs286[0UL] = __ins_0;
  __tempargs286[1UL] = __outs_0;
  sc_parallel_call_cpu_with_env((void*)&cast__1770_closure_286_0wrapper, __stream, __module_data, 0UL, 524288UL, 1UL, __tempargs286);
  return true;
}

static bool reorder__475(int8_t* __restrict__ __outs_0, int8_t* __restrict__ __ins_0) noexcept{
  generic_val __tempargs287[2UL];
  __tempargs287[0UL] = __ins_0;
  __tempargs287[1UL] = __outs_0;
  sc_parallel_call_cpu_with_env((void*)&reorder__4750_closure_287_0wrapper, __stream, __module_data, 0UL, 128UL, 1UL, __tempargs287);
  return true;
}

static bool mul__236(float* __restrict__ __outs_0, float* __restrict__ __ins_0, float* __restrict__ __ins_1) noexcept{
  generic_val __tempargs288[3UL];
  __tempargs288[0UL] = __ins_0;
  __tempargs288[1UL] = __ins_1;
  __tempargs288[2UL] = __outs_0;
  sc_parallel_call_cpu_with_env((void*)&mul__2360_closure_288_0wrapper, __stream, __module_data, 0UL, 524288UL, 1UL, __tempargs288);
  return true;
}

static bool cast__237(int8_t* __restrict__ __outs_0, float* __restrict__ __ins_0) noexcept{
  generic_val __tempargs289[2UL];
  __tempargs289[0UL] = __ins_0;
  __tempargs289[1UL] = __outs_0;
  sc_parallel_call_cpu_with_env((void*)&cast__2370_closure_289_0wrapper, __stream, __module_data, 0UL, 524288UL, 1UL, __tempargs289);
  return true;
}

static bool reorder__535(int8_t* __restrict__ __outs_0, int8_t* __restrict__ __ins_0) noexcept{
  generic_val __tempargs290[2UL];
  __tempargs290[0UL] = __ins_0;
  __tempargs290[1UL] = __outs_0;
  sc_parallel_call_cpu_with_env((void*)&reorder__5350_closure_290_0wrapper, __stream, __module_data, 0UL, 256UL, 1UL, __tempargs290);
  return true;
}

static bool mul__182(float* __restrict__ __outs_0, float* __restrict__ __ins_0, float* __restrict__ __ins_1) noexcept{
  generic_val __tempargs291[3UL];
  __tempargs291[0UL] = __ins_0;
  __tempargs291[1UL] = __ins_1;
  __tempargs291[2UL] = __outs_0;
  sc_parallel_call_cpu_with_env((void*)&mul__1820_closure_291_0wrapper, __stream, __module_data, 0UL, 196608UL, 1UL, __tempargs291);
  return true;
}

static bool cast__183(int8_t* __restrict__ __outs_0, float* __restrict__ __ins_0) noexcept{
  generic_val __tempargs292[2UL];
  __tempargs292[0UL] = __ins_0;
  __tempargs292[1UL] = __outs_0;
  sc_parallel_call_cpu_with_env((void*)&cast__1830_closure_292_0wrapper, __stream, __module_data, 0UL, 196608UL, 1UL, __tempargs292);
  return true;
}

static bool reorder__481(int8_t* __restrict__ __outs_0, int8_t* __restrict__ __ins_0) noexcept{
  generic_val __tempargs293[2UL];
  __tempargs293[0UL] = __ins_0;
  __tempargs293[1UL] = __outs_0;
  sc_parallel_call_cpu_with_env((void*)&reorder__4810_closure_293_0wrapper, __stream, __module_data, 0UL, 48UL, 1UL, __tempargs293);
  return true;
}

static bool mul__191(float* __restrict__ __outs_0, float* __restrict__ __ins_0, float* __restrict__ __ins_1) noexcept{
  generic_val __tempargs294[3UL];
  __tempargs294[0UL] = __ins_0;
  __tempargs294[1UL] = __ins_1;
  __tempargs294[2UL] = __outs_0;
  sc_parallel_call_cpu_with_env((void*)&mul__1910_closure_294_0wrapper, __stream, __module_data, 0UL, 196608UL, 1UL, __tempargs294);
  return true;
}

static bool cast__192(int8_t* __restrict__ __outs_0, float* __restrict__ __ins_0) noexcept{
  generic_val __tempargs295[2UL];
  __tempargs295[0UL] = __ins_0;
  __tempargs295[1UL] = __outs_0;
  sc_parallel_call_cpu_with_env((void*)&cast__1920_closure_295_0wrapper, __stream, __module_data, 0UL, 196608UL, 1UL, __tempargs295);
  return true;
}

static bool reorder__490(int8_t* __restrict__ __outs_0, int8_t* __restrict__ __ins_0) noexcept{
  generic_val __tempargs296[2UL];
  __tempargs296[0UL] = __ins_0;
  __tempargs296[1UL] = __outs_0;
  sc_parallel_call_cpu_with_env((void*)&reorder__4900_closure_296_0wrapper, __stream, __module_data, 0UL, 48UL, 1UL, __tempargs296);
  return true;
}

static bool mul__200(float* __restrict__ __outs_0, float* __restrict__ __ins_0, float* __restrict__ __ins_1) noexcept{
  generic_val __tempargs297[3UL];
  __tempargs297[0UL] = __ins_0;
  __tempargs297[1UL] = __ins_1;
  __tempargs297[2UL] = __outs_0;
  sc_parallel_call_cpu_with_env((void*)&mul__2000_closure_297_0wrapper, __stream, __module_data, 0UL, 196608UL, 1UL, __tempargs297);
  return true;
}

static bool cast__201(int8_t* __restrict__ __outs_0, float* __restrict__ __ins_0) noexcept{
  generic_val __tempargs298[2UL];
  __tempargs298[0UL] = __ins_0;
  __tempargs298[1UL] = __outs_0;
  sc_parallel_call_cpu_with_env((void*)&cast__2010_closure_298_0wrapper, __stream, __module_data, 0UL, 196608UL, 1UL, __tempargs298);
  return true;
}

static bool reorder__499(int8_t* __restrict__ __outs_0, int8_t* __restrict__ __ins_0) noexcept{
  generic_val __tempargs299[2UL];
  __tempargs299[0UL] = __ins_0;
  __tempargs299[1UL] = __outs_0;
  sc_parallel_call_cpu_with_env((void*)&reorder__4990_closure_299_0wrapper, __stream, __module_data, 0UL, 48UL, 1UL, __tempargs299);
  return true;
}

static bool mul__209(float* __restrict__ __outs_0, float* __restrict__ __ins_0, float* __restrict__ __ins_1) noexcept{
  generic_val __tempargs300[3UL];
  __tempargs300[0UL] = __ins_0;
  __tempargs300[1UL] = __ins_1;
  __tempargs300[2UL] = __outs_0;
  sc_parallel_call_cpu_with_env((void*)&mul__2090_closure_300_0wrapper, __stream, __module_data, 0UL, 196608UL, 1UL, __tempargs300);
  return true;
}

static bool cast__210(int8_t* __restrict__ __outs_0, float* __restrict__ __ins_0) noexcept{
  generic_val __tempargs301[2UL];
  __tempargs301[0UL] = __ins_0;
  __tempargs301[1UL] = __outs_0;
  sc_parallel_call_cpu_with_env((void*)&cast__2100_closure_301_0wrapper, __stream, __module_data, 0UL, 196608UL, 1UL, __tempargs301);
  return true;
}

static bool reorder__508(int8_t* __restrict__ __outs_0, int8_t* __restrict__ __ins_0) noexcept{
  generic_val __tempargs302[2UL];
  __tempargs302[0UL] = __ins_0;
  __tempargs302[1UL] = __outs_0;
  sc_parallel_call_cpu_with_env((void*)&reorder__5080_closure_302_0wrapper, __stream, __module_data, 0UL, 48UL, 1UL, __tempargs302);
  return true;
}

static bool mul__218(float* __restrict__ __outs_0, float* __restrict__ __ins_0, float* __restrict__ __ins_1) noexcept{
  generic_val __tempargs303[3UL];
  __tempargs303[0UL] = __ins_0;
  __tempargs303[1UL] = __ins_1;
  __tempargs303[2UL] = __outs_0;
  sc_parallel_call_cpu_with_env((void*)&mul__2180_closure_303_0wrapper, __stream, __module_data, 0UL, 196608UL, 1UL, __tempargs303);
  return true;
}

static bool cast__219(int8_t* __restrict__ __outs_0, float* __restrict__ __ins_0) noexcept{
  generic_val __tempargs304[2UL];
  __tempargs304[0UL] = __ins_0;
  __tempargs304[1UL] = __outs_0;
  sc_parallel_call_cpu_with_env((void*)&cast__2190_closure_304_0wrapper, __stream, __module_data, 0UL, 196608UL, 1UL, __tempargs304);
  return true;
}

static bool reorder__517(int8_t* __restrict__ __outs_0, int8_t* __restrict__ __ins_0) noexcept{
  generic_val __tempargs305[2UL];
  __tempargs305[0UL] = __ins_0;
  __tempargs305[1UL] = __outs_0;
  sc_parallel_call_cpu_with_env((void*)&reorder__5170_closure_305_0wrapper, __stream, __module_data, 0UL, 48UL, 1UL, __tempargs305);
  return true;
}

static bool mul__227(float* __restrict__ __outs_0, float* __restrict__ __ins_0, float* __restrict__ __ins_1) noexcept{
  generic_val __tempargs306[3UL];
  __tempargs306[0UL] = __ins_0;
  __tempargs306[1UL] = __ins_1;
  __tempargs306[2UL] = __outs_0;
  sc_parallel_call_cpu_with_env((void*)&mul__2270_closure_306_0wrapper, __stream, __module_data, 0UL, 196608UL, 1UL, __tempargs306);
  return true;
}

static bool cast__228(int8_t* __restrict__ __outs_0, float* __restrict__ __ins_0) noexcept{
  generic_val __tempargs307[2UL];
  __tempargs307[0UL] = __ins_0;
  __tempargs307[1UL] = __outs_0;
  sc_parallel_call_cpu_with_env((void*)&cast__2280_closure_307_0wrapper, __stream, __module_data, 0UL, 196608UL, 1UL, __tempargs307);
  return true;
}

static bool reorder__526(int8_t* __restrict__ __outs_0, int8_t* __restrict__ __ins_0) noexcept{
  generic_val __tempargs308[2UL];
  __tempargs308[0UL] = __ins_0;
  __tempargs308[1UL] = __outs_0;
  sc_parallel_call_cpu_with_env((void*)&reorder__5260_closure_308_0wrapper, __stream, __module_data, 0UL, 48UL, 1UL, __tempargs308);
  return true;
}

static bool mul__242(float* __restrict__ __outs_0, float* __restrict__ __ins_0, float* __restrict__ __ins_1) noexcept{
  generic_val __tempargs309[3UL];
  __tempargs309[0UL] = __ins_0;
  __tempargs309[1UL] = __ins_1;
  __tempargs309[2UL] = __outs_0;
  sc_parallel_call_cpu_with_env((void*)&mul__2420_closure_309_0wrapper, __stream, __module_data, 0UL, 1048576UL, 1UL, __tempargs309);
  return true;
}

static bool cast__243(int8_t* __restrict__ __outs_0, float* __restrict__ __ins_0) noexcept{
  generic_val __tempargs310[2UL];
  __tempargs310[0UL] = __ins_0;
  __tempargs310[1UL] = __outs_0;
  sc_parallel_call_cpu_with_env((void*)&cast__2430_closure_310_0wrapper, __stream, __module_data, 0UL, 1048576UL, 1UL, __tempargs310);
  return true;
}

static bool reorder__539(int8_t* __restrict__ __outs_0, int8_t* __restrict__ __ins_0) noexcept{
  generic_val __tempargs311[2UL];
  __tempargs311[0UL] = __ins_0;
  __tempargs311[1UL] = __outs_0;
  sc_parallel_call_cpu_with_env((void*)&reorder__5390_closure_311_0wrapper, __stream, __module_data, 0UL, 512UL, 1UL, __tempargs311);
  return true;
}

static bool mul__251(float* __restrict__ __outs_0, float* __restrict__ __ins_0, float* __restrict__ __ins_1) noexcept{
  generic_val __tempargs312[3UL];
  __tempargs312[0UL] = __ins_0;
  __tempargs312[1UL] = __ins_1;
  __tempargs312[2UL] = __outs_0;
  sc_parallel_call_cpu_with_env((void*)&mul__2510_closure_312_0wrapper, __stream, __module_data, 0UL, 1048576UL, 1UL, __tempargs312);
  return true;
}

static bool cast__252(int8_t* __restrict__ __outs_0, float* __restrict__ __ins_0) noexcept{
  generic_val __tempargs313[2UL];
  __tempargs313[0UL] = __ins_0;
  __tempargs313[1UL] = __outs_0;
  sc_parallel_call_cpu_with_env((void*)&cast__2520_closure_313_0wrapper, __stream, __module_data, 0UL, 1048576UL, 1UL, __tempargs313);
  return true;
}

static bool reorder__548(int8_t* __restrict__ __outs_0, int8_t* __restrict__ __ins_0) noexcept{
  generic_val __tempargs314[2UL];
  __tempargs314[0UL] = __ins_0;
  __tempargs314[1UL] = __outs_0;
  sc_parallel_call_cpu_with_env((void*)&reorder__5480_closure_314_0wrapper, __stream, __module_data, 0UL, 512UL, 1UL, __tempargs314);
  return true;
}

static bool mul__260(float* __restrict__ __outs_0, float* __restrict__ __ins_0, float* __restrict__ __ins_1) noexcept{
  generic_val __tempargs315[3UL];
  __tempargs315[0UL] = __ins_0;
  __tempargs315[1UL] = __ins_1;
  __tempargs315[2UL] = __outs_0;
  sc_parallel_call_cpu_with_env((void*)&mul__2600_closure_315_0wrapper, __stream, __module_data, 0UL, 1048576UL, 1UL, __tempargs315);
  return true;
}

static bool cast__261(int8_t* __restrict__ __outs_0, float* __restrict__ __ins_0) noexcept{
  generic_val __tempargs316[2UL];
  __tempargs316[0UL] = __ins_0;
  __tempargs316[1UL] = __outs_0;
  sc_parallel_call_cpu_with_env((void*)&cast__2610_closure_316_0wrapper, __stream, __module_data, 0UL, 1048576UL, 1UL, __tempargs316);
  return true;
}

static bool reorder__557(int8_t* __restrict__ __outs_0, int8_t* __restrict__ __ins_0) noexcept{
  generic_val __tempargs317[2UL];
  __tempargs317[0UL] = __ins_0;
  __tempargs317[1UL] = __outs_0;
  sc_parallel_call_cpu_with_env((void*)&reorder__5570_closure_317_0wrapper, __stream, __module_data, 0UL, 32UL, 1UL, __tempargs317);
  return true;
}

static bool mul__245(float* __restrict__ __outs_0, float* __restrict__ __ins_0, float* __restrict__ __ins_1) noexcept{
  generic_val __tempargs318[3UL];
  __tempargs318[0UL] = __ins_0;
  __tempargs318[1UL] = __ins_1;
  __tempargs318[2UL] = __outs_0;
  sc_parallel_call_cpu_with_env((void*)&mul__2450_closure_318_0wrapper, __stream, __module_data, 0UL, 1048576UL, 1UL, __tempargs318);
  return true;
}

static bool cast__246(int8_t* __restrict__ __outs_0, float* __restrict__ __ins_0) noexcept{
  generic_val __tempargs319[2UL];
  __tempargs319[0UL] = __ins_0;
  __tempargs319[1UL] = __outs_0;
  sc_parallel_call_cpu_with_env((void*)&cast__2460_closure_319_0wrapper, __stream, __module_data, 0UL, 1048576UL, 1UL, __tempargs319);
  return true;
}

static bool reorder__542(int8_t* __restrict__ __outs_0, int8_t* __restrict__ __ins_0) noexcept{
  generic_val __tempargs320[2UL];
  __tempargs320[0UL] = __ins_0;
  __tempargs320[1UL] = __outs_0;
  sc_parallel_call_cpu_with_env((void*)&reorder__5420_closure_320_0wrapper, __stream, __module_data, 0UL, 32UL, 1UL, __tempargs320);
  return true;
}

static bool mul__254(float* __restrict__ __outs_0, float* __restrict__ __ins_0, float* __restrict__ __ins_1) noexcept{
  generic_val __tempargs321[3UL];
  __tempargs321[0UL] = __ins_0;
  __tempargs321[1UL] = __ins_1;
  __tempargs321[2UL] = __outs_0;
  sc_parallel_call_cpu_with_env((void*)&mul__2540_closure_321_0wrapper, __stream, __module_data, 0UL, 1048576UL, 1UL, __tempargs321);
  return true;
}

static bool cast__255(int8_t* __restrict__ __outs_0, float* __restrict__ __ins_0) noexcept{
  generic_val __tempargs322[2UL];
  __tempargs322[0UL] = __ins_0;
  __tempargs322[1UL] = __outs_0;
  sc_parallel_call_cpu_with_env((void*)&cast__2550_closure_322_0wrapper, __stream, __module_data, 0UL, 1048576UL, 1UL, __tempargs322);
  return true;
}

static bool reorder__551(int8_t* __restrict__ __outs_0, int8_t* __restrict__ __ins_0) noexcept{
  generic_val __tempargs323[2UL];
  __tempargs323[0UL] = __ins_0;
  __tempargs323[1UL] = __outs_0;
  sc_parallel_call_cpu_with_env((void*)&reorder__5510_closure_323_0wrapper, __stream, __module_data, 0UL, 1024UL, 1UL, __tempargs323);
  return true;
}

static bool mul__233(float* __restrict__ __outs_0, float* __restrict__ __ins_0, float* __restrict__ __ins_1) noexcept{
  generic_val __tempargs324[3UL];
  __tempargs324[0UL] = __ins_0;
  __tempargs324[1UL] = __ins_1;
  __tempargs324[2UL] = __outs_0;
  sc_parallel_call_cpu_with_env((void*)&mul__2330_closure_324_0wrapper, __stream, __module_data, 0UL, 2097152UL, 1UL, __tempargs324);
  return true;
}

static bool cast__234(int8_t* __restrict__ __outs_0, float* __restrict__ __ins_0) noexcept{
  generic_val __tempargs325[2UL];
  __tempargs325[0UL] = __ins_0;
  __tempargs325[1UL] = __outs_0;
  sc_parallel_call_cpu_with_env((void*)&cast__2340_closure_325_0wrapper, __stream, __module_data, 0UL, 2097152UL, 1UL, __tempargs325);
  return true;
}

static bool reorder__532(int8_t* __restrict__ __outs_0, int8_t* __restrict__ __ins_0) noexcept{
  generic_val __tempargs326[2UL];
  __tempargs326[0UL] = __ins_0;
  __tempargs326[1UL] = __outs_0;
  sc_parallel_call_cpu_with_env((void*)&reorder__5320_closure_326_0wrapper, __stream, __module_data, 0UL, 64UL, 1UL, __tempargs326);
  return true;
}

static bool mul__239(float* __restrict__ __outs_0, float* __restrict__ __ins_0, float* __restrict__ __ins_1) noexcept{
  generic_val __tempargs327[3UL];
  __tempargs327[0UL] = __ins_0;
  __tempargs327[1UL] = __ins_1;
  __tempargs327[2UL] = __outs_0;
  sc_parallel_call_cpu_with_env((void*)&mul__2390_closure_327_0wrapper, __stream, __module_data, 0UL, 786432UL, 1UL, __tempargs327);
  return true;
}

static bool cast__240(int8_t* __restrict__ __outs_0, float* __restrict__ __ins_0) noexcept{
  generic_val __tempargs328[2UL];
  __tempargs328[0UL] = __ins_0;
  __tempargs328[1UL] = __outs_0;
  sc_parallel_call_cpu_with_env((void*)&cast__2400_closure_328_0wrapper, __stream, __module_data, 0UL, 786432UL, 1UL, __tempargs328);
  return true;
}

static bool reorder__536(int8_t* __restrict__ __outs_0, int8_t* __restrict__ __ins_0) noexcept{
  generic_val __tempargs329[2UL];
  __tempargs329[0UL] = __ins_0;
  __tempargs329[1UL] = __outs_0;
  sc_parallel_call_cpu_with_env((void*)&reorder__5360_closure_329_0wrapper, __stream, __module_data, 0UL, 48UL, 1UL, __tempargs329);
  return true;
}

static bool mul__248(float* __restrict__ __outs_0, float* __restrict__ __ins_0, float* __restrict__ __ins_1) noexcept{
  generic_val __tempargs330[3UL];
  __tempargs330[0UL] = __ins_0;
  __tempargs330[1UL] = __ins_1;
  __tempargs330[2UL] = __outs_0;
  sc_parallel_call_cpu_with_env((void*)&mul__2480_closure_330_0wrapper, __stream, __module_data, 0UL, 786432UL, 1UL, __tempargs330);
  return true;
}

static bool cast__249(int8_t* __restrict__ __outs_0, float* __restrict__ __ins_0) noexcept{
  generic_val __tempargs331[2UL];
  __tempargs331[0UL] = __ins_0;
  __tempargs331[1UL] = __outs_0;
  sc_parallel_call_cpu_with_env((void*)&cast__2490_closure_331_0wrapper, __stream, __module_data, 0UL, 786432UL, 1UL, __tempargs331);
  return true;
}

static bool reorder__545(int8_t* __restrict__ __outs_0, int8_t* __restrict__ __ins_0) noexcept{
  generic_val __tempargs332[2UL];
  __tempargs332[0UL] = __ins_0;
  __tempargs332[1UL] = __outs_0;
  sc_parallel_call_cpu_with_env((void*)&reorder__5450_closure_332_0wrapper, __stream, __module_data, 0UL, 32UL, 1UL, __tempargs332);
  return true;
}

static bool mul__257(float* __restrict__ __outs_0, float* __restrict__ __ins_0, float* __restrict__ __ins_1) noexcept{
  generic_val __tempargs333[3UL];
  __tempargs333[0UL] = __ins_0;
  __tempargs333[1UL] = __ins_1;
  __tempargs333[2UL] = __outs_0;
  sc_parallel_call_cpu_with_env((void*)&mul__2570_closure_333_0wrapper, __stream, __module_data, 0UL, 786432UL, 1UL, __tempargs333);
  return true;
}

static bool cast__258(int8_t* __restrict__ __outs_0, float* __restrict__ __ins_0) noexcept{
  generic_val __tempargs334[2UL];
  __tempargs334[0UL] = __ins_0;
  __tempargs334[1UL] = __outs_0;
  sc_parallel_call_cpu_with_env((void*)&cast__2580_closure_334_0wrapper, __stream, __module_data, 0UL, 786432UL, 1UL, __tempargs334);
  return true;
}

static bool reorder__554(int8_t* __restrict__ __outs_0, int8_t* __restrict__ __ins_0) noexcept{
  generic_val __tempargs335[2UL];
  __tempargs335[0UL] = __ins_0;
  __tempargs335[1UL] = __outs_0;
  sc_parallel_call_cpu_with_env((void*)&reorder__5540_closure_335_0wrapper, __stream, __module_data, 0UL, 24UL, 1UL, __tempargs335);
  return true;
}

static bool batchwise_4_fused_res2a_conv_b_cast_mul_add_cast_res2a_conv_0_cast_mul_add_cast_relu_res2a_conv_1_cast_mul_add_cast_relu_res2a_conv_2_cast_mul_add_cast_add_relu_res2b_conv_0_cast_mul_add_cast_relu_res2b_conv_1_cast_mul_add_cast_relu_res2b_conv_2_cast_mul_add_cast_add_relu_res2c_conv_0_cast_mul_add_cast_relu_res2c_conv_1_cast_mul_add_cast_relu_res2c_conv_2_cast_mul_add_cast_add_relu_res3a_conv_b_cast_mul_add_cast_res3a_conv_0_cast_mul_add_cast_relu_res3a_conv_1_cast_mul_add_cast_relu_res3a_conv_2_cast_mul_add_cast_add_relu_res3b_conv_0_cast_mul_add_cast_relu_res3b_conv_1_cast_mul_add_cast_relu_res3b_conv_2_cast_mul_add_cast_add_relu_res3c_conv_0_cast_mul_add_cast_relu_res3c_conv_1_cast_mul_add_cast_relu_res3c_conv_2_cast_mul_add_cast_add_relu_res3d_conv_0_cast_mul_add_cast_relu_res3d_conv_1_cast_mul_add_cast_relu_res3d_conv_2_cast_mul_add_cast_add_relu__684(int8_t* __restrict__ __outs_0, int64_t* __restrict__ input_pointers, int8_t* __restrict__ __ins_1, float* __restrict__ __ins_2, float* __restrict__ __ins_3, int8_t* __restrict__ __ins_4, float* __restrict__ __ins_5, float* __restrict__ __ins_6, int8_t* __restrict__ __ins_7, float* __restrict__ __ins_8, float* __restrict__ __ins_9, int8_t* __restrict__ __ins_10, float* __restrict__ __ins_11, float* __restrict__ __ins_12, int8_t* __restrict__ __ins_13, float* __restrict__ __ins_14, float* __restrict__ __ins_15, int8_t* __restrict__ __ins_16, float* __restrict__ __ins_17, float* __restrict__ __ins_18, int8_t* __restrict__ __ins_19, float* __restrict__ __ins_20, float* __restrict__ __ins_21, int8_t* __restrict__ __ins_22, float* __restrict__ __ins_23, float* __restrict__ __ins_24, int8_t* __restrict__ __ins_25, float* __restrict__ __ins_26, float* __restrict__ __ins_27, int8_t* __restrict__ __ins_28, float* __restrict__ __ins_29, float* __restrict__ __ins_30, int8_t* __restrict__ __ins_31, float* __restrict__ __ins_32, float* __restrict__ __ins_33, int8_t* __restrict__ __ins_34, float* __restrict__ __ins_35, float* __restrict__ __ins_36, int8_t* __restrict__ __ins_37, float* __restrict__ __ins_38, float* __restrict__ __ins_39, int8_t* __restrict__ __ins_40, float* __restrict__ __ins_41, float* __restrict__ __ins_42, int8_t* __restrict__ __ins_43, float* __restrict__ __ins_44, float* __restrict__ __ins_45, int8_t* __restrict__ __ins_46, float* __restrict__ __ins_47, float* __restrict__ __ins_48, int8_t* __restrict__ __ins_49, float* __restrict__ __ins_50, float* __restrict__ __ins_51, int8_t* __restrict__ __ins_52, float* __restrict__ __ins_53, float* __restrict__ __ins_54, int8_t* __restrict__ __ins_55, float* __restrict__ __ins_56, float* __restrict__ __ins_57, int8_t* __restrict__ __ins_58, float* __restrict__ __ins_59, float* __restrict__ __ins_60, int8_t* __restrict__ __ins_61, float* __restrict__ __ins_62, float* __restrict__ __ins_63, int8_t* __restrict__ __ins_64, float* __restrict__ __ins_65, float* __restrict__ __ins_66, int8_t* __restrict__ __ins_67, float* __restrict__ __ins_68, float* __restrict__ __ins_69) noexcept{
  generic_val* __tempargs336 = (generic_val*)sc_aligned_malloc(__stream, 568UL);
  __tempargs336[0UL] = input_pointers;
  __tempargs336[1UL] = __ins_1;
  __tempargs336[2UL] = __ins_2;
  __tempargs336[3UL] = __ins_3;
  __tempargs336[4UL] = __ins_4;
  __tempargs336[5UL] = __ins_5;
  __tempargs336[6UL] = __ins_6;
  __tempargs336[7UL] = __ins_7;
  __tempargs336[8UL] = __ins_8;
  __tempargs336[9UL] = __ins_9;
  __tempargs336[10UL] = __ins_10;
  __tempargs336[11UL] = __ins_11;
  __tempargs336[12UL] = __ins_12;
  __tempargs336[13UL] = __ins_13;
  __tempargs336[14UL] = __ins_14;
  __tempargs336[15UL] = __ins_15;
  __tempargs336[16UL] = __ins_16;
  __tempargs336[17UL] = __ins_17;
  __tempargs336[18UL] = __ins_18;
  __tempargs336[19UL] = __ins_19;
  __tempargs336[20UL] = __ins_20;
  __tempargs336[21UL] = __ins_21;
  __tempargs336[22UL] = __ins_22;
  __tempargs336[23UL] = __ins_23;
  __tempargs336[24UL] = __ins_24;
  __tempargs336[25UL] = __ins_25;
  __tempargs336[26UL] = __ins_26;
  __tempargs336[27UL] = __ins_27;
  __tempargs336[28UL] = __ins_28;
  __tempargs336[29UL] = __ins_29;
  __tempargs336[30UL] = __ins_30;
  __tempargs336[31UL] = __ins_31;
  __tempargs336[32UL] = __ins_32;
  __tempargs336[33UL] = __ins_33;
  __tempargs336[34UL] = __ins_34;
  __tempargs336[35UL] = __ins_35;
  __tempargs336[36UL] = __ins_36;
  __tempargs336[37UL] = __ins_37;
  __tempargs336[38UL] = __ins_38;
  __tempargs336[39UL] = __ins_39;
  __tempargs336[40UL] = __ins_40;
  __tempargs336[41UL] = __ins_41;
  __tempargs336[42UL] = __ins_42;
  __tempargs336[43UL] = __ins_43;
  __tempargs336[44UL] = __ins_44;
  __tempargs336[45UL] = __ins_45;
  __tempargs336[46UL] = __ins_46;
  __tempargs336[47UL] = __ins_47;
  __tempargs336[48UL] = __ins_48;
  __tempargs336[49UL] = __ins_49;
  __tempargs336[50UL] = __ins_50;
  __tempargs336[51UL] = __ins_51;
  __tempargs336[52UL] = __ins_52;
  __tempargs336[53UL] = __ins_53;
  __tempargs336[54UL] = __ins_54;
  __tempargs336[55UL] = __ins_55;
  __tempargs336[56UL] = __ins_56;
  __tempargs336[57UL] = __ins_57;
  __tempargs336[58UL] = __ins_58;
  __tempargs336[59UL] = __ins_59;
  __tempargs336[60UL] = __ins_60;
  __tempargs336[61UL] = __ins_61;
  __tempargs336[62UL] = __ins_62;
  __tempargs336[63UL] = __ins_63;
  __tempargs336[64UL] = __ins_64;
  __tempargs336[65UL] = __ins_65;
  __tempargs336[66UL] = __ins_66;
  __tempargs336[67UL] = __outs_0;
  __tempargs336[68UL] = __ins_67;
  __tempargs336[69UL] = __ins_68;
  __tempargs336[70UL] = __ins_69;
  sc_parallel_call_cpu_with_env((void*)&batchwise_4_fused_res2a_conv_b_cast_mul_add_cast_res2a_conv_0_cast_mul_add_cast_relu_res2a_conv_1_cast_mul_add_cast_relu_res2a_conv_2_cast_mul_add_cast_add_relu_res2b_conv_0_cast_mul_add_cast_relu_res2b_conv_1_cast_mul_add_cast_relu_res2b_conv_2_cast_mul_add_cast_add_relu_res2c_conv_0_cast_mul_add_cast_relu_res2c_conv_1_cast_mul_add_cast_relu_res2c_conv_2_cast_mul_add_cast_add_relu_res3a_conv_b_cast_mul_add_cast_res3a_conv_0_cast_mul_add_cast_relu_res3a_conv_1_cast_mul_add_cast_relu_res3a_conv_2_cast_mul_add_cast_add_relu_res3b_conv_0_cast_mul_add_cast_relu_res3b_conv_1_cast_mul_add_cast_relu_res3b_conv_2_cast_mul_add_cast_add_relu_res3c_conv_0_cast_mul_add_cast_relu_res3c_conv_1_cast_mul_add_cast_relu_res3c_conv_2_cast_mul_add_cast_add_relu_res3d_conv_0_cast_mul_add_cast_relu_res3d_conv_1_cast_mul_add_cast_relu_res3d_conv_2_cast_mul_add_cast_add_relu__6840_closure_336_0wrapper, __stream, __module_data, 0UL, 4UL, 1UL, __tempargs336);
  sc_aligned_free(__stream, __tempargs336);
  return true;
}


static bool res2a_conv_b_cast_mul_add_cast__4(int8_t* __restrict__ __outs_0, int8_t* __restrict__ __ins_0, int8_t* __restrict__ __ins_1, float* __restrict__ __ins_2, float* __restrict__ __ins_3) noexcept{
  void*& __sc_kernel_cache = *(void**)(__module_data + 8);
  alignas(64) int8_t __rescheduled_0[128UL];
  for (uint64_t fused_0fused_0n__n_i_3431__k_3432 = 0UL; fused_0fused_0n__n_i_3431__k_3432 < 4UL; fused_0fused_0n__n_i_3431__k_3432 += 1UL) {
    for (uint64_t p_o = 0UL; p_o < 56UL; p_o += 1UL) {
      int32_t* __origouts_2600_shr = (int32_t*)sc_aligned_malloc(__stream, 14336UL);
      void** A_list = (void**)&__rescheduled_0[0UL];
      void** B_list = (void**)&__rescheduled_0[64UL];
      void* __cached_0;
      __cached_0 = &__ins_0[(((fused_0fused_0n__n_i_3431__k_3432 / 4UL) * 200704UL) + (p_o * 3584UL))];
      A_list[0UL] = __cached_0;
      void* __cached_1;
      __cached_1 = &__ins_1[((fused_0fused_0n__n_i_3431__k_3432 % 4UL) * 4096UL)];
      B_list[0UL] = __cached_1;
      void* _arg_cache_0 = &__origouts_2600_shr[0UL];
      dnnl_brgemm_list_call(__sc_kernel_cache, A_list, B_list, &__origouts_2600_shr[0UL], 1, 1, 1, 1, 7, 7, __stream);
      for (uint64_t _fuseiter10328 = 0UL; _fuseiter10328 < 56UL; _fuseiter10328 += 1UL) {
        for (uint64_t _fuseiter10329 = 0UL; _fuseiter10329 < 64UL; _fuseiter10329 += 16UL) {
          vec_s32x16 __cached_2;
          __cached_2 = vec_s32x16::load(&__origouts_2600_shr[((_fuseiter10328 * 64UL) + _fuseiter10329)]);
          vec_f32x16 __cached_3;
          __cached_3 = (vec_f32x16)(__cached_2);
          vec_f32x16 __cached_4;
          __cached_4 = vec_f32x16::load(&__ins_2[((((fused_0fused_0n__n_i_3431__k_3432 / 4UL) * 256UL) + ((fused_0fused_0n__n_i_3431__k_3432 % 4UL) * 64UL)) + _fuseiter10329)]);
          __cached_3 = (__cached_3 * __cached_4);
          vec_f32x16 __cached_5;
          __cached_5 = vec_f32x16::load(&__ins_3[(((fused_0fused_0n__n_i_3431__k_3432 % 4UL) * 64UL) + _fuseiter10329)]);
          __cached_3 = (__cached_3 + __cached_5);
          vec_s8x16 __cached_6;
          __cached_6 = sc_saturated_cast<vec_s8x16>(sc_round_and_cast<vec_s32x16>(__cached_3));
          vec_s8x16::store(__cached_6, &__outs_0[((((fused_0fused_0n__n_i_3431__k_3432 / 4UL) * 802816UL) + (((fused_0fused_0n__n_i_3431__k_3432 % 4UL) * 200704UL) + (p_o * 3584UL))) + ((_fuseiter10328 * 64UL) + _fuseiter10329))]);
        }
      }
      sc_aligned_free(__stream, __origouts_2600_shr);
    }
  }
  return true;
}

static bool res2a_conv_0_cast_mul_add_cast_relu__8(int8_t* __restrict__ __outs_0, int8_t* __restrict__ __ins_0, int8_t* __restrict__ __ins_1, float* __restrict__ __ins_2, float* __restrict__ __ins_3) noexcept{
  void*& __sc_kernel_cache_107 = *(void**)(__module_data + 16);
  alignas(64) int8_t __rescheduled_0[128UL];
  memset(&__outs_0[0UL], 0, 3712UL);
  for (uint64_t p1 = 0UL; p1 < 56UL; p1 += 1UL) {
    memset(&__outs_0[((p1 + 1UL) * 3712UL)], 0, 64UL);
    memset(&__outs_0[(((p1 + 1UL) * 3712UL) + 3648UL)], 0, 64UL);
  }
  memset(&__outs_0[211584UL], 0, 3712UL);
  for (uint64_t p_o = 0UL; p_o < 28UL; p_o += 1UL) {
    int32_t* __origouts_2610_shr = (int32_t*)sc_aligned_malloc(__stream, 28672UL);
    void** A_list = (void**)&__rescheduled_0[0UL];
    void** B_list = (void**)&__rescheduled_0[64UL];
    void* __cached_0;
    __cached_0 = &__ins_0[(p_o * 7168UL)];
    A_list[0UL] = __cached_0;
    void* __cached_1;
    __cached_1 = &__ins_1[0UL];
    B_list[0UL] = __cached_1;
    void* _arg_cache_1 = &__origouts_2610_shr[0UL];
    dnnl_brgemm_list_call(__sc_kernel_cache_107, A_list, B_list, &__origouts_2610_shr[0UL], 1, 1, 1, 1, 7, 7, __stream);
    for (uint64_t _fuseiter10355 = 0UL; _fuseiter10355 < 2UL; _fuseiter10355 += 1UL) {
      for (uint64_t _fuseiter10356 = 0UL; _fuseiter10356 < 56UL; _fuseiter10356 += 1UL) {
        for (uint64_t _fuseiter10357 = 0UL; _fuseiter10357 < 64UL; _fuseiter10357 += 16UL) {
          vec_s32x16 __cached_2;
          __cached_2 = vec_s32x16::load(&__origouts_2610_shr[((_fuseiter10355 * 3584UL) + ((_fuseiter10356 * 64UL) + _fuseiter10357))]);
          vec_f32x16 __cached_3;
          __cached_3 = (vec_f32x16)(__cached_2);
          vec_f32x16 __cached_4;
          __cached_4 = vec_f32x16::load(&__ins_2[_fuseiter10357]);
          __cached_3 = (__cached_3 * __cached_4);
          vec_f32x16 __cached_5;
          __cached_5 = vec_f32x16::load(&__ins_3[_fuseiter10357]);
          __cached_3 = (__cached_3 + __cached_5);
          vec_s8x16 __cached_6;
          __cached_6 = sc_saturated_cast<vec_s8x16>(sc_round_and_cast<vec_s32x16>(__cached_3));
          vec_s8x16 __cached_7;
          __cached_7 = sc_max(__cached_6, vec_s8x16(0));
          vec_s8x16::store(__cached_7, &__outs_0[(((((p_o * 2UL) + 1UL) * 3712UL) + 64UL) + ((_fuseiter10355 * 3712UL) + ((_fuseiter10356 * 64UL) + _fuseiter10357)))]);
        }
      }
    }
    sc_aligned_free(__stream, __origouts_2610_shr);
  }
  return true;
}

static bool res2a_conv_1_cast_mul_add_cast_relu__12(int8_t* __restrict__ __outs_0, int8_t* __restrict__ __ins_0, int8_t* __restrict__ __ins_1, float* __restrict__ __ins_2, float* __restrict__ __ins_3) noexcept{
  void*& __sc_kernel_cache_109 = *(void**)(__module_data + 24);
  int8_t* __rescheduled_0 = (int8_t*)sc_aligned_malloc(__stream, 256UL);
  for (uint64_t p_o = 0UL; p_o < 56UL; p_o += 1UL) {
    void** A_list = (void**)&__rescheduled_0[0UL];
    void** B_list = (void**)&__rescheduled_0[128UL];
    int32_t* __origouts_2620_shr = (int32_t*)sc_aligned_malloc(__stream, 14336UL);
    for (uint64_t r = 0UL; r < 3UL; r += 1UL) {
      for (uint64_t s = 0UL; s < 3UL; s += 1UL) {
        void* __cached_0;
        __cached_0 = &__ins_0[(((p_o + r) * 3712UL) + (s * 64UL))];
        A_list[((r * 3UL) + s)] = __cached_0;
        void* __cached_1;
        __cached_1 = &__ins_1[((r * 12288UL) + (s * 4096UL))];
        B_list[((r * 3UL) + s)] = __cached_1;
      }
    }
    void* _arg_cache_2 = &__origouts_2620_shr[0UL];
    dnnl_brgemm_list_call(__sc_kernel_cache_109, A_list, B_list, &__origouts_2620_shr[0UL], 1, 64, 4096, 9, 7, 7, __stream);
    for (uint64_t _fuseiter10391 = 0UL; _fuseiter10391 < 56UL; _fuseiter10391 += 1UL) {
      for (uint64_t _fuseiter10392 = 0UL; _fuseiter10392 < 64UL; _fuseiter10392 += 16UL) {
        vec_s32x16 __cached_2;
        __cached_2 = vec_s32x16::load(&__origouts_2620_shr[((_fuseiter10391 * 64UL) + _fuseiter10392)]);
        vec_f32x16 __cached_3;
        __cached_3 = (vec_f32x16)(__cached_2);
        vec_f32x16 __cached_4;
        __cached_4 = vec_f32x16::load(&__ins_2[_fuseiter10392]);
        __cached_3 = (__cached_3 * __cached_4);
        vec_f32x16 __cached_5;
        __cached_5 = vec_f32x16::load(&__ins_3[_fuseiter10392]);
        __cached_3 = (__cached_3 + __cached_5);
        vec_s8x16 __cached_6;
        __cached_6 = sc_saturated_cast<vec_s8x16>(sc_round_and_cast<vec_s32x16>(__cached_3));
        vec_s8x16 __cached_7;
        __cached_7 = sc_max(__cached_6, vec_s8x16(0));
        vec_s8x16::store(__cached_7, &__outs_0[((p_o * 3584UL) + ((_fuseiter10391 * 64UL) + _fuseiter10392))]);
      }
    }
    sc_aligned_free(__stream, __origouts_2620_shr);
  }
  sc_aligned_free(__stream, __rescheduled_0);
  return true;
}

static bool res2a_conv_2_cast_mul_add_cast_add_relu__16(int8_t* __restrict__ __outs_0, int8_t* __restrict__ __ins_0, int8_t* __restrict__ __ins_1, float* __restrict__ __ins_2, float* __restrict__ __ins_3, int8_t* __restrict__ __ins_4) noexcept{
  void*& __sc_kernel_cache = *(void**)(__module_data + 8);
  alignas(64) int8_t __rescheduled_0[128UL];
  for (uint64_t fused_0fused_0k__n_3437__n_i_3438 = 0UL; fused_0fused_0k__n_3437__n_i_3438 < 4UL; fused_0fused_0k__n_3437__n_i_3438 += 1UL) {
    for (uint64_t p_o = 0UL; p_o < 56UL; p_o += 1UL) {
      int32_t* __origouts_2630_shr = (int32_t*)sc_aligned_malloc(__stream, 14336UL);
      void** A_list = (void**)&__rescheduled_0[0UL];
      void** B_list = (void**)&__rescheduled_0[64UL];
      void* __cached_0;
      __cached_0 = &__ins_0[(p_o * 3584UL)];
      A_list[0UL] = __cached_0;
      void* __cached_1;
      __cached_1 = &__ins_1[(fused_0fused_0k__n_3437__n_i_3438 * 4096UL)];
      B_list[0UL] = __cached_1;
      void* _arg_cache_3 = &__origouts_2630_shr[0UL];
      dnnl_brgemm_list_call(__sc_kernel_cache, A_list, B_list, &__origouts_2630_shr[0UL], 1, 1, 1, 1, 7, 7, __stream);
      for (uint64_t _fuseiter10426 = 0UL; _fuseiter10426 < 56UL; _fuseiter10426 += 1UL) {
        for (uint64_t _fuseiter10427 = 0UL; _fuseiter10427 < 64UL; _fuseiter10427 += 16UL) {
          vec_s32x16 __cached_2;
          __cached_2 = vec_s32x16::load(&__origouts_2630_shr[((_fuseiter10426 * 64UL) + _fuseiter10427)]);
          vec_f32x16 __cached_3;
          __cached_3 = (vec_f32x16)(__cached_2);
          vec_f32x16 __cached_4;
          __cached_4 = vec_f32x16::load(&__ins_2[((fused_0fused_0k__n_3437__n_i_3438 * 64UL) + _fuseiter10427)]);
          __cached_3 = (__cached_3 * __cached_4);
          vec_f32x16 __cached_5;
          __cached_5 = vec_f32x16::load(&__ins_3[((fused_0fused_0k__n_3437__n_i_3438 * 64UL) + _fuseiter10427)]);
          __cached_3 = (__cached_3 + __cached_5);
          vec_s8x16 __cached_6;
          __cached_6 = sc_saturated_cast<vec_s8x16>(sc_round_and_cast<vec_s32x16>(__cached_3));
          vec_s8x16 __cached_7;
          __cached_7 = vec_s8x16::load(&__ins_4[(((fused_0fused_0k__n_3437__n_i_3438 * 200704UL) + (p_o * 3584UL)) + ((_fuseiter10426 * 64UL) + _fuseiter10427))]);
          __cached_6 = (__cached_6 + __cached_7);
          vec_s8x16 __cached_8;
          __cached_8 = sc_max(__cached_6, vec_s8x16(0));
          vec_s8x16::store(__cached_8, &__outs_0[(((fused_0fused_0k__n_3437__n_i_3438 * 200704UL) + (p_o * 3584UL)) + ((_fuseiter10426 * 64UL) + _fuseiter10427))]);
        }
      }
      sc_aligned_free(__stream, __origouts_2630_shr);
    }
  }
  return true;
}

static bool res2b_conv_0_cast_mul_add_cast_relu__20(int8_t* __restrict__ __outs_0, int8_t* __restrict__ __ins_0, int8_t* __restrict__ __ins_1, float* __restrict__ __ins_2, float* __restrict__ __ins_3) noexcept{
  void*& __sc_kernel_cache_111 = *(void**)(__module_data + 32);
  alignas(64) int8_t __rescheduled_0[128UL];
  memset(&__outs_0[0UL], 0, 3712UL);
  for (uint64_t p1 = 0UL; p1 < 56UL; p1 += 1UL) {
    memset(&__outs_0[((p1 + 1UL) * 3712UL)], 0, 64UL);
    memset(&__outs_0[(((p1 + 1UL) * 3712UL) + 3648UL)], 0, 64UL);
  }
  memset(&__outs_0[211584UL], 0, 3712UL);
  for (uint64_t p_o = 0UL; p_o < 56UL; p_o += 1UL) {
    int32_t* __origouts_2640_shr = (int32_t*)sc_aligned_malloc(__stream, 14336UL);
    void** A_list = (void**)&__rescheduled_0[0UL];
    void** B_list = (void**)&__rescheduled_0[64UL];
    for (uint64_t c = 0UL; c < 4UL; c += 1UL) {
      void* __cached_0;
      __cached_0 = &__ins_0[((c * 200704UL) + (p_o * 3584UL))];
      A_list[c] = __cached_0;
      void* __cached_1;
      __cached_1 = &__ins_1[(c * 4096UL)];
      B_list[c] = __cached_1;
    }
    void* _arg_cache_4 = &__origouts_2640_shr[0UL];
    dnnl_brgemm_list_call(__sc_kernel_cache_111, A_list, B_list, &__origouts_2640_shr[0UL], 1, 1, 1, 4, 7, 7, __stream);
    for (uint64_t _fuseiter10468 = 0UL; _fuseiter10468 < 56UL; _fuseiter10468 += 1UL) {
      for (uint64_t _fuseiter10469 = 0UL; _fuseiter10469 < 64UL; _fuseiter10469 += 16UL) {
        vec_s32x16 __cached_2;
        __cached_2 = vec_s32x16::load(&__origouts_2640_shr[((_fuseiter10468 * 64UL) + _fuseiter10469)]);
        vec_f32x16 __cached_3;
        __cached_3 = (vec_f32x16)(__cached_2);
        vec_f32x16 __cached_4;
        __cached_4 = vec_f32x16::load(&__ins_2[_fuseiter10469]);
        __cached_3 = (__cached_3 * __cached_4);
        vec_f32x16 __cached_5;
        __cached_5 = vec_f32x16::load(&__ins_3[_fuseiter10469]);
        __cached_3 = (__cached_3 + __cached_5);
        vec_s8x16 __cached_6;
        __cached_6 = sc_saturated_cast<vec_s8x16>(sc_round_and_cast<vec_s32x16>(__cached_3));
        vec_s8x16 __cached_7;
        __cached_7 = sc_max(__cached_6, vec_s8x16(0));
        vec_s8x16::store(__cached_7, &__outs_0[((((p_o + 1UL) * 3712UL) + 64UL) + ((_fuseiter10468 * 64UL) + _fuseiter10469))]);
      }
    }
    sc_aligned_free(__stream, __origouts_2640_shr);
  }
  return true;
}

static bool res2b_conv_1_cast_mul_add_cast_relu__24(int8_t* __restrict__ __outs_0, int8_t* __restrict__ __ins_0, int8_t* __restrict__ __ins_1, float* __restrict__ __ins_2, float* __restrict__ __ins_3) noexcept{
  void*& __sc_kernel_cache_109 = *(void**)(__module_data + 24);
  int8_t* __rescheduled_0 = (int8_t*)sc_aligned_malloc(__stream, 256UL);
  for (uint64_t p_o = 0UL; p_o < 56UL; p_o += 1UL) {
    void** A_list = (void**)&__rescheduled_0[0UL];
    void** B_list = (void**)&__rescheduled_0[128UL];
    int32_t* __origouts_2650_shr = (int32_t*)sc_aligned_malloc(__stream, 14336UL);
    for (uint64_t r = 0UL; r < 3UL; r += 1UL) {
      for (uint64_t s = 0UL; s < 3UL; s += 1UL) {
        void* __cached_0;
        __cached_0 = &__ins_0[(((p_o + r) * 3712UL) + (s * 64UL))];
        A_list[((r * 3UL) + s)] = __cached_0;
        void* __cached_1;
        __cached_1 = &__ins_1[((r * 12288UL) + (s * 4096UL))];
        B_list[((r * 3UL) + s)] = __cached_1;
      }
    }
    void* _arg_cache_5 = &__origouts_2650_shr[0UL];
    dnnl_brgemm_list_call(__sc_kernel_cache_109, A_list, B_list, &__origouts_2650_shr[0UL], 1, 64, 4096, 9, 7, 7, __stream);
    for (uint64_t _fuseiter10503 = 0UL; _fuseiter10503 < 56UL; _fuseiter10503 += 1UL) {
      for (uint64_t _fuseiter10504 = 0UL; _fuseiter10504 < 64UL; _fuseiter10504 += 16UL) {
        vec_s32x16 __cached_2;
        __cached_2 = vec_s32x16::load(&__origouts_2650_shr[((_fuseiter10503 * 64UL) + _fuseiter10504)]);
        vec_f32x16 __cached_3;
        __cached_3 = (vec_f32x16)(__cached_2);
        vec_f32x16 __cached_4;
        __cached_4 = vec_f32x16::load(&__ins_2[_fuseiter10504]);
        __cached_3 = (__cached_3 * __cached_4);
        vec_f32x16 __cached_5;
        __cached_5 = vec_f32x16::load(&__ins_3[_fuseiter10504]);
        __cached_3 = (__cached_3 + __cached_5);
        vec_s8x16 __cached_6;
        __cached_6 = sc_saturated_cast<vec_s8x16>(sc_round_and_cast<vec_s32x16>(__cached_3));
        vec_s8x16 __cached_7;
        __cached_7 = sc_max(__cached_6, vec_s8x16(0));
        vec_s8x16::store(__cached_7, &__outs_0[((p_o * 3584UL) + ((_fuseiter10503 * 64UL) + _fuseiter10504))]);
      }
    }
    sc_aligned_free(__stream, __origouts_2650_shr);
  }
  sc_aligned_free(__stream, __rescheduled_0);
  return true;
}

static bool res2b_conv_2_cast_mul_add_cast_add_relu__28(int8_t* __restrict__ __outs_0, int8_t* __restrict__ __ins_0, int8_t* __restrict__ __ins_1, float* __restrict__ __ins_2, float* __restrict__ __ins_3, int8_t* __restrict__ __ins_4) noexcept{
  void*& __sc_kernel_cache = *(void**)(__module_data + 8);
  alignas(64) int8_t __rescheduled_0[128UL];
  for (uint64_t fused_0fused_0k__n_3443__n_i_3444 = 0UL; fused_0fused_0k__n_3443__n_i_3444 < 4UL; fused_0fused_0k__n_3443__n_i_3444 += 1UL) {
    for (uint64_t p_o = 0UL; p_o < 56UL; p_o += 1UL) {
      int32_t* __origouts_2660_shr = (int32_t*)sc_aligned_malloc(__stream, 14336UL);
      void** A_list = (void**)&__rescheduled_0[0UL];
      void** B_list = (void**)&__rescheduled_0[64UL];
      void* __cached_0;
      __cached_0 = &__ins_0[(p_o * 3584UL)];
      A_list[0UL] = __cached_0;
      void* __cached_1;
      __cached_1 = &__ins_1[(fused_0fused_0k__n_3443__n_i_3444 * 4096UL)];
      B_list[0UL] = __cached_1;
      void* _arg_cache_6 = &__origouts_2660_shr[0UL];
      dnnl_brgemm_list_call(__sc_kernel_cache, A_list, B_list, &__origouts_2660_shr[0UL], 1, 1, 1, 1, 7, 7, __stream);
      for (uint64_t _fuseiter10538 = 0UL; _fuseiter10538 < 56UL; _fuseiter10538 += 1UL) {
        for (uint64_t _fuseiter10539 = 0UL; _fuseiter10539 < 64UL; _fuseiter10539 += 16UL) {
          vec_s32x16 __cached_2;
          __cached_2 = vec_s32x16::load(&__origouts_2660_shr[((_fuseiter10538 * 64UL) + _fuseiter10539)]);
          vec_f32x16 __cached_3;
          __cached_3 = (vec_f32x16)(__cached_2);
          vec_f32x16 __cached_4;
          __cached_4 = vec_f32x16::load(&__ins_2[((fused_0fused_0k__n_3443__n_i_3444 * 64UL) + _fuseiter10539)]);
          __cached_3 = (__cached_3 * __cached_4);
          vec_f32x16 __cached_5;
          __cached_5 = vec_f32x16::load(&__ins_3[((fused_0fused_0k__n_3443__n_i_3444 * 64UL) + _fuseiter10539)]);
          __cached_3 = (__cached_3 + __cached_5);
          vec_s8x16 __cached_6;
          __cached_6 = sc_saturated_cast<vec_s8x16>(sc_round_and_cast<vec_s32x16>(__cached_3));
          vec_s8x16 __cached_7;
          __cached_7 = vec_s8x16::load(&__ins_4[(((fused_0fused_0k__n_3443__n_i_3444 * 200704UL) + (p_o * 3584UL)) + ((_fuseiter10538 * 64UL) + _fuseiter10539))]);
          __cached_6 = (__cached_6 + __cached_7);
          vec_s8x16 __cached_8;
          __cached_8 = sc_max(__cached_6, vec_s8x16(0));
          vec_s8x16::store(__cached_8, &__outs_0[(((fused_0fused_0k__n_3443__n_i_3444 * 200704UL) + (p_o * 3584UL)) + ((_fuseiter10538 * 64UL) + _fuseiter10539))]);
        }
      }
      sc_aligned_free(__stream, __origouts_2660_shr);
    }
  }
  return true;
}

static bool res2c_conv_0_cast_mul_add_cast_relu__32(int8_t* __restrict__ __outs_0, int8_t* __restrict__ __ins_0, int8_t* __restrict__ __ins_1, float* __restrict__ __ins_2, float* __restrict__ __ins_3) noexcept{
  void*& __sc_kernel_cache_111 = *(void**)(__module_data + 32);
  alignas(64) int8_t __rescheduled_0[128UL];
  memset(&__outs_0[0UL], 0, 3712UL);
  for (uint64_t p1 = 0UL; p1 < 56UL; p1 += 1UL) {
    memset(&__outs_0[((p1 + 1UL) * 3712UL)], 0, 64UL);
    memset(&__outs_0[(((p1 + 1UL) * 3712UL) + 3648UL)], 0, 64UL);
  }
  memset(&__outs_0[211584UL], 0, 3712UL);
  for (uint64_t p_o = 0UL; p_o < 56UL; p_o += 1UL) {
    int32_t* __origouts_2670_shr = (int32_t*)sc_aligned_malloc(__stream, 14336UL);
    void** A_list = (void**)&__rescheduled_0[0UL];
    void** B_list = (void**)&__rescheduled_0[64UL];
    for (uint64_t c = 0UL; c < 4UL; c += 1UL) {
      void* __cached_0;
      __cached_0 = &__ins_0[((c * 200704UL) + (p_o * 3584UL))];
      A_list[c] = __cached_0;
      void* __cached_1;
      __cached_1 = &__ins_1[(c * 4096UL)];
      B_list[c] = __cached_1;
    }
    void* _arg_cache_7 = &__origouts_2670_shr[0UL];
    dnnl_brgemm_list_call(__sc_kernel_cache_111, A_list, B_list, &__origouts_2670_shr[0UL], 1, 1, 1, 4, 7, 7, __stream);
    for (uint64_t _fuseiter10580 = 0UL; _fuseiter10580 < 56UL; _fuseiter10580 += 1UL) {
      for (uint64_t _fuseiter10581 = 0UL; _fuseiter10581 < 64UL; _fuseiter10581 += 16UL) {
        vec_s32x16 __cached_2;
        __cached_2 = vec_s32x16::load(&__origouts_2670_shr[((_fuseiter10580 * 64UL) + _fuseiter10581)]);
        vec_f32x16 __cached_3;
        __cached_3 = (vec_f32x16)(__cached_2);
        vec_f32x16 __cached_4;
        __cached_4 = vec_f32x16::load(&__ins_2[_fuseiter10581]);
        __cached_3 = (__cached_3 * __cached_4);
        vec_f32x16 __cached_5;
        __cached_5 = vec_f32x16::load(&__ins_3[_fuseiter10581]);
        __cached_3 = (__cached_3 + __cached_5);
        vec_s8x16 __cached_6;
        __cached_6 = sc_saturated_cast<vec_s8x16>(sc_round_and_cast<vec_s32x16>(__cached_3));
        vec_s8x16 __cached_7;
        __cached_7 = sc_max(__cached_6, vec_s8x16(0));
        vec_s8x16::store(__cached_7, &__outs_0[((((p_o + 1UL) * 3712UL) + 64UL) + ((_fuseiter10580 * 64UL) + _fuseiter10581))]);
      }
    }
    sc_aligned_free(__stream, __origouts_2670_shr);
  }
  return true;
}

static bool res2c_conv_1_cast_mul_add_cast_relu__36(int8_t* __restrict__ __outs_0, int8_t* __restrict__ __ins_0, int8_t* __restrict__ __ins_1, float* __restrict__ __ins_2, float* __restrict__ __ins_3) noexcept{
  void*& __sc_kernel_cache_109 = *(void**)(__module_data + 24);
  int8_t* __rescheduled_0 = (int8_t*)sc_aligned_malloc(__stream, 256UL);
  for (uint64_t p_o = 0UL; p_o < 56UL; p_o += 1UL) {
    void** A_list = (void**)&__rescheduled_0[0UL];
    void** B_list = (void**)&__rescheduled_0[128UL];
    int32_t* __origouts_2680_shr = (int32_t*)sc_aligned_malloc(__stream, 14336UL);
    for (uint64_t r = 0UL; r < 3UL; r += 1UL) {
      for (uint64_t s = 0UL; s < 3UL; s += 1UL) {
        void* __cached_0;
        __cached_0 = &__ins_0[(((p_o + r) * 3712UL) + (s * 64UL))];
        A_list[((r * 3UL) + s)] = __cached_0;
        void* __cached_1;
        __cached_1 = &__ins_1[((r * 12288UL) + (s * 4096UL))];
        B_list[((r * 3UL) + s)] = __cached_1;
      }
    }
    void* _arg_cache_8 = &__origouts_2680_shr[0UL];
    dnnl_brgemm_list_call(__sc_kernel_cache_109, A_list, B_list, &__origouts_2680_shr[0UL], 1, 64, 4096, 9, 7, 7, __stream);
    for (uint64_t _fuseiter10615 = 0UL; _fuseiter10615 < 56UL; _fuseiter10615 += 1UL) {
      for (uint64_t _fuseiter10616 = 0UL; _fuseiter10616 < 64UL; _fuseiter10616 += 16UL) {
        vec_s32x16 __cached_2;
        __cached_2 = vec_s32x16::load(&__origouts_2680_shr[((_fuseiter10615 * 64UL) + _fuseiter10616)]);
        vec_f32x16 __cached_3;
        __cached_3 = (vec_f32x16)(__cached_2);
        vec_f32x16 __cached_4;
        __cached_4 = vec_f32x16::load(&__ins_2[_fuseiter10616]);
        __cached_3 = (__cached_3 * __cached_4);
        vec_f32x16 __cached_5;
        __cached_5 = vec_f32x16::load(&__ins_3[_fuseiter10616]);
        __cached_3 = (__cached_3 + __cached_5);
        vec_s8x16 __cached_6;
        __cached_6 = sc_saturated_cast<vec_s8x16>(sc_round_and_cast<vec_s32x16>(__cached_3));
        vec_s8x16 __cached_7;
        __cached_7 = sc_max(__cached_6, vec_s8x16(0));
        vec_s8x16::store(__cached_7, &__outs_0[((p_o * 3584UL) + ((_fuseiter10615 * 64UL) + _fuseiter10616))]);
      }
    }
    sc_aligned_free(__stream, __origouts_2680_shr);
  }
  sc_aligned_free(__stream, __rescheduled_0);
  return true;
}

static bool res2c_conv_2_cast_mul_add_cast_add_relu__40(int8_t* __restrict__ __outs_0, int8_t* __restrict__ __ins_0, int8_t* __restrict__ __ins_1, float* __restrict__ __ins_2, float* __restrict__ __ins_3, int8_t* __restrict__ __ins_4) noexcept{
  void*& __sc_kernel_cache = *(void**)(__module_data + 8);
  alignas(64) int8_t __rescheduled_0[128UL];
  for (uint64_t fused_0fused_0n__n_i_3449__k_3450 = 0UL; fused_0fused_0n__n_i_3449__k_3450 < 4UL; fused_0fused_0n__n_i_3449__k_3450 += 1UL) {
    for (uint64_t p_o = 0UL; p_o < 56UL; p_o += 1UL) {
      int32_t* __origouts_2690_shr = (int32_t*)sc_aligned_malloc(__stream, 14336UL);
      void** A_list = (void**)&__rescheduled_0[0UL];
      void** B_list = (void**)&__rescheduled_0[64UL];
      void* __cached_0;
      __cached_0 = &__ins_0[(((fused_0fused_0n__n_i_3449__k_3450 / 4UL) * 200704UL) + (p_o * 3584UL))];
      A_list[0UL] = __cached_0;
      void* __cached_1;
      __cached_1 = &__ins_1[((fused_0fused_0n__n_i_3449__k_3450 % 4UL) * 4096UL)];
      B_list[0UL] = __cached_1;
      void* _arg_cache_9 = &__origouts_2690_shr[0UL];
      dnnl_brgemm_list_call(__sc_kernel_cache, A_list, B_list, &__origouts_2690_shr[0UL], 1, 1, 1, 1, 7, 7, __stream);
      for (uint64_t _fuseiter10650 = 0UL; _fuseiter10650 < 56UL; _fuseiter10650 += 1UL) {
        for (uint64_t _fuseiter10651 = 0UL; _fuseiter10651 < 64UL; _fuseiter10651 += 16UL) {
          vec_s32x16 __cached_2;
          __cached_2 = vec_s32x16::load(&__origouts_2690_shr[((_fuseiter10650 * 64UL) + _fuseiter10651)]);
          vec_f32x16 __cached_3;
          __cached_3 = (vec_f32x16)(__cached_2);
          vec_f32x16 __cached_4;
          __cached_4 = vec_f32x16::load(&__ins_2[((((fused_0fused_0n__n_i_3449__k_3450 / 4UL) * 256UL) + ((fused_0fused_0n__n_i_3449__k_3450 % 4UL) * 64UL)) + _fuseiter10651)]);
          __cached_3 = (__cached_3 * __cached_4);
          vec_f32x16 __cached_5;
          __cached_5 = vec_f32x16::load(&__ins_3[(((fused_0fused_0n__n_i_3449__k_3450 % 4UL) * 64UL) + _fuseiter10651)]);
          __cached_3 = (__cached_3 + __cached_5);
          vec_s8x16 __cached_6;
          __cached_6 = sc_saturated_cast<vec_s8x16>(sc_round_and_cast<vec_s32x16>(__cached_3));
          vec_s8x16 __cached_7;
          __cached_7 = vec_s8x16::load(&__ins_4[((((fused_0fused_0n__n_i_3449__k_3450 / 4UL) * 802816UL) + (((fused_0fused_0n__n_i_3449__k_3450 % 4UL) * 200704UL) + (p_o * 3584UL))) + ((_fuseiter10650 * 64UL) + _fuseiter10651))]);
          __cached_6 = (__cached_6 + __cached_7);
          vec_s8x16 __cached_8;
          __cached_8 = sc_max(__cached_6, vec_s8x16(0));
          vec_s8x16::store(__cached_8, &__outs_0[((((fused_0fused_0n__n_i_3449__k_3450 / 4UL) * 802816UL) + (((fused_0fused_0n__n_i_3449__k_3450 % 4UL) * 200704UL) + (p_o * 3584UL))) + ((_fuseiter10650 * 64UL) + _fuseiter10651))]);
        }
      }
      sc_aligned_free(__stream, __origouts_2690_shr);
    }
  }
  return true;
}

static bool res3a_conv_b_cast_mul_add_cast__44(int8_t* __restrict__ __outs_0, int8_t* __restrict__ __ins_0, int8_t* __restrict__ __ins_1, float* __restrict__ __ins_2, float* __restrict__ __ins_3) noexcept{
  void*& __sc_kernel_cache_111 = *(void**)(__module_data + 32);
  alignas(64) int8_t __rescheduled_0[128UL];
  int8_t* input_tmp = (int8_t*)sc_aligned_malloc(__stream, 200704UL);
  for (uint64_t c_o = 0UL; c_o < 4UL; c_o += 1UL) {
    for (uint64_t p = 0UL; p < 28UL; p += 1UL) {
      for (uint64_t q = 0UL; q < 28UL; q += 1UL) {
        vec_s8x64 __cached_0;
        __cached_0 = vec_s8x64::load(&__ins_0[((c_o * 200704UL) + ((p * 7168UL) + (q * 128UL)))]);
        vec_s8x64 __cached_1;
        __cached_1 = __cached_0;
        vec_s8x64::store(__cached_1, &input_tmp[((c_o * 50176UL) + ((p * 1792UL) + (q * 64UL)))]);
      }
    }
  }
  for (uint64_t fused_0fused_0n__n_i_3451__k_3452 = 0UL; fused_0fused_0n__n_i_3451__k_3452 < 8UL; fused_0fused_0n__n_i_3451__k_3452 += 1UL) {
    for (uint64_t p_o = 0UL; p_o < 14UL; p_o += 1UL) {
      int32_t* __origouts_2700_shr = (int32_t*)sc_aligned_malloc(__stream, 14336UL);
      void** A_list = (void**)&__rescheduled_0[0UL];
      void** B_list = (void**)&__rescheduled_0[64UL];
      for (uint64_t c = 0UL; c < 4UL; c += 1UL) {
        void* __cached_2;
        __cached_2 = &input_tmp[(((fused_0fused_0n__n_i_3451__k_3452 / 8UL) * 200704UL) + ((c * 50176UL) + (p_o * 3584UL)))];
        A_list[c] = __cached_2;
        void* __cached_3;
        __cached_3 = &__ins_1[(((fused_0fused_0n__n_i_3451__k_3452 % 8UL) * 16384UL) + (c * 4096UL))];
        B_list[c] = __cached_3;
      }
      void* _arg_cache_10 = &__origouts_2700_shr[0UL];
      dnnl_brgemm_list_call(__sc_kernel_cache_111, A_list, B_list, &__origouts_2700_shr[0UL], 1, 1, 1, 4, 7, 7, __stream);
      for (uint64_t _fuseiter10691 = 0UL; _fuseiter10691 < 2UL; _fuseiter10691 += 1UL) {
        for (uint64_t _fuseiter10692 = 0UL; _fuseiter10692 < 28UL; _fuseiter10692 += 1UL) {
          for (uint64_t _fuseiter10693 = 0UL; _fuseiter10693 < 64UL; _fuseiter10693 += 16UL) {
            vec_s32x16 __cached_4;
            __cached_4 = vec_s32x16::load(&__origouts_2700_shr[((_fuseiter10691 * 1792UL) + ((_fuseiter10692 * 64UL) + _fuseiter10693))]);
            vec_f32x16 __cached_5;
            __cached_5 = (vec_f32x16)(__cached_4);
            vec_f32x16 __cached_6;
            __cached_6 = vec_f32x16::load(&__ins_2[((((fused_0fused_0n__n_i_3451__k_3452 / 8UL) * 512UL) + ((fused_0fused_0n__n_i_3451__k_3452 % 8UL) * 64UL)) + _fuseiter10693)]);
            __cached_5 = (__cached_5 * __cached_6);
            vec_f32x16 __cached_7;
            __cached_7 = vec_f32x16::load(&__ins_3[(((fused_0fused_0n__n_i_3451__k_3452 % 8UL) * 64UL) + _fuseiter10693)]);
            __cached_5 = (__cached_5 + __cached_7);
            vec_s8x16 __cached_8;
            __cached_8 = sc_saturated_cast<vec_s8x16>(sc_round_and_cast<vec_s32x16>(__cached_5));
            vec_s8x16::store(__cached_8, &__outs_0[((((fused_0fused_0n__n_i_3451__k_3452 / 8UL) * 401408UL) + (((fused_0fused_0n__n_i_3451__k_3452 % 8UL) * 50176UL) + (p_o * 3584UL))) + ((_fuseiter10691 * 1792UL) + ((_fuseiter10692 * 64UL) + _fuseiter10693)))]);
          }
        }
      }
      sc_aligned_free(__stream, __origouts_2700_shr);
    }
  }
  sc_aligned_free(__stream, input_tmp);
  return true;
}

static bool res3a_conv_0_cast_mul_add_cast_relu__48(int8_t* __restrict__ __outs_0, int8_t* __restrict__ __ins_0, int8_t* __restrict__ __ins_1, float* __restrict__ __ins_2, float* __restrict__ __ins_3) noexcept{
  void*& __sc_kernel_cache_113 = *(void**)(__module_data + 40);
  alignas(64) int8_t __rescheduled_0[128UL];
  for (uint64_t k = 0UL; k < 2UL; k += 1UL) {
    memset(&__outs_0[(k * 215296UL)], 0, 3712UL);
    for (uint64_t p1 = 0UL; p1 < 56UL; p1 += 1UL) {
      memset(&__outs_0[((k * 215296UL) + ((p1 + 1UL) * 3712UL))], 0, 64UL);
      memset(&__outs_0[(((k * 215296UL) + ((p1 + 1UL) * 3712UL)) + 3648UL)], 0, 64UL);
    }
    memset(&__outs_0[((k * 215296UL) + 211584UL)], 0, 3712UL);
  }
  for (uint64_t fused_0fused_0n__n_i_3453__k_3454 = 0UL; fused_0fused_0n__n_i_3453__k_3454 < 2UL; fused_0fused_0n__n_i_3453__k_3454 += 1UL) {
    for (uint64_t p_o = 0UL; p_o < 56UL; p_o += 1UL) {
      for (uint64_t q_i = 0UL; q_i < 2UL; q_i += 1UL) {
        int32_t* __origouts_2710_shr = (int32_t*)sc_aligned_malloc(__stream, 7168UL);
        void** A_list = (void**)&__rescheduled_0[0UL];
        void** B_list = (void**)&__rescheduled_0[64UL];
        for (uint64_t c = 0UL; c < 4UL; c += 1UL) {
          void* __cached_0;
          __cached_0 = &__ins_0[(((fused_0fused_0n__n_i_3453__k_3454 / 2UL) * 802816UL) + ((c * 200704UL) + ((p_o * 3584UL) + (q_i * 1792UL))))];
          A_list[c] = __cached_0;
          void* __cached_1;
          __cached_1 = &__ins_1[(((fused_0fused_0n__n_i_3453__k_3454 % 2UL) * 16384UL) + (c * 4096UL))];
          B_list[c] = __cached_1;
        }
        void* _arg_cache_11 = &__origouts_2710_shr[0UL];
        dnnl_brgemm_list_call(__sc_kernel_cache_113, A_list, B_list, &__origouts_2710_shr[0UL], 1, 1, 1, 4, 7, 7, __stream);
        for (uint64_t _fuseiter10720 = 0UL; _fuseiter10720 < 28UL; _fuseiter10720 += 1UL) {
          for (uint64_t _fuseiter10721 = 0UL; _fuseiter10721 < 64UL; _fuseiter10721 += 16UL) {
            vec_s32x16 __cached_2;
            __cached_2 = vec_s32x16::load(&__origouts_2710_shr[((_fuseiter10720 * 64UL) + _fuseiter10721)]);
            vec_f32x16 __cached_3;
            __cached_3 = (vec_f32x16)(__cached_2);
            vec_f32x16 __cached_4;
            __cached_4 = vec_f32x16::load(&__ins_2[((((fused_0fused_0n__n_i_3453__k_3454 / 2UL) * 128UL) + ((fused_0fused_0n__n_i_3453__k_3454 % 2UL) * 64UL)) + _fuseiter10721)]);
            __cached_3 = (__cached_3 * __cached_4);
            vec_f32x16 __cached_5;
            __cached_5 = vec_f32x16::load(&__ins_3[(((fused_0fused_0n__n_i_3453__k_3454 % 2UL) * 64UL) + _fuseiter10721)]);
            __cached_3 = (__cached_3 + __cached_5);
            vec_s8x16 __cached_6;
            __cached_6 = sc_saturated_cast<vec_s8x16>(sc_round_and_cast<vec_s32x16>(__cached_3));
            vec_s8x16 __cached_7;
            __cached_7 = sc_max(__cached_6, vec_s8x16(0));
            vec_s8x16::store(__cached_7, &__outs_0[((((fused_0fused_0n__n_i_3453__k_3454 / 2UL) * 430592UL) + (((fused_0fused_0n__n_i_3453__k_3454 % 2UL) * 215296UL) + (((p_o + 1UL) * 3712UL) + (((q_i * 28UL) + 1UL) * 64UL)))) + ((_fuseiter10720 * 64UL) + _fuseiter10721))]);
          }
        }
        sc_aligned_free(__stream, __origouts_2710_shr);
      }
    }
  }
  return true;
}

static bool res3a_conv_1_cast_mul_add_cast_relu__52(int8_t* __restrict__ __outs_0, int8_t* __restrict__ __ins_0, int8_t* __restrict__ __ins_1, float* __restrict__ __ins_2, float* __restrict__ __ins_3) noexcept{
  void*& __sc_kernel_cache_115 = *(void**)(__module_data + 48);
  int8_t* __rescheduled_0 = (int8_t*)sc_aligned_malloc(__stream, 384UL);
  for (uint64_t fused_0fused_0k_o__n_3455__n_i_3456 = 0UL; fused_0fused_0k_o__n_3455__n_i_3456 < 2UL; fused_0fused_0k_o__n_3455__n_i_3456 += 1UL) {
    for (uint64_t p_o = 0UL; p_o < 28UL; p_o += 1UL) {
      void** A_list = (void**)&__rescheduled_0[0UL];
      void** B_list = (void**)&__rescheduled_0[192UL];
      int32_t* __origouts_2720_shr = (int32_t*)sc_aligned_malloc(__stream, 7168UL);
      for (uint64_t c_o = 0UL; c_o < 2UL; c_o += 1UL) {
        for (uint64_t r = 0UL; r < 3UL; r += 1UL) {
          for (uint64_t s = 0UL; s < 3UL; s += 1UL) {
            void* __cached_0;
            __cached_0 = &__ins_0[((c_o * 215296UL) + ((((p_o * 2UL) + r) * 3712UL) + (s * 64UL)))];
            A_list[(((c_o * 9UL) + (r * 3UL)) + s)] = __cached_0;
            void* __cached_1;
            __cached_1 = &__ins_1[((fused_0fused_0k_o__n_3455__n_i_3456 * 73728UL) + ((c_o * 36864UL) + ((r * 12288UL) + (s * 4096UL))))];
            B_list[(((c_o * 9UL) + (r * 3UL)) + s)] = __cached_1;
          }
        }
      }
      void* _arg_cache_12 = &__origouts_2720_shr[0UL];
      dnnl_brgemm_list_call(__sc_kernel_cache_115, A_list, B_list, &__origouts_2720_shr[0UL], 1, 64, 4096, 18, 7, 7, __stream);
      for (uint64_t _fuseiter10755 = 0UL; _fuseiter10755 < 28UL; _fuseiter10755 += 1UL) {
        for (uint64_t _fuseiter10756 = 0UL; _fuseiter10756 < 64UL; _fuseiter10756 += 16UL) {
          vec_s32x16 __cached_2;
          __cached_2 = vec_s32x16::load(&__origouts_2720_shr[((_fuseiter10755 * 64UL) + _fuseiter10756)]);
          vec_f32x16 __cached_3;
          __cached_3 = (vec_f32x16)(__cached_2);
          vec_f32x16 __cached_4;
          __cached_4 = vec_f32x16::load(&__ins_2[((fused_0fused_0k_o__n_3455__n_i_3456 * 64UL) + _fuseiter10756)]);
          __cached_3 = (__cached_3 * __cached_4);
          vec_f32x16 __cached_5;
          __cached_5 = vec_f32x16::load(&__ins_3[((fused_0fused_0k_o__n_3455__n_i_3456 * 64UL) + _fuseiter10756)]);
          __cached_3 = (__cached_3 + __cached_5);
          vec_s8x16 __cached_6;
          __cached_6 = sc_saturated_cast<vec_s8x16>(sc_round_and_cast<vec_s32x16>(__cached_3));
          vec_s8x16 __cached_7;
          __cached_7 = sc_max(__cached_6, vec_s8x16(0));
          vec_s8x16::store(__cached_7, &__outs_0[(((fused_0fused_0k_o__n_3455__n_i_3456 * 50176UL) + (p_o * 1792UL)) + ((_fuseiter10755 * 64UL) + _fuseiter10756))]);
        }
      }
      sc_aligned_free(__stream, __origouts_2720_shr);
    }
  }
  sc_aligned_free(__stream, __rescheduled_0);
  return true;
}

static bool res3a_conv_2_cast_mul_add_cast_add_relu__56(int8_t* __restrict__ __outs_0, int8_t* __restrict__ __ins_0, int8_t* __restrict__ __ins_1, float* __restrict__ __ins_2, float* __restrict__ __ins_3, int8_t* __restrict__ __ins_4) noexcept{
  void*& __sc_kernel_cache_117 = *(void**)(__module_data + 56);
  alignas(64) int8_t __rescheduled_0[128UL];
  for (uint64_t fused_0fused_0k__n_3457__n_i_3458 = 0UL; fused_0fused_0k__n_3457__n_i_3458 < 8UL; fused_0fused_0k__n_3457__n_i_3458 += 1UL) {
    for (uint64_t p_o = 0UL; p_o < 14UL; p_o += 1UL) {
      int32_t* __origouts_2730_shr = (int32_t*)sc_aligned_malloc(__stream, 14336UL);
      void** A_list = (void**)&__rescheduled_0[0UL];
      void** B_list = (void**)&__rescheduled_0[64UL];
      for (uint64_t c = 0UL; c < 2UL; c += 1UL) {
        void* __cached_0;
        __cached_0 = &__ins_0[((c * 50176UL) + (p_o * 3584UL))];
        A_list[c] = __cached_0;
        void* __cached_1;
        __cached_1 = &__ins_1[((fused_0fused_0k__n_3457__n_i_3458 * 8192UL) + (c * 4096UL))];
        B_list[c] = __cached_1;
      }
      void* _arg_cache_13 = &__origouts_2730_shr[0UL];
      dnnl_brgemm_list_call(__sc_kernel_cache_117, A_list, B_list, &__origouts_2730_shr[0UL], 1, 1, 1, 2, 7, 7, __stream);
      for (uint64_t _fuseiter10789 = 0UL; _fuseiter10789 < 2UL; _fuseiter10789 += 1UL) {
        for (uint64_t _fuseiter10790 = 0UL; _fuseiter10790 < 28UL; _fuseiter10790 += 1UL) {
          for (uint64_t _fuseiter10791 = 0UL; _fuseiter10791 < 64UL; _fuseiter10791 += 16UL) {
            vec_s32x16 __cached_2;
            __cached_2 = vec_s32x16::load(&__origouts_2730_shr[((_fuseiter10789 * 1792UL) + ((_fuseiter10790 * 64UL) + _fuseiter10791))]);
            vec_f32x16 __cached_3;
            __cached_3 = (vec_f32x16)(__cached_2);
            vec_f32x16 __cached_4;
            __cached_4 = vec_f32x16::load(&__ins_2[((fused_0fused_0k__n_3457__n_i_3458 * 64UL) + _fuseiter10791)]);
            __cached_3 = (__cached_3 * __cached_4);
            vec_f32x16 __cached_5;
            __cached_5 = vec_f32x16::load(&__ins_3[((fused_0fused_0k__n_3457__n_i_3458 * 64UL) + _fuseiter10791)]);
            __cached_3 = (__cached_3 + __cached_5);
            vec_s8x16 __cached_6;
            __cached_6 = sc_saturated_cast<vec_s8x16>(sc_round_and_cast<vec_s32x16>(__cached_3));
            vec_s8x16 __cached_7;
            __cached_7 = vec_s8x16::load(&__ins_4[(((fused_0fused_0k__n_3457__n_i_3458 * 50176UL) + (p_o * 3584UL)) + ((_fuseiter10789 * 1792UL) + ((_fuseiter10790 * 64UL) + _fuseiter10791)))]);
            __cached_6 = (__cached_6 + __cached_7);
            vec_s8x16 __cached_8;
            __cached_8 = sc_max(__cached_6, vec_s8x16(0));
            vec_s8x16::store(__cached_8, &__outs_0[(((fused_0fused_0k__n_3457__n_i_3458 * 50176UL) + (p_o * 3584UL)) + ((_fuseiter10789 * 1792UL) + ((_fuseiter10790 * 64UL) + _fuseiter10791)))]);
          }
        }
      }
      sc_aligned_free(__stream, __origouts_2730_shr);
    }
  }
  return true;
}

static bool res3b_conv_0_cast_mul_add_cast_relu__60(int8_t* __restrict__ __outs_0, int8_t* __restrict__ __ins_0, int8_t* __restrict__ __ins_1, float* __restrict__ __ins_2, float* __restrict__ __ins_3) noexcept{
  void*& __sc_kernel_cache_119 = *(void**)(__module_data + 64);
  alignas(64) int8_t __rescheduled_0[128UL];
  for (uint64_t k = 0UL; k < 2UL; k += 1UL) {
    memset(&__outs_0[(k * 57600UL)], 0, 1920UL);
    for (uint64_t p1 = 0UL; p1 < 28UL; p1 += 1UL) {
      memset(&__outs_0[((k * 57600UL) + ((p1 + 1UL) * 1920UL))], 0, 64UL);
      memset(&__outs_0[(((k * 57600UL) + ((p1 + 1UL) * 1920UL)) + 1856UL)], 0, 64UL);
    }
    memset(&__outs_0[((k * 57600UL) + 55680UL)], 0, 1920UL);
  }
  for (uint64_t fused_0fused_0n__n_i_3459__k_3460 = 0UL; fused_0fused_0n__n_i_3459__k_3460 < 2UL; fused_0fused_0n__n_i_3459__k_3460 += 1UL) {
    for (uint64_t p_o = 0UL; p_o < 28UL; p_o += 1UL) {
      int32_t* __origouts_2740_shr = (int32_t*)sc_aligned_malloc(__stream, 7168UL);
      void** A_list = (void**)&__rescheduled_0[0UL];
      void** B_list = (void**)&__rescheduled_0[64UL];
      for (uint64_t c = 0UL; c < 8UL; c += 1UL) {
        void* __cached_0;
        __cached_0 = &__ins_0[(((fused_0fused_0n__n_i_3459__k_3460 / 2UL) * 401408UL) + ((c * 50176UL) + (p_o * 1792UL)))];
        A_list[c] = __cached_0;
        void* __cached_1;
        __cached_1 = &__ins_1[(((fused_0fused_0n__n_i_3459__k_3460 % 2UL) * 32768UL) + (c * 4096UL))];
        B_list[c] = __cached_1;
      }
      void* _arg_cache_14 = &__origouts_2740_shr[0UL];
      dnnl_brgemm_list_call(__sc_kernel_cache_119, A_list, B_list, &__origouts_2740_shr[0UL], 1, 1, 1, 8, 7, 7, __stream);
      for (uint64_t _fuseiter10832 = 0UL; _fuseiter10832 < 28UL; _fuseiter10832 += 1UL) {
        for (uint64_t _fuseiter10833 = 0UL; _fuseiter10833 < 64UL; _fuseiter10833 += 16UL) {
          vec_s32x16 __cached_2;
          __cached_2 = vec_s32x16::load(&__origouts_2740_shr[((_fuseiter10832 * 64UL) + _fuseiter10833)]);
          vec_f32x16 __cached_3;
          __cached_3 = (vec_f32x16)(__cached_2);
          vec_f32x16 __cached_4;
          __cached_4 = vec_f32x16::load(&__ins_2[((((fused_0fused_0n__n_i_3459__k_3460 / 2UL) * 128UL) + ((fused_0fused_0n__n_i_3459__k_3460 % 2UL) * 64UL)) + _fuseiter10833)]);
          __cached_3 = (__cached_3 * __cached_4);
          vec_f32x16 __cached_5;
          __cached_5 = vec_f32x16::load(&__ins_3[(((fused_0fused_0n__n_i_3459__k_3460 % 2UL) * 64UL) + _fuseiter10833)]);
          __cached_3 = (__cached_3 + __cached_5);
          vec_s8x16 __cached_6;
          __cached_6 = sc_saturated_cast<vec_s8x16>(sc_round_and_cast<vec_s32x16>(__cached_3));
          vec_s8x16 __cached_7;
          __cached_7 = sc_max(__cached_6, vec_s8x16(0));
          vec_s8x16::store(__cached_7, &__outs_0[(((((fused_0fused_0n__n_i_3459__k_3460 / 2UL) * 115200UL) + (((fused_0fused_0n__n_i_3459__k_3460 % 2UL) * 57600UL) + ((p_o + 1UL) * 1920UL))) + 64UL) + ((_fuseiter10832 * 64UL) + _fuseiter10833))]);
        }
      }
      sc_aligned_free(__stream, __origouts_2740_shr);
    }
  }
  return true;
}

static bool res3b_conv_1_cast_mul_add_cast_relu__64(int8_t* __restrict__ __outs_0, int8_t* __restrict__ __ins_0, int8_t* __restrict__ __ins_1, float* __restrict__ __ins_2, float* __restrict__ __ins_3) noexcept{
  void** __sc_kernel_cache_arr = (void**)&__uninitialized_data[23657488UL];
  int8_t* __rescheduled_0 = (int8_t*)sc_aligned_malloc(__stream, 448UL);
  int32_t* conv_os_acc_size = (int32_t*)&__rescheduled_0[0UL];
  int32_t __cached_0;
  __cached_0 = 0;
  conv_os_acc_size[0] = __cached_0;
  int32_t __cached_1;
  __cached_1 = 392;
  conv_os_acc_size[1] = __cached_1;
  for (uint64_t fused_0fused_0k_o__n_3461__n_i_3462 = 0UL; fused_0fused_0k_o__n_3461__n_i_3462 < 2UL; fused_0fused_0k_o__n_3461__n_i_3462 += 1UL) {
    int32_t* __origouts_2750_shr = (int32_t*)sc_aligned_malloc(__stream, 200704UL);
    for (uint64_t o_o = 0UL; o_o < 2UL; o_o += 1UL) {
      void** A_list = (void**)&__rescheduled_0[64UL];
      void** B_list = (void**)&__rescheduled_0[256UL];
      for (uint64_t c_o = 0UL; c_o < 2UL; c_o += 1UL) {
        for (uint64_t r = 0UL; r < 3UL; r += 1UL) {
          for (uint64_t s = 0UL; s < 3UL; s += 1UL) {
            void* __cached_2;
            __cached_2 = &__ins_0[((c_o * 57600UL) + (((((o_o * 419UL) / 30UL) + r) * 1920UL) + ((((o_o * 419UL) % 30UL) + s) * 64UL)))];
            A_list[(((c_o * 9UL) + (r * 3UL)) + s)] = __cached_2;
            void* __cached_3;
            __cached_3 = &__ins_1[((fused_0fused_0k_o__n_3461__n_i_3462 * 73728UL) + ((c_o * 36864UL) + ((r * 12288UL) + (s * 4096UL))))];
            B_list[(((c_o * 9UL) + (r * 3UL)) + s)] = __cached_3;
          }
        }
      }
      int32_t __cached_4;
      __cached_4 = conv_os_acc_size[o_o];
      void* _arg_cache_15 = &__origouts_2750_shr[(uint64_t)(((__cached_4 / 28) * 1792) + ((__cached_4 % 28) * 64))];
      dnnl_brgemm_list_call(__sc_kernel_cache_arr[o_o], A_list, B_list, &__origouts_2750_shr[(uint64_t)(((__cached_4 / 28) * 1792) + ((__cached_4 % 28) * 64))], 1, 64, 4096, 18, 7, 7, __stream);
    }
    for (uint64_t _fuseiter10866 = 0UL; _fuseiter10866 < 28UL; _fuseiter10866 += 1UL) {
      for (uint64_t _fuseiter10867 = 0UL; _fuseiter10867 < 28UL; _fuseiter10867 += 1UL) {
        for (uint64_t _fuseiter10868 = 0UL; _fuseiter10868 < 64UL; _fuseiter10868 += 16UL) {
          vec_s32x16 __cached_5;
          __cached_5 = vec_s32x16::load(&__origouts_2750_shr[((_fuseiter10866 * 1792UL) + ((_fuseiter10867 * 64UL) + _fuseiter10868))]);
          vec_f32x16 __cached_6;
          __cached_6 = (vec_f32x16)(__cached_5);
          vec_f32x16 __cached_7;
          __cached_7 = vec_f32x16::load(&__ins_2[((fused_0fused_0k_o__n_3461__n_i_3462 * 64UL) + _fuseiter10868)]);
          __cached_6 = (__cached_6 * __cached_7);
          vec_f32x16 __cached_8;
          __cached_8 = vec_f32x16::load(&__ins_3[((fused_0fused_0k_o__n_3461__n_i_3462 * 64UL) + _fuseiter10868)]);
          __cached_6 = (__cached_6 + __cached_8);
          vec_s8x16 __cached_9;
          __cached_9 = sc_saturated_cast<vec_s8x16>(sc_round_and_cast<vec_s32x16>(__cached_6));
          vec_s8x16 __cached_10;
          __cached_10 = sc_max(__cached_9, vec_s8x16(0));
          vec_s8x16::store(__cached_10, &__outs_0[((fused_0fused_0k_o__n_3461__n_i_3462 * 50176UL) + ((_fuseiter10866 * 1792UL) + ((_fuseiter10867 * 64UL) + _fuseiter10868)))]);
        }
      }
    }
    sc_aligned_free(__stream, __origouts_2750_shr);
  }
  sc_aligned_free(__stream, __rescheduled_0);
  return true;
}

static bool res3b_conv_2_cast_mul_add_cast_add_relu__68(int8_t* __restrict__ __outs_0, int8_t* __restrict__ __ins_0, int8_t* __restrict__ __ins_1, float* __restrict__ __ins_2, float* __restrict__ __ins_3, int8_t* __restrict__ __ins_4) noexcept{
  void*& __sc_kernel_cache_122 = *(void**)(__module_data + 72);
  alignas(64) int8_t __rescheduled_0[128UL];
  for (uint64_t fused_0fused_0n__n_i_3463__k_3464 = 0UL; fused_0fused_0n__n_i_3463__k_3464 < 8UL; fused_0fused_0n__n_i_3463__k_3464 += 1UL) {
    for (uint64_t p_o = 0UL; p_o < 28UL; p_o += 1UL) {
      int32_t* __origouts_2760_shr = (int32_t*)sc_aligned_malloc(__stream, 7168UL);
      void** A_list = (void**)&__rescheduled_0[0UL];
      void** B_list = (void**)&__rescheduled_0[64UL];
      for (uint64_t c = 0UL; c < 2UL; c += 1UL) {
        void* __cached_0;
        __cached_0 = &__ins_0[(((fused_0fused_0n__n_i_3463__k_3464 / 8UL) * 100352UL) + ((c * 50176UL) + (p_o * 1792UL)))];
        A_list[c] = __cached_0;
        void* __cached_1;
        __cached_1 = &__ins_1[(((fused_0fused_0n__n_i_3463__k_3464 % 8UL) * 8192UL) + (c * 4096UL))];
        B_list[c] = __cached_1;
      }
      void* _arg_cache_16 = &__origouts_2760_shr[0UL];
      dnnl_brgemm_list_call(__sc_kernel_cache_122, A_list, B_list, &__origouts_2760_shr[0UL], 1, 1, 1, 2, 7, 7, __stream);
      for (uint64_t _fuseiter10902 = 0UL; _fuseiter10902 < 28UL; _fuseiter10902 += 1UL) {
        for (uint64_t _fuseiter10903 = 0UL; _fuseiter10903 < 64UL; _fuseiter10903 += 16UL) {
          vec_s32x16 __cached_2;
          __cached_2 = vec_s32x16::load(&__origouts_2760_shr[((_fuseiter10902 * 64UL) + _fuseiter10903)]);
          vec_f32x16 __cached_3;
          __cached_3 = (vec_f32x16)(__cached_2);
          vec_f32x16 __cached_4;
          __cached_4 = vec_f32x16::load(&__ins_2[((((fused_0fused_0n__n_i_3463__k_3464 / 8UL) * 512UL) + ((fused_0fused_0n__n_i_3463__k_3464 % 8UL) * 64UL)) + _fuseiter10903)]);
          __cached_3 = (__cached_3 * __cached_4);
          vec_f32x16 __cached_5;
          __cached_5 = vec_f32x16::load(&__ins_3[(((fused_0fused_0n__n_i_3463__k_3464 % 8UL) * 64UL) + _fuseiter10903)]);
          __cached_3 = (__cached_3 + __cached_5);
          vec_s8x16 __cached_6;
          __cached_6 = sc_saturated_cast<vec_s8x16>(sc_round_and_cast<vec_s32x16>(__cached_3));
          vec_s8x16 __cached_7;
          __cached_7 = vec_s8x16::load(&__ins_4[((((fused_0fused_0n__n_i_3463__k_3464 / 8UL) * 401408UL) + (((fused_0fused_0n__n_i_3463__k_3464 % 8UL) * 50176UL) + (p_o * 1792UL))) + ((_fuseiter10902 * 64UL) + _fuseiter10903))]);
          __cached_6 = (__cached_6 + __cached_7);
          vec_s8x16 __cached_8;
          __cached_8 = sc_max(__cached_6, vec_s8x16(0));
          vec_s8x16::store(__cached_8, &__outs_0[((((fused_0fused_0n__n_i_3463__k_3464 / 8UL) * 401408UL) + (((fused_0fused_0n__n_i_3463__k_3464 % 8UL) * 50176UL) + (p_o * 1792UL))) + ((_fuseiter10902 * 64UL) + _fuseiter10903))]);
        }
      }
      sc_aligned_free(__stream, __origouts_2760_shr);
    }
  }
  return true;
}

static bool res3c_conv_0_cast_mul_add_cast_relu__72(int8_t* __restrict__ __outs_0, int8_t* __restrict__ __ins_0, int8_t* __restrict__ __ins_1, float* __restrict__ __ins_2, float* __restrict__ __ins_3) noexcept{
  void*& __sc_kernel_cache_124 = *(void**)(__module_data + 80);
  alignas(64) int8_t __rescheduled_0[128UL];
  for (uint64_t k = 0UL; k < 2UL; k += 1UL) {
    memset(&__outs_0[(k * 57600UL)], 0, 1920UL);
    for (uint64_t p1 = 0UL; p1 < 28UL; p1 += 1UL) {
      memset(&__outs_0[((k * 57600UL) + ((p1 + 1UL) * 1920UL))], 0, 64UL);
      memset(&__outs_0[(((k * 57600UL) + ((p1 + 1UL) * 1920UL)) + 1856UL)], 0, 64UL);
    }
    memset(&__outs_0[((k * 57600UL) + 55680UL)], 0, 1920UL);
  }
  for (uint64_t fused_0fused_0n__n_i_3465__k_3466 = 0UL; fused_0fused_0n__n_i_3465__k_3466 < 2UL; fused_0fused_0n__n_i_3465__k_3466 += 1UL) {
    for (uint64_t p_o = 0UL; p_o < 2UL; p_o += 1UL) {
      int32_t* __origouts_2770_shr = (int32_t*)sc_aligned_malloc(__stream, 100352UL);
      void** A_list = (void**)&__rescheduled_0[0UL];
      void** B_list = (void**)&__rescheduled_0[64UL];
      for (uint64_t c = 0UL; c < 8UL; c += 1UL) {
        void* __cached_0;
        __cached_0 = &__ins_0[(((fused_0fused_0n__n_i_3465__k_3466 / 2UL) * 401408UL) + ((c * 50176UL) + (p_o * 25088UL)))];
        A_list[c] = __cached_0;
        void* __cached_1;
        __cached_1 = &__ins_1[(((fused_0fused_0n__n_i_3465__k_3466 % 2UL) * 32768UL) + (c * 4096UL))];
        B_list[c] = __cached_1;
      }
      void* _arg_cache_17 = &__origouts_2770_shr[0UL];
      dnnl_brgemm_list_call(__sc_kernel_cache_124, A_list, B_list, &__origouts_2770_shr[0UL], 1, 1, 1, 8, 7, 7, __stream);
      for (uint64_t _fuseiter10943 = 0UL; _fuseiter10943 < 14UL; _fuseiter10943 += 1UL) {
        for (uint64_t _fuseiter10944 = 0UL; _fuseiter10944 < 28UL; _fuseiter10944 += 1UL) {
          for (uint64_t _fuseiter10945 = 0UL; _fuseiter10945 < 64UL; _fuseiter10945 += 16UL) {
            vec_s32x16 __cached_2;
            __cached_2 = vec_s32x16::load(&__origouts_2770_shr[((_fuseiter10943 * 1792UL) + ((_fuseiter10944 * 64UL) + _fuseiter10945))]);
            vec_f32x16 __cached_3;
            __cached_3 = (vec_f32x16)(__cached_2);
            vec_f32x16 __cached_4;
            __cached_4 = vec_f32x16::load(&__ins_2[((((fused_0fused_0n__n_i_3465__k_3466 / 2UL) * 128UL) + ((fused_0fused_0n__n_i_3465__k_3466 % 2UL) * 64UL)) + _fuseiter10945)]);
            __cached_3 = (__cached_3 * __cached_4);
            vec_f32x16 __cached_5;
            __cached_5 = vec_f32x16::load(&__ins_3[(((fused_0fused_0n__n_i_3465__k_3466 % 2UL) * 64UL) + _fuseiter10945)]);
            __cached_3 = (__cached_3 + __cached_5);
            vec_s8x16 __cached_6;
            __cached_6 = sc_saturated_cast<vec_s8x16>(sc_round_and_cast<vec_s32x16>(__cached_3));
            vec_s8x16 __cached_7;
            __cached_7 = sc_max(__cached_6, vec_s8x16(0));
            vec_s8x16::store(__cached_7, &__outs_0[(((((fused_0fused_0n__n_i_3465__k_3466 / 2UL) * 115200UL) + (((fused_0fused_0n__n_i_3465__k_3466 % 2UL) * 57600UL) + (((p_o * 14UL) + 1UL) * 1920UL))) + 64UL) + ((_fuseiter10943 * 1920UL) + ((_fuseiter10944 * 64UL) + _fuseiter10945)))]);
          }
        }
      }
      sc_aligned_free(__stream, __origouts_2770_shr);
    }
  }
  return true;
}

static bool res3c_conv_1_cast_mul_add_cast_relu__76(int8_t* __restrict__ __outs_0, int8_t* __restrict__ __ins_0, int8_t* __restrict__ __ins_1, float* __restrict__ __ins_2, float* __restrict__ __ins_3) noexcept{
  void** __sc_kernel_cache_arr = (void**)&__uninitialized_data[23657488UL];
  int8_t* __rescheduled_0 = (int8_t*)sc_aligned_malloc(__stream, 448UL);
  int32_t* conv_os_acc_size = (int32_t*)&__rescheduled_0[0UL];
  int32_t __cached_0;
  __cached_0 = 0;
  conv_os_acc_size[0] = __cached_0;
  int32_t __cached_1;
  __cached_1 = 392;
  conv_os_acc_size[1] = __cached_1;
  for (uint64_t fused_0fused_0k_o__n_3467__n_i_3468 = 0UL; fused_0fused_0k_o__n_3467__n_i_3468 < 2UL; fused_0fused_0k_o__n_3467__n_i_3468 += 1UL) {
    int32_t* __origouts_2780_shr = (int32_t*)sc_aligned_malloc(__stream, 200704UL);
    for (uint64_t o_o = 0UL; o_o < 2UL; o_o += 1UL) {
      void** A_list = (void**)&__rescheduled_0[64UL];
      void** B_list = (void**)&__rescheduled_0[256UL];
      for (uint64_t c_o = 0UL; c_o < 2UL; c_o += 1UL) {
        for (uint64_t r = 0UL; r < 3UL; r += 1UL) {
          for (uint64_t s = 0UL; s < 3UL; s += 1UL) {
            void* __cached_2;
            __cached_2 = &__ins_0[((c_o * 57600UL) + (((((o_o * 419UL) / 30UL) + r) * 1920UL) + ((((o_o * 419UL) % 30UL) + s) * 64UL)))];
            A_list[(((c_o * 9UL) + (r * 3UL)) + s)] = __cached_2;
            void* __cached_3;
            __cached_3 = &__ins_1[((fused_0fused_0k_o__n_3467__n_i_3468 * 73728UL) + ((c_o * 36864UL) + ((r * 12288UL) + (s * 4096UL))))];
            B_list[(((c_o * 9UL) + (r * 3UL)) + s)] = __cached_3;
          }
        }
      }
      int32_t __cached_4;
      __cached_4 = conv_os_acc_size[o_o];
      void* _arg_cache_18 = &__origouts_2780_shr[(uint64_t)(((__cached_4 / 28) * 1792) + ((__cached_4 % 28) * 64))];
      dnnl_brgemm_list_call(__sc_kernel_cache_arr[o_o], A_list, B_list, &__origouts_2780_shr[(uint64_t)(((__cached_4 / 28) * 1792) + ((__cached_4 % 28) * 64))], 1, 64, 4096, 18, 7, 7, __stream);
    }
    for (uint64_t _fuseiter10978 = 0UL; _fuseiter10978 < 28UL; _fuseiter10978 += 1UL) {
      for (uint64_t _fuseiter10979 = 0UL; _fuseiter10979 < 28UL; _fuseiter10979 += 1UL) {
        for (uint64_t _fuseiter10980 = 0UL; _fuseiter10980 < 64UL; _fuseiter10980 += 16UL) {
          vec_s32x16 __cached_5;
          __cached_5 = vec_s32x16::load(&__origouts_2780_shr[((_fuseiter10978 * 1792UL) + ((_fuseiter10979 * 64UL) + _fuseiter10980))]);
          vec_f32x16 __cached_6;
          __cached_6 = (vec_f32x16)(__cached_5);
          vec_f32x16 __cached_7;
          __cached_7 = vec_f32x16::load(&__ins_2[((fused_0fused_0k_o__n_3467__n_i_3468 * 64UL) + _fuseiter10980)]);
          __cached_6 = (__cached_6 * __cached_7);
          vec_f32x16 __cached_8;
          __cached_8 = vec_f32x16::load(&__ins_3[((fused_0fused_0k_o__n_3467__n_i_3468 * 64UL) + _fuseiter10980)]);
          __cached_6 = (__cached_6 + __cached_8);
          vec_s8x16 __cached_9;
          __cached_9 = sc_saturated_cast<vec_s8x16>(sc_round_and_cast<vec_s32x16>(__cached_6));
          vec_s8x16 __cached_10;
          __cached_10 = sc_max(__cached_9, vec_s8x16(0));
          vec_s8x16::store(__cached_10, &__outs_0[((fused_0fused_0k_o__n_3467__n_i_3468 * 50176UL) + ((_fuseiter10978 * 1792UL) + ((_fuseiter10979 * 64UL) + _fuseiter10980)))]);
        }
      }
    }
    sc_aligned_free(__stream, __origouts_2780_shr);
  }
  sc_aligned_free(__stream, __rescheduled_0);
  return true;
}

static bool res3c_conv_2_cast_mul_add_cast_add_relu__80(int8_t* __restrict__ __outs_0, int8_t* __restrict__ __ins_0, int8_t* __restrict__ __ins_1, float* __restrict__ __ins_2, float* __restrict__ __ins_3, int8_t* __restrict__ __ins_4) noexcept{
  void*& __sc_kernel_cache_126 = *(void**)(__module_data + 88);
  alignas(64) int8_t __rescheduled_0[128UL];
  for (uint64_t fused_0fused_0n__n_i_3469__k_3470 = 0UL; fused_0fused_0n__n_i_3469__k_3470 < 8UL; fused_0fused_0n__n_i_3469__k_3470 += 1UL) {
    for (uint64_t p_o = 0UL; p_o < 7UL; p_o += 1UL) {
      int32_t* __origouts_2790_shr = (int32_t*)sc_aligned_malloc(__stream, 28672UL);
      void** A_list = (void**)&__rescheduled_0[0UL];
      void** B_list = (void**)&__rescheduled_0[64UL];
      for (uint64_t c = 0UL; c < 2UL; c += 1UL) {
        void* __cached_0;
        __cached_0 = &__ins_0[(((fused_0fused_0n__n_i_3469__k_3470 / 8UL) * 100352UL) + ((c * 50176UL) + (p_o * 7168UL)))];
        A_list[c] = __cached_0;
        void* __cached_1;
        __cached_1 = &__ins_1[(((fused_0fused_0n__n_i_3469__k_3470 % 8UL) * 8192UL) + (c * 4096UL))];
        B_list[c] = __cached_1;
      }
      void* _arg_cache_19 = &__origouts_2790_shr[0UL];
      dnnl_brgemm_list_call(__sc_kernel_cache_126, A_list, B_list, &__origouts_2790_shr[0UL], 1, 1, 1, 2, 7, 7, __stream);
      for (uint64_t _fuseiter11013 = 0UL; _fuseiter11013 < 4UL; _fuseiter11013 += 1UL) {
        for (uint64_t _fuseiter11014 = 0UL; _fuseiter11014 < 28UL; _fuseiter11014 += 1UL) {
          for (uint64_t _fuseiter11015 = 0UL; _fuseiter11015 < 64UL; _fuseiter11015 += 16UL) {
            vec_s32x16 __cached_2;
            __cached_2 = vec_s32x16::load(&__origouts_2790_shr[((_fuseiter11013 * 1792UL) + ((_fuseiter11014 * 64UL) + _fuseiter11015))]);
            vec_f32x16 __cached_3;
            __cached_3 = (vec_f32x16)(__cached_2);
            vec_f32x16 __cached_4;
            __cached_4 = vec_f32x16::load(&__ins_2[((((fused_0fused_0n__n_i_3469__k_3470 / 8UL) * 512UL) + ((fused_0fused_0n__n_i_3469__k_3470 % 8UL) * 64UL)) + _fuseiter11015)]);
            __cached_3 = (__cached_3 * __cached_4);
            vec_f32x16 __cached_5;
            __cached_5 = vec_f32x16::load(&__ins_3[(((fused_0fused_0n__n_i_3469__k_3470 % 8UL) * 64UL) + _fuseiter11015)]);
            __cached_3 = (__cached_3 + __cached_5);
            vec_s8x16 __cached_6;
            __cached_6 = sc_saturated_cast<vec_s8x16>(sc_round_and_cast<vec_s32x16>(__cached_3));
            vec_s8x16 __cached_7;
            __cached_7 = vec_s8x16::load(&__ins_4[((((fused_0fused_0n__n_i_3469__k_3470 / 8UL) * 401408UL) + (((fused_0fused_0n__n_i_3469__k_3470 % 8UL) * 50176UL) + (p_o * 7168UL))) + ((_fuseiter11013 * 1792UL) + ((_fuseiter11014 * 64UL) + _fuseiter11015)))]);
            __cached_6 = (__cached_6 + __cached_7);
            vec_s8x16 __cached_8;
            __cached_8 = sc_max(__cached_6, vec_s8x16(0));
            vec_s8x16::store(__cached_8, &__outs_0[((((fused_0fused_0n__n_i_3469__k_3470 / 8UL) * 401408UL) + (((fused_0fused_0n__n_i_3469__k_3470 % 8UL) * 50176UL) + (p_o * 7168UL))) + ((_fuseiter11013 * 1792UL) + ((_fuseiter11014 * 64UL) + _fuseiter11015)))]);
          }
        }
      }
      sc_aligned_free(__stream, __origouts_2790_shr);
    }
  }
  return true;
}

static bool res3d_conv_0_cast_mul_add_cast_relu__84(int8_t* __restrict__ __outs_0, int8_t* __restrict__ __ins_0, int8_t* __restrict__ __ins_1, float* __restrict__ __ins_2, float* __restrict__ __ins_3) noexcept{
  void*& __sc_kernel_cache_128 = *(void**)(__module_data + 96);
  alignas(64) int8_t __rescheduled_0[128UL];
  for (uint64_t k = 0UL; k < 2UL; k += 1UL) {
    memset(&__outs_0[(k * 57600UL)], 0, 1920UL);
    for (uint64_t p1 = 0UL; p1 < 28UL; p1 += 1UL) {
      memset(&__outs_0[((k * 57600UL) + ((p1 + 1UL) * 1920UL))], 0, 64UL);
      memset(&__outs_0[(((k * 57600UL) + ((p1 + 1UL) * 1920UL)) + 1856UL)], 0, 64UL);
    }
    memset(&__outs_0[((k * 57600UL) + 55680UL)], 0, 1920UL);
  }
  for (uint64_t fused_0fused_0n__n_i_3471__k_3472 = 0UL; fused_0fused_0n__n_i_3471__k_3472 < 2UL; fused_0fused_0n__n_i_3471__k_3472 += 1UL) {
    for (uint64_t p_o = 0UL; p_o < 14UL; p_o += 1UL) {
      int32_t* __origouts_2800_shr = (int32_t*)sc_aligned_malloc(__stream, 14336UL);
      void** A_list = (void**)&__rescheduled_0[0UL];
      void** B_list = (void**)&__rescheduled_0[64UL];
      for (uint64_t c = 0UL; c < 8UL; c += 1UL) {
        void* __cached_0;
        __cached_0 = &__ins_0[(((fused_0fused_0n__n_i_3471__k_3472 / 2UL) * 401408UL) + ((c * 50176UL) + (p_o * 3584UL)))];
        A_list[c] = __cached_0;
        void* __cached_1;
        __cached_1 = &__ins_1[(((fused_0fused_0n__n_i_3471__k_3472 % 2UL) * 32768UL) + (c * 4096UL))];
        B_list[c] = __cached_1;
      }
      void* _arg_cache_20 = &__origouts_2800_shr[0UL];
      dnnl_brgemm_list_call(__sc_kernel_cache_128, A_list, B_list, &__origouts_2800_shr[0UL], 1, 1, 1, 8, 7, 7, __stream);
      for (uint64_t _fuseiter11055 = 0UL; _fuseiter11055 < 2UL; _fuseiter11055 += 1UL) {
        for (uint64_t _fuseiter11056 = 0UL; _fuseiter11056 < 28UL; _fuseiter11056 += 1UL) {
          for (uint64_t _fuseiter11057 = 0UL; _fuseiter11057 < 64UL; _fuseiter11057 += 16UL) {
            vec_s32x16 __cached_2;
            __cached_2 = vec_s32x16::load(&__origouts_2800_shr[((_fuseiter11055 * 1792UL) + ((_fuseiter11056 * 64UL) + _fuseiter11057))]);
            vec_f32x16 __cached_3;
            __cached_3 = (vec_f32x16)(__cached_2);
            vec_f32x16 __cached_4;
            __cached_4 = vec_f32x16::load(&__ins_2[((((fused_0fused_0n__n_i_3471__k_3472 / 2UL) * 128UL) + ((fused_0fused_0n__n_i_3471__k_3472 % 2UL) * 64UL)) + _fuseiter11057)]);
            __cached_3 = (__cached_3 * __cached_4);
            vec_f32x16 __cached_5;
            __cached_5 = vec_f32x16::load(&__ins_3[(((fused_0fused_0n__n_i_3471__k_3472 % 2UL) * 64UL) + _fuseiter11057)]);
            __cached_3 = (__cached_3 + __cached_5);
            vec_s8x16 __cached_6;
            __cached_6 = sc_saturated_cast<vec_s8x16>(sc_round_and_cast<vec_s32x16>(__cached_3));
            vec_s8x16 __cached_7;
            __cached_7 = sc_max(__cached_6, vec_s8x16(0));
            vec_s8x16::store(__cached_7, &__outs_0[(((((fused_0fused_0n__n_i_3471__k_3472 / 2UL) * 115200UL) + (((fused_0fused_0n__n_i_3471__k_3472 % 2UL) * 57600UL) + (((p_o * 2UL) + 1UL) * 1920UL))) + 64UL) + ((_fuseiter11055 * 1920UL) + ((_fuseiter11056 * 64UL) + _fuseiter11057)))]);
          }
        }
      }
      sc_aligned_free(__stream, __origouts_2800_shr);
    }
  }
  return true;
}

static bool res3d_conv_1_cast_mul_add_cast_relu__88(int8_t* __restrict__ __outs_0, int8_t* __restrict__ __ins_0, int8_t* __restrict__ __ins_1, float* __restrict__ __ins_2, float* __restrict__ __ins_3) noexcept{
  void** __sc_kernel_cache_arr = (void**)&__uninitialized_data[23657488UL];
  int8_t* __rescheduled_0 = (int8_t*)sc_aligned_malloc(__stream, 448UL);
  int32_t* conv_os_acc_size = (int32_t*)&__rescheduled_0[0UL];
  int32_t __cached_0;
  __cached_0 = 0;
  conv_os_acc_size[0] = __cached_0;
  int32_t __cached_1;
  __cached_1 = 392;
  conv_os_acc_size[1] = __cached_1;
  for (uint64_t fused_0fused_0k_o__n_3473__n_i_3474 = 0UL; fused_0fused_0k_o__n_3473__n_i_3474 < 2UL; fused_0fused_0k_o__n_3473__n_i_3474 += 1UL) {
    int32_t* __origouts_2810_shr = (int32_t*)sc_aligned_malloc(__stream, 200704UL);
    for (uint64_t o_o = 0UL; o_o < 2UL; o_o += 1UL) {
      void** A_list = (void**)&__rescheduled_0[64UL];
      void** B_list = (void**)&__rescheduled_0[256UL];
      for (uint64_t c_o = 0UL; c_o < 2UL; c_o += 1UL) {
        for (uint64_t r = 0UL; r < 3UL; r += 1UL) {
          for (uint64_t s = 0UL; s < 3UL; s += 1UL) {
            void* __cached_2;
            __cached_2 = &__ins_0[((c_o * 57600UL) + (((((o_o * 419UL) / 30UL) + r) * 1920UL) + ((((o_o * 419UL) % 30UL) + s) * 64UL)))];
            A_list[(((c_o * 9UL) + (r * 3UL)) + s)] = __cached_2;
            void* __cached_3;
            __cached_3 = &__ins_1[((fused_0fused_0k_o__n_3473__n_i_3474 * 73728UL) + ((c_o * 36864UL) + ((r * 12288UL) + (s * 4096UL))))];
            B_list[(((c_o * 9UL) + (r * 3UL)) + s)] = __cached_3;
          }
        }
      }
      int32_t __cached_4;
      __cached_4 = conv_os_acc_size[o_o];
      void* _arg_cache_21 = &__origouts_2810_shr[(uint64_t)(((__cached_4 / 28) * 1792) + ((__cached_4 % 28) * 64))];
      dnnl_brgemm_list_call(__sc_kernel_cache_arr[o_o], A_list, B_list, &__origouts_2810_shr[(uint64_t)(((__cached_4 / 28) * 1792) + ((__cached_4 % 28) * 64))], 1, 64, 4096, 18, 7, 7, __stream);
    }
    for (uint64_t _fuseiter11090 = 0UL; _fuseiter11090 < 28UL; _fuseiter11090 += 1UL) {
      for (uint64_t _fuseiter11091 = 0UL; _fuseiter11091 < 28UL; _fuseiter11091 += 1UL) {
        for (uint64_t _fuseiter11092 = 0UL; _fuseiter11092 < 64UL; _fuseiter11092 += 16UL) {
          vec_s32x16 __cached_5;
          __cached_5 = vec_s32x16::load(&__origouts_2810_shr[((_fuseiter11090 * 1792UL) + ((_fuseiter11091 * 64UL) + _fuseiter11092))]);
          vec_f32x16 __cached_6;
          __cached_6 = (vec_f32x16)(__cached_5);
          vec_f32x16 __cached_7;
          __cached_7 = vec_f32x16::load(&__ins_2[((fused_0fused_0k_o__n_3473__n_i_3474 * 64UL) + _fuseiter11092)]);
          __cached_6 = (__cached_6 * __cached_7);
          vec_f32x16 __cached_8;
          __cached_8 = vec_f32x16::load(&__ins_3[((fused_0fused_0k_o__n_3473__n_i_3474 * 64UL) + _fuseiter11092)]);
          __cached_6 = (__cached_6 + __cached_8);
          vec_s8x16 __cached_9;
          __cached_9 = sc_saturated_cast<vec_s8x16>(sc_round_and_cast<vec_s32x16>(__cached_6));
          vec_s8x16 __cached_10;
          __cached_10 = sc_max(__cached_9, vec_s8x16(0));
          vec_s8x16::store(__cached_10, &__outs_0[((fused_0fused_0k_o__n_3473__n_i_3474 * 50176UL) + ((_fuseiter11090 * 1792UL) + ((_fuseiter11091 * 64UL) + _fuseiter11092)))]);
        }
      }
    }
    sc_aligned_free(__stream, __origouts_2810_shr);
  }
  sc_aligned_free(__stream, __rescheduled_0);
  return true;
}

static bool res3d_conv_2_cast_mul_add_cast_add_relu__93(int8_t* __restrict__ __outs_0, int8_t* __restrict__ __ins_0, int8_t* __restrict__ __ins_1, float* __restrict__ __ins_2, float* __restrict__ __ins_3, int8_t* __restrict__ __ins_4) noexcept{
  void*& __sc_kernel_cache_117 = *(void**)(__module_data + 56);
  alignas(64) int8_t __rescheduled_0[128UL];
  for (uint64_t fused_0fused_0n__n_i_3475__k_3476 = 0UL; fused_0fused_0n__n_i_3475__k_3476 < 8UL; fused_0fused_0n__n_i_3475__k_3476 += 1UL) {
    for (uint64_t p_o = 0UL; p_o < 14UL; p_o += 1UL) {
      int32_t* __origouts_2820_shr = (int32_t*)sc_aligned_malloc(__stream, 14336UL);
      void** A_list = (void**)&__rescheduled_0[0UL];
      void** B_list = (void**)&__rescheduled_0[64UL];
      for (uint64_t c = 0UL; c < 2UL; c += 1UL) {
        void* __cached_0;
        __cached_0 = &__ins_0[(((fused_0fused_0n__n_i_3475__k_3476 / 8UL) * 100352UL) + ((c * 50176UL) + (p_o * 3584UL)))];
        A_list[c] = __cached_0;
        void* __cached_1;
        __cached_1 = &__ins_1[(((fused_0fused_0n__n_i_3475__k_3476 % 8UL) * 8192UL) + (c * 4096UL))];
        B_list[c] = __cached_1;
      }
      void* _arg_cache_22 = &__origouts_2820_shr[0UL];
      dnnl_brgemm_list_call(__sc_kernel_cache_117, A_list, B_list, &__origouts_2820_shr[0UL], 1, 1, 1, 2, 7, 7, __stream);
      for (uint64_t _fuseiter11125 = 0UL; _fuseiter11125 < 2UL; _fuseiter11125 += 1UL) {
        for (uint64_t _fuseiter11126 = 0UL; _fuseiter11126 < 28UL; _fuseiter11126 += 1UL) {
          for (uint64_t _fuseiter11127 = 0UL; _fuseiter11127 < 64UL; _fuseiter11127 += 16UL) {
            vec_s32x16 __cached_2;
            __cached_2 = vec_s32x16::load(&__origouts_2820_shr[((_fuseiter11125 * 1792UL) + ((_fuseiter11126 * 64UL) + _fuseiter11127))]);
            vec_f32x16 __cached_3;
            __cached_3 = (vec_f32x16)(__cached_2);
            vec_f32x16 __cached_4;
            __cached_4 = vec_f32x16::load(&__ins_2[((((fused_0fused_0n__n_i_3475__k_3476 / 8UL) * 512UL) + ((fused_0fused_0n__n_i_3475__k_3476 % 8UL) * 64UL)) + _fuseiter11127)]);
            __cached_3 = (__cached_3 * __cached_4);
            vec_f32x16 __cached_5;
            __cached_5 = vec_f32x16::load(&__ins_3[(((fused_0fused_0n__n_i_3475__k_3476 % 8UL) * 64UL) + _fuseiter11127)]);
            __cached_3 = (__cached_3 + __cached_5);
            vec_s8x16 __cached_6;
            __cached_6 = sc_saturated_cast<vec_s8x16>(sc_round_and_cast<vec_s32x16>(__cached_3));
            vec_s8x16 __cached_7;
            __cached_7 = vec_s8x16::load(&__ins_4[((((fused_0fused_0n__n_i_3475__k_3476 / 8UL) * 401408UL) + (((fused_0fused_0n__n_i_3475__k_3476 % 8UL) * 50176UL) + (p_o * 3584UL))) + ((_fuseiter11125 * 1792UL) + ((_fuseiter11126 * 64UL) + _fuseiter11127)))]);
            __cached_6 = (__cached_6 + __cached_7);
            vec_s8x16 __cached_8;
            __cached_8 = sc_max(__cached_6, vec_s8x16(0));
            vec_s8x16::store(__cached_8, &__outs_0[((((fused_0fused_0n__n_i_3475__k_3476 / 8UL) * 401408UL) + (((fused_0fused_0n__n_i_3475__k_3476 % 8UL) * 50176UL) + (p_o * 3584UL))) + ((_fuseiter11125 * 1792UL) + ((_fuseiter11126 * 64UL) + _fuseiter11127)))]);
          }
        }
      }
      sc_aligned_free(__stream, __origouts_2820_shr);
    }
  }
  return true;
}

static bool batchwise_2_fused_res4a_conv_b_cast_mul_add_cast_res4a_conv_0_cast_mul_add_cast_relu_res4a_conv_1_cast_mul_add_cast_relu_res4a_conv_2_cast_mul_add_cast_add_relu_res4b_conv_0_cast_mul_add_cast_relu_res4b_conv_1_cast_mul_add_cast_relu_res4b_conv_2_cast_mul_add_cast_add_relu_res4c_conv_0_cast_mul_add_cast_relu_res4c_conv_1_cast_mul_add_cast_relu_res4c_conv_2_cast_mul_add_cast_add_relu_res4d_conv_0_cast_mul_add_cast_relu_res4d_conv_1_cast_mul_add_cast_relu_res4d_conv_2_cast_mul_add_cast_add_relu_res4e_conv_0_cast_mul_add_cast_relu_res4e_conv_1_cast_mul_add_cast_relu_res4e_conv_2_cast_mul_add_cast_add_relu_res4f_conv_0_cast_mul_add_cast_relu_res4f_conv_1_cast_mul_add_cast_relu_res4f_conv_2_cast_mul_add_cast_add_relu__685(int8_t* __restrict__ __outs_0, int8_t* __restrict__ __ins_0, int8_t* __restrict__ __ins_1, float* __restrict__ __ins_2, float* __restrict__ __ins_3, int8_t* __restrict__ __ins_4, float* __restrict__ __ins_5, float* __restrict__ __ins_6, int8_t* __restrict__ __ins_7, float* __restrict__ __ins_8, float* __restrict__ __ins_9, int8_t* __restrict__ __ins_10, float* __restrict__ __ins_11, float* __restrict__ __ins_12, int8_t* __restrict__ __ins_13, float* __restrict__ __ins_14, float* __restrict__ __ins_15, int8_t* __restrict__ __ins_16, float* __restrict__ __ins_17, float* __restrict__ __ins_18, int8_t* __restrict__ __ins_19, float* __restrict__ __ins_20, float* __restrict__ __ins_21, int8_t* __restrict__ __ins_22, float* __restrict__ __ins_23, float* __restrict__ __ins_24, int8_t* __restrict__ __ins_25, float* __restrict__ __ins_26, float* __restrict__ __ins_27, int8_t* __restrict__ __ins_28, float* __restrict__ __ins_29, float* __restrict__ __ins_30, int8_t* __restrict__ __ins_31, float* __restrict__ __ins_32, float* __restrict__ __ins_33, int8_t* __restrict__ __ins_34, float* __restrict__ __ins_35, float* __restrict__ __ins_36, int8_t* __restrict__ __ins_37, float* __restrict__ __ins_38, float* __restrict__ __ins_39, int8_t* __restrict__ __ins_40, float* __restrict__ __ins_41, float* __restrict__ __ins_42, int8_t* __restrict__ __ins_43, float* __restrict__ __ins_44, float* __restrict__ __ins_45, int8_t* __restrict__ __ins_46, float* __restrict__ __ins_47, float* __restrict__ __ins_48, int8_t* __restrict__ __ins_49, float* __restrict__ __ins_50, float* __restrict__ __ins_51, int8_t* __restrict__ __ins_52, float* __restrict__ __ins_53, float* __restrict__ __ins_54, int8_t* __restrict__ __ins_55, float* __restrict__ __ins_56, float* __restrict__ __ins_57) noexcept{
  generic_val* __tempargs337 = (generic_val*)sc_aligned_malloc(__stream, 472UL);
  __tempargs337[0UL] = __ins_0;
  __tempargs337[1UL] = __ins_1;
  __tempargs337[2UL] = __ins_2;
  __tempargs337[3UL] = __ins_3;
  __tempargs337[4UL] = __ins_4;
  __tempargs337[5UL] = __ins_5;
  __tempargs337[6UL] = __ins_6;
  __tempargs337[7UL] = __ins_7;
  __tempargs337[8UL] = __ins_8;
  __tempargs337[9UL] = __ins_9;
  __tempargs337[10UL] = __ins_10;
  __tempargs337[11UL] = __ins_11;
  __tempargs337[12UL] = __ins_12;
  __tempargs337[13UL] = __ins_13;
  __tempargs337[14UL] = __ins_14;
  __tempargs337[15UL] = __ins_15;
  __tempargs337[16UL] = __ins_16;
  __tempargs337[17UL] = __ins_17;
  __tempargs337[18UL] = __ins_18;
  __tempargs337[19UL] = __ins_19;
  __tempargs337[20UL] = __ins_20;
  __tempargs337[21UL] = __ins_21;
  __tempargs337[22UL] = __ins_22;
  __tempargs337[23UL] = __ins_23;
  __tempargs337[24UL] = __ins_24;
  __tempargs337[25UL] = __ins_25;
  __tempargs337[26UL] = __ins_26;
  __tempargs337[27UL] = __ins_27;
  __tempargs337[28UL] = __ins_28;
  __tempargs337[29UL] = __ins_29;
  __tempargs337[30UL] = __ins_30;
  __tempargs337[31UL] = __ins_31;
  __tempargs337[32UL] = __ins_32;
  __tempargs337[33UL] = __ins_33;
  __tempargs337[34UL] = __ins_34;
  __tempargs337[35UL] = __ins_35;
  __tempargs337[36UL] = __ins_36;
  __tempargs337[37UL] = __ins_37;
  __tempargs337[38UL] = __ins_38;
  __tempargs337[39UL] = __ins_39;
  __tempargs337[40UL] = __ins_40;
  __tempargs337[41UL] = __ins_41;
  __tempargs337[42UL] = __ins_42;
  __tempargs337[43UL] = __ins_43;
  __tempargs337[44UL] = __ins_44;
  __tempargs337[45UL] = __ins_45;
  __tempargs337[46UL] = __ins_46;
  __tempargs337[47UL] = __ins_47;
  __tempargs337[48UL] = __ins_48;
  __tempargs337[49UL] = __ins_49;
  __tempargs337[50UL] = __ins_50;
  __tempargs337[51UL] = __ins_51;
  __tempargs337[52UL] = __ins_52;
  __tempargs337[53UL] = __ins_53;
  __tempargs337[54UL] = __ins_54;
  __tempargs337[55UL] = __outs_0;
  __tempargs337[56UL] = __ins_55;
  __tempargs337[57UL] = __ins_56;
  __tempargs337[58UL] = __ins_57;
  sc_parallel_call_cpu_with_env((void*)&batchwise_2_fused_res4a_conv_b_cast_mul_add_cast_res4a_conv_0_cast_mul_add_cast_relu_res4a_conv_1_cast_mul_add_cast_relu_res4a_conv_2_cast_mul_add_cast_add_relu_res4b_conv_0_cast_mul_add_cast_relu_res4b_conv_1_cast_mul_add_cast_relu_res4b_conv_2_cast_mul_add_cast_add_relu_res4c_conv_0_cast_mul_add_cast_relu_res4c_conv_1_cast_mul_add_cast_relu_res4c_conv_2_cast_mul_add_cast_add_relu_res4d_conv_0_cast_mul_add_cast_relu_res4d_conv_1_cast_mul_add_cast_relu_res4d_conv_2_cast_mul_add_cast_add_relu_res4e_conv_0_cast_mul_add_cast_relu_res4e_conv_1_cast_mul_add_cast_relu_res4e_conv_2_cast_mul_add_cast_add_relu_res4f_conv_0_cast_mul_add_cast_relu_res4f_conv_1_cast_mul_add_cast_relu_res4f_conv_2_cast_mul_add_cast_add_relu__6850_closure_337_0wrapper, __stream, __module_data, 0UL, 2UL, 1UL, __tempargs337);
  sc_aligned_free(__stream, __tempargs337);
  return true;
}

extern "C" void main_entry_105(int8_t* __restrict__ buffer_61, int8_t* __restrict__ buffer_57, int8_t* __restrict__ buffer_56, float* __restrict__ buffer_55, float* __restrict__ buffer_54, int8_t* __restrict__ buffer_53, float* __restrict__ buffer_52, float* __restrict__ buffer_51, int8_t* __restrict__ buffer_50, float* __restrict__ buffer_49, float* __restrict__ buffer_48, int8_t* __restrict__ buffer_47, float* __restrict__ buffer_46, float* __restrict__ buffer_45, int8_t* __restrict__ buffer_44, float* __restrict__ buffer_43, float* __restrict__ buffer_42, int8_t* __restrict__ buffer_41, float* __restrict__ buffer_40, float* __restrict__ buffer_39, int8_t* __restrict__ buffer_38, float* __restrict__ buffer_37, float* __restrict__ buffer_36, int8_t* __restrict__ buffer_35, float* __restrict__ buffer_34, float* __restrict__ buffer_33, int8_t* __restrict__ buffer_32, float* __restrict__ buffer_31, float* __restrict__ buffer_30, int8_t* __restrict__ buffer_29, float* __restrict__ buffer_28, float* __restrict__ buffer_27, int8_t* __restrict__ buffer_26, float* __restrict__ buffer_25, float* __restrict__ buffer_24, int8_t* __restrict__ buffer_23, float* __restrict__ buffer_22, float* __restrict__ buffer_21, int8_t* __restrict__ buffer_20, float* __restrict__ buffer_19, float* __restrict__ buffer_18, int8_t* __restrict__ buffer_17, float* __restrict__ buffer_16, float* __restrict__ buffer_15, int8_t* __restrict__ buffer_14, float* __restrict__ buffer_13, float* __restrict__ buffer_12, int8_t* __restrict__ buffer_11, float* __restrict__ buffer_10, float* __restrict__ buffer_9, int8_t* __restrict__ buffer_8, float* __restrict__ buffer_7, float* __restrict__ buffer_6, int8_t* __restrict__ buffer_5, float* __restrict__ buffer_4, float* __restrict__ buffer_3, int8_t* __restrict__ buffer_2, float* __restrict__ buffer_1, float* __restrict__ buffer_0) noexcept{
  int8_t* __rescheduled_0 = (int8_t*)sc_aligned_malloc(__stream, 993280UL);
  // [s8 [1, 2, 16, 14, 14, 64] @ A2aBCD64b]
  int8_t* buffer_58 = (int8_t*)&__rescheduled_0[0UL];
  res4a_conv_b_cast_mul_add_cast__4(buffer_58, buffer_57, buffer_56, buffer_55, buffer_54);
  // [s8 [1, 2, 4, 30, 30, 64] @ A2aBCD64b]
  int8_t* buffer_59 = (int8_t*)&__rescheduled_0[401408UL];
  res4a_conv_0_cast_mul_add_cast_relu__8(buffer_59, buffer_57, buffer_53, buffer_52, buffer_51);
  // [s8 [1, 2, 4, 14, 14, 64] @ A2aBCD64b]
  int8_t* buffer_60 = (int8_t*)&__rescheduled_0[862208UL];
  res4a_conv_1_cast_mul_add_cast_relu__12(buffer_60, buffer_59, buffer_50, buffer_49, buffer_48);
  res4a_conv_2_cast_mul_add_cast_add_relu__16(buffer_58, buffer_60, buffer_47, buffer_46, buffer_45, buffer_58);
  res4b_conv_0_cast_mul_add_cast_relu__20(buffer_60, buffer_58, buffer_44, buffer_43, buffer_42);
  res4b_conv_1_cast_mul_add_cast_relu__24(buffer_59, buffer_60, buffer_41, buffer_40, buffer_39);
  res4b_conv_2_cast_mul_add_cast_add_relu__28(buffer_58, buffer_59, buffer_38, buffer_37, buffer_36, buffer_58);
  res4c_conv_0_cast_mul_add_cast_relu__32(buffer_60, buffer_58, buffer_35, buffer_34, buffer_33);
  res4c_conv_1_cast_mul_add_cast_relu__36(buffer_59, buffer_60, buffer_32, buffer_31, buffer_30);
  res4c_conv_2_cast_mul_add_cast_add_relu__40(buffer_58, buffer_59, buffer_29, buffer_28, buffer_27, buffer_58);
  res4d_conv_0_cast_mul_add_cast_relu__44(buffer_60, buffer_58, buffer_26, buffer_25, buffer_24);
  res4d_conv_1_cast_mul_add_cast_relu__48(buffer_59, buffer_60, buffer_23, buffer_22, buffer_21);
  res4d_conv_2_cast_mul_add_cast_add_relu__52(buffer_58, buffer_59, buffer_20, buffer_19, buffer_18, buffer_58);
  res4e_conv_0_cast_mul_add_cast_relu__56(buffer_60, buffer_58, buffer_17, buffer_16, buffer_15);
  res4e_conv_1_cast_mul_add_cast_relu__60(buffer_59, buffer_60, buffer_14, buffer_13, buffer_12);
  res4e_conv_2_cast_mul_add_cast_add_relu__64(buffer_58, buffer_59, buffer_11, buffer_10, buffer_9, buffer_58);
  res4f_conv_0_cast_mul_add_cast_relu__68(buffer_60, buffer_58, buffer_8, buffer_7, buffer_6);
  res4f_conv_1_cast_mul_add_cast_relu__72(buffer_59, buffer_60, buffer_5, buffer_4, buffer_3);
  res4f_conv_2_cast_mul_add_cast_add_relu__77(buffer_61, buffer_59, buffer_2, buffer_1, buffer_0, buffer_58);
  sc_aligned_free(__stream, __rescheduled_0);
}

static bool res4a_conv_b_cast_mul_add_cast__4(int8_t* __restrict__ __outs_0, int8_t* __restrict__ __ins_0, int8_t* __restrict__ __ins_1, float* __restrict__ __ins_2, float* __restrict__ __ins_3) noexcept{
  void*& __sc_kernel_cache_119 = *(void**)(__module_data + 64);
  alignas(64) int8_t __rescheduled_0[128UL];
  int8_t* input_tmp = (int8_t*)sc_aligned_malloc(__stream, 200704UL);
  for (uint64_t n_i = 0UL; n_i < 2UL; n_i += 1UL) {
    for (uint64_t c_o = 0UL; c_o < 8UL; c_o += 1UL) {
      for (uint64_t p = 0UL; p < 14UL; p += 1UL) {
        for (uint64_t q = 0UL; q < 14UL; q += 1UL) {
          vec_s8x64 __cached_0;
          __cached_0 = vec_s8x64::load(&__ins_0[((n_i * 401408UL) + ((c_o * 50176UL) + ((p * 3584UL) + (q * 128UL))))]);
          vec_s8x64 __cached_1;
          __cached_1 = __cached_0;
          vec_s8x64::store(__cached_1, &input_tmp[((n_i * 100352UL) + ((c_o * 12544UL) + ((p * 896UL) + (q * 64UL))))]);
        }
      }
    }
  }
  for (uint64_t fused_0fused_0k__n_3477__n_i_3478 = 0UL; fused_0fused_0k__n_3477__n_i_3478 < 32UL; fused_0fused_0k__n_3477__n_i_3478 += 1UL) {
    for (uint64_t p_o = 0UL; p_o < 7UL; p_o += 1UL) {
      int32_t* __origouts_2830_shr = (int32_t*)sc_aligned_malloc(__stream, 7168UL);
      void** A_list = (void**)&__rescheduled_0[0UL];
      void** B_list = (void**)&__rescheduled_0[64UL];
      for (uint64_t c = 0UL; c < 8UL; c += 1UL) {
        void* __cached_2;
        __cached_2 = &input_tmp[(((fused_0fused_0k__n_3477__n_i_3478 % 2UL) * 100352UL) + ((c * 12544UL) + (p_o * 1792UL)))];
        A_list[c] = __cached_2;
        void* __cached_3;
        __cached_3 = &__ins_1[(((fused_0fused_0k__n_3477__n_i_3478 / 2UL) * 32768UL) + (c * 4096UL))];
        B_list[c] = __cached_3;
      }
      void* _arg_cache_23 = &__origouts_2830_shr[0UL];
      dnnl_brgemm_list_call(__sc_kernel_cache_119, A_list, B_list, &__origouts_2830_shr[0UL], 1, 1, 1, 8, 7, 7, __stream);
      for (uint64_t _fuseiter11167 = 0UL; _fuseiter11167 < 2UL; _fuseiter11167 += 1UL) {
        for (uint64_t _fuseiter11168 = 0UL; _fuseiter11168 < 14UL; _fuseiter11168 += 1UL) {
          for (uint64_t _fuseiter11169 = 0UL; _fuseiter11169 < 64UL; _fuseiter11169 += 16UL) {
            vec_s32x16 __cached_4;
            __cached_4 = vec_s32x16::load(&__origouts_2830_shr[((_fuseiter11167 * 896UL) + ((_fuseiter11168 * 64UL) + _fuseiter11169))]);
            vec_f32x16 __cached_5;
            __cached_5 = (vec_f32x16)(__cached_4);
            vec_f32x16 __cached_6;
            __cached_6 = vec_f32x16::load(&__ins_2[(((fused_0fused_0k__n_3477__n_i_3478 / 2UL) * 64UL) + _fuseiter11169)]);
            __cached_5 = (__cached_5 * __cached_6);
            vec_f32x16 __cached_7;
            __cached_7 = vec_f32x16::load(&__ins_3[(((fused_0fused_0k__n_3477__n_i_3478 / 2UL) * 64UL) + _fuseiter11169)]);
            __cached_5 = (__cached_5 + __cached_7);
            vec_s8x16 __cached_8;
            __cached_8 = sc_saturated_cast<vec_s8x16>(sc_round_and_cast<vec_s32x16>(__cached_5));
            vec_s8x16::store(__cached_8, &__outs_0[((((fused_0fused_0k__n_3477__n_i_3478 % 2UL) * 200704UL) + (((fused_0fused_0k__n_3477__n_i_3478 / 2UL) * 12544UL) + (p_o * 1792UL))) + ((_fuseiter11167 * 896UL) + ((_fuseiter11168 * 64UL) + _fuseiter11169)))]);
          }
        }
      }
      sc_aligned_free(__stream, __origouts_2830_shr);
    }
  }
  sc_aligned_free(__stream, input_tmp);
  return true;
}

static bool res4a_conv_0_cast_mul_add_cast_relu__8(int8_t* __restrict__ __outs_0, int8_t* __restrict__ __ins_0, int8_t* __restrict__ __ins_1, float* __restrict__ __ins_2, float* __restrict__ __ins_3) noexcept{
  void*& __sc_kernel_cache_128 = *(void**)(__module_data + 96);
  alignas(64) int8_t __rescheduled_0[128UL];
  for (uint64_t n_i = 0UL; n_i < 2UL; n_i += 1UL) {
    for (uint64_t k = 0UL; k < 4UL; k += 1UL) {
      memset(&__outs_0[((n_i * 230400UL) + (k * 57600UL))], 0, 1920UL);
      for (uint64_t p1 = 0UL; p1 < 28UL; p1 += 1UL) {
        memset(&__outs_0[((n_i * 230400UL) + ((k * 57600UL) + ((p1 + 1UL) * 1920UL)))], 0, 64UL);
        memset(&__outs_0[(((n_i * 230400UL) + ((k * 57600UL) + ((p1 + 1UL) * 1920UL))) + 1856UL)], 0, 64UL);
      }
      memset(&__outs_0[(((n_i * 230400UL) + (k * 57600UL)) + 55680UL)], 0, 1920UL);
    }
  }
  for (uint64_t fused_0fused_0n__n_i_3479__k_3480 = 0UL; fused_0fused_0n__n_i_3479__k_3480 < 8UL; fused_0fused_0n__n_i_3479__k_3480 += 1UL) {
    for (uint64_t p_o = 0UL; p_o < 14UL; p_o += 1UL) {
      int32_t* __origouts_2840_shr = (int32_t*)sc_aligned_malloc(__stream, 14336UL);
      void** A_list = (void**)&__rescheduled_0[0UL];
      void** B_list = (void**)&__rescheduled_0[64UL];
      for (uint64_t c = 0UL; c < 8UL; c += 1UL) {
        void* __cached_0;
        __cached_0 = &__ins_0[(((fused_0fused_0n__n_i_3479__k_3480 / 8UL) * 802816UL) + ((((fused_0fused_0n__n_i_3479__k_3480 / 4UL) % 2UL) * 401408UL) + ((c * 50176UL) + (p_o * 3584UL))))];
        A_list[c] = __cached_0;
        void* __cached_1;
        __cached_1 = &__ins_1[(((fused_0fused_0n__n_i_3479__k_3480 % 4UL) * 32768UL) + (c * 4096UL))];
        B_list[c] = __cached_1;
      }
      void* _arg_cache_24 = &__origouts_2840_shr[0UL];
      dnnl_brgemm_list_call(__sc_kernel_cache_128, A_list, B_list, &__origouts_2840_shr[0UL], 1, 1, 1, 8, 7, 7, __stream);
      for (uint64_t _fuseiter11195 = 0UL; _fuseiter11195 < 2UL; _fuseiter11195 += 1UL) {
        for (uint64_t _fuseiter11196 = 0UL; _fuseiter11196 < 28UL; _fuseiter11196 += 1UL) {
          for (uint64_t _fuseiter11197 = 0UL; _fuseiter11197 < 64UL; _fuseiter11197 += 16UL) {
            vec_s32x16 __cached_2;
            __cached_2 = vec_s32x16::load(&__origouts_2840_shr[((_fuseiter11195 * 1792UL) + ((_fuseiter11196 * 64UL) + _fuseiter11197))]);
            vec_f32x16 __cached_3;
            __cached_3 = (vec_f32x16)(__cached_2);
            vec_f32x16 __cached_4;
            __cached_4 = vec_f32x16::load(&__ins_2[(((fused_0fused_0n__n_i_3479__k_3480 % 4UL) * 64UL) + _fuseiter11197)]);
            __cached_3 = (__cached_3 * __cached_4);
            vec_f32x16 __cached_5;
            __cached_5 = vec_f32x16::load(&__ins_3[(((fused_0fused_0n__n_i_3479__k_3480 % 4UL) * 64UL) + _fuseiter11197)]);
            __cached_3 = (__cached_3 + __cached_5);
            vec_s8x16 __cached_6;
            __cached_6 = sc_saturated_cast<vec_s8x16>(sc_round_and_cast<vec_s32x16>(__cached_3));
            vec_s8x16 __cached_7;
            __cached_7 = sc_max(__cached_6, vec_s8x16(0));
            vec_s8x16::store(__cached_7, &__outs_0[(((((fused_0fused_0n__n_i_3479__k_3480 / 8UL) * 460800UL) + ((((fused_0fused_0n__n_i_3479__k_3480 / 4UL) % 2UL) * 230400UL) + (((fused_0fused_0n__n_i_3479__k_3480 % 4UL) * 57600UL) + (((p_o * 2UL) + 1UL) * 1920UL)))) + 64UL) + ((_fuseiter11195 * 1920UL) + ((_fuseiter11196 * 64UL) + _fuseiter11197)))]);
          }
        }
      }
      sc_aligned_free(__stream, __origouts_2840_shr);
    }
  }
  return true;
}

static bool res4a_conv_1_cast_mul_add_cast_relu__12(int8_t* __restrict__ __outs_0, int8_t* __restrict__ __ins_0, int8_t* __restrict__ __ins_1, float* __restrict__ __ins_2, float* __restrict__ __ins_3) noexcept{
  void*& __sc_kernel_cache_130 = *(void**)(__module_data + 104);
  int8_t* __rescheduled_0 = (int8_t*)sc_aligned_malloc(__stream, 640UL);
  for (uint64_t fused_0fused_0n__n_i_3481__k_o_3482 = 0UL; fused_0fused_0n__n_i_3481__k_o_3482 < 8UL; fused_0fused_0n__n_i_3481__k_o_3482 += 1UL) {
    for (uint64_t p_o = 0UL; p_o < 7UL; p_o += 1UL) {
      void** A_list = (void**)&__rescheduled_0[0UL];
      void** B_list = (void**)&__rescheduled_0[320UL];
      for (uint64_t p_i = 0UL; p_i < 2UL; p_i += 1UL) {
        int32_t* __origouts_2850_shr = (int32_t*)sc_aligned_malloc(__stream, 3584UL);
        for (uint64_t c_o = 0UL; c_o < 4UL; c_o += 1UL) {
          for (uint64_t r = 0UL; r < 3UL; r += 1UL) {
            for (uint64_t s = 0UL; s < 3UL; s += 1UL) {
              void* __cached_0;
              __cached_0 = &__ins_0[(((fused_0fused_0n__n_i_3481__k_o_3482 / 8UL) * 460800UL) + ((((fused_0fused_0n__n_i_3481__k_o_3482 / 4UL) % 2UL) * 230400UL) + ((c_o * 57600UL) + ((((((p_o * 2UL) + p_i) * 2UL) + r) * 1920UL) + (s * 64UL)))))];
              A_list[(((c_o * 9UL) + (r * 3UL)) + s)] = __cached_0;
              void* __cached_1;
              __cached_1 = &__ins_1[(((fused_0fused_0n__n_i_3481__k_o_3482 % 4UL) * 147456UL) + ((c_o * 36864UL) + ((r * 12288UL) + (s * 4096UL))))];
              B_list[(((c_o * 9UL) + (r * 3UL)) + s)] = __cached_1;
            }
          }
        }
        void* _arg_cache_25 = &__origouts_2850_shr[0UL];
        dnnl_brgemm_list_call(__sc_kernel_cache_130, A_list, B_list, &__origouts_2850_shr[0UL], 1, 64, 4096, 36, 7, 7, __stream);
        for (uint64_t _fuseiter11231 = 0UL; _fuseiter11231 < 14UL; _fuseiter11231 += 1UL) {
          for (uint64_t _fuseiter11232 = 0UL; _fuseiter11232 < 64UL; _fuseiter11232 += 16UL) {
            vec_s32x16 __cached_2;
            __cached_2 = vec_s32x16::load(&__origouts_2850_shr[((_fuseiter11231 * 64UL) + _fuseiter11232)]);
            vec_f32x16 __cached_3;
            __cached_3 = (vec_f32x16)(__cached_2);
            vec_f32x16 __cached_4;
            __cached_4 = vec_f32x16::load(&__ins_2[(((fused_0fused_0n__n_i_3481__k_o_3482 % 4UL) * 64UL) + _fuseiter11232)]);
            __cached_3 = (__cached_3 * __cached_4);
            vec_f32x16 __cached_5;
            __cached_5 = vec_f32x16::load(&__ins_3[(((fused_0fused_0n__n_i_3481__k_o_3482 % 4UL) * 64UL) + _fuseiter11232)]);
            __cached_3 = (__cached_3 + __cached_5);
            vec_s8x16 __cached_6;
            __cached_6 = sc_saturated_cast<vec_s8x16>(sc_round_and_cast<vec_s32x16>(__cached_3));
            vec_s8x16 __cached_7;
            __cached_7 = sc_max(__cached_6, vec_s8x16(0));
            vec_s8x16::store(__cached_7, &__outs_0[((((fused_0fused_0n__n_i_3481__k_o_3482 / 8UL) * 100352UL) + ((((fused_0fused_0n__n_i_3481__k_o_3482 / 4UL) % 2UL) * 50176UL) + (((fused_0fused_0n__n_i_3481__k_o_3482 % 4UL) * 12544UL) + (((p_o * 2UL) + p_i) * 896UL)))) + ((_fuseiter11231 * 64UL) + _fuseiter11232))]);
          }
        }
        sc_aligned_free(__stream, __origouts_2850_shr);
      }
    }
  }
  sc_aligned_free(__stream, __rescheduled_0);
  return true;
}

static bool res4a_conv_2_cast_mul_add_cast_add_relu__16(int8_t* __restrict__ __outs_0, int8_t* __restrict__ __ins_0, int8_t* __restrict__ __ins_1, float* __restrict__ __ins_2, float* __restrict__ __ins_3, int8_t* __restrict__ __ins_4) noexcept{
  void*& __sc_kernel_cache_113 = *(void**)(__module_data + 40);
  alignas(64) int8_t __rescheduled_0[128UL];
  for (uint64_t fused_0fused_0k__n_3483__n_i_3484 = 0UL; fused_0fused_0k__n_3483__n_i_3484 < 32UL; fused_0fused_0k__n_3483__n_i_3484 += 1UL) {
    for (uint64_t p_o = 0UL; p_o < 7UL; p_o += 1UL) {
      int32_t* __origouts_2860_shr = (int32_t*)sc_aligned_malloc(__stream, 7168UL);
      void** A_list = (void**)&__rescheduled_0[0UL];
      void** B_list = (void**)&__rescheduled_0[64UL];
      for (uint64_t c = 0UL; c < 4UL; c += 1UL) {
        void* __cached_0;
        __cached_0 = &__ins_0[(((fused_0fused_0k__n_3483__n_i_3484 % 2UL) * 50176UL) + ((c * 12544UL) + (p_o * 1792UL)))];
        A_list[c] = __cached_0;
        void* __cached_1;
        __cached_1 = &__ins_1[(((fused_0fused_0k__n_3483__n_i_3484 / 2UL) * 16384UL) + (c * 4096UL))];
        B_list[c] = __cached_1;
      }
      void* _arg_cache_26 = &__origouts_2860_shr[0UL];
      dnnl_brgemm_list_call(__sc_kernel_cache_113, A_list, B_list, &__origouts_2860_shr[0UL], 1, 1, 1, 4, 7, 7, __stream);
      for (uint64_t _fuseiter11265 = 0UL; _fuseiter11265 < 2UL; _fuseiter11265 += 1UL) {
        for (uint64_t _fuseiter11266 = 0UL; _fuseiter11266 < 14UL; _fuseiter11266 += 1UL) {
          for (uint64_t _fuseiter11267 = 0UL; _fuseiter11267 < 64UL; _fuseiter11267 += 16UL) {
            vec_s32x16 __cached_2;
            __cached_2 = vec_s32x16::load(&__origouts_2860_shr[((_fuseiter11265 * 896UL) + ((_fuseiter11266 * 64UL) + _fuseiter11267))]);
            vec_f32x16 __cached_3;
            __cached_3 = (vec_f32x16)(__cached_2);
            vec_f32x16 __cached_4;
            __cached_4 = vec_f32x16::load(&__ins_2[(((fused_0fused_0k__n_3483__n_i_3484 / 2UL) * 64UL) + _fuseiter11267)]);
            __cached_3 = (__cached_3 * __cached_4);
            vec_f32x16 __cached_5;
            __cached_5 = vec_f32x16::load(&__ins_3[(((fused_0fused_0k__n_3483__n_i_3484 / 2UL) * 64UL) + _fuseiter11267)]);
            __cached_3 = (__cached_3 + __cached_5);
            vec_s8x16 __cached_6;
            __cached_6 = sc_saturated_cast<vec_s8x16>(sc_round_and_cast<vec_s32x16>(__cached_3));
            vec_s8x16 __cached_7;
            __cached_7 = vec_s8x16::load(&__ins_4[((((fused_0fused_0k__n_3483__n_i_3484 % 2UL) * 200704UL) + (((fused_0fused_0k__n_3483__n_i_3484 / 2UL) * 12544UL) + (p_o * 1792UL))) + ((_fuseiter11265 * 896UL) + ((_fuseiter11266 * 64UL) + _fuseiter11267)))]);
            __cached_6 = (__cached_6 + __cached_7);
            vec_s8x16 __cached_8;
            __cached_8 = sc_max(__cached_6, vec_s8x16(0));
            vec_s8x16::store(__cached_8, &__outs_0[((((fused_0fused_0k__n_3483__n_i_3484 % 2UL) * 200704UL) + (((fused_0fused_0k__n_3483__n_i_3484 / 2UL) * 12544UL) + (p_o * 1792UL))) + ((_fuseiter11265 * 896UL) + ((_fuseiter11266 * 64UL) + _fuseiter11267)))]);
          }
        }
      }
      sc_aligned_free(__stream, __origouts_2860_shr);
    }
  }
  return true;
}

static bool res4b_conv_0_cast_mul_add_cast_relu__20(int8_t* __restrict__ __outs_0, int8_t* __restrict__ __ins_0, int8_t* __restrict__ __ins_1, float* __restrict__ __ins_2, float* __restrict__ __ins_3) noexcept{
  void*& __sc_kernel_cache_132 = *(void**)(__module_data + 112);
  int8_t* __rescheduled_0 = (int8_t*)sc_aligned_malloc(__stream, 256UL);
  for (uint64_t n_i = 0UL; n_i < 2UL; n_i += 1UL) {
    for (uint64_t k = 0UL; k < 4UL; k += 1UL) {
      memset(&__outs_0[((n_i * 65536UL) + (k * 16384UL))], 0, 1024UL);
      for (uint64_t p1 = 0UL; p1 < 14UL; p1 += 1UL) {
        memset(&__outs_0[((n_i * 65536UL) + ((k * 16384UL) + ((p1 + 1UL) * 1024UL)))], 0, 64UL);
        memset(&__outs_0[(((n_i * 65536UL) + ((k * 16384UL) + ((p1 + 1UL) * 1024UL))) + 960UL)], 0, 64UL);
      }
      memset(&__outs_0[(((n_i * 65536UL) + (k * 16384UL)) + 15360UL)], 0, 1024UL);
    }
  }
  for (uint64_t fused_0fused_0n__n_i_3485__k_3486 = 0UL; fused_0fused_0n__n_i_3485__k_3486 < 8UL; fused_0fused_0n__n_i_3485__k_3486 += 1UL) {
    for (uint64_t p_o = 0UL; p_o < 7UL; p_o += 1UL) {
      int32_t* __origouts_2870_shr = (int32_t*)sc_aligned_malloc(__stream, 7168UL);
      void** A_list = (void**)&__rescheduled_0[0UL];
      void** B_list = (void**)&__rescheduled_0[128UL];
      for (uint64_t c = 0UL; c < 16UL; c += 1UL) {
        void* __cached_0;
        __cached_0 = &__ins_0[(((fused_0fused_0n__n_i_3485__k_3486 / 8UL) * 401408UL) + ((((fused_0fused_0n__n_i_3485__k_3486 / 4UL) % 2UL) * 200704UL) + ((c * 12544UL) + (p_o * 1792UL))))];
        A_list[c] = __cached_0;
        void* __cached_1;
        __cached_1 = &__ins_1[(((fused_0fused_0n__n_i_3485__k_3486 % 4UL) * 65536UL) + (c * 4096UL))];
        B_list[c] = __cached_1;
      }
      void* _arg_cache_27 = &__origouts_2870_shr[0UL];
      dnnl_brgemm_list_call(__sc_kernel_cache_132, A_list, B_list, &__origouts_2870_shr[0UL], 1, 1, 1, 16, 7, 7, __stream);
      for (uint64_t _fuseiter11307 = 0UL; _fuseiter11307 < 2UL; _fuseiter11307 += 1UL) {
        for (uint64_t _fuseiter11308 = 0UL; _fuseiter11308 < 14UL; _fuseiter11308 += 1UL) {
          for (uint64_t _fuseiter11309 = 0UL; _fuseiter11309 < 64UL; _fuseiter11309 += 16UL) {
            vec_s32x16 __cached_2;
            __cached_2 = vec_s32x16::load(&__origouts_2870_shr[((_fuseiter11307 * 896UL) + ((_fuseiter11308 * 64UL) + _fuseiter11309))]);
            vec_f32x16 __cached_3;
            __cached_3 = (vec_f32x16)(__cached_2);
            vec_f32x16 __cached_4;
            __cached_4 = vec_f32x16::load(&__ins_2[(((fused_0fused_0n__n_i_3485__k_3486 % 4UL) * 64UL) + _fuseiter11309)]);
            __cached_3 = (__cached_3 * __cached_4);
            vec_f32x16 __cached_5;
            __cached_5 = vec_f32x16::load(&__ins_3[(((fused_0fused_0n__n_i_3485__k_3486 % 4UL) * 64UL) + _fuseiter11309)]);
            __cached_3 = (__cached_3 + __cached_5);
            vec_s8x16 __cached_6;
            __cached_6 = sc_saturated_cast<vec_s8x16>(sc_round_and_cast<vec_s32x16>(__cached_3));
            vec_s8x16 __cached_7;
            __cached_7 = sc_max(__cached_6, vec_s8x16(0));
            vec_s8x16::store(__cached_7, &__outs_0[(((((fused_0fused_0n__n_i_3485__k_3486 / 8UL) * 131072UL) + ((((fused_0fused_0n__n_i_3485__k_3486 / 4UL) % 2UL) * 65536UL) + (((fused_0fused_0n__n_i_3485__k_3486 % 4UL) * 16384UL) + (((p_o * 2UL) + 1UL) * 1024UL)))) + 64UL) + ((_fuseiter11307 * 1024UL) + ((_fuseiter11308 * 64UL) + _fuseiter11309)))]);
          }
        }
      }
      sc_aligned_free(__stream, __origouts_2870_shr);
    }
  }
  sc_aligned_free(__stream, __rescheduled_0);
  return true;
}

static bool res4b_conv_1_cast_mul_add_cast_relu__24(int8_t* __restrict__ __outs_0, int8_t* __restrict__ __ins_0, int8_t* __restrict__ __ins_1, float* __restrict__ __ins_2, float* __restrict__ __ins_3) noexcept{
  void** __sc_kernel_cache_arr_136 = (void**)&__uninitialized_data[23657512UL];
  int8_t* __rescheduled_0 = (int8_t*)sc_aligned_malloc(__stream, 640UL);
  int32_t __cached_0;
  __cached_0 = 0;
  for (uint64_t fused_0fused_0n__n_i_3487__k_o_3488 = 0UL; fused_0fused_0n__n_i_3487__k_o_3488 < 8UL; fused_0fused_0n__n_i_3487__k_o_3488 += 1UL) {
    int32_t* __origouts_2880_shr = (int32_t*)sc_aligned_malloc(__stream, 50176UL);
    void** A_list = (void**)&__rescheduled_0[0UL];
    void** B_list = (void**)&__rescheduled_0[320UL];
    for (uint64_t c_o = 0UL; c_o < 4UL; c_o += 1UL) {
      for (uint64_t r = 0UL; r < 3UL; r += 1UL) {
        for (uint64_t s = 0UL; s < 3UL; s += 1UL) {
          void* __cached_1;
          __cached_1 = &__ins_0[(((fused_0fused_0n__n_i_3487__k_o_3488 / 8UL) * 131072UL) + ((((fused_0fused_0n__n_i_3487__k_o_3488 / 4UL) % 2UL) * 65536UL) + ((c_o * 16384UL) + ((r * 1024UL) + (s * 64UL)))))];
          A_list[(((c_o * 9UL) + (r * 3UL)) + s)] = __cached_1;
          void* __cached_2;
          __cached_2 = &__ins_1[(((fused_0fused_0n__n_i_3487__k_o_3488 % 4UL) * 147456UL) + ((c_o * 36864UL) + ((r * 12288UL) + (s * 4096UL))))];
          B_list[(((c_o * 9UL) + (r * 3UL)) + s)] = __cached_2;
        }
      }
    }
    void* _arg_cache_28 = &__origouts_2880_shr[0UL];
    dnnl_brgemm_list_call(__sc_kernel_cache_arr_136[0UL], A_list, B_list, &__origouts_2880_shr[0UL], 1, 64, 4096, 36, 7, 7, __stream);
    for (uint64_t _fuseiter11342 = 0UL; _fuseiter11342 < 14UL; _fuseiter11342 += 1UL) {
      for (uint64_t _fuseiter11343 = 0UL; _fuseiter11343 < 14UL; _fuseiter11343 += 1UL) {
        for (uint64_t _fuseiter11344 = 0UL; _fuseiter11344 < 64UL; _fuseiter11344 += 16UL) {
          vec_s32x16 __cached_3;
          __cached_3 = vec_s32x16::load(&__origouts_2880_shr[((_fuseiter11342 * 896UL) + ((_fuseiter11343 * 64UL) + _fuseiter11344))]);
          vec_f32x16 __cached_4;
          __cached_4 = (vec_f32x16)(__cached_3);
          vec_f32x16 __cached_5;
          __cached_5 = vec_f32x16::load(&__ins_2[(((fused_0fused_0n__n_i_3487__k_o_3488 % 4UL) * 64UL) + _fuseiter11344)]);
          __cached_4 = (__cached_4 * __cached_5);
          vec_f32x16 __cached_6;
          __cached_6 = vec_f32x16::load(&__ins_3[(((fused_0fused_0n__n_i_3487__k_o_3488 % 4UL) * 64UL) + _fuseiter11344)]);
          __cached_4 = (__cached_4 + __cached_6);
          vec_s8x16 __cached_7;
          __cached_7 = sc_saturated_cast<vec_s8x16>(sc_round_and_cast<vec_s32x16>(__cached_4));
          vec_s8x16 __cached_8;
          __cached_8 = sc_max(__cached_7, vec_s8x16(0));
          vec_s8x16::store(__cached_8, &__outs_0[(((fused_0fused_0n__n_i_3487__k_o_3488 / 8UL) * 100352UL) + ((((fused_0fused_0n__n_i_3487__k_o_3488 / 4UL) % 2UL) * 50176UL) + (((fused_0fused_0n__n_i_3487__k_o_3488 % 4UL) * 12544UL) + ((_fuseiter11342 * 896UL) + ((_fuseiter11343 * 64UL) + _fuseiter11344)))))]);
        }
      }
    }
    sc_aligned_free(__stream, __origouts_2880_shr);
  }
  sc_aligned_free(__stream, __rescheduled_0);
  return true;
}

static bool res4b_conv_2_cast_mul_add_cast_add_relu__28(int8_t* __restrict__ __outs_0, int8_t* __restrict__ __ins_0, int8_t* __restrict__ __ins_1, float* __restrict__ __ins_2, float* __restrict__ __ins_3, int8_t* __restrict__ __ins_4) noexcept{
  void*& __sc_kernel_cache_113 = *(void**)(__module_data + 40);
  alignas(64) int8_t __rescheduled_0[128UL];
  for (uint64_t fused_0fused_0n__n_i_3489__k_3490 = 0UL; fused_0fused_0n__n_i_3489__k_3490 < 32UL; fused_0fused_0n__n_i_3489__k_3490 += 1UL) {
    for (uint64_t p_o = 0UL; p_o < 7UL; p_o += 1UL) {
      int32_t* __origouts_2890_shr = (int32_t*)sc_aligned_malloc(__stream, 7168UL);
      void** A_list = (void**)&__rescheduled_0[0UL];
      void** B_list = (void**)&__rescheduled_0[64UL];
      for (uint64_t c = 0UL; c < 4UL; c += 1UL) {
        void* __cached_0;
        __cached_0 = &__ins_0[(((fused_0fused_0n__n_i_3489__k_3490 / 32UL) * 100352UL) + ((((fused_0fused_0n__n_i_3489__k_3490 / 16UL) % 2UL) * 50176UL) + ((c * 12544UL) + (p_o * 1792UL))))];
        A_list[c] = __cached_0;
        void* __cached_1;
        __cached_1 = &__ins_1[(((fused_0fused_0n__n_i_3489__k_3490 % 16UL) * 16384UL) + (c * 4096UL))];
        B_list[c] = __cached_1;
      }
      void* _arg_cache_29 = &__origouts_2890_shr[0UL];
      dnnl_brgemm_list_call(__sc_kernel_cache_113, A_list, B_list, &__origouts_2890_shr[0UL], 1, 1, 1, 4, 7, 7, __stream);
      for (uint64_t _fuseiter11377 = 0UL; _fuseiter11377 < 2UL; _fuseiter11377 += 1UL) {
        for (uint64_t _fuseiter11378 = 0UL; _fuseiter11378 < 14UL; _fuseiter11378 += 1UL) {
          for (uint64_t _fuseiter11379 = 0UL; _fuseiter11379 < 64UL; _fuseiter11379 += 16UL) {
            vec_s32x16 __cached_2;
            __cached_2 = vec_s32x16::load(&__origouts_2890_shr[((_fuseiter11377 * 896UL) + ((_fuseiter11378 * 64UL) + _fuseiter11379))]);
            vec_f32x16 __cached_3;
            __cached_3 = (vec_f32x16)(__cached_2);
            vec_f32x16 __cached_4;
            __cached_4 = vec_f32x16::load(&__ins_2[(((fused_0fused_0n__n_i_3489__k_3490 % 16UL) * 64UL) + _fuseiter11379)]);
            __cached_3 = (__cached_3 * __cached_4);
            vec_f32x16 __cached_5;
            __cached_5 = vec_f32x16::load(&__ins_3[(((fused_0fused_0n__n_i_3489__k_3490 % 16UL) * 64UL) + _fuseiter11379)]);
            __cached_3 = (__cached_3 + __cached_5);
            vec_s8x16 __cached_6;
            __cached_6 = sc_saturated_cast<vec_s8x16>(sc_round_and_cast<vec_s32x16>(__cached_3));
            vec_s8x16 __cached_7;
            __cached_7 = vec_s8x16::load(&__ins_4[((((fused_0fused_0n__n_i_3489__k_3490 / 32UL) * 401408UL) + ((((fused_0fused_0n__n_i_3489__k_3490 / 16UL) % 2UL) * 200704UL) + (((fused_0fused_0n__n_i_3489__k_3490 % 16UL) * 12544UL) + (p_o * 1792UL)))) + ((_fuseiter11377 * 896UL) + ((_fuseiter11378 * 64UL) + _fuseiter11379)))]);
            __cached_6 = (__cached_6 + __cached_7);
            vec_s8x16 __cached_8;
            __cached_8 = sc_max(__cached_6, vec_s8x16(0));
            vec_s8x16::store(__cached_8, &__outs_0[((((fused_0fused_0n__n_i_3489__k_3490 / 32UL) * 401408UL) + ((((fused_0fused_0n__n_i_3489__k_3490 / 16UL) % 2UL) * 200704UL) + (((fused_0fused_0n__n_i_3489__k_3490 % 16UL) * 12544UL) + (p_o * 1792UL)))) + ((_fuseiter11377 * 896UL) + ((_fuseiter11378 * 64UL) + _fuseiter11379)))]);
          }
        }
      }
      sc_aligned_free(__stream, __origouts_2890_shr);
    }
  }
  return true;
}

static bool res4c_conv_0_cast_mul_add_cast_relu__32(int8_t* __restrict__ __outs_0, int8_t* __restrict__ __ins_0, int8_t* __restrict__ __ins_1, float* __restrict__ __ins_2, float* __restrict__ __ins_3) noexcept{
  void*& __sc_kernel_cache_132 = *(void**)(__module_data + 112);
  int8_t* __rescheduled_0 = (int8_t*)sc_aligned_malloc(__stream, 256UL);
  for (uint64_t n_i = 0UL; n_i < 2UL; n_i += 1UL) {
    for (uint64_t k = 0UL; k < 4UL; k += 1UL) {
      memset(&__outs_0[((n_i * 65536UL) + (k * 16384UL))], 0, 1024UL);
      for (uint64_t p1 = 0UL; p1 < 14UL; p1 += 1UL) {
        memset(&__outs_0[((n_i * 65536UL) + ((k * 16384UL) + ((p1 + 1UL) * 1024UL)))], 0, 64UL);
        memset(&__outs_0[(((n_i * 65536UL) + ((k * 16384UL) + ((p1 + 1UL) * 1024UL))) + 960UL)], 0, 64UL);
      }
      memset(&__outs_0[(((n_i * 65536UL) + (k * 16384UL)) + 15360UL)], 0, 1024UL);
    }
  }
  for (uint64_t fused_0fused_0n__n_i_3491__k_3492 = 0UL; fused_0fused_0n__n_i_3491__k_3492 < 8UL; fused_0fused_0n__n_i_3491__k_3492 += 1UL) {
    for (uint64_t p_o = 0UL; p_o < 7UL; p_o += 1UL) {
      int32_t* __origouts_2900_shr = (int32_t*)sc_aligned_malloc(__stream, 7168UL);
      void** A_list = (void**)&__rescheduled_0[0UL];
      void** B_list = (void**)&__rescheduled_0[128UL];
      for (uint64_t c = 0UL; c < 16UL; c += 1UL) {
        void* __cached_0;
        __cached_0 = &__ins_0[(((fused_0fused_0n__n_i_3491__k_3492 / 8UL) * 401408UL) + ((((fused_0fused_0n__n_i_3491__k_3492 / 4UL) % 2UL) * 200704UL) + ((c * 12544UL) + (p_o * 1792UL))))];
        A_list[c] = __cached_0;
        void* __cached_1;
        __cached_1 = &__ins_1[(((fused_0fused_0n__n_i_3491__k_3492 % 4UL) * 65536UL) + (c * 4096UL))];
        B_list[c] = __cached_1;
      }
      void* _arg_cache_30 = &__origouts_2900_shr[0UL];
      dnnl_brgemm_list_call(__sc_kernel_cache_132, A_list, B_list, &__origouts_2900_shr[0UL], 1, 1, 1, 16, 7, 7, __stream);
      for (uint64_t _fuseiter11419 = 0UL; _fuseiter11419 < 2UL; _fuseiter11419 += 1UL) {
        for (uint64_t _fuseiter11420 = 0UL; _fuseiter11420 < 14UL; _fuseiter11420 += 1UL) {
          for (uint64_t _fuseiter11421 = 0UL; _fuseiter11421 < 64UL; _fuseiter11421 += 16UL) {
            vec_s32x16 __cached_2;
            __cached_2 = vec_s32x16::load(&__origouts_2900_shr[((_fuseiter11419 * 896UL) + ((_fuseiter11420 * 64UL) + _fuseiter11421))]);
            vec_f32x16 __cached_3;
            __cached_3 = (vec_f32x16)(__cached_2);
            vec_f32x16 __cached_4;
            __cached_4 = vec_f32x16::load(&__ins_2[(((fused_0fused_0n__n_i_3491__k_3492 % 4UL) * 64UL) + _fuseiter11421)]);
            __cached_3 = (__cached_3 * __cached_4);
            vec_f32x16 __cached_5;
            __cached_5 = vec_f32x16::load(&__ins_3[(((fused_0fused_0n__n_i_3491__k_3492 % 4UL) * 64UL) + _fuseiter11421)]);
            __cached_3 = (__cached_3 + __cached_5);
            vec_s8x16 __cached_6;
            __cached_6 = sc_saturated_cast<vec_s8x16>(sc_round_and_cast<vec_s32x16>(__cached_3));
            vec_s8x16 __cached_7;
            __cached_7 = sc_max(__cached_6, vec_s8x16(0));
            vec_s8x16::store(__cached_7, &__outs_0[(((((fused_0fused_0n__n_i_3491__k_3492 / 8UL) * 131072UL) + ((((fused_0fused_0n__n_i_3491__k_3492 / 4UL) % 2UL) * 65536UL) + (((fused_0fused_0n__n_i_3491__k_3492 % 4UL) * 16384UL) + (((p_o * 2UL) + 1UL) * 1024UL)))) + 64UL) + ((_fuseiter11419 * 1024UL) + ((_fuseiter11420 * 64UL) + _fuseiter11421)))]);
          }
        }
      }
      sc_aligned_free(__stream, __origouts_2900_shr);
    }
  }
  sc_aligned_free(__stream, __rescheduled_0);
  return true;
}

static bool res4c_conv_1_cast_mul_add_cast_relu__36(int8_t* __restrict__ __outs_0, int8_t* __restrict__ __ins_0, int8_t* __restrict__ __ins_1, float* __restrict__ __ins_2, float* __restrict__ __ins_3) noexcept{
  void** __sc_kernel_cache_arr_136 = (void**)&__uninitialized_data[23657512UL];
  int8_t* __rescheduled_0 = (int8_t*)sc_aligned_malloc(__stream, 640UL);
  int32_t __cached_0;
  __cached_0 = 0;
  for (uint64_t fused_0fused_0n__n_i_3493__k_o_3494 = 0UL; fused_0fused_0n__n_i_3493__k_o_3494 < 8UL; fused_0fused_0n__n_i_3493__k_o_3494 += 1UL) {
    int32_t* __origouts_2910_shr = (int32_t*)sc_aligned_malloc(__stream, 50176UL);
    void** A_list = (void**)&__rescheduled_0[0UL];
    void** B_list = (void**)&__rescheduled_0[320UL];
    for (uint64_t c_o = 0UL; c_o < 4UL; c_o += 1UL) {
      for (uint64_t r = 0UL; r < 3UL; r += 1UL) {
        for (uint64_t s = 0UL; s < 3UL; s += 1UL) {
          void* __cached_1;
          __cached_1 = &__ins_0[(((fused_0fused_0n__n_i_3493__k_o_3494 / 8UL) * 131072UL) + ((((fused_0fused_0n__n_i_3493__k_o_3494 / 4UL) % 2UL) * 65536UL) + ((c_o * 16384UL) + ((r * 1024UL) + (s * 64UL)))))];
          A_list[(((c_o * 9UL) + (r * 3UL)) + s)] = __cached_1;
          void* __cached_2;
          __cached_2 = &__ins_1[(((fused_0fused_0n__n_i_3493__k_o_3494 % 4UL) * 147456UL) + ((c_o * 36864UL) + ((r * 12288UL) + (s * 4096UL))))];
          B_list[(((c_o * 9UL) + (r * 3UL)) + s)] = __cached_2;
        }
      }
    }
    void* _arg_cache_31 = &__origouts_2910_shr[0UL];
    dnnl_brgemm_list_call(__sc_kernel_cache_arr_136[0UL], A_list, B_list, &__origouts_2910_shr[0UL], 1, 64, 4096, 36, 7, 7, __stream);
    for (uint64_t _fuseiter11454 = 0UL; _fuseiter11454 < 14UL; _fuseiter11454 += 1UL) {
      for (uint64_t _fuseiter11455 = 0UL; _fuseiter11455 < 14UL; _fuseiter11455 += 1UL) {
        for (uint64_t _fuseiter11456 = 0UL; _fuseiter11456 < 64UL; _fuseiter11456 += 16UL) {
          vec_s32x16 __cached_3;
          __cached_3 = vec_s32x16::load(&__origouts_2910_shr[((_fuseiter11454 * 896UL) + ((_fuseiter11455 * 64UL) + _fuseiter11456))]);
          vec_f32x16 __cached_4;
          __cached_4 = (vec_f32x16)(__cached_3);
          vec_f32x16 __cached_5;
          __cached_5 = vec_f32x16::load(&__ins_2[(((fused_0fused_0n__n_i_3493__k_o_3494 % 4UL) * 64UL) + _fuseiter11456)]);
          __cached_4 = (__cached_4 * __cached_5);
          vec_f32x16 __cached_6;
          __cached_6 = vec_f32x16::load(&__ins_3[(((fused_0fused_0n__n_i_3493__k_o_3494 % 4UL) * 64UL) + _fuseiter11456)]);
          __cached_4 = (__cached_4 + __cached_6);
          vec_s8x16 __cached_7;
          __cached_7 = sc_saturated_cast<vec_s8x16>(sc_round_and_cast<vec_s32x16>(__cached_4));
          vec_s8x16 __cached_8;
          __cached_8 = sc_max(__cached_7, vec_s8x16(0));
          vec_s8x16::store(__cached_8, &__outs_0[(((fused_0fused_0n__n_i_3493__k_o_3494 / 8UL) * 100352UL) + ((((fused_0fused_0n__n_i_3493__k_o_3494 / 4UL) % 2UL) * 50176UL) + (((fused_0fused_0n__n_i_3493__k_o_3494 % 4UL) * 12544UL) + ((_fuseiter11454 * 896UL) + ((_fuseiter11455 * 64UL) + _fuseiter11456)))))]);
        }
      }
    }
    sc_aligned_free(__stream, __origouts_2910_shr);
  }
  sc_aligned_free(__stream, __rescheduled_0);
  return true;
}

static bool res4c_conv_2_cast_mul_add_cast_add_relu__40(int8_t* __restrict__ __outs_0, int8_t* __restrict__ __ins_0, int8_t* __restrict__ __ins_1, float* __restrict__ __ins_2, float* __restrict__ __ins_3, int8_t* __restrict__ __ins_4) noexcept{
  void*& __sc_kernel_cache_113 = *(void**)(__module_data + 40);
  alignas(64) int8_t __rescheduled_0[128UL];
  for (uint64_t fused_0fused_0n__n_i_3495__k_3496 = 0UL; fused_0fused_0n__n_i_3495__k_3496 < 32UL; fused_0fused_0n__n_i_3495__k_3496 += 1UL) {
    for (uint64_t p_o = 0UL; p_o < 7UL; p_o += 1UL) {
      int32_t* __origouts_2920_shr = (int32_t*)sc_aligned_malloc(__stream, 7168UL);
      void** A_list = (void**)&__rescheduled_0[0UL];
      void** B_list = (void**)&__rescheduled_0[64UL];
      for (uint64_t c = 0UL; c < 4UL; c += 1UL) {
        void* __cached_0;
        __cached_0 = &__ins_0[(((fused_0fused_0n__n_i_3495__k_3496 / 32UL) * 100352UL) + ((((fused_0fused_0n__n_i_3495__k_3496 / 16UL) % 2UL) * 50176UL) + ((c * 12544UL) + (p_o * 1792UL))))];
        A_list[c] = __cached_0;
        void* __cached_1;
        __cached_1 = &__ins_1[(((fused_0fused_0n__n_i_3495__k_3496 % 16UL) * 16384UL) + (c * 4096UL))];
        B_list[c] = __cached_1;
      }
      void* _arg_cache_32 = &__origouts_2920_shr[0UL];
      dnnl_brgemm_list_call(__sc_kernel_cache_113, A_list, B_list, &__origouts_2920_shr[0UL], 1, 1, 1, 4, 7, 7, __stream);
      for (uint64_t _fuseiter11489 = 0UL; _fuseiter11489 < 2UL; _fuseiter11489 += 1UL) {
        for (uint64_t _fuseiter11490 = 0UL; _fuseiter11490 < 14UL; _fuseiter11490 += 1UL) {
          for (uint64_t _fuseiter11491 = 0UL; _fuseiter11491 < 64UL; _fuseiter11491 += 16UL) {
            vec_s32x16 __cached_2;
            __cached_2 = vec_s32x16::load(&__origouts_2920_shr[((_fuseiter11489 * 896UL) + ((_fuseiter11490 * 64UL) + _fuseiter11491))]);
            vec_f32x16 __cached_3;
            __cached_3 = (vec_f32x16)(__cached_2);
            vec_f32x16 __cached_4;
            __cached_4 = vec_f32x16::load(&__ins_2[(((fused_0fused_0n__n_i_3495__k_3496 % 16UL) * 64UL) + _fuseiter11491)]);
            __cached_3 = (__cached_3 * __cached_4);
            vec_f32x16 __cached_5;
            __cached_5 = vec_f32x16::load(&__ins_3[(((fused_0fused_0n__n_i_3495__k_3496 % 16UL) * 64UL) + _fuseiter11491)]);
            __cached_3 = (__cached_3 + __cached_5);
            vec_s8x16 __cached_6;
            __cached_6 = sc_saturated_cast<vec_s8x16>(sc_round_and_cast<vec_s32x16>(__cached_3));
            vec_s8x16 __cached_7;
            __cached_7 = vec_s8x16::load(&__ins_4[((((fused_0fused_0n__n_i_3495__k_3496 / 32UL) * 401408UL) + ((((fused_0fused_0n__n_i_3495__k_3496 / 16UL) % 2UL) * 200704UL) + (((fused_0fused_0n__n_i_3495__k_3496 % 16UL) * 12544UL) + (p_o * 1792UL)))) + ((_fuseiter11489 * 896UL) + ((_fuseiter11490 * 64UL) + _fuseiter11491)))]);
            __cached_6 = (__cached_6 + __cached_7);
            vec_s8x16 __cached_8;
            __cached_8 = sc_max(__cached_6, vec_s8x16(0));
            vec_s8x16::store(__cached_8, &__outs_0[((((fused_0fused_0n__n_i_3495__k_3496 / 32UL) * 401408UL) + ((((fused_0fused_0n__n_i_3495__k_3496 / 16UL) % 2UL) * 200704UL) + (((fused_0fused_0n__n_i_3495__k_3496 % 16UL) * 12544UL) + (p_o * 1792UL)))) + ((_fuseiter11489 * 896UL) + ((_fuseiter11490 * 64UL) + _fuseiter11491)))]);
          }
        }
      }
      sc_aligned_free(__stream, __origouts_2920_shr);
    }
  }
  return true;
}

static bool res4d_conv_0_cast_mul_add_cast_relu__44(int8_t* __restrict__ __outs_0, int8_t* __restrict__ __ins_0, int8_t* __restrict__ __ins_1, float* __restrict__ __ins_2, float* __restrict__ __ins_3) noexcept{
  void*& __sc_kernel_cache_132 = *(void**)(__module_data + 112);
  int8_t* __rescheduled_0 = (int8_t*)sc_aligned_malloc(__stream, 256UL);
  for (uint64_t n_i = 0UL; n_i < 2UL; n_i += 1UL) {
    for (uint64_t k = 0UL; k < 4UL; k += 1UL) {
      memset(&__outs_0[((n_i * 65536UL) + (k * 16384UL))], 0, 1024UL);
      for (uint64_t p1 = 0UL; p1 < 14UL; p1 += 1UL) {
        memset(&__outs_0[((n_i * 65536UL) + ((k * 16384UL) + ((p1 + 1UL) * 1024UL)))], 0, 64UL);
        memset(&__outs_0[(((n_i * 65536UL) + ((k * 16384UL) + ((p1 + 1UL) * 1024UL))) + 960UL)], 0, 64UL);
      }
      memset(&__outs_0[(((n_i * 65536UL) + (k * 16384UL)) + 15360UL)], 0, 1024UL);
    }
  }
  for (uint64_t fused_0fused_0n__n_i_3497__k_3498 = 0UL; fused_0fused_0n__n_i_3497__k_3498 < 8UL; fused_0fused_0n__n_i_3497__k_3498 += 1UL) {
    for (uint64_t p_o = 0UL; p_o < 7UL; p_o += 1UL) {
      int32_t* __origouts_2930_shr = (int32_t*)sc_aligned_malloc(__stream, 7168UL);
      void** A_list = (void**)&__rescheduled_0[0UL];
      void** B_list = (void**)&__rescheduled_0[128UL];
      for (uint64_t c = 0UL; c < 16UL; c += 1UL) {
        void* __cached_0;
        __cached_0 = &__ins_0[(((fused_0fused_0n__n_i_3497__k_3498 / 8UL) * 401408UL) + ((((fused_0fused_0n__n_i_3497__k_3498 / 4UL) % 2UL) * 200704UL) + ((c * 12544UL) + (p_o * 1792UL))))];
        A_list[c] = __cached_0;
        void* __cached_1;
        __cached_1 = &__ins_1[(((fused_0fused_0n__n_i_3497__k_3498 % 4UL) * 65536UL) + (c * 4096UL))];
        B_list[c] = __cached_1;
      }
      void* _arg_cache_33 = &__origouts_2930_shr[0UL];
      dnnl_brgemm_list_call(__sc_kernel_cache_132, A_list, B_list, &__origouts_2930_shr[0UL], 1, 1, 1, 16, 7, 7, __stream);
      for (uint64_t _fuseiter11531 = 0UL; _fuseiter11531 < 2UL; _fuseiter11531 += 1UL) {
        for (uint64_t _fuseiter11532 = 0UL; _fuseiter11532 < 14UL; _fuseiter11532 += 1UL) {
          for (uint64_t _fuseiter11533 = 0UL; _fuseiter11533 < 64UL; _fuseiter11533 += 16UL) {
            vec_s32x16 __cached_2;
            __cached_2 = vec_s32x16::load(&__origouts_2930_shr[((_fuseiter11531 * 896UL) + ((_fuseiter11532 * 64UL) + _fuseiter11533))]);
            vec_f32x16 __cached_3;
            __cached_3 = (vec_f32x16)(__cached_2);
            vec_f32x16 __cached_4;
            __cached_4 = vec_f32x16::load(&__ins_2[(((fused_0fused_0n__n_i_3497__k_3498 % 4UL) * 64UL) + _fuseiter11533)]);
            __cached_3 = (__cached_3 * __cached_4);
            vec_f32x16 __cached_5;
            __cached_5 = vec_f32x16::load(&__ins_3[(((fused_0fused_0n__n_i_3497__k_3498 % 4UL) * 64UL) + _fuseiter11533)]);
            __cached_3 = (__cached_3 + __cached_5);
            vec_s8x16 __cached_6;
            __cached_6 = sc_saturated_cast<vec_s8x16>(sc_round_and_cast<vec_s32x16>(__cached_3));
            vec_s8x16 __cached_7;
            __cached_7 = sc_max(__cached_6, vec_s8x16(0));
            vec_s8x16::store(__cached_7, &__outs_0[(((((fused_0fused_0n__n_i_3497__k_3498 / 8UL) * 131072UL) + ((((fused_0fused_0n__n_i_3497__k_3498 / 4UL) % 2UL) * 65536UL) + (((fused_0fused_0n__n_i_3497__k_3498 % 4UL) * 16384UL) + (((p_o * 2UL) + 1UL) * 1024UL)))) + 64UL) + ((_fuseiter11531 * 1024UL) + ((_fuseiter11532 * 64UL) + _fuseiter11533)))]);
          }
        }
      }
      sc_aligned_free(__stream, __origouts_2930_shr);
    }
  }
  sc_aligned_free(__stream, __rescheduled_0);
  return true;
}

static bool res4d_conv_1_cast_mul_add_cast_relu__48(int8_t* __restrict__ __outs_0, int8_t* __restrict__ __ins_0, int8_t* __restrict__ __ins_1, float* __restrict__ __ins_2, float* __restrict__ __ins_3) noexcept{
  void** __sc_kernel_cache_arr_136 = (void**)&__uninitialized_data[23657512UL];
  int8_t* __rescheduled_0 = (int8_t*)sc_aligned_malloc(__stream, 640UL);
  int32_t __cached_0;
  __cached_0 = 0;
  for (uint64_t fused_0fused_0n__n_i_3499__k_o_3500 = 0UL; fused_0fused_0n__n_i_3499__k_o_3500 < 8UL; fused_0fused_0n__n_i_3499__k_o_3500 += 1UL) {
    int32_t* __origouts_2940_shr = (int32_t*)sc_aligned_malloc(__stream, 50176UL);
    void** A_list = (void**)&__rescheduled_0[0UL];
    void** B_list = (void**)&__rescheduled_0[320UL];
    for (uint64_t c_o = 0UL; c_o < 4UL; c_o += 1UL) {
      for (uint64_t r = 0UL; r < 3UL; r += 1UL) {
        for (uint64_t s = 0UL; s < 3UL; s += 1UL) {
          void* __cached_1;
          __cached_1 = &__ins_0[(((fused_0fused_0n__n_i_3499__k_o_3500 / 8UL) * 131072UL) + ((((fused_0fused_0n__n_i_3499__k_o_3500 / 4UL) % 2UL) * 65536UL) + ((c_o * 16384UL) + ((r * 1024UL) + (s * 64UL)))))];
          A_list[(((c_o * 9UL) + (r * 3UL)) + s)] = __cached_1;
          void* __cached_2;
          __cached_2 = &__ins_1[(((fused_0fused_0n__n_i_3499__k_o_3500 % 4UL) * 147456UL) + ((c_o * 36864UL) + ((r * 12288UL) + (s * 4096UL))))];
          B_list[(((c_o * 9UL) + (r * 3UL)) + s)] = __cached_2;
        }
      }
    }
    void* _arg_cache_34 = &__origouts_2940_shr[0UL];
    dnnl_brgemm_list_call(__sc_kernel_cache_arr_136[0UL], A_list, B_list, &__origouts_2940_shr[0UL], 1, 64, 4096, 36, 7, 7, __stream);
    for (uint64_t _fuseiter11566 = 0UL; _fuseiter11566 < 14UL; _fuseiter11566 += 1UL) {
      for (uint64_t _fuseiter11567 = 0UL; _fuseiter11567 < 14UL; _fuseiter11567 += 1UL) {
        for (uint64_t _fuseiter11568 = 0UL; _fuseiter11568 < 64UL; _fuseiter11568 += 16UL) {
          vec_s32x16 __cached_3;
          __cached_3 = vec_s32x16::load(&__origouts_2940_shr[((_fuseiter11566 * 896UL) + ((_fuseiter11567 * 64UL) + _fuseiter11568))]);
          vec_f32x16 __cached_4;
          __cached_4 = (vec_f32x16)(__cached_3);
          vec_f32x16 __cached_5;
          __cached_5 = vec_f32x16::load(&__ins_2[(((fused_0fused_0n__n_i_3499__k_o_3500 % 4UL) * 64UL) + _fuseiter11568)]);
          __cached_4 = (__cached_4 * __cached_5);
          vec_f32x16 __cached_6;
          __cached_6 = vec_f32x16::load(&__ins_3[(((fused_0fused_0n__n_i_3499__k_o_3500 % 4UL) * 64UL) + _fuseiter11568)]);
          __cached_4 = (__cached_4 + __cached_6);
          vec_s8x16 __cached_7;
          __cached_7 = sc_saturated_cast<vec_s8x16>(sc_round_and_cast<vec_s32x16>(__cached_4));
          vec_s8x16 __cached_8;
          __cached_8 = sc_max(__cached_7, vec_s8x16(0));
          vec_s8x16::store(__cached_8, &__outs_0[(((fused_0fused_0n__n_i_3499__k_o_3500 / 8UL) * 100352UL) + ((((fused_0fused_0n__n_i_3499__k_o_3500 / 4UL) % 2UL) * 50176UL) + (((fused_0fused_0n__n_i_3499__k_o_3500 % 4UL) * 12544UL) + ((_fuseiter11566 * 896UL) + ((_fuseiter11567 * 64UL) + _fuseiter11568)))))]);
        }
      }
    }
    sc_aligned_free(__stream, __origouts_2940_shr);
  }
  sc_aligned_free(__stream, __rescheduled_0);
  return true;
}

static bool res4d_conv_2_cast_mul_add_cast_add_relu__52(int8_t* __restrict__ __outs_0, int8_t* __restrict__ __ins_0, int8_t* __restrict__ __ins_1, float* __restrict__ __ins_2, float* __restrict__ __ins_3, int8_t* __restrict__ __ins_4) noexcept{
  void*& __sc_kernel_cache_113 = *(void**)(__module_data + 40);
  alignas(64) int8_t __rescheduled_0[128UL];
  for (uint64_t fused_0fused_0n__n_i_3501__k_3502 = 0UL; fused_0fused_0n__n_i_3501__k_3502 < 32UL; fused_0fused_0n__n_i_3501__k_3502 += 1UL) {
    for (uint64_t p_o = 0UL; p_o < 7UL; p_o += 1UL) {
      int32_t* __origouts_2950_shr = (int32_t*)sc_aligned_malloc(__stream, 7168UL);
      void** A_list = (void**)&__rescheduled_0[0UL];
      void** B_list = (void**)&__rescheduled_0[64UL];
      for (uint64_t c = 0UL; c < 4UL; c += 1UL) {
        void* __cached_0;
        __cached_0 = &__ins_0[(((fused_0fused_0n__n_i_3501__k_3502 / 32UL) * 100352UL) + ((((fused_0fused_0n__n_i_3501__k_3502 / 16UL) % 2UL) * 50176UL) + ((c * 12544UL) + (p_o * 1792UL))))];
        A_list[c] = __cached_0;
        void* __cached_1;
        __cached_1 = &__ins_1[(((fused_0fused_0n__n_i_3501__k_3502 % 16UL) * 16384UL) + (c * 4096UL))];
        B_list[c] = __cached_1;
      }
      void* _arg_cache_35 = &__origouts_2950_shr[0UL];
      dnnl_brgemm_list_call(__sc_kernel_cache_113, A_list, B_list, &__origouts_2950_shr[0UL], 1, 1, 1, 4, 7, 7, __stream);
      for (uint64_t _fuseiter11601 = 0UL; _fuseiter11601 < 2UL; _fuseiter11601 += 1UL) {
        for (uint64_t _fuseiter11602 = 0UL; _fuseiter11602 < 14UL; _fuseiter11602 += 1UL) {
          for (uint64_t _fuseiter11603 = 0UL; _fuseiter11603 < 64UL; _fuseiter11603 += 16UL) {
            vec_s32x16 __cached_2;
            __cached_2 = vec_s32x16::load(&__origouts_2950_shr[((_fuseiter11601 * 896UL) + ((_fuseiter11602 * 64UL) + _fuseiter11603))]);
            vec_f32x16 __cached_3;
            __cached_3 = (vec_f32x16)(__cached_2);
            vec_f32x16 __cached_4;
            __cached_4 = vec_f32x16::load(&__ins_2[(((fused_0fused_0n__n_i_3501__k_3502 % 16UL) * 64UL) + _fuseiter11603)]);
            __cached_3 = (__cached_3 * __cached_4);
            vec_f32x16 __cached_5;
            __cached_5 = vec_f32x16::load(&__ins_3[(((fused_0fused_0n__n_i_3501__k_3502 % 16UL) * 64UL) + _fuseiter11603)]);
            __cached_3 = (__cached_3 + __cached_5);
            vec_s8x16 __cached_6;
            __cached_6 = sc_saturated_cast<vec_s8x16>(sc_round_and_cast<vec_s32x16>(__cached_3));
            vec_s8x16 __cached_7;
            __cached_7 = vec_s8x16::load(&__ins_4[((((fused_0fused_0n__n_i_3501__k_3502 / 32UL) * 401408UL) + ((((fused_0fused_0n__n_i_3501__k_3502 / 16UL) % 2UL) * 200704UL) + (((fused_0fused_0n__n_i_3501__k_3502 % 16UL) * 12544UL) + (p_o * 1792UL)))) + ((_fuseiter11601 * 896UL) + ((_fuseiter11602 * 64UL) + _fuseiter11603)))]);
            __cached_6 = (__cached_6 + __cached_7);
            vec_s8x16 __cached_8;
            __cached_8 = sc_max(__cached_6, vec_s8x16(0));
            vec_s8x16::store(__cached_8, &__outs_0[((((fused_0fused_0n__n_i_3501__k_3502 / 32UL) * 401408UL) + ((((fused_0fused_0n__n_i_3501__k_3502 / 16UL) % 2UL) * 200704UL) + (((fused_0fused_0n__n_i_3501__k_3502 % 16UL) * 12544UL) + (p_o * 1792UL)))) + ((_fuseiter11601 * 896UL) + ((_fuseiter11602 * 64UL) + _fuseiter11603)))]);
          }
        }
      }
      sc_aligned_free(__stream, __origouts_2950_shr);
    }
  }
  return true;
}

static bool res4e_conv_0_cast_mul_add_cast_relu__56(int8_t* __restrict__ __outs_0, int8_t* __restrict__ __ins_0, int8_t* __restrict__ __ins_1, float* __restrict__ __ins_2, float* __restrict__ __ins_3) noexcept{
  void*& __sc_kernel_cache_132 = *(void**)(__module_data + 112);
  int8_t* __rescheduled_0 = (int8_t*)sc_aligned_malloc(__stream, 256UL);
  for (uint64_t n_i = 0UL; n_i < 2UL; n_i += 1UL) {
    for (uint64_t k = 0UL; k < 4UL; k += 1UL) {
      memset(&__outs_0[((n_i * 65536UL) + (k * 16384UL))], 0, 1024UL);
      for (uint64_t p1 = 0UL; p1 < 14UL; p1 += 1UL) {
        memset(&__outs_0[((n_i * 65536UL) + ((k * 16384UL) + ((p1 + 1UL) * 1024UL)))], 0, 64UL);
        memset(&__outs_0[(((n_i * 65536UL) + ((k * 16384UL) + ((p1 + 1UL) * 1024UL))) + 960UL)], 0, 64UL);
      }
      memset(&__outs_0[(((n_i * 65536UL) + (k * 16384UL)) + 15360UL)], 0, 1024UL);
    }
  }
  for (uint64_t fused_0fused_0n__n_i_3503__k_3504 = 0UL; fused_0fused_0n__n_i_3503__k_3504 < 8UL; fused_0fused_0n__n_i_3503__k_3504 += 1UL) {
    for (uint64_t p_o = 0UL; p_o < 7UL; p_o += 1UL) {
      int32_t* __origouts_2960_shr = (int32_t*)sc_aligned_malloc(__stream, 7168UL);
      void** A_list = (void**)&__rescheduled_0[0UL];
      void** B_list = (void**)&__rescheduled_0[128UL];
      for (uint64_t c = 0UL; c < 16UL; c += 1UL) {
        void* __cached_0;
        __cached_0 = &__ins_0[(((fused_0fused_0n__n_i_3503__k_3504 / 8UL) * 401408UL) + ((((fused_0fused_0n__n_i_3503__k_3504 / 4UL) % 2UL) * 200704UL) + ((c * 12544UL) + (p_o * 1792UL))))];
        A_list[c] = __cached_0;
        void* __cached_1;
        __cached_1 = &__ins_1[(((fused_0fused_0n__n_i_3503__k_3504 % 4UL) * 65536UL) + (c * 4096UL))];
        B_list[c] = __cached_1;
      }
      void* _arg_cache_36 = &__origouts_2960_shr[0UL];
      dnnl_brgemm_list_call(__sc_kernel_cache_132, A_list, B_list, &__origouts_2960_shr[0UL], 1, 1, 1, 16, 7, 7, __stream);
      for (uint64_t _fuseiter11643 = 0UL; _fuseiter11643 < 2UL; _fuseiter11643 += 1UL) {
        for (uint64_t _fuseiter11644 = 0UL; _fuseiter11644 < 14UL; _fuseiter11644 += 1UL) {
          for (uint64_t _fuseiter11645 = 0UL; _fuseiter11645 < 64UL; _fuseiter11645 += 16UL) {
            vec_s32x16 __cached_2;
            __cached_2 = vec_s32x16::load(&__origouts_2960_shr[((_fuseiter11643 * 896UL) + ((_fuseiter11644 * 64UL) + _fuseiter11645))]);
            vec_f32x16 __cached_3;
            __cached_3 = (vec_f32x16)(__cached_2);
            vec_f32x16 __cached_4;
            __cached_4 = vec_f32x16::load(&__ins_2[(((fused_0fused_0n__n_i_3503__k_3504 % 4UL) * 64UL) + _fuseiter11645)]);
            __cached_3 = (__cached_3 * __cached_4);
            vec_f32x16 __cached_5;
            __cached_5 = vec_f32x16::load(&__ins_3[(((fused_0fused_0n__n_i_3503__k_3504 % 4UL) * 64UL) + _fuseiter11645)]);
            __cached_3 = (__cached_3 + __cached_5);
            vec_s8x16 __cached_6;
            __cached_6 = sc_saturated_cast<vec_s8x16>(sc_round_and_cast<vec_s32x16>(__cached_3));
            vec_s8x16 __cached_7;
            __cached_7 = sc_max(__cached_6, vec_s8x16(0));
            vec_s8x16::store(__cached_7, &__outs_0[(((((fused_0fused_0n__n_i_3503__k_3504 / 8UL) * 131072UL) + ((((fused_0fused_0n__n_i_3503__k_3504 / 4UL) % 2UL) * 65536UL) + (((fused_0fused_0n__n_i_3503__k_3504 % 4UL) * 16384UL) + (((p_o * 2UL) + 1UL) * 1024UL)))) + 64UL) + ((_fuseiter11643 * 1024UL) + ((_fuseiter11644 * 64UL) + _fuseiter11645)))]);
          }
        }
      }
      sc_aligned_free(__stream, __origouts_2960_shr);
    }
  }
  sc_aligned_free(__stream, __rescheduled_0);
  return true;
}

static bool res4e_conv_1_cast_mul_add_cast_relu__60(int8_t* __restrict__ __outs_0, int8_t* __restrict__ __ins_0, int8_t* __restrict__ __ins_1, float* __restrict__ __ins_2, float* __restrict__ __ins_3) noexcept{
  void** __sc_kernel_cache_arr_136 = (void**)&__uninitialized_data[23657512UL];
  int8_t* __rescheduled_0 = (int8_t*)sc_aligned_malloc(__stream, 640UL);
  int32_t __cached_0;
  __cached_0 = 0;
  for (uint64_t fused_0fused_0n__n_i_3505__k_o_3506 = 0UL; fused_0fused_0n__n_i_3505__k_o_3506 < 8UL; fused_0fused_0n__n_i_3505__k_o_3506 += 1UL) {
    int32_t* __origouts_2970_shr = (int32_t*)sc_aligned_malloc(__stream, 50176UL);
    void** A_list = (void**)&__rescheduled_0[0UL];
    void** B_list = (void**)&__rescheduled_0[320UL];
    for (uint64_t c_o = 0UL; c_o < 4UL; c_o += 1UL) {
      for (uint64_t r = 0UL; r < 3UL; r += 1UL) {
        for (uint64_t s = 0UL; s < 3UL; s += 1UL) {
          void* __cached_1;
          __cached_1 = &__ins_0[(((fused_0fused_0n__n_i_3505__k_o_3506 / 8UL) * 131072UL) + ((((fused_0fused_0n__n_i_3505__k_o_3506 / 4UL) % 2UL) * 65536UL) + ((c_o * 16384UL) + ((r * 1024UL) + (s * 64UL)))))];
          A_list[(((c_o * 9UL) + (r * 3UL)) + s)] = __cached_1;
          void* __cached_2;
          __cached_2 = &__ins_1[(((fused_0fused_0n__n_i_3505__k_o_3506 % 4UL) * 147456UL) + ((c_o * 36864UL) + ((r * 12288UL) + (s * 4096UL))))];
          B_list[(((c_o * 9UL) + (r * 3UL)) + s)] = __cached_2;
        }
      }
    }
    void* _arg_cache_37 = &__origouts_2970_shr[0UL];
    dnnl_brgemm_list_call(__sc_kernel_cache_arr_136[0UL], A_list, B_list, &__origouts_2970_shr[0UL], 1, 64, 4096, 36, 7, 7, __stream);
    for (uint64_t _fuseiter11678 = 0UL; _fuseiter11678 < 14UL; _fuseiter11678 += 1UL) {
      for (uint64_t _fuseiter11679 = 0UL; _fuseiter11679 < 14UL; _fuseiter11679 += 1UL) {
        for (uint64_t _fuseiter11680 = 0UL; _fuseiter11680 < 64UL; _fuseiter11680 += 16UL) {
          vec_s32x16 __cached_3;
          __cached_3 = vec_s32x16::load(&__origouts_2970_shr[((_fuseiter11678 * 896UL) + ((_fuseiter11679 * 64UL) + _fuseiter11680))]);
          vec_f32x16 __cached_4;
          __cached_4 = (vec_f32x16)(__cached_3);
          vec_f32x16 __cached_5;
          __cached_5 = vec_f32x16::load(&__ins_2[(((fused_0fused_0n__n_i_3505__k_o_3506 % 4UL) * 64UL) + _fuseiter11680)]);
          __cached_4 = (__cached_4 * __cached_5);
          vec_f32x16 __cached_6;
          __cached_6 = vec_f32x16::load(&__ins_3[(((fused_0fused_0n__n_i_3505__k_o_3506 % 4UL) * 64UL) + _fuseiter11680)]);
          __cached_4 = (__cached_4 + __cached_6);
          vec_s8x16 __cached_7;
          __cached_7 = sc_saturated_cast<vec_s8x16>(sc_round_and_cast<vec_s32x16>(__cached_4));
          vec_s8x16 __cached_8;
          __cached_8 = sc_max(__cached_7, vec_s8x16(0));
          vec_s8x16::store(__cached_8, &__outs_0[(((fused_0fused_0n__n_i_3505__k_o_3506 / 8UL) * 100352UL) + ((((fused_0fused_0n__n_i_3505__k_o_3506 / 4UL) % 2UL) * 50176UL) + (((fused_0fused_0n__n_i_3505__k_o_3506 % 4UL) * 12544UL) + ((_fuseiter11678 * 896UL) + ((_fuseiter11679 * 64UL) + _fuseiter11680)))))]);
        }
      }
    }
    sc_aligned_free(__stream, __origouts_2970_shr);
  }
  sc_aligned_free(__stream, __rescheduled_0);
  return true;
}

static bool res4e_conv_2_cast_mul_add_cast_add_relu__64(int8_t* __restrict__ __outs_0, int8_t* __restrict__ __ins_0, int8_t* __restrict__ __ins_1, float* __restrict__ __ins_2, float* __restrict__ __ins_3, int8_t* __restrict__ __ins_4) noexcept{
  void*& __sc_kernel_cache_113 = *(void**)(__module_data + 40);
  alignas(64) int8_t __rescheduled_0[128UL];
  for (uint64_t fused_0fused_0n__n_i_3507__k_3508 = 0UL; fused_0fused_0n__n_i_3507__k_3508 < 32UL; fused_0fused_0n__n_i_3507__k_3508 += 1UL) {
    for (uint64_t p_o = 0UL; p_o < 7UL; p_o += 1UL) {
      int32_t* __origouts_2980_shr = (int32_t*)sc_aligned_malloc(__stream, 7168UL);
      void** A_list = (void**)&__rescheduled_0[0UL];
      void** B_list = (void**)&__rescheduled_0[64UL];
      for (uint64_t c = 0UL; c < 4UL; c += 1UL) {
        void* __cached_0;
        __cached_0 = &__ins_0[(((fused_0fused_0n__n_i_3507__k_3508 / 32UL) * 100352UL) + ((((fused_0fused_0n__n_i_3507__k_3508 / 16UL) % 2UL) * 50176UL) + ((c * 12544UL) + (p_o * 1792UL))))];
        A_list[c] = __cached_0;
        void* __cached_1;
        __cached_1 = &__ins_1[(((fused_0fused_0n__n_i_3507__k_3508 % 16UL) * 16384UL) + (c * 4096UL))];
        B_list[c] = __cached_1;
      }
      void* _arg_cache_38 = &__origouts_2980_shr[0UL];
      dnnl_brgemm_list_call(__sc_kernel_cache_113, A_list, B_list, &__origouts_2980_shr[0UL], 1, 1, 1, 4, 7, 7, __stream);
      for (uint64_t _fuseiter11713 = 0UL; _fuseiter11713 < 2UL; _fuseiter11713 += 1UL) {
        for (uint64_t _fuseiter11714 = 0UL; _fuseiter11714 < 14UL; _fuseiter11714 += 1UL) {
          for (uint64_t _fuseiter11715 = 0UL; _fuseiter11715 < 64UL; _fuseiter11715 += 16UL) {
            vec_s32x16 __cached_2;
            __cached_2 = vec_s32x16::load(&__origouts_2980_shr[((_fuseiter11713 * 896UL) + ((_fuseiter11714 * 64UL) + _fuseiter11715))]);
            vec_f32x16 __cached_3;
            __cached_3 = (vec_f32x16)(__cached_2);
            vec_f32x16 __cached_4;
            __cached_4 = vec_f32x16::load(&__ins_2[(((fused_0fused_0n__n_i_3507__k_3508 % 16UL) * 64UL) + _fuseiter11715)]);
            __cached_3 = (__cached_3 * __cached_4);
            vec_f32x16 __cached_5;
            __cached_5 = vec_f32x16::load(&__ins_3[(((fused_0fused_0n__n_i_3507__k_3508 % 16UL) * 64UL) + _fuseiter11715)]);
            __cached_3 = (__cached_3 + __cached_5);
            vec_s8x16 __cached_6;
            __cached_6 = sc_saturated_cast<vec_s8x16>(sc_round_and_cast<vec_s32x16>(__cached_3));
            vec_s8x16 __cached_7;
            __cached_7 = vec_s8x16::load(&__ins_4[((((fused_0fused_0n__n_i_3507__k_3508 / 32UL) * 401408UL) + ((((fused_0fused_0n__n_i_3507__k_3508 / 16UL) % 2UL) * 200704UL) + (((fused_0fused_0n__n_i_3507__k_3508 % 16UL) * 12544UL) + (p_o * 1792UL)))) + ((_fuseiter11713 * 896UL) + ((_fuseiter11714 * 64UL) + _fuseiter11715)))]);
            __cached_6 = (__cached_6 + __cached_7);
            vec_s8x16 __cached_8;
            __cached_8 = sc_max(__cached_6, vec_s8x16(0));
            vec_s8x16::store(__cached_8, &__outs_0[((((fused_0fused_0n__n_i_3507__k_3508 / 32UL) * 401408UL) + ((((fused_0fused_0n__n_i_3507__k_3508 / 16UL) % 2UL) * 200704UL) + (((fused_0fused_0n__n_i_3507__k_3508 % 16UL) * 12544UL) + (p_o * 1792UL)))) + ((_fuseiter11713 * 896UL) + ((_fuseiter11714 * 64UL) + _fuseiter11715)))]);
          }
        }
      }
      sc_aligned_free(__stream, __origouts_2980_shr);
    }
  }
  return true;
}

static bool res4f_conv_0_cast_mul_add_cast_relu__68(int8_t* __restrict__ __outs_0, int8_t* __restrict__ __ins_0, int8_t* __restrict__ __ins_1, float* __restrict__ __ins_2, float* __restrict__ __ins_3) noexcept{
  void*& __sc_kernel_cache_132 = *(void**)(__module_data + 112);
  int8_t* __rescheduled_0 = (int8_t*)sc_aligned_malloc(__stream, 256UL);
  for (uint64_t n_i = 0UL; n_i < 2UL; n_i += 1UL) {
    for (uint64_t k = 0UL; k < 4UL; k += 1UL) {
      memset(&__outs_0[((n_i * 65536UL) + (k * 16384UL))], 0, 1024UL);
      for (uint64_t p1 = 0UL; p1 < 14UL; p1 += 1UL) {
        memset(&__outs_0[((n_i * 65536UL) + ((k * 16384UL) + ((p1 + 1UL) * 1024UL)))], 0, 64UL);
        memset(&__outs_0[(((n_i * 65536UL) + ((k * 16384UL) + ((p1 + 1UL) * 1024UL))) + 960UL)], 0, 64UL);
      }
      memset(&__outs_0[(((n_i * 65536UL) + (k * 16384UL)) + 15360UL)], 0, 1024UL);
    }
  }
  for (uint64_t fused_0fused_0n__n_i_3509__k_3510 = 0UL; fused_0fused_0n__n_i_3509__k_3510 < 8UL; fused_0fused_0n__n_i_3509__k_3510 += 1UL) {
    for (uint64_t p_o = 0UL; p_o < 7UL; p_o += 1UL) {
      int32_t* __origouts_2990_shr = (int32_t*)sc_aligned_malloc(__stream, 7168UL);
      void** A_list = (void**)&__rescheduled_0[0UL];
      void** B_list = (void**)&__rescheduled_0[128UL];
      for (uint64_t c = 0UL; c < 16UL; c += 1UL) {
        void* __cached_0;
        __cached_0 = &__ins_0[(((fused_0fused_0n__n_i_3509__k_3510 / 8UL) * 401408UL) + ((((fused_0fused_0n__n_i_3509__k_3510 / 4UL) % 2UL) * 200704UL) + ((c * 12544UL) + (p_o * 1792UL))))];
        A_list[c] = __cached_0;
        void* __cached_1;
        __cached_1 = &__ins_1[(((fused_0fused_0n__n_i_3509__k_3510 % 4UL) * 65536UL) + (c * 4096UL))];
        B_list[c] = __cached_1;
      }
      void* _arg_cache_39 = &__origouts_2990_shr[0UL];
      dnnl_brgemm_list_call(__sc_kernel_cache_132, A_list, B_list, &__origouts_2990_shr[0UL], 1, 1, 1, 16, 7, 7, __stream);
      for (uint64_t _fuseiter11755 = 0UL; _fuseiter11755 < 2UL; _fuseiter11755 += 1UL) {
        for (uint64_t _fuseiter11756 = 0UL; _fuseiter11756 < 14UL; _fuseiter11756 += 1UL) {
          for (uint64_t _fuseiter11757 = 0UL; _fuseiter11757 < 64UL; _fuseiter11757 += 16UL) {
            vec_s32x16 __cached_2;
            __cached_2 = vec_s32x16::load(&__origouts_2990_shr[((_fuseiter11755 * 896UL) + ((_fuseiter11756 * 64UL) + _fuseiter11757))]);
            vec_f32x16 __cached_3;
            __cached_3 = (vec_f32x16)(__cached_2);
            vec_f32x16 __cached_4;
            __cached_4 = vec_f32x16::load(&__ins_2[(((fused_0fused_0n__n_i_3509__k_3510 % 4UL) * 64UL) + _fuseiter11757)]);
            __cached_3 = (__cached_3 * __cached_4);
            vec_f32x16 __cached_5;
            __cached_5 = vec_f32x16::load(&__ins_3[(((fused_0fused_0n__n_i_3509__k_3510 % 4UL) * 64UL) + _fuseiter11757)]);
            __cached_3 = (__cached_3 + __cached_5);
            vec_s8x16 __cached_6;
            __cached_6 = sc_saturated_cast<vec_s8x16>(sc_round_and_cast<vec_s32x16>(__cached_3));
            vec_s8x16 __cached_7;
            __cached_7 = sc_max(__cached_6, vec_s8x16(0));
            vec_s8x16::store(__cached_7, &__outs_0[(((((fused_0fused_0n__n_i_3509__k_3510 / 8UL) * 131072UL) + ((((fused_0fused_0n__n_i_3509__k_3510 / 4UL) % 2UL) * 65536UL) + (((fused_0fused_0n__n_i_3509__k_3510 % 4UL) * 16384UL) + (((p_o * 2UL) + 1UL) * 1024UL)))) + 64UL) + ((_fuseiter11755 * 1024UL) + ((_fuseiter11756 * 64UL) + _fuseiter11757)))]);
          }
        }
      }
      sc_aligned_free(__stream, __origouts_2990_shr);
    }
  }
  sc_aligned_free(__stream, __rescheduled_0);
  return true;
}

static bool res4f_conv_1_cast_mul_add_cast_relu__72(int8_t* __restrict__ __outs_0, int8_t* __restrict__ __ins_0, int8_t* __restrict__ __ins_1, float* __restrict__ __ins_2, float* __restrict__ __ins_3) noexcept{
  void** __sc_kernel_cache_arr_136 = (void**)&__uninitialized_data[23657512UL];
  int8_t* __rescheduled_0 = (int8_t*)sc_aligned_malloc(__stream, 640UL);
  int32_t __cached_0;
  __cached_0 = 0;
  for (uint64_t fused_0fused_0k_o__n_3511__n_i_3512 = 0UL; fused_0fused_0k_o__n_3511__n_i_3512 < 8UL; fused_0fused_0k_o__n_3511__n_i_3512 += 1UL) {
    int32_t* __origouts_3000_shr = (int32_t*)sc_aligned_malloc(__stream, 50176UL);
    void** A_list = (void**)&__rescheduled_0[0UL];
    void** B_list = (void**)&__rescheduled_0[320UL];
    for (uint64_t c_o = 0UL; c_o < 4UL; c_o += 1UL) {
      for (uint64_t r = 0UL; r < 3UL; r += 1UL) {
        for (uint64_t s = 0UL; s < 3UL; s += 1UL) {
          void* __cached_1;
          __cached_1 = &__ins_0[(((fused_0fused_0k_o__n_3511__n_i_3512 % 2UL) * 65536UL) + ((c_o * 16384UL) + ((r * 1024UL) + (s * 64UL))))];
          A_list[(((c_o * 9UL) + (r * 3UL)) + s)] = __cached_1;
          void* __cached_2;
          __cached_2 = &__ins_1[(((fused_0fused_0k_o__n_3511__n_i_3512 / 2UL) * 147456UL) + ((c_o * 36864UL) + ((r * 12288UL) + (s * 4096UL))))];
          B_list[(((c_o * 9UL) + (r * 3UL)) + s)] = __cached_2;
        }
      }
    }
    void* _arg_cache_40 = &__origouts_3000_shr[0UL];
    dnnl_brgemm_list_call(__sc_kernel_cache_arr_136[0UL], A_list, B_list, &__origouts_3000_shr[0UL], 1, 64, 4096, 36, 7, 7, __stream);
    for (uint64_t _fuseiter11790 = 0UL; _fuseiter11790 < 14UL; _fuseiter11790 += 1UL) {
      for (uint64_t _fuseiter11791 = 0UL; _fuseiter11791 < 14UL; _fuseiter11791 += 1UL) {
        for (uint64_t _fuseiter11792 = 0UL; _fuseiter11792 < 64UL; _fuseiter11792 += 16UL) {
          vec_s32x16 __cached_3;
          __cached_3 = vec_s32x16::load(&__origouts_3000_shr[((_fuseiter11790 * 896UL) + ((_fuseiter11791 * 64UL) + _fuseiter11792))]);
          vec_f32x16 __cached_4;
          __cached_4 = (vec_f32x16)(__cached_3);
          vec_f32x16 __cached_5;
          __cached_5 = vec_f32x16::load(&__ins_2[(((fused_0fused_0k_o__n_3511__n_i_3512 / 2UL) * 64UL) + _fuseiter11792)]);
          __cached_4 = (__cached_4 * __cached_5);
          vec_f32x16 __cached_6;
          __cached_6 = vec_f32x16::load(&__ins_3[(((fused_0fused_0k_o__n_3511__n_i_3512 / 2UL) * 64UL) + _fuseiter11792)]);
          __cached_4 = (__cached_4 + __cached_6);
          vec_s8x16 __cached_7;
          __cached_7 = sc_saturated_cast<vec_s8x16>(sc_round_and_cast<vec_s32x16>(__cached_4));
          vec_s8x16 __cached_8;
          __cached_8 = sc_max(__cached_7, vec_s8x16(0));
          vec_s8x16::store(__cached_8, &__outs_0[(((fused_0fused_0k_o__n_3511__n_i_3512 % 2UL) * 50176UL) + (((fused_0fused_0k_o__n_3511__n_i_3512 / 2UL) * 12544UL) + ((_fuseiter11790 * 896UL) + ((_fuseiter11791 * 64UL) + _fuseiter11792))))]);
        }
      }
    }
    sc_aligned_free(__stream, __origouts_3000_shr);
  }
  sc_aligned_free(__stream, __rescheduled_0);
  return true;
}

static bool res4f_conv_2_cast_mul_add_cast_add_relu__77(int8_t* __restrict__ __outs_0, int8_t* __restrict__ __ins_0, int8_t* __restrict__ __ins_1, float* __restrict__ __ins_2, float* __restrict__ __ins_3, int8_t* __restrict__ __ins_4) noexcept{
  void*& __sc_kernel_cache_113 = *(void**)(__module_data + 40);
  alignas(64) int8_t __rescheduled_0[128UL];
  for (uint64_t fused_0fused_0k__n_3513__n_i_3514 = 0UL; fused_0fused_0k__n_3513__n_i_3514 < 32UL; fused_0fused_0k__n_3513__n_i_3514 += 1UL) {
    for (uint64_t p_o = 0UL; p_o < 7UL; p_o += 1UL) {
      int32_t* __origouts_3010_shr = (int32_t*)sc_aligned_malloc(__stream, 7168UL);
      void** A_list = (void**)&__rescheduled_0[0UL];
      void** B_list = (void**)&__rescheduled_0[64UL];
      for (uint64_t c = 0UL; c < 4UL; c += 1UL) {
        void* __cached_0;
        __cached_0 = &__ins_0[(((fused_0fused_0k__n_3513__n_i_3514 % 2UL) * 50176UL) + ((c * 12544UL) + (p_o * 1792UL)))];
        A_list[c] = __cached_0;
        void* __cached_1;
        __cached_1 = &__ins_1[(((fused_0fused_0k__n_3513__n_i_3514 / 2UL) * 16384UL) + (c * 4096UL))];
        B_list[c] = __cached_1;
      }
      void* _arg_cache_41 = &__origouts_3010_shr[0UL];
      dnnl_brgemm_list_call(__sc_kernel_cache_113, A_list, B_list, &__origouts_3010_shr[0UL], 1, 1, 1, 4, 7, 7, __stream);
      for (uint64_t _fuseiter11825 = 0UL; _fuseiter11825 < 2UL; _fuseiter11825 += 1UL) {
        for (uint64_t _fuseiter11826 = 0UL; _fuseiter11826 < 14UL; _fuseiter11826 += 1UL) {
          for (uint64_t _fuseiter11827 = 0UL; _fuseiter11827 < 64UL; _fuseiter11827 += 16UL) {
            vec_s32x16 __cached_2;
            __cached_2 = vec_s32x16::load(&__origouts_3010_shr[((_fuseiter11825 * 896UL) + ((_fuseiter11826 * 64UL) + _fuseiter11827))]);
            vec_f32x16 __cached_3;
            __cached_3 = (vec_f32x16)(__cached_2);
            vec_f32x16 __cached_4;
            __cached_4 = vec_f32x16::load(&__ins_2[(((fused_0fused_0k__n_3513__n_i_3514 / 2UL) * 64UL) + _fuseiter11827)]);
            __cached_3 = (__cached_3 * __cached_4);
            vec_f32x16 __cached_5;
            __cached_5 = vec_f32x16::load(&__ins_3[(((fused_0fused_0k__n_3513__n_i_3514 / 2UL) * 64UL) + _fuseiter11827)]);
            __cached_3 = (__cached_3 + __cached_5);
            vec_s8x16 __cached_6;
            __cached_6 = sc_saturated_cast<vec_s8x16>(sc_round_and_cast<vec_s32x16>(__cached_3));
            vec_s8x16 __cached_7;
            __cached_7 = vec_s8x16::load(&__ins_4[((((fused_0fused_0k__n_3513__n_i_3514 % 2UL) * 200704UL) + (((fused_0fused_0k__n_3513__n_i_3514 / 2UL) * 12544UL) + (p_o * 1792UL))) + ((_fuseiter11825 * 896UL) + ((_fuseiter11826 * 64UL) + _fuseiter11827)))]);
            __cached_6 = (__cached_6 + __cached_7);
            vec_s8x16 __cached_8;
            __cached_8 = sc_max(__cached_6, vec_s8x16(0));
            vec_s8x16::store(__cached_8, &__outs_0[((((fused_0fused_0k__n_3513__n_i_3514 % 2UL) * 200704UL) + (((fused_0fused_0k__n_3513__n_i_3514 / 2UL) * 12544UL) + (p_o * 1792UL))) + ((_fuseiter11825 * 896UL) + ((_fuseiter11826 * 64UL) + _fuseiter11827)))]);
          }
        }
      }
      sc_aligned_free(__stream, __origouts_3010_shr);
    }
  }
  return true;
}

static bool res5a_conv_b_cast_mul_add_cast__683(int8_t* __restrict__ __outs_0, int8_t* __restrict__ __ins_0, int8_t* __restrict__ __ins_1, float* __restrict__ __ins_2, float* __restrict__ __ins_3) noexcept{
  int8_t* input_tmp = (int8_t*)sc_aligned_malloc(__stream, 200704UL);
  generic_val __tempargs338[2UL];
  __tempargs338[0UL] = __ins_0;
  __tempargs338[1UL] = input_tmp;
  sc_parallel_call_cpu_with_env((void*)&res5a_conv_b_cast_mul_add_cast__6830_closure_338_0wrapper, __stream, __module_data, 0UL, 4UL, 1UL, __tempargs338);
  generic_val __tempargs339[5UL];
  __tempargs339[0UL] = input_tmp;
  __tempargs339[1UL] = __ins_1;
  __tempargs339[2UL] = __ins_2;
  __tempargs339[3UL] = __ins_3;
  __tempargs339[4UL] = __outs_0;
  sc_parallel_call_cpu_with_env((void*)&res5a_conv_b_cast_mul_add_cast__6830_closure_339_0wrapper, __stream, __module_data, 0UL, 16UL, 1UL, __tempargs339);
  sc_aligned_free(__stream, input_tmp);
  return true;
}

static bool res5a_conv_0_cast_mul_add_cast_relu_reorder__682(int8_t* __restrict__ __outs_0, int8_t* __restrict__ __ins_0, int8_t* __restrict__ __ins_1, float* __restrict__ __ins_2, float* __restrict__ __ins_3) noexcept{
  generic_val __tempargs340[1UL];
  __tempargs340[0UL] = __outs_0;
  sc_parallel_call_cpu_with_env((void*)&res5a_conv_0_cast_mul_add_cast_relu_reorder__6820_closure_340_0wrapper, __stream, __module_data, 0UL, 4UL, 1UL, __tempargs340);
  generic_val __tempargs341[5UL];
  __tempargs341[0UL] = __ins_0;
  __tempargs341[1UL] = __ins_1;
  __tempargs341[2UL] = __ins_2;
  __tempargs341[3UL] = __ins_3;
  __tempargs341[4UL] = __outs_0;
  sc_parallel_call_cpu_with_env((void*)&res5a_conv_0_cast_mul_add_cast_relu_reorder__6820_closure_341_0wrapper, __stream, __module_data, 0UL, 4UL, 1UL, __tempargs341);
  return true;
}

static bool res5a_conv_1_cast_mul_add_cast_relu_reorder__681(int8_t* __restrict__ __outs_0, int8_t* __restrict__ __ins_0, int8_t* __restrict__ __ins_1, float* __restrict__ __ins_2, float* __restrict__ __ins_3) noexcept{
  generic_val __tempargs342[5UL];
  __tempargs342[0UL] = __ins_0;
  __tempargs342[1UL] = __ins_1;
  __tempargs342[2UL] = __ins_2;
  __tempargs342[3UL] = __ins_3;
  __tempargs342[4UL] = __outs_0;
  sc_parallel_call_cpu_with_env((void*)&res5a_conv_1_cast_mul_add_cast_relu_reorder__6810_closure_342_0wrapper, __stream, __module_data, 0UL, 8UL, 1UL, __tempargs342);
  return true;
}

static bool res5a_conv_2_cast_mul_add_cast_add_relu__680(int8_t* __restrict__ __outs_0, int8_t* __restrict__ __ins_0, int8_t* __restrict__ __ins_1, float* __restrict__ __ins_2, float* __restrict__ __ins_3, int8_t* __restrict__ __ins_4) noexcept{
  generic_val __tempargs343[6UL];
  __tempargs343[0UL] = __ins_0;
  __tempargs343[1UL] = __ins_1;
  __tempargs343[2UL] = __ins_2;
  __tempargs343[3UL] = __ins_3;
  __tempargs343[4UL] = __ins_4;
  __tempargs343[5UL] = __outs_0;
  sc_parallel_call_cpu_with_env((void*)&res5a_conv_2_cast_mul_add_cast_add_relu__6800_closure_343_0wrapper, __stream, __module_data, 0UL, 16UL, 1UL, __tempargs343);
  return true;
}

static bool res5b_conv_0_cast_mul_add_cast_relu__679(int8_t* __restrict__ __outs_0, int8_t* __restrict__ __ins_0, int8_t* __restrict__ __ins_1, float* __restrict__ __ins_2, float* __restrict__ __ins_3) noexcept{
  generic_val __tempargs344[1UL];
  __tempargs344[0UL] = __outs_0;
  sc_parallel_call_cpu_with_env((void*)&res5b_conv_0_cast_mul_add_cast_relu__6790_closure_344_0wrapper, __stream, __module_data, 0UL, 4UL, 1UL, __tempargs344);
  generic_val __tempargs345[5UL];
  __tempargs345[0UL] = __ins_0;
  __tempargs345[1UL] = __ins_1;
  __tempargs345[2UL] = __ins_2;
  __tempargs345[3UL] = __ins_3;
  __tempargs345[4UL] = __outs_0;
  sc_parallel_call_cpu_with_env((void*)&res5b_conv_0_cast_mul_add_cast_relu__6790_closure_345_0wrapper, __stream, __module_data, 0UL, 32UL, 1UL, __tempargs345);
  return true;
}

static bool res5b_conv_1_cast_mul_add_cast_relu_reorder__678(int8_t* __restrict__ __outs_0, int8_t* __restrict__ __ins_0, int8_t* __restrict__ __ins_1, float* __restrict__ __ins_2, float* __restrict__ __ins_3) noexcept{
  int32_t __cached_0;
  __cached_0 = 0;
  generic_val __tempargs346[5UL];
  __tempargs346[0UL] = __ins_0;
  __tempargs346[1UL] = __ins_1;
  __tempargs346[2UL] = __ins_2;
  __tempargs346[3UL] = __ins_3;
  __tempargs346[4UL] = __outs_0;
  sc_parallel_call_cpu_with_env((void*)&res5b_conv_1_cast_mul_add_cast_relu_reorder__6780_closure_346_0wrapper, __stream, __module_data, 0UL, 16UL, 1UL, __tempargs346);
  return true;
}

static bool res5b_conv_2_cast_mul_add_cast_add_relu__677(int8_t* __restrict__ __outs_0, int8_t* __restrict__ __ins_0, int8_t* __restrict__ __ins_1, float* __restrict__ __ins_2, float* __restrict__ __ins_3, int8_t* __restrict__ __ins_4) noexcept{
  generic_val __tempargs347[6UL];
  __tempargs347[0UL] = __ins_0;
  __tempargs347[1UL] = __ins_1;
  __tempargs347[2UL] = __ins_2;
  __tempargs347[3UL] = __ins_3;
  __tempargs347[4UL] = __ins_4;
  __tempargs347[5UL] = __outs_0;
  sc_parallel_call_cpu_with_env((void*)&res5b_conv_2_cast_mul_add_cast_add_relu__6770_closure_347_0wrapper, __stream, __module_data, 0UL, 16UL, 1UL, __tempargs347);
  return true;
}

static bool res5c_conv_0_cast_mul_add_cast_relu_reorder__676(int8_t* __restrict__ __outs_0, int8_t* __restrict__ __ins_0, int8_t* __restrict__ __ins_1, float* __restrict__ __ins_2, float* __restrict__ __ins_3) noexcept{
  generic_val __tempargs348[1UL];
  __tempargs348[0UL] = __outs_0;
  sc_parallel_call_cpu_with_env((void*)&res5c_conv_0_cast_mul_add_cast_relu_reorder__6760_closure_348_0wrapper, __stream, __module_data, 0UL, 4UL, 1UL, __tempargs348);
  generic_val __tempargs349[5UL];
  __tempargs349[0UL] = __ins_0;
  __tempargs349[1UL] = __ins_1;
  __tempargs349[2UL] = __ins_2;
  __tempargs349[3UL] = __ins_3;
  __tempargs349[4UL] = __outs_0;
  sc_parallel_call_cpu_with_env((void*)&res5c_conv_0_cast_mul_add_cast_relu_reorder__6760_closure_349_0wrapper, __stream, __module_data, 0UL, 8UL, 1UL, __tempargs349);
  return true;
}

static bool res5c_conv_1_cast_mul_add_cast_relu__675(int8_t* __restrict__ __outs_0, int8_t* __restrict__ __ins_0, int8_t* __restrict__ __ins_1, float* __restrict__ __ins_2, float* __restrict__ __ins_3) noexcept{
  int32_t __cached_0;
  __cached_0 = 0;
  generic_val __tempargs350[5UL];
  __tempargs350[0UL] = __ins_0;
  __tempargs350[1UL] = __ins_1;
  __tempargs350[2UL] = __ins_2;
  __tempargs350[3UL] = __ins_3;
  __tempargs350[4UL] = __outs_0;
  sc_parallel_call_cpu_with_env((void*)&res5c_conv_1_cast_mul_add_cast_relu__6750_closure_350_0wrapper, __stream, __module_data, 0UL, 32UL, 1UL, __tempargs350);
  return true;
}

static bool res5c_conv_2_cast_mul_add_cast_add_relu_reorder__674(int8_t* __restrict__ __outs_0, int8_t* __restrict__ __ins_0, int8_t* __restrict__ __ins_1, float* __restrict__ __ins_2, float* __restrict__ __ins_3, int8_t* __restrict__ __ins_4) noexcept{
  generic_val __tempargs351[6UL];
  __tempargs351[0UL] = __ins_0;
  __tempargs351[1UL] = __ins_1;
  __tempargs351[2UL] = __ins_2;
  __tempargs351[3UL] = __ins_3;
  __tempargs351[4UL] = __ins_4;
  __tempargs351[5UL] = __outs_0;
  sc_parallel_call_cpu_with_env((void*)&res5c_conv_2_cast_mul_add_cast_add_relu_reorder__6740_closure_351_0wrapper, __stream, __module_data, 0UL, 16UL, 1UL, __tempargs351);
  return true;
}

static void __init_const_globals(int8_t* __restrict__ backbone_output, int64_t* __restrict__ input_pointers, float* __restrict__ res2a_weight_b, float* __restrict__ res2a_bias_b, float* __restrict__ res2a_weight_0, float* __restrict__ res2a_bias_0, float* __restrict__ res2a_weight_1, float* __restrict__ res2a_bias_1, float* __restrict__ res2a_weight_2, float* __restrict__ res2a_bias_2, float* __restrict__ res2b_weight_0, float* __restrict__ res2b_bias_0, float* __restrict__ res2b_weight_1, float* __restrict__ res2b_bias_1, float* __restrict__ res2b_weight_2, float* __restrict__ res2b_bias_2, float* __restrict__ res2c_weight_0, float* __restrict__ res2c_bias_0, float* __restrict__ res2c_weight_1, float* __restrict__ res2c_bias_1, float* __restrict__ res2c_weight_2, float* __restrict__ res2c_bias_2, float* __restrict__ res3a_weight_b, float* __restrict__ res3a_bias_b, float* __restrict__ res3a_weight_0, float* __restrict__ res3a_bias_0, float* __restrict__ res3a_weight_1, float* __restrict__ res3a_bias_1, float* __restrict__ res3a_weight_2, float* __restrict__ res3a_bias_2, float* __restrict__ res3b_weight_0, float* __restrict__ res3b_bias_0, float* __restrict__ res3b_weight_1, float* __restrict__ res3b_bias_1, float* __restrict__ res3b_weight_2, float* __restrict__ res3b_bias_2, float* __restrict__ res3c_weight_0, float* __restrict__ res3c_bias_0, float* __restrict__ res3c_weight_1, float* __restrict__ res3c_bias_1, float* __restrict__ res3c_weight_2, float* __restrict__ res3c_bias_2, float* __restrict__ res3d_weight_0, float* __restrict__ res3d_bias_0, float* __restrict__ res3d_weight_1, float* __restrict__ res3d_bias_1, float* __restrict__ res3d_weight_2, float* __restrict__ res3d_bias_2, float* __restrict__ res4a_weight_b, float* __restrict__ res4a_bias_b, float* __restrict__ res4a_weight_0, float* __restrict__ res4a_bias_0, float* __restrict__ res4a_weight_1, float* __restrict__ res4a_bias_1, float* __restrict__ res4a_weight_2, float* __restrict__ res4a_bias_2, float* __restrict__ res4b_weight_0, float* __restrict__ res4b_bias_0, float* __restrict__ res4b_weight_1, float* __restrict__ res4b_bias_1, float* __restrict__ res4b_weight_2, float* __restrict__ res4b_bias_2, float* __restrict__ res4c_weight_0, float* __restrict__ res4c_bias_0, float* __restrict__ res4c_weight_1, float* __restrict__ res4c_bias_1, float* __restrict__ res4c_weight_2, float* __restrict__ res4c_bias_2, float* __restrict__ res4d_weight_0, float* __restrict__ res4d_bias_0, float* __restrict__ res4d_weight_1, float* __restrict__ res4d_bias_1, float* __restrict__ res4d_weight_2, float* __restrict__ res4d_bias_2, float* __restrict__ res4e_weight_0, float* __restrict__ res4e_bias_0, float* __restrict__ res4e_weight_1, float* __restrict__ res4e_bias_1, float* __restrict__ res4e_weight_2, float* __restrict__ res4e_bias_2, float* __restrict__ res4f_weight_0, float* __restrict__ res4f_bias_0, float* __restrict__ res4f_weight_1, float* __restrict__ res4f_bias_1, float* __restrict__ res4f_weight_2, float* __restrict__ res4f_bias_2, float* __restrict__ res5a_weight_b, float* __restrict__ res5a_bias_b, float* __restrict__ res5a_weight_0, float* __restrict__ res5a_bias_0, float* __restrict__ res5a_weight_1, float* __restrict__ res5a_bias_1, float* __restrict__ res5a_weight_2, float* __restrict__ res5a_bias_2, float* __restrict__ res5b_weight_0, float* __restrict__ res5b_bias_0, float* __restrict__ res5b_weight_1, float* __restrict__ res5b_bias_1, float* __restrict__ res5b_weight_2, float* __restrict__ res5b_bias_2, float* __restrict__ res5c_weight_0, float* __restrict__ res5c_bias_0, float* __restrict__ res5c_weight_1, float* __restrict__ res5c_bias_1, float* __restrict__ res5c_weight_2, float* __restrict__ res5c_bias_2) noexcept{
  float* folded_const_103 = (float*)&__module_data[111680UL];
  float* folded_const_156 = (float*)&__uninitialized_data[0UL];
  float* folded_const_101 = (float*)&__module_data[111376UL];
  float* folded_const_157 = (float*)&__uninitialized_data[1024UL];
  float* folded_const_102 = (float*)&__module_data[111424UL];
  float* folded_const_81 = (float*)&__module_data[111296UL];
  float* folded_const_158 = (float*)&__uninitialized_data[1280UL];
  float* folded_const_80 = (float*)&__module_data[111040UL];
  float* folded_const_79 = (float*)&__module_data[110976UL];
  float* folded_const_78 = (float*)&__module_data[109952UL];
  float* folded_const_159 = (float*)&__uninitialized_data[1536UL];
  float* folded_const_100 = (float*)&__module_data[111372UL];
  float* folded_const_160 = (float*)&__uninitialized_data[2560UL];
  float* folded_const_77 = (float*)&__module_data[109696UL];
  float* folded_const_76 = (float*)&__module_data[109632UL];
  float* folded_const_161 = (float*)&__uninitialized_data[2816UL];
  float* folded_const_75 = (float*)&__module_data[109376UL];
  float* folded_const_74 = (float*)&__module_data[109312UL];
  float* folded_const_73 = (float*)&__module_data[108288UL];
  float* folded_const_162 = (float*)&__uninitialized_data[3072UL];
  float* folded_const_99 = (float*)&__module_data[111368UL];
  float* folded_const_163 = (float*)&__uninitialized_data[4096UL];
  float* folded_const_72 = (float*)&__module_data[108032UL];
  float* folded_const_71 = (float*)&__module_data[107968UL];
  float* folded_const_164 = (float*)&__uninitialized_data[4352UL];
  float* folded_const_70 = (float*)&__module_data[107712UL];
  float* folded_const_69 = (float*)&__module_data[107648UL];
  float* folded_const_68 = (float*)&__module_data[106624UL];
  float* folded_const_165 = (float*)&__uninitialized_data[4608UL];
  float* folded_const_98 = (float*)&__module_data[111364UL];
  float* folded_const_67 = (float*)&__module_data[104576UL];
  float* folded_const_166 = (float*)&__uninitialized_data[5632UL];
  float* folded_const_97 = (float*)&__module_data[111360UL];
  float* folded_const_66 = (float*)&__module_data[104064UL];
  float* folded_const_167 = (float*)&__uninitialized_data[7680UL];
  float* folded_const_65 = (float*)&__module_data[104000UL];
  float* folded_const_64 = (float*)&__module_data[103488UL];
  float* folded_const_168 = (float*)&__uninitialized_data[8192UL];
  float* folded_const_63 = (float*)&__module_data[103424UL];
  float* folded_const_62 = (float*)&__module_data[101376UL];
  float* folded_const_169 = (float*)&__uninitialized_data[8704UL];
  float* folded_const_96 = (float*)&__module_data[111356UL];
  float* folded_const_61 = (float*)&__module_data[100864UL];
  float* folded_const_170 = (float*)&__uninitialized_data[10752UL];
  float* folded_const_60 = (float*)&__module_data[100800UL];
  float* folded_const_59 = (float*)&__module_data[100288UL];
  float* folded_const_171 = (float*)&__uninitialized_data[11264UL];
  float* folded_const_58 = (float*)&__module_data[100224UL];
  float* folded_const_57 = (float*)&__module_data[98176UL];
  float* folded_const_172 = (float*)&__uninitialized_data[11776UL];
  float* folded_const_95 = (float*)&__module_data[111352UL];
  float* folded_const_56 = (float*)&__module_data[97664UL];
  float* folded_const_173 = (float*)&__uninitialized_data[13824UL];
  float* folded_const_55 = (float*)&__module_data[97600UL];
  float* folded_const_54 = (float*)&__module_data[97088UL];
  float* folded_const_174 = (float*)&__uninitialized_data[14336UL];
  float* folded_const_53 = (float*)&__module_data[97024UL];
  float* folded_const_52 = (float*)&__module_data[94976UL];
  float* folded_const_175 = (float*)&__uninitialized_data[14848UL];
  float* folded_const_94 = (float*)&__module_data[111348UL];
  float* folded_const_51 = (float*)&__module_data[94464UL];
  float* folded_const_176 = (float*)&__uninitialized_data[16896UL];
  float* folded_const_50 = (float*)&__module_data[94400UL];
  float* folded_const_49 = (float*)&__module_data[93888UL];
  float* folded_const_177 = (float*)&__uninitialized_data[17408UL];
  float* folded_const_48 = (float*)&__module_data[93824UL];
  float* folded_const_47 = (float*)&__module_data[91776UL];
  float* folded_const_178 = (float*)&__uninitialized_data[17920UL];
  float* folded_const_93 = (float*)&__module_data[111344UL];
  float* folded_const_46 = (float*)&__module_data[87680UL];
  float* folded_const_179 = (float*)&__uninitialized_data[19968UL];
  float* folded_const_92 = (float*)&__module_data[111340UL];
  float* folded_const_45 = (float*)&__module_data[86656UL];
  float* folded_const_180 = (float*)&__uninitialized_data[24064UL];
  float* folded_const_44 = (float*)&__module_data[86592UL];
  float* folded_const_43 = (float*)&__module_data[85568UL];
  float* folded_const_181 = (float*)&__uninitialized_data[25088UL];
  float* folded_const_42 = (float*)&__module_data[85504UL];
  float* folded_const_41 = (float*)&__module_data[81408UL];
  float* folded_const_182 = (float*)&__uninitialized_data[26112UL];
  float* folded_const_91 = (float*)&__module_data[111336UL];
  float* folded_const_40 = (float*)&__module_data[80384UL];
  float* folded_const_183 = (float*)&__uninitialized_data[30208UL];
  float* folded_const_39 = (float*)&__module_data[80320UL];
  float* folded_const_38 = (float*)&__module_data[79296UL];
  float* folded_const_184 = (float*)&__uninitialized_data[31232UL];
  float* folded_const_37 = (float*)&__module_data[79232UL];
  float* folded_const_36 = (float*)&__module_data[75136UL];
  float* folded_const_185 = (float*)&__uninitialized_data[32256UL];
  float* folded_const_90 = (float*)&__module_data[111332UL];
  float* folded_const_35 = (float*)&__module_data[74112UL];
  float* folded_const_186 = (float*)&__uninitialized_data[36352UL];
  float* folded_const_34 = (float*)&__module_data[74048UL];
  float* folded_const_33 = (float*)&__module_data[73024UL];
  float* folded_const_187 = (float*)&__uninitialized_data[37376UL];
  float* folded_const_32 = (float*)&__module_data[72960UL];
  float* folded_const_31 = (float*)&__module_data[68864UL];
  float* folded_const_188 = (float*)&__uninitialized_data[38400UL];
  float* folded_const_89 = (float*)&__module_data[111328UL];
  float* folded_const_30 = (float*)&__module_data[67840UL];
  float* folded_const_189 = (float*)&__uninitialized_data[42496UL];
  float* folded_const_29 = (float*)&__module_data[67776UL];
  float* folded_const_28 = (float*)&__module_data[66752UL];
  float* folded_const_190 = (float*)&__uninitialized_data[43520UL];
  float* folded_const_27 = (float*)&__module_data[66688UL];
  float* folded_const_26 = (float*)&__module_data[62592UL];
  float* folded_const_191 = (float*)&__uninitialized_data[44544UL];
  float* folded_const_88 = (float*)&__module_data[111324UL];
  float* folded_const_25 = (float*)&__module_data[61568UL];
  float* folded_const_192 = (float*)&__uninitialized_data[48640UL];
  float* folded_const_24 = (float*)&__module_data[61504UL];
  float* folded_const_23 = (float*)&__module_data[60480UL];
  float* folded_const_193 = (float*)&__uninitialized_data[49664UL];
  float* folded_const_22 = (float*)&__module_data[60416UL];
  float* folded_const_21 = (float*)&__module_data[56320UL];
  float* folded_const_194 = (float*)&__uninitialized_data[50688UL];
  float* folded_const_87 = (float*)&__module_data[111320UL];
  float* folded_const_20 = (float*)&__module_data[55296UL];
  float* folded_const_195 = (float*)&__uninitialized_data[54784UL];
  float* folded_const_19 = (float*)&__module_data[55232UL];
  float* folded_const_18 = (float*)&__module_data[54208UL];
  float* folded_const_196 = (float*)&__uninitialized_data[55808UL];
  float* folded_const_17 = (float*)&__module_data[54144UL];
  float* folded_const_16 = (float*)&__module_data[50048UL];
  float* folded_const_197 = (float*)&__uninitialized_data[56832UL];
  float* folded_const_86 = (float*)&__module_data[111316UL];
  float* folded_const_15 = (float*)&__module_data[41856UL];
  float* folded_const_198 = (float*)&__uninitialized_data[60928UL];
  float* folded_const_85 = (float*)&__module_data[111312UL];
  float* folded_const_199 = (float*)&__uninitialized_data[69120UL];
  float* folded_const_14 = (float*)&__module_data[39808UL];
  float* folded_const_13 = (float*)&__module_data[39744UL];
  float* folded_const_12 = (float*)&__module_data[37696UL];
  float* folded_const_200 = (float*)&__uninitialized_data[71168UL];
  float* folded_const_11 = (float*)&__module_data[37632UL];
  float* folded_const_10 = (float*)&__module_data[29440UL];
  float* folded_const_201 = (float*)&__uninitialized_data[73216UL];
  float* folded_const_84 = (float*)&__module_data[111308UL];
  float* folded_const_9 = (float*)&__module_data[27392UL];
  float* folded_const_202 = (float*)&__uninitialized_data[81408UL];
  float* folded_const_8 = (float*)&__module_data[27328UL];
  float* folded_const_7 = (float*)&__module_data[25280UL];
  float* folded_const_203 = (float*)&__uninitialized_data[83456UL];
  float* folded_const_6 = (float*)&__module_data[25216UL];
  float* folded_const_5 = (float*)&__module_data[17024UL];
  float* folded_const_204 = (float*)&__uninitialized_data[85504UL];
  float* folded_const_83 = (float*)&__module_data[111304UL];
  float* folded_const_4 = (float*)&__module_data[14976UL];
  float* folded_const_205 = (float*)&__uninitialized_data[93696UL];
  float* folded_const_3 = (float*)&__module_data[14912UL];
  float* folded_const_2 = (float*)&__module_data[12864UL];
  float* folded_const_206 = (float*)&__uninitialized_data[95744UL];
  float* folded_const_1 = (float*)&__module_data[12800UL];
  float* folded_const_0 = (float*)&__module_data[4608UL];
  float* folded_const_207 = (float*)&__uninitialized_data[97792UL];
  float* folded_const_82 = (float*)&__module_data[111300UL];
  float* folded_const_208 = (float*)&__uninitialized_data[105984UL];
  float* folded_const_209 = (float*)&__uninitialized_data[106240UL];
  float* folded_const_210 = (float*)&__uninitialized_data[106496UL];
  float* folded_const_211 = (float*)&__uninitialized_data[106752UL];
  float* folded_const_212 = (float*)&__uninitialized_data[107008UL];
  float* folded_const_213 = (float*)&__uninitialized_data[107264UL];
  float* folded_const_214 = (float*)&__uninitialized_data[107520UL];
  float* folded_const_215 = (float*)&__uninitialized_data[108032UL];
  float* folded_const_216 = (float*)&__uninitialized_data[108544UL];
  float* folded_const_217 = (float*)&__uninitialized_data[109056UL];
  float* folded_const_218 = (float*)&__uninitialized_data[109568UL];
  float* folded_const_219 = (float*)&__uninitialized_data[110080UL];
  float* folded_const_220 = (float*)&__uninitialized_data[110592UL];
  float* folded_const_221 = (float*)&__uninitialized_data[111104UL];
  float* folded_const_222 = (float*)&__uninitialized_data[111616UL];
  float* folded_const_223 = (float*)&__uninitialized_data[112640UL];
  float* folded_const_224 = (float*)&__uninitialized_data[113664UL];
  float* folded_const_225 = (float*)&__uninitialized_data[114688UL];
  float* folded_const_226 = (float*)&__uninitialized_data[115712UL];
  float* folded_const_227 = (float*)&__uninitialized_data[116736UL];
  float* folded_const_228 = (float*)&__uninitialized_data[117760UL];
  float* folded_const_229 = (float*)&__uninitialized_data[118784UL];
  float* folded_const_230 = (float*)&__uninitialized_data[119808UL];
  float* folded_const_231 = (float*)&__uninitialized_data[120832UL];
  float* folded_const_232 = (float*)&__uninitialized_data[121856UL];
  float* folded_const_233 = (float*)&__uninitialized_data[122880UL];
  float* folded_const_234 = (float*)&__uninitialized_data[123904UL];
  float* folded_const_235 = (float*)&__uninitialized_data[124928UL];
  float* folded_const_236 = (float*)&__uninitialized_data[125952UL];
  float* folded_const_237 = (float*)&__uninitialized_data[126976UL];
  float* folded_const_238 = (float*)&__uninitialized_data[128000UL];
  float* folded_const_239 = (float*)&__uninitialized_data[130048UL];
  float* folded_const_240 = (float*)&__uninitialized_data[132096UL];
  float* folded_const_241 = (float*)&__uninitialized_data[134144UL];
  float* folded_const_242 = (float*)&__uninitialized_data[136192UL];
  float* folded_const_243 = (float*)&__uninitialized_data[138240UL];
  float* folded_const_244 = (float*)&__uninitialized_data[140288UL];
  float* folded_const_245 = (float*)&__uninitialized_data[142336UL];
  float* folded_const_246 = (float*)&__uninitialized_data[144384UL];
  float* folded_const_247 = (float*)&__uninitialized_data[146432UL];
  float* folded_const_248 = (float*)&__uninitialized_data[148480UL];
  float* folded_const_249 = (float*)&__uninitialized_data[150528UL];
  float* folded_const_250 = (float*)&__uninitialized_data[154624UL];
  float* folded_const_251 = (float*)&__uninitialized_data[158720UL];
  float* folded_const_252 = (float*)&__uninitialized_data[162816UL];
  float* folded_const_253 = (float*)&__uninitialized_data[166912UL];
  float* folded_const_254 = (float*)&__uninitialized_data[171008UL];
  float* folded_const_255 = (float*)&__uninitialized_data[175104UL];
  float* folded_const_256 = (float*)&__uninitialized_data[179200UL];
  float* folded_const_257 = (float*)&__uninitialized_data[187392UL];
  float* folded_const_258 = (float*)&__uninitialized_data[195584UL];
  float* folded_const_259 = (float*)&__uninitialized_data[203776UL];
  float* folded_const_154 = (float*)&__module_data[217408UL];
  int8_t* folded_const_260 = (int8_t*)&__uninitialized_data[211968UL];
  float* folded_const_155 = (float*)&__module_data[217664UL];
  int8_t* folded_const_261 = (int8_t*)&__uninitialized_data[216064UL];
  float* folded_const_152 = (float*)&__module_data[216128UL];
  int8_t* folded_const_262 = (int8_t*)&__uninitialized_data[232448UL];
  float* folded_const_149 = (float*)&__module_data[214592UL];
  int8_t* folded_const_263 = (int8_t*)&__uninitialized_data[248832UL];
  float* folded_const_146 = (float*)&__module_data[213056UL];
  int8_t* folded_const_264 = (int8_t*)&__uninitialized_data[265216UL];
  float* folded_const_151 = (float*)&__module_data[215872UL];
  int8_t* folded_const_265 = (int8_t*)&__uninitialized_data[281600UL];
  float* folded_const_148 = (float*)&__module_data[214336UL];
  int8_t* folded_const_266 = (int8_t*)&__uninitialized_data[297984UL];
  float* folded_const_144 = (float*)&__module_data[210496UL];
  int8_t* folded_const_267 = (int8_t*)&__uninitialized_data[314368UL];
  float* folded_const_153 = (float*)&__module_data[217152UL];
  int8_t* folded_const_268 = (int8_t*)&__uninitialized_data[347136UL];
  float* folded_const_150 = (float*)&__module_data[215616UL];
  int8_t* folded_const_269 = (int8_t*)&__uninitialized_data[384000UL];
  float* folded_const_147 = (float*)&__module_data[214080UL];
  int8_t* folded_const_270 = (int8_t*)&__uninitialized_data[420864UL];
  float* folded_const_142 = (float*)&__module_data[207936UL];
  int8_t* folded_const_271 = (int8_t*)&__uninitialized_data[457728UL];
  float* folded_const_139 = (float*)&__module_data[204864UL];
  int8_t* folded_const_272 = (int8_t*)&__uninitialized_data[523264UL];
  float* folded_const_136 = (float*)&__module_data[201792UL];
  int8_t* folded_const_273 = (int8_t*)&__uninitialized_data[588800UL];
  float* folded_const_133 = (float*)&__module_data[198720UL];
  int8_t* folded_const_274 = (int8_t*)&__uninitialized_data[654336UL];
  float* folded_const_141 = (float*)&__module_data[207424UL];
  int8_t* folded_const_275 = (int8_t*)&__uninitialized_data[719872UL];
  float* folded_const_138 = (float*)&__module_data[204352UL];
  int8_t* folded_const_276 = (int8_t*)&__uninitialized_data[785408UL];
  float* folded_const_135 = (float*)&__module_data[201280UL];
  int8_t* folded_const_277 = (int8_t*)&__uninitialized_data[850944UL];
  float* folded_const_145 = (float*)&__module_data[211008UL];
  int8_t* folded_const_278 = (int8_t*)&__uninitialized_data[916480UL];
  float* folded_const_131 = (float*)&__module_data[193600UL];
  int8_t* folded_const_279 = (int8_t*)&__uninitialized_data[1047552UL];
  float* folded_const_143 = (float*)&__module_data[209984UL];
  int8_t* folded_const_280 = (int8_t*)&__uninitialized_data[1178624UL];
  float* folded_const_140 = (float*)&__module_data[206912UL];
  int8_t* folded_const_281 = (int8_t*)&__uninitialized_data[1326080UL];
  float* folded_const_137 = (float*)&__module_data[203840UL];
  int8_t* folded_const_282 = (int8_t*)&__uninitialized_data[1473536UL];
  float* folded_const_134 = (float*)&__module_data[200768UL];
  int8_t* folded_const_283 = (int8_t*)&__uninitialized_data[1620992UL];
  float* folded_const_129 = (float*)&__module_data[188480UL];
  int8_t* folded_const_284 = (int8_t*)&__uninitialized_data[1768448UL];
  float* folded_const_126 = (float*)&__module_data[182336UL];
  int8_t* folded_const_285 = (int8_t*)&__uninitialized_data[2030592UL];
  float* folded_const_123 = (float*)&__module_data[176192UL];
  int8_t* folded_const_286 = (int8_t*)&__uninitialized_data[2292736UL];
  float* folded_const_120 = (float*)&__module_data[170048UL];
  int8_t* folded_const_287 = (int8_t*)&__uninitialized_data[2554880UL];
  float* folded_const_117 = (float*)&__module_data[163904UL];
  int8_t* folded_const_288 = (int8_t*)&__uninitialized_data[2817024UL];
  float* folded_const_114 = (float*)&__module_data[157760UL];
  int8_t* folded_const_289 = (int8_t*)&__uninitialized_data[3079168UL];
  float* folded_const_128 = (float*)&__module_data[187456UL];
  int8_t* folded_const_290 = (int8_t*)&__uninitialized_data[3341312UL];
  float* folded_const_125 = (float*)&__module_data[181312UL];
  int8_t* folded_const_291 = (int8_t*)&__uninitialized_data[3603456UL];
  float* folded_const_122 = (float*)&__module_data[175168UL];
  int8_t* folded_const_292 = (int8_t*)&__uninitialized_data[3865600UL];
  float* folded_const_119 = (float*)&__module_data[169024UL];
  int8_t* folded_const_293 = (int8_t*)&__uninitialized_data[4127744UL];
  float* folded_const_116 = (float*)&__module_data[162880UL];
  int8_t* folded_const_294 = (int8_t*)&__uninitialized_data[4389888UL];
  float* folded_const_132 = (float*)&__module_data[194624UL];
  int8_t* folded_const_295 = (int8_t*)&__uninitialized_data[4652032UL];
  float* folded_const_112 = (float*)&__module_data[147520UL];
  int8_t* folded_const_296 = (int8_t*)&__uninitialized_data[5176320UL];
  float* folded_const_130 = (float*)&__module_data[192576UL];
  int8_t* folded_const_297 = (int8_t*)&__uninitialized_data[5700608UL];
  float* folded_const_127 = (float*)&__module_data[186432UL];
  int8_t* folded_const_298 = (int8_t*)&__uninitialized_data[6290432UL];
  float* folded_const_124 = (float*)&__module_data[180288UL];
  int8_t* folded_const_299 = (int8_t*)&__uninitialized_data[6880256UL];
  float* folded_const_121 = (float*)&__module_data[174144UL];
  int8_t* folded_const_300 = (int8_t*)&__uninitialized_data[7470080UL];
  float* folded_const_118 = (float*)&__module_data[168000UL];
  int8_t* folded_const_301 = (int8_t*)&__uninitialized_data[8059904UL];
  float* folded_const_115 = (float*)&__module_data[161856UL];
  int8_t* folded_const_302 = (int8_t*)&__uninitialized_data[8649728UL];
  float* folded_const_110 = (float*)&__module_data[137280UL];
  int8_t* folded_const_303 = (int8_t*)&__uninitialized_data[9239552UL];
  float* folded_const_107 = (float*)&__module_data[124992UL];
  int8_t* folded_const_304 = (int8_t*)&__uninitialized_data[10288128UL];
  float* folded_const_104 = (float*)&__module_data[112704UL];
  int8_t* folded_const_305 = (int8_t*)&__uninitialized_data[11336704UL];
  float* folded_const_109 = (float*)&__module_data[135232UL];
  int8_t* folded_const_306 = (int8_t*)&__uninitialized_data[12385280UL];
  float* folded_const_106 = (float*)&__module_data[122944UL];
  int8_t* folded_const_307 = (int8_t*)&__uninitialized_data[13433856UL];
  float* folded_const_113 = (float*)&__module_data[149568UL];
  int8_t* folded_const_308 = (int8_t*)&__uninitialized_data[14482432UL];
  float* folded_const_111 = (float*)&__module_data[145472UL];
  int8_t* folded_const_309 = (int8_t*)&__uninitialized_data[16579584UL];
  float* folded_const_108 = (float*)&__module_data[133184UL];
  int8_t* folded_const_310 = (int8_t*)&__uninitialized_data[18938880UL];
  float* folded_const_105 = (float*)&__module_data[120896UL];
  int8_t* folded_const_311 = (int8_t*)&__uninitialized_data[21298176UL];
  bool& is_init = *(bool*)(__module_data + 0);
  int8_t* __rescheduled_0 = (int8_t*)sc_aligned_malloc(__stream, 11796480UL);
  // [f32 [1, 1, 4, 1, 1, 64] @ A1aBCD64b]
  float* buffer_261 = (float*)&__rescheduled_0[0UL];
  reorder__419(buffer_261, folded_const_103);
  mul__570(folded_const_156, buffer_261, folded_const_101);
  mul__572(folded_const_157, &folded_const_102[0UL], folded_const_81);
  mul__574(folded_const_158, &folded_const_80[0UL], folded_const_79);
  // [f32 [1, 1, 4, 1, 1, 64] @ A1aBCD64b]
  float* buffer_265 = (float*)&__rescheduled_0[0UL];
  reorder__424(buffer_265, folded_const_78);
  mul__576(folded_const_159, buffer_265, folded_const_100);
  mul__578(folded_const_160, &folded_const_77[0UL], folded_const_76);
  mul__580(folded_const_161, &folded_const_75[0UL], folded_const_74);
  // [f32 [1, 1, 4, 1, 1, 64] @ A1aBCD64b]
  float* buffer_269 = (float*)&__rescheduled_0[0UL];
  reorder__429(buffer_269, folded_const_73);
  mul__582(folded_const_162, buffer_269, folded_const_99);
  mul__584(folded_const_163, &folded_const_72[0UL], folded_const_71);
  mul__586(folded_const_164, &folded_const_70[0UL], folded_const_69);
  // [f32 [1, 1, 4, 1, 1, 64] @ A1aBCD64b]
  float* buffer_273 = (float*)&__rescheduled_0[0UL];
  reorder__434(buffer_273, folded_const_68);
  mul__588(folded_const_165, buffer_273, folded_const_98);
  // [f32 [1, 1, 8, 1, 1, 64] @ A1aBCD64b]
  float* buffer_275 = (float*)&__rescheduled_0[0UL];
  reorder__437(buffer_275, folded_const_67);
  mul__590(folded_const_166, buffer_275, folded_const_97);
  // [f32 [1, 1, 2, 1, 1, 64] @ A1aBCD64b]
  float* buffer_277 = (float*)&__rescheduled_0[0UL];
  reorder__440(buffer_277, folded_const_66);
  mul__592(folded_const_167, buffer_277, folded_const_65);
  // [f32 [1, 1, 2, 1, 1, 64] @ A1aBCD64b]
  float* buffer_279 = (float*)&__rescheduled_0[0UL];
  reorder__443(buffer_279, folded_const_64);
  mul__594(folded_const_168, buffer_279, folded_const_63);
  // [f32 [1, 1, 8, 1, 1, 64] @ A1aBCD64b]
  float* buffer_281 = (float*)&__rescheduled_0[0UL];
  reorder__446(buffer_281, folded_const_62);
  mul__596(folded_const_169, buffer_281, folded_const_96);
  // [f32 [1, 1, 2, 1, 1, 64] @ A1aBCD64b]
  float* buffer_283 = (float*)&__rescheduled_0[0UL];
  reorder__449(buffer_283, folded_const_61);
  mul__598(folded_const_170, buffer_283, folded_const_60);
  // [f32 [1, 1, 2, 1, 1, 64] @ A1aBCD64b]
  float* buffer_285 = (float*)&__rescheduled_0[0UL];
  reorder__452(buffer_285, folded_const_59);
  mul__600(folded_const_171, buffer_285, folded_const_58);
  // [f32 [1, 1, 8, 1, 1, 64] @ A1aBCD64b]
  float* buffer_287 = (float*)&__rescheduled_0[0UL];
  reorder__455(buffer_287, folded_const_57);
  mul__602(folded_const_172, buffer_287, folded_const_95);
  // [f32 [1, 1, 2, 1, 1, 64] @ A1aBCD64b]
  float* buffer_289 = (float*)&__rescheduled_0[0UL];
  reorder__458(buffer_289, folded_const_56);
  mul__604(folded_const_173, buffer_289, folded_const_55);
  // [f32 [1, 1, 2, 1, 1, 64] @ A1aBCD64b]
  float* buffer_291 = (float*)&__rescheduled_0[0UL];
  reorder__461(buffer_291, folded_const_54);
  mul__606(folded_const_174, buffer_291, folded_const_53);
  // [f32 [1, 1, 8, 1, 1, 64] @ A1aBCD64b]
  float* buffer_293 = (float*)&__rescheduled_0[0UL];
  reorder__464(buffer_293, folded_const_52);
  mul__608(folded_const_175, buffer_293, folded_const_94);
  // [f32 [1, 1, 2, 1, 1, 64] @ A1aBCD64b]
  float* buffer_295 = (float*)&__rescheduled_0[0UL];
  reorder__467(buffer_295, folded_const_51);
  mul__610(folded_const_176, buffer_295, folded_const_50);
  // [f32 [1, 1, 2, 1, 1, 64] @ A1aBCD64b]
  float* buffer_297 = (float*)&__rescheduled_0[0UL];
  reorder__470(buffer_297, folded_const_49);
  mul__612(folded_const_177, buffer_297, folded_const_48);
  // [f32 [1, 1, 8, 1, 1, 64] @ A1aBCD64b]
  float* buffer_299 = (float*)&__rescheduled_0[0UL];
  reorder__473(buffer_299, folded_const_47);
  mul__614(folded_const_178, buffer_299, folded_const_93);
  // [f32 [1, 1, 16, 1, 1, 64] @ A1aBCD64b]
  float* buffer_301 = (float*)&__rescheduled_0[0UL];
  reorder__476(buffer_301, folded_const_46);
  mul__616(folded_const_179, buffer_301, folded_const_92);
  // [f32 [1, 1, 4, 1, 1, 64] @ A1aBCD64b]
  float* buffer_303 = (float*)&__rescheduled_0[0UL];
  reorder__479(buffer_303, folded_const_45);
  mul__618(folded_const_180, buffer_303, folded_const_44);
  // [f32 [1, 1, 4, 1, 1, 64] @ A1aBCD64b]
  float* buffer_305 = (float*)&__rescheduled_0[0UL];
  reorder__482(buffer_305, folded_const_43);
  mul__620(folded_const_181, buffer_305, folded_const_42);
  // [f32 [1, 1, 16, 1, 1, 64] @ A1aBCD64b]
  float* buffer_307 = (float*)&__rescheduled_0[0UL];
  reorder__485(buffer_307, folded_const_41);
  mul__622(folded_const_182, buffer_307, folded_const_91);
  // [f32 [1, 1, 4, 1, 1, 64] @ A1aBCD64b]
  float* buffer_309 = (float*)&__rescheduled_0[0UL];
  reorder__488(buffer_309, folded_const_40);
  mul__624(folded_const_183, buffer_309, folded_const_39);
  // [f32 [1, 1, 4, 1, 1, 64] @ A1aBCD64b]
  float* buffer_311 = (float*)&__rescheduled_0[0UL];
  reorder__491(buffer_311, folded_const_38);
  mul__626(folded_const_184, buffer_311, folded_const_37);
  // [f32 [1, 1, 16, 1, 1, 64] @ A1aBCD64b]
  float* buffer_313 = (float*)&__rescheduled_0[0UL];
  reorder__494(buffer_313, folded_const_36);
  mul__628(folded_const_185, buffer_313, folded_const_90);
  // [f32 [1, 1, 4, 1, 1, 64] @ A1aBCD64b]
  float* buffer_315 = (float*)&__rescheduled_0[0UL];
  reorder__497(buffer_315, folded_const_35);
  mul__630(folded_const_186, buffer_315, folded_const_34);
  // [f32 [1, 1, 4, 1, 1, 64] @ A1aBCD64b]
  float* buffer_317 = (float*)&__rescheduled_0[0UL];
  reorder__500(buffer_317, folded_const_33);
  mul__632(folded_const_187, buffer_317, folded_const_32);
  // [f32 [1, 1, 16, 1, 1, 64] @ A1aBCD64b]
  float* buffer_319 = (float*)&__rescheduled_0[0UL];
  reorder__503(buffer_319, folded_const_31);
  mul__634(folded_const_188, buffer_319, folded_const_89);
  // [f32 [1, 1, 4, 1, 1, 64] @ A1aBCD64b]
  float* buffer_321 = (float*)&__rescheduled_0[0UL];
  reorder__506(buffer_321, folded_const_30);
  mul__636(folded_const_189, buffer_321, folded_const_29);
  // [f32 [1, 1, 4, 1, 1, 64] @ A1aBCD64b]
  float* buffer_323 = (float*)&__rescheduled_0[0UL];
  reorder__509(buffer_323, folded_const_28);
  mul__638(folded_const_190, buffer_323, folded_const_27);
  // [f32 [1, 1, 16, 1, 1, 64] @ A1aBCD64b]
  float* buffer_325 = (float*)&__rescheduled_0[0UL];
  reorder__512(buffer_325, folded_const_26);
  mul__640(folded_const_191, buffer_325, folded_const_88);
  // [f32 [1, 1, 4, 1, 1, 64] @ A1aBCD64b]
  float* buffer_327 = (float*)&__rescheduled_0[0UL];
  reorder__515(buffer_327, folded_const_25);
  mul__642(folded_const_192, buffer_327, folded_const_24);
  // [f32 [1, 1, 4, 1, 1, 64] @ A1aBCD64b]
  float* buffer_329 = (float*)&__rescheduled_0[0UL];
  reorder__518(buffer_329, folded_const_23);
  mul__644(folded_const_193, buffer_329, folded_const_22);
  // [f32 [1, 1, 16, 1, 1, 64] @ A1aBCD64b]
  float* buffer_331 = (float*)&__rescheduled_0[0UL];
  reorder__521(buffer_331, folded_const_21);
  mul__646(folded_const_194, buffer_331, folded_const_87);
  // [f32 [1, 1, 4, 1, 1, 64] @ A1aBCD64b]
  float* buffer_333 = (float*)&__rescheduled_0[0UL];
  reorder__524(buffer_333, folded_const_20);
  mul__648(folded_const_195, buffer_333, folded_const_19);
  // [f32 [1, 1, 4, 1, 1, 64] @ A1aBCD64b]
  float* buffer_335 = (float*)&__rescheduled_0[0UL];
  reorder__527(buffer_335, folded_const_18);
  mul__650(folded_const_196, buffer_335, folded_const_17);
  // [f32 [1, 1, 16, 1, 1, 64] @ A1aBCD64b]
  float* buffer_337 = (float*)&__rescheduled_0[0UL];
  reorder__530(buffer_337, folded_const_16);
  mul__652(folded_const_197, buffer_337, folded_const_86);
  // [f32 [1, 1, 4, 1, 1, 512] @ A1aBCD512b]
  float* buffer_339 = (float*)&__rescheduled_0[0UL];
  reorder__533(buffer_339, folded_const_15);
  mul__654(folded_const_198, buffer_339, folded_const_85);
  mul__656(folded_const_199, &folded_const_14[0UL], folded_const_13);
  // [f32 [1, 1, 2, 1, 1, 256] @ A1aBCD256b]
  float* buffer_342 = (float*)&__rescheduled_0[0UL];
  reorder__537(buffer_342, folded_const_12);
  mul__658(folded_const_200, buffer_342, folded_const_11);
  // [f32 [1, 1, 4, 1, 1, 512] @ A1aBCD512b]
  float* buffer_344 = (float*)&__rescheduled_0[0UL];
  reorder__540(buffer_344, folded_const_10);
  mul__660(folded_const_201, buffer_344, folded_const_84);
  // [f32 [1, 1, 8, 1, 1, 64] @ A1aBCD64b]
  float* buffer_346 = (float*)&__rescheduled_0[0UL];
  reorder__543(buffer_346, folded_const_9);
  mul__662(folded_const_202, buffer_346, folded_const_8);
  // [f32 [1, 1, 4, 1, 1, 128] @ A1aBCD128b]
  float* buffer_348 = (float*)&__rescheduled_0[0UL];
  reorder__546(buffer_348, folded_const_7);
  mul__664(folded_const_203, buffer_348, folded_const_6);
  // [f32 [1, 1, 4, 1, 1, 512] @ A1aBCD512b]
  float* buffer_350 = (float*)&__rescheduled_0[0UL];
  reorder__549(buffer_350, folded_const_5);
  mul__666(folded_const_204, buffer_350, folded_const_83);
  // [f32 [1, 1, 2, 1, 1, 256] @ A1aBCD256b]
  float* buffer_352 = (float*)&__rescheduled_0[0UL];
  reorder__552(buffer_352, folded_const_4);
  mul__668(folded_const_205, buffer_352, folded_const_3);
  // [f32 [1, 1, 8, 1, 1, 64] @ A1aBCD64b]
  float* buffer_354 = (float*)&__rescheduled_0[0UL];
  reorder__555(buffer_354, folded_const_2);
  mul__670(folded_const_206, buffer_354, folded_const_1);
  // [f32 [1, 1, 4, 1, 1, 512] @ A1aBCD512b]
  float* buffer_356 = (float*)&__rescheduled_0[0UL];
  reorder__558(buffer_356, folded_const_0);
  mul__672(folded_const_207, buffer_356, folded_const_82);
  mul__573(folded_const_208, &res2a_bias_0[0], folded_const_81);
  mul__575(folded_const_209, &res2a_bias_1[0], folded_const_79);
  mul__579(folded_const_210, &res2b_bias_0[0], folded_const_76);
  mul__581(folded_const_211, &res2b_bias_1[0], folded_const_74);
  mul__585(folded_const_212, &res2c_bias_0[0], folded_const_71);
  mul__587(folded_const_213, &res2c_bias_1[0], folded_const_69);
  // [f32 [1, 1, 2, 1, 1, 64] @ A1aBCD64b]
  float* buffer_364 = (float*)&__rescheduled_0[0UL];
  reorder__441(buffer_364, &res3a_bias_0[0]);
  mul__593(folded_const_214, buffer_364, folded_const_65);
  // [f32 [1, 1, 2, 1, 1, 64] @ A1aBCD64b]
  float* buffer_366 = (float*)&__rescheduled_0[0UL];
  reorder__444(buffer_366, &res3a_bias_1[0]);
  mul__595(folded_const_215, buffer_366, folded_const_63);
  // [f32 [1, 1, 2, 1, 1, 64] @ A1aBCD64b]
  float* buffer_368 = (float*)&__rescheduled_0[0UL];
  reorder__450(buffer_368, &res3b_bias_0[0]);
  mul__599(folded_const_216, buffer_368, folded_const_60);
  // [f32 [1, 1, 2, 1, 1, 64] @ A1aBCD64b]
  float* buffer_370 = (float*)&__rescheduled_0[0UL];
  reorder__453(buffer_370, &res3b_bias_1[0]);
  mul__601(folded_const_217, buffer_370, folded_const_58);
  // [f32 [1, 1, 2, 1, 1, 64] @ A1aBCD64b]
  float* buffer_372 = (float*)&__rescheduled_0[0UL];
  reorder__459(buffer_372, &res3c_bias_0[0]);
  mul__605(folded_const_218, buffer_372, folded_const_55);
  // [f32 [1, 1, 2, 1, 1, 64] @ A1aBCD64b]
  float* buffer_374 = (float*)&__rescheduled_0[0UL];
  reorder__462(buffer_374, &res3c_bias_1[0]);
  mul__607(folded_const_219, buffer_374, folded_const_53);
  // [f32 [1, 1, 2, 1, 1, 64] @ A1aBCD64b]
  float* buffer_376 = (float*)&__rescheduled_0[0UL];
  reorder__468(buffer_376, &res3d_bias_0[0]);
  mul__611(folded_const_220, buffer_376, folded_const_50);
  // [f32 [1, 1, 2, 1, 1, 64] @ A1aBCD64b]
  float* buffer_378 = (float*)&__rescheduled_0[0UL];
  reorder__471(buffer_378, &res3d_bias_1[0]);
  mul__613(folded_const_221, buffer_378, folded_const_48);
  // [f32 [1, 1, 4, 1, 1, 64] @ A1aBCD64b]
  float* buffer_380 = (float*)&__rescheduled_0[0UL];
  reorder__420(buffer_380, &res2a_bias_b[0]);
  mul__571(folded_const_222, buffer_380, folded_const_101);
  // [f32 [1, 1, 4, 1, 1, 64] @ A1aBCD64b]
  float* buffer_382 = (float*)&__rescheduled_0[0UL];
  reorder__425(buffer_382, &res2a_bias_2[0]);
  mul__577(folded_const_223, buffer_382, folded_const_100);
  // [f32 [1, 1, 4, 1, 1, 64] @ A1aBCD64b]
  float* buffer_384 = (float*)&__rescheduled_0[0UL];
  reorder__430(buffer_384, &res2b_bias_2[0]);
  mul__583(folded_const_224, buffer_384, folded_const_99);
  // [f32 [1, 1, 4, 1, 1, 64] @ A1aBCD64b]
  float* buffer_386 = (float*)&__rescheduled_0[0UL];
  reorder__435(buffer_386, &res2c_bias_2[0]);
  mul__589(folded_const_225, buffer_386, folded_const_98);
  // [f32 [1, 1, 4, 1, 1, 64] @ A1aBCD64b]
  float* buffer_388 = (float*)&__rescheduled_0[0UL];
  reorder__480(buffer_388, &res4a_bias_0[0]);
  mul__619(folded_const_226, buffer_388, folded_const_44);
  // [f32 [1, 1, 4, 1, 1, 64] @ A1aBCD64b]
  float* buffer_390 = (float*)&__rescheduled_0[0UL];
  reorder__483(buffer_390, &res4a_bias_1[0]);
  mul__621(folded_const_227, buffer_390, folded_const_42);
  // [f32 [1, 1, 4, 1, 1, 64] @ A1aBCD64b]
  float* buffer_392 = (float*)&__rescheduled_0[0UL];
  reorder__489(buffer_392, &res4b_bias_0[0]);
  mul__625(folded_const_228, buffer_392, folded_const_39);
  // [f32 [1, 1, 4, 1, 1, 64] @ A1aBCD64b]
  float* buffer_394 = (float*)&__rescheduled_0[0UL];
  reorder__492(buffer_394, &res4b_bias_1[0]);
  mul__627(folded_const_229, buffer_394, folded_const_37);
  // [f32 [1, 1, 4, 1, 1, 64] @ A1aBCD64b]
  float* buffer_396 = (float*)&__rescheduled_0[0UL];
  reorder__498(buffer_396, &res4c_bias_0[0]);
  mul__631(folded_const_230, buffer_396, folded_const_34);
  // [f32 [1, 1, 4, 1, 1, 64] @ A1aBCD64b]
  float* buffer_398 = (float*)&__rescheduled_0[0UL];
  reorder__501(buffer_398, &res4c_bias_1[0]);
  mul__633(folded_const_231, buffer_398, folded_const_32);
  // [f32 [1, 1, 4, 1, 1, 64] @ A1aBCD64b]
  float* buffer_400 = (float*)&__rescheduled_0[0UL];
  reorder__507(buffer_400, &res4d_bias_0[0]);
  mul__637(folded_const_232, buffer_400, folded_const_29);
  // [f32 [1, 1, 4, 1, 1, 64] @ A1aBCD64b]
  float* buffer_402 = (float*)&__rescheduled_0[0UL];
  reorder__510(buffer_402, &res4d_bias_1[0]);
  mul__639(folded_const_233, buffer_402, folded_const_27);
  // [f32 [1, 1, 4, 1, 1, 64] @ A1aBCD64b]
  float* buffer_404 = (float*)&__rescheduled_0[0UL];
  reorder__516(buffer_404, &res4e_bias_0[0]);
  mul__643(folded_const_234, buffer_404, folded_const_24);
  // [f32 [1, 1, 4, 1, 1, 64] @ A1aBCD64b]
  float* buffer_406 = (float*)&__rescheduled_0[0UL];
  reorder__519(buffer_406, &res4e_bias_1[0]);
  mul__645(folded_const_235, buffer_406, folded_const_22);
  // [f32 [1, 1, 4, 1, 1, 64] @ A1aBCD64b]
  float* buffer_408 = (float*)&__rescheduled_0[0UL];
  reorder__525(buffer_408, &res4f_bias_0[0]);
  mul__649(folded_const_236, buffer_408, folded_const_19);
  // [f32 [1, 1, 4, 1, 1, 64] @ A1aBCD64b]
  float* buffer_410 = (float*)&__rescheduled_0[0UL];
  reorder__528(buffer_410, &res4f_bias_1[0]);
  mul__651(folded_const_237, buffer_410, folded_const_17);
  // [f32 [1, 1, 8, 1, 1, 64] @ A1aBCD64b]
  float* buffer_412 = (float*)&__rescheduled_0[0UL];
  reorder__438(buffer_412, &res3a_bias_b[0]);
  mul__591(folded_const_238, buffer_412, folded_const_97);
  // [f32 [1, 1, 8, 1, 1, 64] @ A1aBCD64b]
  float* buffer_414 = (float*)&__rescheduled_0[0UL];
  reorder__447(buffer_414, &res3a_bias_2[0]);
  mul__597(folded_const_239, buffer_414, folded_const_96);
  // [f32 [1, 1, 8, 1, 1, 64] @ A1aBCD64b]
  float* buffer_416 = (float*)&__rescheduled_0[0UL];
  reorder__456(buffer_416, &res3b_bias_2[0]);
  mul__603(folded_const_240, buffer_416, folded_const_95);
  // [f32 [1, 1, 8, 1, 1, 64] @ A1aBCD64b]
  float* buffer_418 = (float*)&__rescheduled_0[0UL];
  reorder__465(buffer_418, &res3c_bias_2[0]);
  mul__609(folded_const_241, buffer_418, folded_const_94);
  // [f32 [1, 1, 8, 1, 1, 64] @ A1aBCD64b]
  float* buffer_420 = (float*)&__rescheduled_0[0UL];
  reorder__474(buffer_420, &res3d_bias_2[0]);
  mul__615(folded_const_242, buffer_420, folded_const_93);
  mul__657(folded_const_243, &res5a_bias_0[0], folded_const_13);
  // [f32 [1, 1, 2, 1, 1, 256] @ A1aBCD256b]
  float* buffer_423 = (float*)&__rescheduled_0[0UL];
  reorder__538(buffer_423, &res5a_bias_1[0]);
  mul__659(folded_const_244, buffer_423, folded_const_11);
  // [f32 [1, 1, 8, 1, 1, 64] @ A1aBCD64b]
  float* buffer_425 = (float*)&__rescheduled_0[0UL];
  reorder__544(buffer_425, &res5b_bias_0[0]);
  mul__663(folded_const_245, buffer_425, folded_const_8);
  // [f32 [1, 1, 4, 1, 1, 128] @ A1aBCD128b]
  float* buffer_427 = (float*)&__rescheduled_0[0UL];
  reorder__547(buffer_427, &res5b_bias_1[0]);
  mul__665(folded_const_246, buffer_427, folded_const_6);
  // [f32 [1, 1, 2, 1, 1, 256] @ A1aBCD256b]
  float* buffer_429 = (float*)&__rescheduled_0[0UL];
  reorder__553(buffer_429, &res5c_bias_0[0]);
  mul__669(folded_const_247, buffer_429, folded_const_3);
  // [f32 [1, 1, 8, 1, 1, 64] @ A1aBCD64b]
  float* buffer_431 = (float*)&__rescheduled_0[0UL];
  reorder__556(buffer_431, &res5c_bias_1[0]);
  mul__671(folded_const_248, buffer_431, folded_const_1);
  // [f32 [1, 1, 16, 1, 1, 64] @ A1aBCD64b]
  float* buffer_433 = (float*)&__rescheduled_0[0UL];
  reorder__477(buffer_433, &res4a_bias_b[0]);
  mul__617(folded_const_249, buffer_433, folded_const_92);
  // [f32 [1, 1, 16, 1, 1, 64] @ A1aBCD64b]
  float* buffer_435 = (float*)&__rescheduled_0[0UL];
  reorder__486(buffer_435, &res4a_bias_2[0]);
  mul__623(folded_const_250, buffer_435, folded_const_91);
  // [f32 [1, 1, 16, 1, 1, 64] @ A1aBCD64b]
  float* buffer_437 = (float*)&__rescheduled_0[0UL];
  reorder__495(buffer_437, &res4b_bias_2[0]);
  mul__629(folded_const_251, buffer_437, folded_const_90);
  // [f32 [1, 1, 16, 1, 1, 64] @ A1aBCD64b]
  float* buffer_439 = (float*)&__rescheduled_0[0UL];
  reorder__504(buffer_439, &res4c_bias_2[0]);
  mul__635(folded_const_252, buffer_439, folded_const_89);
  // [f32 [1, 1, 16, 1, 1, 64] @ A1aBCD64b]
  float* buffer_441 = (float*)&__rescheduled_0[0UL];
  reorder__513(buffer_441, &res4d_bias_2[0]);
  mul__641(folded_const_253, buffer_441, folded_const_88);
  // [f32 [1, 1, 16, 1, 1, 64] @ A1aBCD64b]
  float* buffer_443 = (float*)&__rescheduled_0[0UL];
  reorder__522(buffer_443, &res4e_bias_2[0]);
  mul__647(folded_const_254, buffer_443, folded_const_87);
  // [f32 [1, 1, 16, 1, 1, 64] @ A1aBCD64b]
  float* buffer_445 = (float*)&__rescheduled_0[0UL];
  reorder__531(buffer_445, &res4f_bias_2[0]);
  mul__653(folded_const_255, buffer_445, folded_const_86);
  // [f32 [1, 1, 4, 1, 1, 512] @ A1aBCD512b]
  float* buffer_447 = (float*)&__rescheduled_0[0UL];
  reorder__534(buffer_447, &res5a_bias_b[0]);
  mul__655(folded_const_256, buffer_447, folded_const_85);
  // [f32 [1, 1, 4, 1, 1, 512] @ A1aBCD512b]
  float* buffer_449 = (float*)&__rescheduled_0[0UL];
  reorder__541(buffer_449, &res5a_bias_2[0]);
  mul__661(folded_const_257, buffer_449, folded_const_84);
  // [f32 [1, 1, 4, 1, 1, 512] @ A1aBCD512b]
  float* buffer_451 = (float*)&__rescheduled_0[0UL];
  reorder__550(buffer_451, &res5b_bias_2[0]);
  mul__667(folded_const_258, buffer_451, folded_const_83);
  // [f32 [1, 1, 4, 1, 1, 512] @ A1aBCD512b]
  float* buffer_453 = (float*)&__rescheduled_0[0UL];
  reorder__559(buffer_453, &res5c_bias_2[0]);
  mul__673(folded_const_259, buffer_453, folded_const_82);
  // [f32 [64, 64, 1, 1] @ ABCD]
  float* buffer_455 = (float*)&__rescheduled_0[0UL];
  mul__110(buffer_455, res2a_weight_0, folded_const_154);
  // [s8 [64, 64, 1, 1] @ ABCD]
  int8_t* buffer_456 = (int8_t*)&__rescheduled_0[16384UL];
  cast__111(buffer_456, buffer_455);
  reorder__421(folded_const_260, buffer_456);
  // [f32 [256, 64, 1, 1] @ ABCD]
  float* buffer_458 = (float*)&__rescheduled_0[0UL];
  mul__107(buffer_458, res2a_weight_b, folded_const_155);
  // [s8 [256, 64, 1, 1] @ ABCD]
  int8_t* buffer_459 = (int8_t*)&__rescheduled_0[65536UL];
  cast__108(buffer_459, buffer_458);
  reorder__418(folded_const_261, buffer_459);
  // [f32 [256, 64, 1, 1] @ ABCD]
  float* buffer_461 = (float*)&__rescheduled_0[0UL];
  mul__116(buffer_461, res2a_weight_2, folded_const_152);
  // [s8 [256, 64, 1, 1] @ ABCD]
  int8_t* buffer_462 = (int8_t*)&__rescheduled_0[65536UL];
  cast__117(buffer_462, buffer_461);
  reorder__423(folded_const_262, buffer_462);
  // [f32 [256, 64, 1, 1] @ ABCD]
  float* buffer_464 = (float*)&__rescheduled_0[0UL];
  mul__125(buffer_464, res2b_weight_2, folded_const_149);
  // [s8 [256, 64, 1, 1] @ ABCD]
  int8_t* buffer_465 = (int8_t*)&__rescheduled_0[65536UL];
  cast__126(buffer_465, buffer_464);
  reorder__428(folded_const_263, buffer_465);
  // [f32 [256, 64, 1, 1] @ ABCD]
  float* buffer_467 = (float*)&__rescheduled_0[0UL];
  mul__134(buffer_467, res2c_weight_2, folded_const_146);
  // [s8 [256, 64, 1, 1] @ ABCD]
  int8_t* buffer_468 = (int8_t*)&__rescheduled_0[65536UL];
  cast__135(buffer_468, buffer_467);
  reorder__433(folded_const_264, buffer_468);
  // [f32 [64, 256, 1, 1] @ ABCD]
  float* buffer_470 = (float*)&__rescheduled_0[0UL];
  mul__119(buffer_470, res2b_weight_0, folded_const_151);
  // [s8 [64, 256, 1, 1] @ ABCD]
  int8_t* buffer_471 = (int8_t*)&__rescheduled_0[65536UL];
  cast__120(buffer_471, buffer_470);
  reorder__426(folded_const_265, buffer_471);
  // [f32 [64, 256, 1, 1] @ ABCD]
  float* buffer_473 = (float*)&__rescheduled_0[0UL];
  mul__128(buffer_473, res2c_weight_0, folded_const_148);
  // [s8 [64, 256, 1, 1] @ ABCD]
  int8_t* buffer_474 = (int8_t*)&__rescheduled_0[65536UL];
  cast__129(buffer_474, buffer_473);
  reorder__431(folded_const_266, buffer_474);
  // [f32 [128, 256, 1, 1] @ ABCD]
  float* buffer_476 = (float*)&__rescheduled_0[0UL];
  mul__140(buffer_476, res3a_weight_0, folded_const_144);
  // [s8 [128, 256, 1, 1] @ ABCD]
  int8_t* buffer_477 = (int8_t*)&__rescheduled_0[131072UL];
  cast__141(buffer_477, buffer_476);
  reorder__439(folded_const_267, buffer_477);
  // [f32 [64, 64, 3, 3] @ ABCD]
  float* buffer_479 = (float*)&__rescheduled_0[0UL];
  mul__113(buffer_479, res2a_weight_1, folded_const_153);
  // [s8 [64, 64, 3, 3] @ ABCD]
  int8_t* buffer_480 = (int8_t*)&__rescheduled_0[147456UL];
  cast__114(buffer_480, buffer_479);
  reorder__422(folded_const_268, buffer_480);
  // [f32 [64, 64, 3, 3] @ ABCD]
  float* buffer_482 = (float*)&__rescheduled_0[0UL];
  mul__122(buffer_482, res2b_weight_1, folded_const_150);
  // [s8 [64, 64, 3, 3] @ ABCD]
  int8_t* buffer_483 = (int8_t*)&__rescheduled_0[147456UL];
  cast__123(buffer_483, buffer_482);
  reorder__427(folded_const_269, buffer_483);
  // [f32 [64, 64, 3, 3] @ ABCD]
  float* buffer_485 = (float*)&__rescheduled_0[0UL];
  mul__131(buffer_485, res2c_weight_1, folded_const_147);
  // [s8 [64, 64, 3, 3] @ ABCD]
  int8_t* buffer_486 = (int8_t*)&__rescheduled_0[147456UL];
  cast__132(buffer_486, buffer_485);
  reorder__432(folded_const_270, buffer_486);
  // [f32 [512, 128, 1, 1] @ ABCD]
  float* buffer_488 = (float*)&__rescheduled_0[0UL];
  mul__146(buffer_488, res3a_weight_2, folded_const_142);
  // [s8 [512, 128, 1, 1] @ ABCD]
  int8_t* buffer_489 = (int8_t*)&__rescheduled_0[262144UL];
  cast__147(buffer_489, buffer_488);
  reorder__445(folded_const_271, buffer_489);
  // [f32 [512, 128, 1, 1] @ ABCD]
  float* buffer_491 = (float*)&__rescheduled_0[0UL];
  mul__155(buffer_491, res3b_weight_2, folded_const_139);
  // [s8 [512, 128, 1, 1] @ ABCD]
  int8_t* buffer_492 = (int8_t*)&__rescheduled_0[262144UL];
  cast__156(buffer_492, buffer_491);
  reorder__454(folded_const_272, buffer_492);
  // [f32 [512, 128, 1, 1] @ ABCD]
  float* buffer_494 = (float*)&__rescheduled_0[0UL];
  mul__164(buffer_494, res3c_weight_2, folded_const_136);
  // [s8 [512, 128, 1, 1] @ ABCD]
  int8_t* buffer_495 = (int8_t*)&__rescheduled_0[262144UL];
  cast__165(buffer_495, buffer_494);
  reorder__463(folded_const_273, buffer_495);
  // [f32 [512, 128, 1, 1] @ ABCD]
  float* buffer_497 = (float*)&__rescheduled_0[0UL];
  mul__173(buffer_497, res3d_weight_2, folded_const_133);
  // [s8 [512, 128, 1, 1] @ ABCD]
  int8_t* buffer_498 = (int8_t*)&__rescheduled_0[262144UL];
  cast__174(buffer_498, buffer_497);
  reorder__472(folded_const_274, buffer_498);
  // [f32 [128, 512, 1, 1] @ ABCD]
  float* buffer_500 = (float*)&__rescheduled_0[0UL];
  mul__149(buffer_500, res3b_weight_0, folded_const_141);
  // [s8 [128, 512, 1, 1] @ ABCD]
  int8_t* buffer_501 = (int8_t*)&__rescheduled_0[262144UL];
  cast__150(buffer_501, buffer_500);
  reorder__448(folded_const_275, buffer_501);
  // [f32 [128, 512, 1, 1] @ ABCD]
  float* buffer_503 = (float*)&__rescheduled_0[0UL];
  mul__158(buffer_503, res3c_weight_0, folded_const_138);
  // [s8 [128, 512, 1, 1] @ ABCD]
  int8_t* buffer_504 = (int8_t*)&__rescheduled_0[262144UL];
  cast__159(buffer_504, buffer_503);
  reorder__457(folded_const_276, buffer_504);
  // [f32 [128, 512, 1, 1] @ ABCD]
  float* buffer_506 = (float*)&__rescheduled_0[0UL];
  mul__167(buffer_506, res3d_weight_0, folded_const_135);
  // [s8 [128, 512, 1, 1] @ ABCD]
  int8_t* buffer_507 = (int8_t*)&__rescheduled_0[262144UL];
  cast__168(buffer_507, buffer_506);
  reorder__466(folded_const_277, buffer_507);
  // [f32 [512, 256, 1, 1] @ ABCD]
  float* buffer_509 = (float*)&__rescheduled_0[0UL];
  mul__137(buffer_509, res3a_weight_b, folded_const_145);
  // [s8 [512, 256, 1, 1] @ ABCD]
  int8_t* buffer_510 = (int8_t*)&__rescheduled_0[524288UL];
  cast__138(buffer_510, buffer_509);
  reorder__436(folded_const_278, buffer_510);
  // [f32 [256, 512, 1, 1] @ ABCD]
  float* buffer_512 = (float*)&__rescheduled_0[0UL];
  mul__179(buffer_512, res4a_weight_0, folded_const_131);
  // [s8 [256, 512, 1, 1] @ ABCD]
  int8_t* buffer_513 = (int8_t*)&__rescheduled_0[524288UL];
  cast__180(buffer_513, buffer_512);
  reorder__478(folded_const_279, buffer_513);
  // [f32 [128, 128, 3, 3] @ ABCD]
  float* buffer_515 = (float*)&__rescheduled_0[0UL];
  mul__143(buffer_515, res3a_weight_1, folded_const_143);
  // [s8 [128, 128, 3, 3] @ ABCD]
  int8_t* buffer_516 = (int8_t*)&__rescheduled_0[589824UL];
  cast__144(buffer_516, buffer_515);
  reorder__442(folded_const_280, buffer_516);
  // [f32 [128, 128, 3, 3] @ ABCD]
  float* buffer_518 = (float*)&__rescheduled_0[0UL];
  mul__152(buffer_518, res3b_weight_1, folded_const_140);
  // [s8 [128, 128, 3, 3] @ ABCD]
  int8_t* buffer_519 = (int8_t*)&__rescheduled_0[589824UL];
  cast__153(buffer_519, buffer_518);
  reorder__451(folded_const_281, buffer_519);
  // [f32 [128, 128, 3, 3] @ ABCD]
  float* buffer_521 = (float*)&__rescheduled_0[0UL];
  mul__161(buffer_521, res3c_weight_1, folded_const_137);
  // [s8 [128, 128, 3, 3] @ ABCD]
  int8_t* buffer_522 = (int8_t*)&__rescheduled_0[589824UL];
  cast__162(buffer_522, buffer_521);
  reorder__460(folded_const_282, buffer_522);
  // [f32 [128, 128, 3, 3] @ ABCD]
  float* buffer_524 = (float*)&__rescheduled_0[0UL];
  mul__170(buffer_524, res3d_weight_1, folded_const_134);
  // [s8 [128, 128, 3, 3] @ ABCD]
  int8_t* buffer_525 = (int8_t*)&__rescheduled_0[589824UL];
  cast__171(buffer_525, buffer_524);
  reorder__469(folded_const_283, buffer_525);
  // [f32 [1024, 256, 1, 1] @ ABCD]
  float* buffer_527 = (float*)&__rescheduled_0[0UL];
  mul__185(buffer_527, res4a_weight_2, folded_const_129);
  // [s8 [1024, 256, 1, 1] @ ABCD]
  int8_t* buffer_528 = (int8_t*)&__rescheduled_0[1048576UL];
  cast__186(buffer_528, buffer_527);
  reorder__484(folded_const_284, buffer_528);
  // [f32 [1024, 256, 1, 1] @ ABCD]
  float* buffer_530 = (float*)&__rescheduled_0[0UL];
  mul__194(buffer_530, res4b_weight_2, folded_const_126);
  // [s8 [1024, 256, 1, 1] @ ABCD]
  int8_t* buffer_531 = (int8_t*)&__rescheduled_0[1048576UL];
  cast__195(buffer_531, buffer_530);
  reorder__493(folded_const_285, buffer_531);
  // [f32 [1024, 256, 1, 1] @ ABCD]
  float* buffer_533 = (float*)&__rescheduled_0[0UL];
  mul__203(buffer_533, res4c_weight_2, folded_const_123);
  // [s8 [1024, 256, 1, 1] @ ABCD]
  int8_t* buffer_534 = (int8_t*)&__rescheduled_0[1048576UL];
  cast__204(buffer_534, buffer_533);
  reorder__502(folded_const_286, buffer_534);
  // [f32 [1024, 256, 1, 1] @ ABCD]
  float* buffer_536 = (float*)&__rescheduled_0[0UL];
  mul__212(buffer_536, res4d_weight_2, folded_const_120);
  // [s8 [1024, 256, 1, 1] @ ABCD]
  int8_t* buffer_537 = (int8_t*)&__rescheduled_0[1048576UL];
  cast__213(buffer_537, buffer_536);
  reorder__511(folded_const_287, buffer_537);
  // [f32 [1024, 256, 1, 1] @ ABCD]
  float* buffer_539 = (float*)&__rescheduled_0[0UL];
  mul__221(buffer_539, res4e_weight_2, folded_const_117);
  // [s8 [1024, 256, 1, 1] @ ABCD]
  int8_t* buffer_540 = (int8_t*)&__rescheduled_0[1048576UL];
  cast__222(buffer_540, buffer_539);
  reorder__520(folded_const_288, buffer_540);
  // [f32 [1024, 256, 1, 1] @ ABCD]
  float* buffer_542 = (float*)&__rescheduled_0[0UL];
  mul__230(buffer_542, res4f_weight_2, folded_const_114);
  // [s8 [1024, 256, 1, 1] @ ABCD]
  int8_t* buffer_543 = (int8_t*)&__rescheduled_0[1048576UL];
  cast__231(buffer_543, buffer_542);
  reorder__529(folded_const_289, buffer_543);
  // [f32 [256, 1024, 1, 1] @ ABCD]
  float* buffer_545 = (float*)&__rescheduled_0[0UL];
  mul__188(buffer_545, res4b_weight_0, folded_const_128);
  // [s8 [256, 1024, 1, 1] @ ABCD]
  int8_t* buffer_546 = (int8_t*)&__rescheduled_0[1048576UL];
  cast__189(buffer_546, buffer_545);
  reorder__487(folded_const_290, buffer_546);
  // [f32 [256, 1024, 1, 1] @ ABCD]
  float* buffer_548 = (float*)&__rescheduled_0[0UL];
  mul__197(buffer_548, res4c_weight_0, folded_const_125);
  // [s8 [256, 1024, 1, 1] @ ABCD]
  int8_t* buffer_549 = (int8_t*)&__rescheduled_0[1048576UL];
  cast__198(buffer_549, buffer_548);
  reorder__496(folded_const_291, buffer_549);
  // [f32 [256, 1024, 1, 1] @ ABCD]
  float* buffer_551 = (float*)&__rescheduled_0[0UL];
  mul__206(buffer_551, res4d_weight_0, folded_const_122);
  // [s8 [256, 1024, 1, 1] @ ABCD]
  int8_t* buffer_552 = (int8_t*)&__rescheduled_0[1048576UL];
  cast__207(buffer_552, buffer_551);
  reorder__505(folded_const_292, buffer_552);
  // [f32 [256, 1024, 1, 1] @ ABCD]
  float* buffer_554 = (float*)&__rescheduled_0[0UL];
  mul__215(buffer_554, res4e_weight_0, folded_const_119);
  // [s8 [256, 1024, 1, 1] @ ABCD]
  int8_t* buffer_555 = (int8_t*)&__rescheduled_0[1048576UL];
  cast__216(buffer_555, buffer_554);
  reorder__514(folded_const_293, buffer_555);
  // [f32 [256, 1024, 1, 1] @ ABCD]
  float* buffer_557 = (float*)&__rescheduled_0[0UL];
  mul__224(buffer_557, res4f_weight_0, folded_const_116);
  // [s8 [256, 1024, 1, 1] @ ABCD]
  int8_t* buffer_558 = (int8_t*)&__rescheduled_0[1048576UL];
  cast__225(buffer_558, buffer_557);
  reorder__523(folded_const_294, buffer_558);
  // [f32 [1024, 512, 1, 1] @ ABCD]
  float* buffer_560 = (float*)&__rescheduled_0[0UL];
  mul__176(buffer_560, res4a_weight_b, folded_const_132);
  // [s8 [1024, 512, 1, 1] @ ABCD]
  int8_t* buffer_561 = (int8_t*)&__rescheduled_0[2097152UL];
  cast__177(buffer_561, buffer_560);
  reorder__475(folded_const_295, buffer_561);
  // [f32 [512, 1024, 1, 1] @ ABCD]
  float* buffer_563 = (float*)&__rescheduled_0[0UL];
  mul__236(buffer_563, res5a_weight_0, folded_const_112);
  // [s8 [512, 1024, 1, 1] @ ABCD]
  int8_t* buffer_564 = (int8_t*)&__rescheduled_0[2097152UL];
  cast__237(buffer_564, buffer_563);
  reorder__535(folded_const_296, buffer_564);
  // [f32 [256, 256, 3, 3] @ ABCD]
  float* buffer_566 = (float*)&__rescheduled_0[0UL];
  mul__182(buffer_566, res4a_weight_1, folded_const_130);
  // [s8 [256, 256, 3, 3] @ ABCD]
  int8_t* buffer_567 = (int8_t*)&__rescheduled_0[2359296UL];
  cast__183(buffer_567, buffer_566);
  reorder__481(folded_const_297, buffer_567);
  // [f32 [256, 256, 3, 3] @ ABCD]
  float* buffer_569 = (float*)&__rescheduled_0[0UL];
  mul__191(buffer_569, res4b_weight_1, folded_const_127);
  // [s8 [256, 256, 3, 3] @ ABCD]
  int8_t* buffer_570 = (int8_t*)&__rescheduled_0[2359296UL];
  cast__192(buffer_570, buffer_569);
  reorder__490(folded_const_298, buffer_570);
  // [f32 [256, 256, 3, 3] @ ABCD]
  float* buffer_572 = (float*)&__rescheduled_0[0UL];
  mul__200(buffer_572, res4c_weight_1, folded_const_124);
  // [s8 [256, 256, 3, 3] @ ABCD]
  int8_t* buffer_573 = (int8_t*)&__rescheduled_0[2359296UL];
  cast__201(buffer_573, buffer_572);
  reorder__499(folded_const_299, buffer_573);
  // [f32 [256, 256, 3, 3] @ ABCD]
  float* buffer_575 = (float*)&__rescheduled_0[0UL];
  mul__209(buffer_575, res4d_weight_1, folded_const_121);
  // [s8 [256, 256, 3, 3] @ ABCD]
  int8_t* buffer_576 = (int8_t*)&__rescheduled_0[2359296UL];
  cast__210(buffer_576, buffer_575);
  reorder__508(folded_const_300, buffer_576);
  // [f32 [256, 256, 3, 3] @ ABCD]
  float* buffer_578 = (float*)&__rescheduled_0[0UL];
  mul__218(buffer_578, res4e_weight_1, folded_const_118);
  // [s8 [256, 256, 3, 3] @ ABCD]
  int8_t* buffer_579 = (int8_t*)&__rescheduled_0[2359296UL];
  cast__219(buffer_579, buffer_578);
  reorder__517(folded_const_301, buffer_579);
  // [f32 [256, 256, 3, 3] @ ABCD]
  float* buffer_581 = (float*)&__rescheduled_0[0UL];
  mul__227(buffer_581, res4f_weight_1, folded_const_115);
  // [s8 [256, 256, 3, 3] @ ABCD]
  int8_t* buffer_582 = (int8_t*)&__rescheduled_0[2359296UL];
  cast__228(buffer_582, buffer_581);
  reorder__526(folded_const_302, buffer_582);
  // [f32 [2048, 512, 1, 1] @ ABCD]
  float* buffer_584 = (float*)&__rescheduled_0[0UL];
  mul__242(buffer_584, res5a_weight_2, folded_const_110);
  // [s8 [2048, 512, 1, 1] @ ABCD]
  int8_t* buffer_585 = (int8_t*)&__rescheduled_0[4194304UL];
  cast__243(buffer_585, buffer_584);
  reorder__539(folded_const_303, buffer_585);
  // [f32 [2048, 512, 1, 1] @ ABCD]
  float* buffer_587 = (float*)&__rescheduled_0[0UL];
  mul__251(buffer_587, res5b_weight_2, folded_const_107);
  // [s8 [2048, 512, 1, 1] @ ABCD]
  int8_t* buffer_588 = (int8_t*)&__rescheduled_0[4194304UL];
  cast__252(buffer_588, buffer_587);
  reorder__548(folded_const_304, buffer_588);
  // [f32 [2048, 512, 1, 1] @ ABCD]
  float* buffer_590 = (float*)&__rescheduled_0[0UL];
  mul__260(buffer_590, res5c_weight_2, folded_const_104);
  // [s8 [2048, 512, 1, 1] @ ABCD]
  int8_t* buffer_591 = (int8_t*)&__rescheduled_0[4194304UL];
  cast__261(buffer_591, buffer_590);
  reorder__557(folded_const_305, buffer_591);
  // [f32 [512, 2048, 1, 1] @ ABCD]
  float* buffer_593 = (float*)&__rescheduled_0[0UL];
  mul__245(buffer_593, res5b_weight_0, folded_const_109);
  // [s8 [512, 2048, 1, 1] @ ABCD]
  int8_t* buffer_594 = (int8_t*)&__rescheduled_0[4194304UL];
  cast__246(buffer_594, buffer_593);
  reorder__542(folded_const_306, buffer_594);
  // [f32 [512, 2048, 1, 1] @ ABCD]
  float* buffer_596 = (float*)&__rescheduled_0[0UL];
  mul__254(buffer_596, res5c_weight_0, folded_const_106);
  // [s8 [512, 2048, 1, 1] @ ABCD]
  int8_t* buffer_597 = (int8_t*)&__rescheduled_0[4194304UL];
  cast__255(buffer_597, buffer_596);
  reorder__551(folded_const_307, buffer_597);
  // [f32 [2048, 1024, 1, 1] @ ABCD]
  float* buffer_599 = (float*)&__rescheduled_0[0UL];
  mul__233(buffer_599, res5a_weight_b, folded_const_113);
  // [s8 [2048, 1024, 1, 1] @ ABCD]
  int8_t* buffer_600 = (int8_t*)&__rescheduled_0[8388608UL];
  cast__234(buffer_600, buffer_599);
  reorder__532(folded_const_308, buffer_600);
  // [f32 [512, 512, 3, 3] @ ABCD]
  float* buffer_602 = (float*)&__rescheduled_0[0UL];
  mul__239(buffer_602, res5a_weight_1, folded_const_111);
  // [s8 [512, 512, 3, 3] @ ABCD]
  int8_t* buffer_603 = (int8_t*)&__rescheduled_0[9437184UL];
  cast__240(buffer_603, buffer_602);
  reorder__536(folded_const_309, buffer_603);
  // [f32 [512, 512, 3, 3] @ ABCD]
  float* buffer_605 = (float*)&__rescheduled_0[0UL];
  mul__248(buffer_605, res5b_weight_1, folded_const_108);
  // [s8 [512, 512, 3, 3] @ ABCD]
  int8_t* buffer_606 = (int8_t*)&__rescheduled_0[9437184UL];
  cast__249(buffer_606, buffer_605);
  reorder__545(folded_const_310, buffer_606);
  // [f32 [512, 512, 3, 3] @ ABCD]
  float* buffer_608 = (float*)&__rescheduled_0[0UL];
  mul__257(buffer_608, res5c_weight_1, folded_const_105);
  // [s8 [512, 512, 3, 3] @ ABCD]
  int8_t* buffer_609 = (int8_t*)&__rescheduled_0[9437184UL];
  cast__258(buffer_609, buffer_608);
  reorder__554(folded_const_311, buffer_609);
  is_init = true;
  sc_aligned_free(__stream, __rescheduled_0);
}

extern "C" void  sc_init_rn50_backbone_bs4(float* conv1_weight, float* conv1_bias, float* fc_weight, float* fc_bias) {
  prepareOneDNN(conv1_weight, conv1_bias,fc_weight,fc_bias);
  bool& is_init = *(bool*)(__module_data + 0);
  void*& __sc_kernel_cache = *(void**)(__module_data + 8);
  uint8_t* __brgemm_attrs = (uint8_t*)&__module_data[192UL];
  void*& __sc_kernel_cache_107 = *(void**)(__module_data + 16);
  uint8_t* __brgemm_attrs_106 = (uint8_t*)&__module_data[320UL];
  void*& __sc_kernel_cache_109 = *(void**)(__module_data + 24);
  uint8_t* __brgemm_attrs_108 = (uint8_t*)&__module_data[448UL];
  void*& __sc_kernel_cache_111 = *(void**)(__module_data + 32);
  uint8_t* __brgemm_attrs_110 = (uint8_t*)&__module_data[576UL];
  void*& __sc_kernel_cache_113 = *(void**)(__module_data + 40);
  uint8_t* __brgemm_attrs_112 = (uint8_t*)&__module_data[704UL];
  void*& __sc_kernel_cache_115 = *(void**)(__module_data + 48);
  uint8_t* __brgemm_attrs_114 = (uint8_t*)&__module_data[832UL];
  void*& __sc_kernel_cache_117 = *(void**)(__module_data + 56);
  uint8_t* __brgemm_attrs_116 = (uint8_t*)&__module_data[960UL];
  void*& __sc_kernel_cache_119 = *(void**)(__module_data + 64);
  uint8_t* __brgemm_attrs_118 = (uint8_t*)&__module_data[1088UL];
  void*& __sc_kernel_cache_122 = *(void**)(__module_data + 72);
  uint8_t* __brgemm_attrs_121 = (uint8_t*)&__module_data[2240UL];
  void*& __sc_kernel_cache_124 = *(void**)(__module_data + 80);
  uint8_t* __brgemm_attrs_123 = (uint8_t*)&__module_data[2368UL];
  void*& __sc_kernel_cache_126 = *(void**)(__module_data + 88);
  uint8_t* __brgemm_attrs_125 = (uint8_t*)&__module_data[2496UL];
  void*& __sc_kernel_cache_128 = *(void**)(__module_data + 96);
  uint8_t* __brgemm_attrs_127 = (uint8_t*)&__module_data[2624UL];
  void*& __sc_kernel_cache_130 = *(void**)(__module_data + 104);
  uint8_t* __brgemm_attrs_129 = (uint8_t*)&__module_data[2752UL];
  void*& __sc_kernel_cache_132 = *(void**)(__module_data + 112);
  uint8_t* __brgemm_attrs_131 = (uint8_t*)&__module_data[2880UL];
  void*& __sc_kernel_cache_138 = *(void**)(__module_data + 120);
  uint8_t* __brgemm_attrs_137 = (uint8_t*)&__module_data[3392UL];
  void*& __sc_kernel_cache_140 = *(void**)(__module_data + 128);
  uint8_t* __brgemm_attrs_139 = (uint8_t*)&__module_data[3520UL];
  void*& __sc_kernel_cache_142 = *(void**)(__module_data + 136);
  uint8_t* __brgemm_attrs_141 = (uint8_t*)&__module_data[3648UL];
  void*& __sc_kernel_cache_144 = *(void**)(__module_data + 144);
  uint8_t* __brgemm_attrs_143 = (uint8_t*)&__module_data[3776UL];
  void*& __sc_kernel_cache_146 = *(void**)(__module_data + 152);
  uint8_t* __brgemm_attrs_145 = (uint8_t*)&__module_data[3904UL];
  void*& __sc_kernel_cache_152 = *(void**)(__module_data + 160);
  uint8_t* __brgemm_attrs_151 = (uint8_t*)&__module_data[4224UL];
  void*& __sc_kernel_cache_156 = *(void**)(__module_data + 168);
  uint8_t* __brgemm_attrs_155 = (uint8_t*)&__module_data[4480UL];
  void** __brgemm_bd_mask_arr = (void**)&__uninitialized_data[23657472UL];
  uint8_t* __brgemm_full_bd_mask = (uint8_t*)&__module_data[1344UL];
  void** __brgemm_bd_mask_arr_135 = (void**)&__uninitialized_data[23657504UL];
  uint8_t* __brgemm_full_bd_mask_134 = (uint8_t*)&__module_data[3136UL];
  void** __brgemm_bd_mask_arr_149 = (void**)&__uninitialized_data[23657520UL];
  uint8_t* __brgemm_full_bd_mask_148 = (uint8_t*)&__module_data[4152UL];
  void** __sc_kernel_cache_arr = (void**)&__uninitialized_data[23657488UL];
  uint8_t* __brgemm_attrs_120 = (uint8_t*)&__module_data[1216UL];
  void** __sc_kernel_cache_arr_136 = (void**)&__uninitialized_data[23657512UL];
  uint8_t* __brgemm_attrs_133 = (uint8_t*)&__module_data[3008UL];
  void** __sc_kernel_cache_arr_150 = (void**)&__uninitialized_data[23657528UL];
  uint8_t* __brgemm_attrs_147 = (uint8_t*)&__module_data[4032UL];
  void** __sc_kernel_cache_arr_154 = (void**)&__uninitialized_data[23657536UL];
  uint8_t* __brgemm_attrs_153 = (uint8_t*)&__module_data[4352UL];
  is_init = false;
  __sc_kernel_cache = dnnl_brgemm_list_func(56, 64, 64, 64, 64, 64, 0.f, 7, 7, __brgemm_attrs, ((void*)0), ((void*)0));
  __sc_kernel_cache_107 = dnnl_brgemm_list_func(112, 64, 64, 64, 64, 64, 0.f, 7, 7, __brgemm_attrs_106, ((void*)0), ((void*)0));
  __sc_kernel_cache_109 = dnnl_brgemm_list_func(56, 64, 64, 64, 64, 64, 0.f, 7, 7, __brgemm_attrs_108, ((void*)0), ((void*)0));
  __sc_kernel_cache_111 = dnnl_brgemm_list_func(56, 64, 64, 64, 64, 64, 0.f, 7, 7, __brgemm_attrs_110, ((void*)0), ((void*)0));
  __sc_kernel_cache_113 = dnnl_brgemm_list_func(28, 64, 64, 64, 64, 64, 0.f, 7, 7, __brgemm_attrs_112, ((void*)0), ((void*)0));
  __sc_kernel_cache_115 = dnnl_brgemm_list_func(28, 64, 64, 128, 64, 64, 0.f, 7, 7, __brgemm_attrs_114, ((void*)0), ((void*)0));
  __sc_kernel_cache_117 = dnnl_brgemm_list_func(56, 64, 64, 64, 64, 64, 0.f, 7, 7, __brgemm_attrs_116, ((void*)0), ((void*)0));
  __sc_kernel_cache_119 = dnnl_brgemm_list_func(28, 64, 64, 64, 64, 64, 0.f, 7, 7, __brgemm_attrs_118, ((void*)0), ((void*)0));
  __sc_kernel_cache_122 = dnnl_brgemm_list_func(28, 64, 64, 64, 64, 64, 0.f, 7, 7, __brgemm_attrs_121, ((void*)0), ((void*)0));
  __sc_kernel_cache_124 = dnnl_brgemm_list_func(392, 64, 64, 64, 64, 64, 0.f, 7, 7, __brgemm_attrs_123, ((void*)0), ((void*)0));
  __sc_kernel_cache_126 = dnnl_brgemm_list_func(112, 64, 64, 64, 64, 64, 0.f, 7, 7, __brgemm_attrs_125, ((void*)0), ((void*)0));
  __sc_kernel_cache_128 = dnnl_brgemm_list_func(56, 64, 64, 64, 64, 64, 0.f, 7, 7, __brgemm_attrs_127, ((void*)0), ((void*)0));
  __sc_kernel_cache_130 = dnnl_brgemm_list_func(14, 64, 64, 128, 64, 64, 0.f, 7, 7, __brgemm_attrs_129, ((void*)0), ((void*)0));
  __sc_kernel_cache_132 = dnnl_brgemm_list_func(28, 64, 64, 64, 64, 64, 0.f, 7, 7, __brgemm_attrs_131, ((void*)0), ((void*)0));
  __sc_kernel_cache_138 = dnnl_brgemm_list_func(49, 512, 64, 64, 512, 512, 0.f, 7, 7, __brgemm_attrs_137, ((void*)0), ((void*)0));
  __sc_kernel_cache_140 = dnnl_brgemm_list_func(28, 512, 64, 64, 512, 512, 0.f, 7, 7, __brgemm_attrs_139, ((void*)0), ((void*)0));
  __sc_kernel_cache_142 = dnnl_brgemm_list_func(7, 256, 64, 128, 256, 256, 0.f, 7, 7, __brgemm_attrs_141, ((void*)0), ((void*)0));
  __sc_kernel_cache_144 = dnnl_brgemm_list_func(49, 512, 512, 512, 512, 512, 0.f, 7, 7, __brgemm_attrs_143, ((void*)0), ((void*)0));
  __sc_kernel_cache_146 = dnnl_brgemm_list_func(49, 64, 512, 512, 64, 64, 0.f, 7, 7, __brgemm_attrs_145, ((void*)0), ((void*)0));
  __sc_kernel_cache_152 = dnnl_brgemm_list_func(49, 256, 512, 512, 256, 256, 0.f, 7, 7, __brgemm_attrs_151, ((void*)0), ((void*)0));
  __sc_kernel_cache_156 = dnnl_brgemm_list_func(49, 512, 64, 64, 512, 512, 0.f, 7, 7, __brgemm_attrs_155, ((void*)0), ((void*)0));
  __brgemm_bd_mask_arr[0] = &__brgemm_full_bd_mask[(0 * 419)];
  __brgemm_bd_mask_arr[1] = &__brgemm_full_bd_mask[(1 * 419)];
  __brgemm_bd_mask_arr_135[0] = &__brgemm_full_bd_mask_134[(0 * 222)];
  __brgemm_bd_mask_arr_149[0] = &__brgemm_full_bd_mask_148[(0 * 61)];
  __sc_kernel_cache_arr[0] = dnnl_brgemm_list_func(419, 64, 64, 64, 64, 64, 0.f, 7, 7, __brgemm_attrs_120, __brgemm_bd_mask_arr[0], ((void*)0));
  __sc_kernel_cache_arr[1] = dnnl_brgemm_list_func(419, 64, 64, 64, 64, 64, 0.f, 7, 7, __brgemm_attrs_120, __brgemm_bd_mask_arr[1], ((void*)0));
  __sc_kernel_cache_arr_136[0] = dnnl_brgemm_list_func(222, 64, 64, 64, 64, 64, 0.f, 7, 7, __brgemm_attrs_133, __brgemm_bd_mask_arr_135[0], ((void*)0));
  __sc_kernel_cache_arr_150[0] = dnnl_brgemm_list_func(61, 128, 64, 64, 128, 128, 0.f, 7, 7, __brgemm_attrs_147, __brgemm_bd_mask_arr_149[0], ((void*)0));
  __sc_kernel_cache_arr_154[0] = dnnl_brgemm_list_func(61, 64, 512, 512, 64, 64, 0.f, 7, 7, __brgemm_attrs_153, __brgemm_bd_mask_arr_149[0], ((void*)0));
}

static void reorder__4190_closure_0(uint64_t fused_0fused_0fused_0fused_0_fuseiter_8172___fuseiter_8173_2312___fuseiter_8174_2313___fuseiter_8175_2314___fuseiter_8176_2315, float* __restrict__ __ins_0, float* __restrict__ __outs_0) noexcept{
  for (uint64_t _fuseiter_8177 = 0UL; _fuseiter_8177 < 64UL; _fuseiter_8177 += 1UL) {
    float __cached_0;
    __cached_0 = __ins_0[(((fused_0fused_0fused_0fused_0_fuseiter_8172___fuseiter_8173_2312___fuseiter_8174_2313___fuseiter_8175_2314___fuseiter_8176_2315 / 4UL) * 256UL) + (_fuseiter_8177 + ((fused_0fused_0fused_0fused_0_fuseiter_8172___fuseiter_8173_2312___fuseiter_8174_2313___fuseiter_8175_2314___fuseiter_8176_2315 % 4UL) * 64UL)))];
    float __cached_1;
    __cached_1 = __cached_0;
    __outs_0[(((fused_0fused_0fused_0fused_0_fuseiter_8172___fuseiter_8173_2312___fuseiter_8174_2313___fuseiter_8175_2314___fuseiter_8176_2315 / 4UL) * 256UL) + (((fused_0fused_0fused_0fused_0_fuseiter_8172___fuseiter_8173_2312___fuseiter_8174_2313___fuseiter_8175_2314___fuseiter_8176_2315 % 4UL) * 64UL) + _fuseiter_8177))] = __cached_1;
  }
}

static void reorder__4190_closure_0_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept{
  reorder__4190_closure_0(i, (float*)(args[0UL].v_ptr), (float*)(args[1UL].v_ptr));
}

static void mul__5700_closure_1(uint64_t fused_0fused_0fused_0fused_0__itr_0____itr_1_2316____itr_2_2317____itr_3_2318____itr_4_2319, float* __restrict__ __ins_0, float* __restrict__ __ins_1, float* __restrict__ __outs_0) noexcept{
  for (uint64_t _fuseiter_8183 = 0UL; _fuseiter_8183 < 64UL; _fuseiter_8183 += 16UL) {
    vec_f32x16 __cached_0;
    __cached_0 = vec_f32x16::load(&__ins_0[((((fused_0fused_0fused_0fused_0__itr_0____itr_1_2316____itr_2_2317____itr_3_2318____itr_4_2319 / 4UL) * 256UL) + ((fused_0fused_0fused_0fused_0__itr_0____itr_1_2316____itr_2_2317____itr_3_2318____itr_4_2319 % 4UL) * 64UL)) + _fuseiter_8183)]);
    float __cached_1;
    __cached_1 = __ins_1[0];
    vec_f32x16 __cached_2;
    __cached_2 = (__cached_0 * vec_f32x16(__cached_1));
    vec_f32x16::store(__cached_2, &__outs_0[((((fused_0fused_0fused_0fused_0__itr_0____itr_1_2316____itr_2_2317____itr_3_2318____itr_4_2319 / 4UL) * 256UL) + ((fused_0fused_0fused_0fused_0__itr_0____itr_1_2316____itr_2_2317____itr_3_2318____itr_4_2319 % 4UL) * 64UL)) + _fuseiter_8183)]);
  }
}

static void mul__5700_closure_1_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept{
  mul__5700_closure_1(i, (float*)(args[0UL].v_ptr), (float*)(args[1UL].v_ptr), (float*)(args[2UL].v_ptr));
}

static void reorder__4240_closure_2(uint64_t fused_0fused_0fused_0fused_0_fuseiter_8199___fuseiter_8200_2328___fuseiter_8201_2329___fuseiter_8202_2330___fuseiter_8203_2331, float* __restrict__ __ins_0, float* __restrict__ __outs_0) noexcept{
  for (uint64_t _fuseiter_8204 = 0UL; _fuseiter_8204 < 64UL; _fuseiter_8204 += 1UL) {
    float __cached_0;
    __cached_0 = __ins_0[(((fused_0fused_0fused_0fused_0_fuseiter_8199___fuseiter_8200_2328___fuseiter_8201_2329___fuseiter_8202_2330___fuseiter_8203_2331 / 4UL) * 256UL) + (_fuseiter_8204 + ((fused_0fused_0fused_0fused_0_fuseiter_8199___fuseiter_8200_2328___fuseiter_8201_2329___fuseiter_8202_2330___fuseiter_8203_2331 % 4UL) * 64UL)))];
    float __cached_1;
    __cached_1 = __cached_0;
    __outs_0[(((fused_0fused_0fused_0fused_0_fuseiter_8199___fuseiter_8200_2328___fuseiter_8201_2329___fuseiter_8202_2330___fuseiter_8203_2331 / 4UL) * 256UL) + (((fused_0fused_0fused_0fused_0_fuseiter_8199___fuseiter_8200_2328___fuseiter_8201_2329___fuseiter_8202_2330___fuseiter_8203_2331 % 4UL) * 64UL) + _fuseiter_8204))] = __cached_1;
  }
}

static void reorder__4240_closure_2_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept{
  reorder__4240_closure_2(i, (float*)(args[0UL].v_ptr), (float*)(args[1UL].v_ptr));
}

static void mul__5760_closure_3(uint64_t fused_0fused_0fused_0fused_0__itr_0____itr_1_2332____itr_2_2333____itr_3_2334____itr_4_2335, float* __restrict__ __ins_0, float* __restrict__ __ins_1, float* __restrict__ __outs_0) noexcept{
  for (uint64_t _fuseiter_8210 = 0UL; _fuseiter_8210 < 64UL; _fuseiter_8210 += 16UL) {
    vec_f32x16 __cached_0;
    __cached_0 = vec_f32x16::load(&__ins_0[((((fused_0fused_0fused_0fused_0__itr_0____itr_1_2332____itr_2_2333____itr_3_2334____itr_4_2335 / 4UL) * 256UL) + ((fused_0fused_0fused_0fused_0__itr_0____itr_1_2332____itr_2_2333____itr_3_2334____itr_4_2335 % 4UL) * 64UL)) + _fuseiter_8210)]);
    float __cached_1;
    __cached_1 = __ins_1[0];
    vec_f32x16 __cached_2;
    __cached_2 = (__cached_0 * vec_f32x16(__cached_1));
    vec_f32x16::store(__cached_2, &__outs_0[((((fused_0fused_0fused_0fused_0__itr_0____itr_1_2332____itr_2_2333____itr_3_2334____itr_4_2335 / 4UL) * 256UL) + ((fused_0fused_0fused_0fused_0__itr_0____itr_1_2332____itr_2_2333____itr_3_2334____itr_4_2335 % 4UL) * 64UL)) + _fuseiter_8210)]);
  }
}

static void mul__5760_closure_3_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept{
  mul__5760_closure_3(i, (float*)(args[0UL].v_ptr), (float*)(args[1UL].v_ptr), (float*)(args[2UL].v_ptr));
}

static void reorder__4290_closure_4(uint64_t fused_0fused_0fused_0fused_0_fuseiter_8226___fuseiter_8227_2344___fuseiter_8228_2345___fuseiter_8229_2346___fuseiter_8230_2347, float* __restrict__ __ins_0, float* __restrict__ __outs_0) noexcept{
  for (uint64_t _fuseiter_8231 = 0UL; _fuseiter_8231 < 64UL; _fuseiter_8231 += 1UL) {
    float __cached_0;
    __cached_0 = __ins_0[(((fused_0fused_0fused_0fused_0_fuseiter_8226___fuseiter_8227_2344___fuseiter_8228_2345___fuseiter_8229_2346___fuseiter_8230_2347 / 4UL) * 256UL) + (_fuseiter_8231 + ((fused_0fused_0fused_0fused_0_fuseiter_8226___fuseiter_8227_2344___fuseiter_8228_2345___fuseiter_8229_2346___fuseiter_8230_2347 % 4UL) * 64UL)))];
    float __cached_1;
    __cached_1 = __cached_0;
    __outs_0[(((fused_0fused_0fused_0fused_0_fuseiter_8226___fuseiter_8227_2344___fuseiter_8228_2345___fuseiter_8229_2346___fuseiter_8230_2347 / 4UL) * 256UL) + (((fused_0fused_0fused_0fused_0_fuseiter_8226___fuseiter_8227_2344___fuseiter_8228_2345___fuseiter_8229_2346___fuseiter_8230_2347 % 4UL) * 64UL) + _fuseiter_8231))] = __cached_1;
  }
}

static void reorder__4290_closure_4_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept{
  reorder__4290_closure_4(i, (float*)(args[0UL].v_ptr), (float*)(args[1UL].v_ptr));
}

static void mul__5820_closure_5(uint64_t fused_0fused_0fused_0fused_0__itr_0____itr_1_2348____itr_2_2349____itr_3_2350____itr_4_2351, float* __restrict__ __ins_0, float* __restrict__ __ins_1, float* __restrict__ __outs_0) noexcept{
  for (uint64_t _fuseiter_8237 = 0UL; _fuseiter_8237 < 64UL; _fuseiter_8237 += 16UL) {
    vec_f32x16 __cached_0;
    __cached_0 = vec_f32x16::load(&__ins_0[((((fused_0fused_0fused_0fused_0__itr_0____itr_1_2348____itr_2_2349____itr_3_2350____itr_4_2351 / 4UL) * 256UL) + ((fused_0fused_0fused_0fused_0__itr_0____itr_1_2348____itr_2_2349____itr_3_2350____itr_4_2351 % 4UL) * 64UL)) + _fuseiter_8237)]);
    float __cached_1;
    __cached_1 = __ins_1[0];
    vec_f32x16 __cached_2;
    __cached_2 = (__cached_0 * vec_f32x16(__cached_1));
    vec_f32x16::store(__cached_2, &__outs_0[((((fused_0fused_0fused_0fused_0__itr_0____itr_1_2348____itr_2_2349____itr_3_2350____itr_4_2351 / 4UL) * 256UL) + ((fused_0fused_0fused_0fused_0__itr_0____itr_1_2348____itr_2_2349____itr_3_2350____itr_4_2351 % 4UL) * 64UL)) + _fuseiter_8237)]);
  }
}

static void mul__5820_closure_5_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept{
  mul__5820_closure_5(i, (float*)(args[0UL].v_ptr), (float*)(args[1UL].v_ptr), (float*)(args[2UL].v_ptr));
}

static void reorder__4340_closure_6(uint64_t fused_0fused_0fused_0fused_0_fuseiter_8253___fuseiter_8254_2360___fuseiter_8255_2361___fuseiter_8256_2362___fuseiter_8257_2363, float* __restrict__ __ins_0, float* __restrict__ __outs_0) noexcept{
  for (uint64_t _fuseiter_8258 = 0UL; _fuseiter_8258 < 64UL; _fuseiter_8258 += 1UL) {
    float __cached_0;
    __cached_0 = __ins_0[(((fused_0fused_0fused_0fused_0_fuseiter_8253___fuseiter_8254_2360___fuseiter_8255_2361___fuseiter_8256_2362___fuseiter_8257_2363 / 4UL) * 256UL) + (_fuseiter_8258 + ((fused_0fused_0fused_0fused_0_fuseiter_8253___fuseiter_8254_2360___fuseiter_8255_2361___fuseiter_8256_2362___fuseiter_8257_2363 % 4UL) * 64UL)))];
    float __cached_1;
    __cached_1 = __cached_0;
    __outs_0[(((fused_0fused_0fused_0fused_0_fuseiter_8253___fuseiter_8254_2360___fuseiter_8255_2361___fuseiter_8256_2362___fuseiter_8257_2363 / 4UL) * 256UL) + (((fused_0fused_0fused_0fused_0_fuseiter_8253___fuseiter_8254_2360___fuseiter_8255_2361___fuseiter_8256_2362___fuseiter_8257_2363 % 4UL) * 64UL) + _fuseiter_8258))] = __cached_1;
  }
}

static void reorder__4340_closure_6_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept{
  reorder__4340_closure_6(i, (float*)(args[0UL].v_ptr), (float*)(args[1UL].v_ptr));
}

static void mul__5880_closure_7(uint64_t fused_0fused_0fused_0fused_0__itr_0____itr_1_2364____itr_2_2365____itr_3_2366____itr_4_2367, float* __restrict__ __ins_0, float* __restrict__ __ins_1, float* __restrict__ __outs_0) noexcept{
  for (uint64_t _fuseiter_8264 = 0UL; _fuseiter_8264 < 64UL; _fuseiter_8264 += 16UL) {
    vec_f32x16 __cached_0;
    __cached_0 = vec_f32x16::load(&__ins_0[((((fused_0fused_0fused_0fused_0__itr_0____itr_1_2364____itr_2_2365____itr_3_2366____itr_4_2367 / 4UL) * 256UL) + ((fused_0fused_0fused_0fused_0__itr_0____itr_1_2364____itr_2_2365____itr_3_2366____itr_4_2367 % 4UL) * 64UL)) + _fuseiter_8264)]);
    float __cached_1;
    __cached_1 = __ins_1[0];
    vec_f32x16 __cached_2;
    __cached_2 = (__cached_0 * vec_f32x16(__cached_1));
    vec_f32x16::store(__cached_2, &__outs_0[((((fused_0fused_0fused_0fused_0__itr_0____itr_1_2364____itr_2_2365____itr_3_2366____itr_4_2367 / 4UL) * 256UL) + ((fused_0fused_0fused_0fused_0__itr_0____itr_1_2364____itr_2_2365____itr_3_2366____itr_4_2367 % 4UL) * 64UL)) + _fuseiter_8264)]);
  }
}

static void mul__5880_closure_7_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept{
  mul__5880_closure_7(i, (float*)(args[0UL].v_ptr), (float*)(args[1UL].v_ptr), (float*)(args[2UL].v_ptr));
}

static void reorder__4370_closure_8(uint64_t fused_0fused_0fused_0fused_0_fuseiter_8266___fuseiter_8267_2368___fuseiter_8268_2369___fuseiter_8269_2370___fuseiter_8270_2371, float* __restrict__ __ins_0, float* __restrict__ __outs_0) noexcept{
  for (uint64_t _fuseiter_8271 = 0UL; _fuseiter_8271 < 64UL; _fuseiter_8271 += 1UL) {
    float __cached_0;
    __cached_0 = __ins_0[(((fused_0fused_0fused_0fused_0_fuseiter_8266___fuseiter_8267_2368___fuseiter_8268_2369___fuseiter_8269_2370___fuseiter_8270_2371 / 8UL) * 512UL) + (_fuseiter_8271 + ((fused_0fused_0fused_0fused_0_fuseiter_8266___fuseiter_8267_2368___fuseiter_8268_2369___fuseiter_8269_2370___fuseiter_8270_2371 % 8UL) * 64UL)))];
    float __cached_1;
    __cached_1 = __cached_0;
    __outs_0[(((fused_0fused_0fused_0fused_0_fuseiter_8266___fuseiter_8267_2368___fuseiter_8268_2369___fuseiter_8269_2370___fuseiter_8270_2371 / 8UL) * 512UL) + (((fused_0fused_0fused_0fused_0_fuseiter_8266___fuseiter_8267_2368___fuseiter_8268_2369___fuseiter_8269_2370___fuseiter_8270_2371 % 8UL) * 64UL) + _fuseiter_8271))] = __cached_1;
  }
}

static void reorder__4370_closure_8_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept{
  reorder__4370_closure_8(i, (float*)(args[0UL].v_ptr), (float*)(args[1UL].v_ptr));
}

static void mul__5900_closure_9(uint64_t fused_0fused_0fused_0fused_0__itr_0____itr_1_2372____itr_2_2373____itr_3_2374____itr_4_2375, float* __restrict__ __ins_0, float* __restrict__ __ins_1, float* __restrict__ __outs_0) noexcept{
  for (uint64_t _fuseiter_8277 = 0UL; _fuseiter_8277 < 64UL; _fuseiter_8277 += 16UL) {
    vec_f32x16 __cached_0;
    __cached_0 = vec_f32x16::load(&__ins_0[((((fused_0fused_0fused_0fused_0__itr_0____itr_1_2372____itr_2_2373____itr_3_2374____itr_4_2375 / 8UL) * 512UL) + ((fused_0fused_0fused_0fused_0__itr_0____itr_1_2372____itr_2_2373____itr_3_2374____itr_4_2375 % 8UL) * 64UL)) + _fuseiter_8277)]);
    float __cached_1;
    __cached_1 = __ins_1[0];
    vec_f32x16 __cached_2;
    __cached_2 = (__cached_0 * vec_f32x16(__cached_1));
    vec_f32x16::store(__cached_2, &__outs_0[((((fused_0fused_0fused_0fused_0__itr_0____itr_1_2372____itr_2_2373____itr_3_2374____itr_4_2375 / 8UL) * 512UL) + ((fused_0fused_0fused_0fused_0__itr_0____itr_1_2372____itr_2_2373____itr_3_2374____itr_4_2375 % 8UL) * 64UL)) + _fuseiter_8277)]);
  }
}

static void mul__5900_closure_9_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept{
  mul__5900_closure_9(i, (float*)(args[0UL].v_ptr), (float*)(args[1UL].v_ptr), (float*)(args[2UL].v_ptr));
}

static void reorder__4400_closure_10(uint64_t fused_0fused_0fused_0fused_0_fuseiter_8279___fuseiter_8280_2376___fuseiter_8281_2377___fuseiter_8282_2378___fuseiter_8283_2379, float* __restrict__ __ins_0, float* __restrict__ __outs_0) noexcept{
  for (uint64_t _fuseiter_8284 = 0UL; _fuseiter_8284 < 64UL; _fuseiter_8284 += 1UL) {
    float __cached_0;
    __cached_0 = __ins_0[(((fused_0fused_0fused_0fused_0_fuseiter_8279___fuseiter_8280_2376___fuseiter_8281_2377___fuseiter_8282_2378___fuseiter_8283_2379 / 2UL) * 128UL) + (_fuseiter_8284 + ((fused_0fused_0fused_0fused_0_fuseiter_8279___fuseiter_8280_2376___fuseiter_8281_2377___fuseiter_8282_2378___fuseiter_8283_2379 % 2UL) * 64UL)))];
    float __cached_1;
    __cached_1 = __cached_0;
    __outs_0[(((fused_0fused_0fused_0fused_0_fuseiter_8279___fuseiter_8280_2376___fuseiter_8281_2377___fuseiter_8282_2378___fuseiter_8283_2379 / 2UL) * 128UL) + (((fused_0fused_0fused_0fused_0_fuseiter_8279___fuseiter_8280_2376___fuseiter_8281_2377___fuseiter_8282_2378___fuseiter_8283_2379 % 2UL) * 64UL) + _fuseiter_8284))] = __cached_1;
  }
}

static void reorder__4400_closure_10_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept{
  reorder__4400_closure_10(i, (float*)(args[0UL].v_ptr), (float*)(args[1UL].v_ptr));
}

static void mul__5920_closure_11(uint64_t fused_0fused_0fused_0fused_0__itr_0____itr_1_2380____itr_2_2381____itr_3_2382____itr_4_2383, float* __restrict__ __ins_0, float* __restrict__ __ins_1, float* __restrict__ __outs_0) noexcept{
  for (uint64_t _fuseiter_8290 = 0UL; _fuseiter_8290 < 64UL; _fuseiter_8290 += 16UL) {
    vec_f32x16 __cached_0;
    __cached_0 = vec_f32x16::load(&__ins_0[((((fused_0fused_0fused_0fused_0__itr_0____itr_1_2380____itr_2_2381____itr_3_2382____itr_4_2383 / 2UL) * 128UL) + ((fused_0fused_0fused_0fused_0__itr_0____itr_1_2380____itr_2_2381____itr_3_2382____itr_4_2383 % 2UL) * 64UL)) + _fuseiter_8290)]);
    float __cached_1;
    __cached_1 = __ins_1[0];
    vec_f32x16 __cached_2;
    __cached_2 = (__cached_0 * vec_f32x16(__cached_1));
    vec_f32x16::store(__cached_2, &__outs_0[((((fused_0fused_0fused_0fused_0__itr_0____itr_1_2380____itr_2_2381____itr_3_2382____itr_4_2383 / 2UL) * 128UL) + ((fused_0fused_0fused_0fused_0__itr_0____itr_1_2380____itr_2_2381____itr_3_2382____itr_4_2383 % 2UL) * 64UL)) + _fuseiter_8290)]);
  }
}

static void mul__5920_closure_11_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept{
  mul__5920_closure_11(i, (float*)(args[0UL].v_ptr), (float*)(args[1UL].v_ptr), (float*)(args[2UL].v_ptr));
}

static void reorder__4430_closure_12(uint64_t fused_0fused_0fused_0fused_0_fuseiter_8292___fuseiter_8293_2384___fuseiter_8294_2385___fuseiter_8295_2386___fuseiter_8296_2387, float* __restrict__ __ins_0, float* __restrict__ __outs_0) noexcept{
  for (uint64_t _fuseiter_8297 = 0UL; _fuseiter_8297 < 64UL; _fuseiter_8297 += 1UL) {
    float __cached_0;
    __cached_0 = __ins_0[(((fused_0fused_0fused_0fused_0_fuseiter_8292___fuseiter_8293_2384___fuseiter_8294_2385___fuseiter_8295_2386___fuseiter_8296_2387 / 2UL) * 128UL) + (_fuseiter_8297 + ((fused_0fused_0fused_0fused_0_fuseiter_8292___fuseiter_8293_2384___fuseiter_8294_2385___fuseiter_8295_2386___fuseiter_8296_2387 % 2UL) * 64UL)))];
    float __cached_1;
    __cached_1 = __cached_0;
    __outs_0[(((fused_0fused_0fused_0fused_0_fuseiter_8292___fuseiter_8293_2384___fuseiter_8294_2385___fuseiter_8295_2386___fuseiter_8296_2387 / 2UL) * 128UL) + (((fused_0fused_0fused_0fused_0_fuseiter_8292___fuseiter_8293_2384___fuseiter_8294_2385___fuseiter_8295_2386___fuseiter_8296_2387 % 2UL) * 64UL) + _fuseiter_8297))] = __cached_1;
  }
}

static void reorder__4430_closure_12_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept{
  reorder__4430_closure_12(i, (float*)(args[0UL].v_ptr), (float*)(args[1UL].v_ptr));
}

static void mul__5940_closure_13(uint64_t fused_0fused_0fused_0fused_0__itr_0____itr_1_2388____itr_2_2389____itr_3_2390____itr_4_2391, float* __restrict__ __ins_0, float* __restrict__ __ins_1, float* __restrict__ __outs_0) noexcept{
  for (uint64_t _fuseiter_8303 = 0UL; _fuseiter_8303 < 64UL; _fuseiter_8303 += 16UL) {
    vec_f32x16 __cached_0;
    __cached_0 = vec_f32x16::load(&__ins_0[((((fused_0fused_0fused_0fused_0__itr_0____itr_1_2388____itr_2_2389____itr_3_2390____itr_4_2391 / 2UL) * 128UL) + ((fused_0fused_0fused_0fused_0__itr_0____itr_1_2388____itr_2_2389____itr_3_2390____itr_4_2391 % 2UL) * 64UL)) + _fuseiter_8303)]);
    float __cached_1;
    __cached_1 = __ins_1[0];
    vec_f32x16 __cached_2;
    __cached_2 = (__cached_0 * vec_f32x16(__cached_1));
    vec_f32x16::store(__cached_2, &__outs_0[((((fused_0fused_0fused_0fused_0__itr_0____itr_1_2388____itr_2_2389____itr_3_2390____itr_4_2391 / 2UL) * 128UL) + ((fused_0fused_0fused_0fused_0__itr_0____itr_1_2388____itr_2_2389____itr_3_2390____itr_4_2391 % 2UL) * 64UL)) + _fuseiter_8303)]);
  }
}

static void mul__5940_closure_13_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept{
  mul__5940_closure_13(i, (float*)(args[0UL].v_ptr), (float*)(args[1UL].v_ptr), (float*)(args[2UL].v_ptr));
}

static void reorder__4460_closure_14(uint64_t fused_0fused_0fused_0fused_0_fuseiter_8305___fuseiter_8306_2392___fuseiter_8307_2393___fuseiter_8308_2394___fuseiter_8309_2395, float* __restrict__ __ins_0, float* __restrict__ __outs_0) noexcept{
  for (uint64_t _fuseiter_8310 = 0UL; _fuseiter_8310 < 64UL; _fuseiter_8310 += 1UL) {
    float __cached_0;
    __cached_0 = __ins_0[(((fused_0fused_0fused_0fused_0_fuseiter_8305___fuseiter_8306_2392___fuseiter_8307_2393___fuseiter_8308_2394___fuseiter_8309_2395 / 8UL) * 512UL) + (_fuseiter_8310 + ((fused_0fused_0fused_0fused_0_fuseiter_8305___fuseiter_8306_2392___fuseiter_8307_2393___fuseiter_8308_2394___fuseiter_8309_2395 % 8UL) * 64UL)))];
    float __cached_1;
    __cached_1 = __cached_0;
    __outs_0[(((fused_0fused_0fused_0fused_0_fuseiter_8305___fuseiter_8306_2392___fuseiter_8307_2393___fuseiter_8308_2394___fuseiter_8309_2395 / 8UL) * 512UL) + (((fused_0fused_0fused_0fused_0_fuseiter_8305___fuseiter_8306_2392___fuseiter_8307_2393___fuseiter_8308_2394___fuseiter_8309_2395 % 8UL) * 64UL) + _fuseiter_8310))] = __cached_1;
  }
}

static void reorder__4460_closure_14_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept{
  reorder__4460_closure_14(i, (float*)(args[0UL].v_ptr), (float*)(args[1UL].v_ptr));
}

static void mul__5960_closure_15(uint64_t fused_0fused_0fused_0fused_0__itr_0____itr_1_2396____itr_2_2397____itr_3_2398____itr_4_2399, float* __restrict__ __ins_0, float* __restrict__ __ins_1, float* __restrict__ __outs_0) noexcept{
  for (uint64_t _fuseiter_8316 = 0UL; _fuseiter_8316 < 64UL; _fuseiter_8316 += 16UL) {
    vec_f32x16 __cached_0;
    __cached_0 = vec_f32x16::load(&__ins_0[((((fused_0fused_0fused_0fused_0__itr_0____itr_1_2396____itr_2_2397____itr_3_2398____itr_4_2399 / 8UL) * 512UL) + ((fused_0fused_0fused_0fused_0__itr_0____itr_1_2396____itr_2_2397____itr_3_2398____itr_4_2399 % 8UL) * 64UL)) + _fuseiter_8316)]);
    float __cached_1;
    __cached_1 = __ins_1[0];
    vec_f32x16 __cached_2;
    __cached_2 = (__cached_0 * vec_f32x16(__cached_1));
    vec_f32x16::store(__cached_2, &__outs_0[((((fused_0fused_0fused_0fused_0__itr_0____itr_1_2396____itr_2_2397____itr_3_2398____itr_4_2399 / 8UL) * 512UL) + ((fused_0fused_0fused_0fused_0__itr_0____itr_1_2396____itr_2_2397____itr_3_2398____itr_4_2399 % 8UL) * 64UL)) + _fuseiter_8316)]);
  }
}

static void mul__5960_closure_15_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept{
  mul__5960_closure_15(i, (float*)(args[0UL].v_ptr), (float*)(args[1UL].v_ptr), (float*)(args[2UL].v_ptr));
}

static void reorder__4490_closure_16(uint64_t fused_0fused_0fused_0fused_0_fuseiter_8318___fuseiter_8319_2400___fuseiter_8320_2401___fuseiter_8321_2402___fuseiter_8322_2403, float* __restrict__ __ins_0, float* __restrict__ __outs_0) noexcept{
  for (uint64_t _fuseiter_8323 = 0UL; _fuseiter_8323 < 64UL; _fuseiter_8323 += 1UL) {
    float __cached_0;
    __cached_0 = __ins_0[(((fused_0fused_0fused_0fused_0_fuseiter_8318___fuseiter_8319_2400___fuseiter_8320_2401___fuseiter_8321_2402___fuseiter_8322_2403 / 2UL) * 128UL) + (_fuseiter_8323 + ((fused_0fused_0fused_0fused_0_fuseiter_8318___fuseiter_8319_2400___fuseiter_8320_2401___fuseiter_8321_2402___fuseiter_8322_2403 % 2UL) * 64UL)))];
    float __cached_1;
    __cached_1 = __cached_0;
    __outs_0[(((fused_0fused_0fused_0fused_0_fuseiter_8318___fuseiter_8319_2400___fuseiter_8320_2401___fuseiter_8321_2402___fuseiter_8322_2403 / 2UL) * 128UL) + (((fused_0fused_0fused_0fused_0_fuseiter_8318___fuseiter_8319_2400___fuseiter_8320_2401___fuseiter_8321_2402___fuseiter_8322_2403 % 2UL) * 64UL) + _fuseiter_8323))] = __cached_1;
  }
}

static void reorder__4490_closure_16_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept{
  reorder__4490_closure_16(i, (float*)(args[0UL].v_ptr), (float*)(args[1UL].v_ptr));
}

static void mul__5980_closure_17(uint64_t fused_0fused_0fused_0fused_0__itr_0____itr_1_2404____itr_2_2405____itr_3_2406____itr_4_2407, float* __restrict__ __ins_0, float* __restrict__ __ins_1, float* __restrict__ __outs_0) noexcept{
  for (uint64_t _fuseiter_8329 = 0UL; _fuseiter_8329 < 64UL; _fuseiter_8329 += 16UL) {
    vec_f32x16 __cached_0;
    __cached_0 = vec_f32x16::load(&__ins_0[((((fused_0fused_0fused_0fused_0__itr_0____itr_1_2404____itr_2_2405____itr_3_2406____itr_4_2407 / 2UL) * 128UL) + ((fused_0fused_0fused_0fused_0__itr_0____itr_1_2404____itr_2_2405____itr_3_2406____itr_4_2407 % 2UL) * 64UL)) + _fuseiter_8329)]);
    float __cached_1;
    __cached_1 = __ins_1[0];
    vec_f32x16 __cached_2;
    __cached_2 = (__cached_0 * vec_f32x16(__cached_1));
    vec_f32x16::store(__cached_2, &__outs_0[((((fused_0fused_0fused_0fused_0__itr_0____itr_1_2404____itr_2_2405____itr_3_2406____itr_4_2407 / 2UL) * 128UL) + ((fused_0fused_0fused_0fused_0__itr_0____itr_1_2404____itr_2_2405____itr_3_2406____itr_4_2407 % 2UL) * 64UL)) + _fuseiter_8329)]);
  }
}

static void mul__5980_closure_17_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept{
  mul__5980_closure_17(i, (float*)(args[0UL].v_ptr), (float*)(args[1UL].v_ptr), (float*)(args[2UL].v_ptr));
}

static void reorder__4520_closure_18(uint64_t fused_0fused_0fused_0fused_0_fuseiter_8331___fuseiter_8332_2408___fuseiter_8333_2409___fuseiter_8334_2410___fuseiter_8335_2411, float* __restrict__ __ins_0, float* __restrict__ __outs_0) noexcept{
  for (uint64_t _fuseiter_8336 = 0UL; _fuseiter_8336 < 64UL; _fuseiter_8336 += 1UL) {
    float __cached_0;
    __cached_0 = __ins_0[(((fused_0fused_0fused_0fused_0_fuseiter_8331___fuseiter_8332_2408___fuseiter_8333_2409___fuseiter_8334_2410___fuseiter_8335_2411 / 2UL) * 128UL) + (_fuseiter_8336 + ((fused_0fused_0fused_0fused_0_fuseiter_8331___fuseiter_8332_2408___fuseiter_8333_2409___fuseiter_8334_2410___fuseiter_8335_2411 % 2UL) * 64UL)))];
    float __cached_1;
    __cached_1 = __cached_0;
    __outs_0[(((fused_0fused_0fused_0fused_0_fuseiter_8331___fuseiter_8332_2408___fuseiter_8333_2409___fuseiter_8334_2410___fuseiter_8335_2411 / 2UL) * 128UL) + (((fused_0fused_0fused_0fused_0_fuseiter_8331___fuseiter_8332_2408___fuseiter_8333_2409___fuseiter_8334_2410___fuseiter_8335_2411 % 2UL) * 64UL) + _fuseiter_8336))] = __cached_1;
  }
}

static void reorder__4520_closure_18_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept{
  reorder__4520_closure_18(i, (float*)(args[0UL].v_ptr), (float*)(args[1UL].v_ptr));
}

static void mul__6000_closure_19(uint64_t fused_0fused_0fused_0fused_0__itr_0____itr_1_2412____itr_2_2413____itr_3_2414____itr_4_2415, float* __restrict__ __ins_0, float* __restrict__ __ins_1, float* __restrict__ __outs_0) noexcept{
  for (uint64_t _fuseiter_8342 = 0UL; _fuseiter_8342 < 64UL; _fuseiter_8342 += 16UL) {
    vec_f32x16 __cached_0;
    __cached_0 = vec_f32x16::load(&__ins_0[((((fused_0fused_0fused_0fused_0__itr_0____itr_1_2412____itr_2_2413____itr_3_2414____itr_4_2415 / 2UL) * 128UL) + ((fused_0fused_0fused_0fused_0__itr_0____itr_1_2412____itr_2_2413____itr_3_2414____itr_4_2415 % 2UL) * 64UL)) + _fuseiter_8342)]);
    float __cached_1;
    __cached_1 = __ins_1[0];
    vec_f32x16 __cached_2;
    __cached_2 = (__cached_0 * vec_f32x16(__cached_1));
    vec_f32x16::store(__cached_2, &__outs_0[((((fused_0fused_0fused_0fused_0__itr_0____itr_1_2412____itr_2_2413____itr_3_2414____itr_4_2415 / 2UL) * 128UL) + ((fused_0fused_0fused_0fused_0__itr_0____itr_1_2412____itr_2_2413____itr_3_2414____itr_4_2415 % 2UL) * 64UL)) + _fuseiter_8342)]);
  }
}

static void mul__6000_closure_19_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept{
  mul__6000_closure_19(i, (float*)(args[0UL].v_ptr), (float*)(args[1UL].v_ptr), (float*)(args[2UL].v_ptr));
}

static void reorder__4550_closure_20(uint64_t fused_0fused_0fused_0fused_0_fuseiter_8344___fuseiter_8345_2416___fuseiter_8346_2417___fuseiter_8347_2418___fuseiter_8348_2419, float* __restrict__ __ins_0, float* __restrict__ __outs_0) noexcept{
  for (uint64_t _fuseiter_8349 = 0UL; _fuseiter_8349 < 64UL; _fuseiter_8349 += 1UL) {
    float __cached_0;
    __cached_0 = __ins_0[(((fused_0fused_0fused_0fused_0_fuseiter_8344___fuseiter_8345_2416___fuseiter_8346_2417___fuseiter_8347_2418___fuseiter_8348_2419 / 8UL) * 512UL) + (_fuseiter_8349 + ((fused_0fused_0fused_0fused_0_fuseiter_8344___fuseiter_8345_2416___fuseiter_8346_2417___fuseiter_8347_2418___fuseiter_8348_2419 % 8UL) * 64UL)))];
    float __cached_1;
    __cached_1 = __cached_0;
    __outs_0[(((fused_0fused_0fused_0fused_0_fuseiter_8344___fuseiter_8345_2416___fuseiter_8346_2417___fuseiter_8347_2418___fuseiter_8348_2419 / 8UL) * 512UL) + (((fused_0fused_0fused_0fused_0_fuseiter_8344___fuseiter_8345_2416___fuseiter_8346_2417___fuseiter_8347_2418___fuseiter_8348_2419 % 8UL) * 64UL) + _fuseiter_8349))] = __cached_1;
  }
}

static void reorder__4550_closure_20_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept{
  reorder__4550_closure_20(i, (float*)(args[0UL].v_ptr), (float*)(args[1UL].v_ptr));
}

static void mul__6020_closure_21(uint64_t fused_0fused_0fused_0fused_0__itr_0____itr_1_2420____itr_2_2421____itr_3_2422____itr_4_2423, float* __restrict__ __ins_0, float* __restrict__ __ins_1, float* __restrict__ __outs_0) noexcept{
  for (uint64_t _fuseiter_8355 = 0UL; _fuseiter_8355 < 64UL; _fuseiter_8355 += 16UL) {
    vec_f32x16 __cached_0;
    __cached_0 = vec_f32x16::load(&__ins_0[((((fused_0fused_0fused_0fused_0__itr_0____itr_1_2420____itr_2_2421____itr_3_2422____itr_4_2423 / 8UL) * 512UL) + ((fused_0fused_0fused_0fused_0__itr_0____itr_1_2420____itr_2_2421____itr_3_2422____itr_4_2423 % 8UL) * 64UL)) + _fuseiter_8355)]);
    float __cached_1;
    __cached_1 = __ins_1[0];
    vec_f32x16 __cached_2;
    __cached_2 = (__cached_0 * vec_f32x16(__cached_1));
    vec_f32x16::store(__cached_2, &__outs_0[((((fused_0fused_0fused_0fused_0__itr_0____itr_1_2420____itr_2_2421____itr_3_2422____itr_4_2423 / 8UL) * 512UL) + ((fused_0fused_0fused_0fused_0__itr_0____itr_1_2420____itr_2_2421____itr_3_2422____itr_4_2423 % 8UL) * 64UL)) + _fuseiter_8355)]);
  }
}

static void mul__6020_closure_21_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept{
  mul__6020_closure_21(i, (float*)(args[0UL].v_ptr), (float*)(args[1UL].v_ptr), (float*)(args[2UL].v_ptr));
}

static void reorder__4580_closure_22(uint64_t fused_0fused_0fused_0fused_0_fuseiter_8357___fuseiter_8358_2424___fuseiter_8359_2425___fuseiter_8360_2426___fuseiter_8361_2427, float* __restrict__ __ins_0, float* __restrict__ __outs_0) noexcept{
  for (uint64_t _fuseiter_8362 = 0UL; _fuseiter_8362 < 64UL; _fuseiter_8362 += 1UL) {
    float __cached_0;
    __cached_0 = __ins_0[(((fused_0fused_0fused_0fused_0_fuseiter_8357___fuseiter_8358_2424___fuseiter_8359_2425___fuseiter_8360_2426___fuseiter_8361_2427 / 2UL) * 128UL) + (_fuseiter_8362 + ((fused_0fused_0fused_0fused_0_fuseiter_8357___fuseiter_8358_2424___fuseiter_8359_2425___fuseiter_8360_2426___fuseiter_8361_2427 % 2UL) * 64UL)))];
    float __cached_1;
    __cached_1 = __cached_0;
    __outs_0[(((fused_0fused_0fused_0fused_0_fuseiter_8357___fuseiter_8358_2424___fuseiter_8359_2425___fuseiter_8360_2426___fuseiter_8361_2427 / 2UL) * 128UL) + (((fused_0fused_0fused_0fused_0_fuseiter_8357___fuseiter_8358_2424___fuseiter_8359_2425___fuseiter_8360_2426___fuseiter_8361_2427 % 2UL) * 64UL) + _fuseiter_8362))] = __cached_1;
  }
}

static void reorder__4580_closure_22_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept{
  reorder__4580_closure_22(i, (float*)(args[0UL].v_ptr), (float*)(args[1UL].v_ptr));
}

static void mul__6040_closure_23(uint64_t fused_0fused_0fused_0fused_0__itr_0____itr_1_2428____itr_2_2429____itr_3_2430____itr_4_2431, float* __restrict__ __ins_0, float* __restrict__ __ins_1, float* __restrict__ __outs_0) noexcept{
  for (uint64_t _fuseiter_8368 = 0UL; _fuseiter_8368 < 64UL; _fuseiter_8368 += 16UL) {
    vec_f32x16 __cached_0;
    __cached_0 = vec_f32x16::load(&__ins_0[((((fused_0fused_0fused_0fused_0__itr_0____itr_1_2428____itr_2_2429____itr_3_2430____itr_4_2431 / 2UL) * 128UL) + ((fused_0fused_0fused_0fused_0__itr_0____itr_1_2428____itr_2_2429____itr_3_2430____itr_4_2431 % 2UL) * 64UL)) + _fuseiter_8368)]);
    float __cached_1;
    __cached_1 = __ins_1[0];
    vec_f32x16 __cached_2;
    __cached_2 = (__cached_0 * vec_f32x16(__cached_1));
    vec_f32x16::store(__cached_2, &__outs_0[((((fused_0fused_0fused_0fused_0__itr_0____itr_1_2428____itr_2_2429____itr_3_2430____itr_4_2431 / 2UL) * 128UL) + ((fused_0fused_0fused_0fused_0__itr_0____itr_1_2428____itr_2_2429____itr_3_2430____itr_4_2431 % 2UL) * 64UL)) + _fuseiter_8368)]);
  }
}

static void mul__6040_closure_23_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept{
  mul__6040_closure_23(i, (float*)(args[0UL].v_ptr), (float*)(args[1UL].v_ptr), (float*)(args[2UL].v_ptr));
}

static void reorder__4610_closure_24(uint64_t fused_0fused_0fused_0fused_0_fuseiter_8370___fuseiter_8371_2432___fuseiter_8372_2433___fuseiter_8373_2434___fuseiter_8374_2435, float* __restrict__ __ins_0, float* __restrict__ __outs_0) noexcept{
  for (uint64_t _fuseiter_8375 = 0UL; _fuseiter_8375 < 64UL; _fuseiter_8375 += 1UL) {
    float __cached_0;
    __cached_0 = __ins_0[(((fused_0fused_0fused_0fused_0_fuseiter_8370___fuseiter_8371_2432___fuseiter_8372_2433___fuseiter_8373_2434___fuseiter_8374_2435 / 2UL) * 128UL) + (_fuseiter_8375 + ((fused_0fused_0fused_0fused_0_fuseiter_8370___fuseiter_8371_2432___fuseiter_8372_2433___fuseiter_8373_2434___fuseiter_8374_2435 % 2UL) * 64UL)))];
    float __cached_1;
    __cached_1 = __cached_0;
    __outs_0[(((fused_0fused_0fused_0fused_0_fuseiter_8370___fuseiter_8371_2432___fuseiter_8372_2433___fuseiter_8373_2434___fuseiter_8374_2435 / 2UL) * 128UL) + (((fused_0fused_0fused_0fused_0_fuseiter_8370___fuseiter_8371_2432___fuseiter_8372_2433___fuseiter_8373_2434___fuseiter_8374_2435 % 2UL) * 64UL) + _fuseiter_8375))] = __cached_1;
  }
}

static void reorder__4610_closure_24_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept{
  reorder__4610_closure_24(i, (float*)(args[0UL].v_ptr), (float*)(args[1UL].v_ptr));
}

static void mul__6060_closure_25(uint64_t fused_0fused_0fused_0fused_0__itr_0____itr_1_2436____itr_2_2437____itr_3_2438____itr_4_2439, float* __restrict__ __ins_0, float* __restrict__ __ins_1, float* __restrict__ __outs_0) noexcept{
  for (uint64_t _fuseiter_8381 = 0UL; _fuseiter_8381 < 64UL; _fuseiter_8381 += 16UL) {
    vec_f32x16 __cached_0;
    __cached_0 = vec_f32x16::load(&__ins_0[((((fused_0fused_0fused_0fused_0__itr_0____itr_1_2436____itr_2_2437____itr_3_2438____itr_4_2439 / 2UL) * 128UL) + ((fused_0fused_0fused_0fused_0__itr_0____itr_1_2436____itr_2_2437____itr_3_2438____itr_4_2439 % 2UL) * 64UL)) + _fuseiter_8381)]);
    float __cached_1;
    __cached_1 = __ins_1[0];
    vec_f32x16 __cached_2;
    __cached_2 = (__cached_0 * vec_f32x16(__cached_1));
    vec_f32x16::store(__cached_2, &__outs_0[((((fused_0fused_0fused_0fused_0__itr_0____itr_1_2436____itr_2_2437____itr_3_2438____itr_4_2439 / 2UL) * 128UL) + ((fused_0fused_0fused_0fused_0__itr_0____itr_1_2436____itr_2_2437____itr_3_2438____itr_4_2439 % 2UL) * 64UL)) + _fuseiter_8381)]);
  }
}

static void mul__6060_closure_25_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept{
  mul__6060_closure_25(i, (float*)(args[0UL].v_ptr), (float*)(args[1UL].v_ptr), (float*)(args[2UL].v_ptr));
}

static void reorder__4640_closure_26(uint64_t fused_0fused_0fused_0fused_0_fuseiter_8383___fuseiter_8384_2440___fuseiter_8385_2441___fuseiter_8386_2442___fuseiter_8387_2443, float* __restrict__ __ins_0, float* __restrict__ __outs_0) noexcept{
  for (uint64_t _fuseiter_8388 = 0UL; _fuseiter_8388 < 64UL; _fuseiter_8388 += 1UL) {
    float __cached_0;
    __cached_0 = __ins_0[(((fused_0fused_0fused_0fused_0_fuseiter_8383___fuseiter_8384_2440___fuseiter_8385_2441___fuseiter_8386_2442___fuseiter_8387_2443 / 8UL) * 512UL) + (_fuseiter_8388 + ((fused_0fused_0fused_0fused_0_fuseiter_8383___fuseiter_8384_2440___fuseiter_8385_2441___fuseiter_8386_2442___fuseiter_8387_2443 % 8UL) * 64UL)))];
    float __cached_1;
    __cached_1 = __cached_0;
    __outs_0[(((fused_0fused_0fused_0fused_0_fuseiter_8383___fuseiter_8384_2440___fuseiter_8385_2441___fuseiter_8386_2442___fuseiter_8387_2443 / 8UL) * 512UL) + (((fused_0fused_0fused_0fused_0_fuseiter_8383___fuseiter_8384_2440___fuseiter_8385_2441___fuseiter_8386_2442___fuseiter_8387_2443 % 8UL) * 64UL) + _fuseiter_8388))] = __cached_1;
  }
}

static void reorder__4640_closure_26_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept{
  reorder__4640_closure_26(i, (float*)(args[0UL].v_ptr), (float*)(args[1UL].v_ptr));
}

static void mul__6080_closure_27(uint64_t fused_0fused_0fused_0fused_0__itr_0____itr_1_2444____itr_2_2445____itr_3_2446____itr_4_2447, float* __restrict__ __ins_0, float* __restrict__ __ins_1, float* __restrict__ __outs_0) noexcept{
  for (uint64_t _fuseiter_8394 = 0UL; _fuseiter_8394 < 64UL; _fuseiter_8394 += 16UL) {
    vec_f32x16 __cached_0;
    __cached_0 = vec_f32x16::load(&__ins_0[((((fused_0fused_0fused_0fused_0__itr_0____itr_1_2444____itr_2_2445____itr_3_2446____itr_4_2447 / 8UL) * 512UL) + ((fused_0fused_0fused_0fused_0__itr_0____itr_1_2444____itr_2_2445____itr_3_2446____itr_4_2447 % 8UL) * 64UL)) + _fuseiter_8394)]);
    float __cached_1;
    __cached_1 = __ins_1[0];
    vec_f32x16 __cached_2;
    __cached_2 = (__cached_0 * vec_f32x16(__cached_1));
    vec_f32x16::store(__cached_2, &__outs_0[((((fused_0fused_0fused_0fused_0__itr_0____itr_1_2444____itr_2_2445____itr_3_2446____itr_4_2447 / 8UL) * 512UL) + ((fused_0fused_0fused_0fused_0__itr_0____itr_1_2444____itr_2_2445____itr_3_2446____itr_4_2447 % 8UL) * 64UL)) + _fuseiter_8394)]);
  }
}

static void mul__6080_closure_27_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept{
  mul__6080_closure_27(i, (float*)(args[0UL].v_ptr), (float*)(args[1UL].v_ptr), (float*)(args[2UL].v_ptr));
}

static void reorder__4670_closure_28(uint64_t fused_0fused_0fused_0fused_0_fuseiter_8396___fuseiter_8397_2448___fuseiter_8398_2449___fuseiter_8399_2450___fuseiter_8400_2451, float* __restrict__ __ins_0, float* __restrict__ __outs_0) noexcept{
  for (uint64_t _fuseiter_8401 = 0UL; _fuseiter_8401 < 64UL; _fuseiter_8401 += 1UL) {
    float __cached_0;
    __cached_0 = __ins_0[(((fused_0fused_0fused_0fused_0_fuseiter_8396___fuseiter_8397_2448___fuseiter_8398_2449___fuseiter_8399_2450___fuseiter_8400_2451 / 2UL) * 128UL) + (_fuseiter_8401 + ((fused_0fused_0fused_0fused_0_fuseiter_8396___fuseiter_8397_2448___fuseiter_8398_2449___fuseiter_8399_2450___fuseiter_8400_2451 % 2UL) * 64UL)))];
    float __cached_1;
    __cached_1 = __cached_0;
    __outs_0[(((fused_0fused_0fused_0fused_0_fuseiter_8396___fuseiter_8397_2448___fuseiter_8398_2449___fuseiter_8399_2450___fuseiter_8400_2451 / 2UL) * 128UL) + (((fused_0fused_0fused_0fused_0_fuseiter_8396___fuseiter_8397_2448___fuseiter_8398_2449___fuseiter_8399_2450___fuseiter_8400_2451 % 2UL) * 64UL) + _fuseiter_8401))] = __cached_1;
  }
}

static void reorder__4670_closure_28_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept{
  reorder__4670_closure_28(i, (float*)(args[0UL].v_ptr), (float*)(args[1UL].v_ptr));
}

static void mul__6100_closure_29(uint64_t fused_0fused_0fused_0fused_0__itr_0____itr_1_2452____itr_2_2453____itr_3_2454____itr_4_2455, float* __restrict__ __ins_0, float* __restrict__ __ins_1, float* __restrict__ __outs_0) noexcept{
  for (uint64_t _fuseiter_8407 = 0UL; _fuseiter_8407 < 64UL; _fuseiter_8407 += 16UL) {
    vec_f32x16 __cached_0;
    __cached_0 = vec_f32x16::load(&__ins_0[((((fused_0fused_0fused_0fused_0__itr_0____itr_1_2452____itr_2_2453____itr_3_2454____itr_4_2455 / 2UL) * 128UL) + ((fused_0fused_0fused_0fused_0__itr_0____itr_1_2452____itr_2_2453____itr_3_2454____itr_4_2455 % 2UL) * 64UL)) + _fuseiter_8407)]);
    float __cached_1;
    __cached_1 = __ins_1[0];
    vec_f32x16 __cached_2;
    __cached_2 = (__cached_0 * vec_f32x16(__cached_1));
    vec_f32x16::store(__cached_2, &__outs_0[((((fused_0fused_0fused_0fused_0__itr_0____itr_1_2452____itr_2_2453____itr_3_2454____itr_4_2455 / 2UL) * 128UL) + ((fused_0fused_0fused_0fused_0__itr_0____itr_1_2452____itr_2_2453____itr_3_2454____itr_4_2455 % 2UL) * 64UL)) + _fuseiter_8407)]);
  }
}

static void mul__6100_closure_29_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept{
  mul__6100_closure_29(i, (float*)(args[0UL].v_ptr), (float*)(args[1UL].v_ptr), (float*)(args[2UL].v_ptr));
}

static void reorder__4700_closure_30(uint64_t fused_0fused_0fused_0fused_0_fuseiter_8409___fuseiter_8410_2456___fuseiter_8411_2457___fuseiter_8412_2458___fuseiter_8413_2459, float* __restrict__ __ins_0, float* __restrict__ __outs_0) noexcept{
  for (uint64_t _fuseiter_8414 = 0UL; _fuseiter_8414 < 64UL; _fuseiter_8414 += 1UL) {
    float __cached_0;
    __cached_0 = __ins_0[(((fused_0fused_0fused_0fused_0_fuseiter_8409___fuseiter_8410_2456___fuseiter_8411_2457___fuseiter_8412_2458___fuseiter_8413_2459 / 2UL) * 128UL) + (_fuseiter_8414 + ((fused_0fused_0fused_0fused_0_fuseiter_8409___fuseiter_8410_2456___fuseiter_8411_2457___fuseiter_8412_2458___fuseiter_8413_2459 % 2UL) * 64UL)))];
    float __cached_1;
    __cached_1 = __cached_0;
    __outs_0[(((fused_0fused_0fused_0fused_0_fuseiter_8409___fuseiter_8410_2456___fuseiter_8411_2457___fuseiter_8412_2458___fuseiter_8413_2459 / 2UL) * 128UL) + (((fused_0fused_0fused_0fused_0_fuseiter_8409___fuseiter_8410_2456___fuseiter_8411_2457___fuseiter_8412_2458___fuseiter_8413_2459 % 2UL) * 64UL) + _fuseiter_8414))] = __cached_1;
  }
}

static void reorder__4700_closure_30_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept{
  reorder__4700_closure_30(i, (float*)(args[0UL].v_ptr), (float*)(args[1UL].v_ptr));
}

static void mul__6120_closure_31(uint64_t fused_0fused_0fused_0fused_0__itr_0____itr_1_2460____itr_2_2461____itr_3_2462____itr_4_2463, float* __restrict__ __ins_0, float* __restrict__ __ins_1, float* __restrict__ __outs_0) noexcept{
  for (uint64_t _fuseiter_8420 = 0UL; _fuseiter_8420 < 64UL; _fuseiter_8420 += 16UL) {
    vec_f32x16 __cached_0;
    __cached_0 = vec_f32x16::load(&__ins_0[((((fused_0fused_0fused_0fused_0__itr_0____itr_1_2460____itr_2_2461____itr_3_2462____itr_4_2463 / 2UL) * 128UL) + ((fused_0fused_0fused_0fused_0__itr_0____itr_1_2460____itr_2_2461____itr_3_2462____itr_4_2463 % 2UL) * 64UL)) + _fuseiter_8420)]);
    float __cached_1;
    __cached_1 = __ins_1[0];
    vec_f32x16 __cached_2;
    __cached_2 = (__cached_0 * vec_f32x16(__cached_1));
    vec_f32x16::store(__cached_2, &__outs_0[((((fused_0fused_0fused_0fused_0__itr_0____itr_1_2460____itr_2_2461____itr_3_2462____itr_4_2463 / 2UL) * 128UL) + ((fused_0fused_0fused_0fused_0__itr_0____itr_1_2460____itr_2_2461____itr_3_2462____itr_4_2463 % 2UL) * 64UL)) + _fuseiter_8420)]);
  }
}

static void mul__6120_closure_31_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept{
  mul__6120_closure_31(i, (float*)(args[0UL].v_ptr), (float*)(args[1UL].v_ptr), (float*)(args[2UL].v_ptr));
}

static void reorder__4730_closure_32(uint64_t fused_0fused_0fused_0fused_0_fuseiter_8422___fuseiter_8423_2464___fuseiter_8424_2465___fuseiter_8425_2466___fuseiter_8426_2467, float* __restrict__ __ins_0, float* __restrict__ __outs_0) noexcept{
  for (uint64_t _fuseiter_8427 = 0UL; _fuseiter_8427 < 64UL; _fuseiter_8427 += 1UL) {
    float __cached_0;
    __cached_0 = __ins_0[(((fused_0fused_0fused_0fused_0_fuseiter_8422___fuseiter_8423_2464___fuseiter_8424_2465___fuseiter_8425_2466___fuseiter_8426_2467 / 8UL) * 512UL) + (_fuseiter_8427 + ((fused_0fused_0fused_0fused_0_fuseiter_8422___fuseiter_8423_2464___fuseiter_8424_2465___fuseiter_8425_2466___fuseiter_8426_2467 % 8UL) * 64UL)))];
    float __cached_1;
    __cached_1 = __cached_0;
    __outs_0[(((fused_0fused_0fused_0fused_0_fuseiter_8422___fuseiter_8423_2464___fuseiter_8424_2465___fuseiter_8425_2466___fuseiter_8426_2467 / 8UL) * 512UL) + (((fused_0fused_0fused_0fused_0_fuseiter_8422___fuseiter_8423_2464___fuseiter_8424_2465___fuseiter_8425_2466___fuseiter_8426_2467 % 8UL) * 64UL) + _fuseiter_8427))] = __cached_1;
  }
}

static void reorder__4730_closure_32_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept{
  reorder__4730_closure_32(i, (float*)(args[0UL].v_ptr), (float*)(args[1UL].v_ptr));
}

static void mul__6140_closure_33(uint64_t fused_0fused_0fused_0fused_0__itr_0____itr_1_2468____itr_2_2469____itr_3_2470____itr_4_2471, float* __restrict__ __ins_0, float* __restrict__ __ins_1, float* __restrict__ __outs_0) noexcept{
  for (uint64_t _fuseiter_8433 = 0UL; _fuseiter_8433 < 64UL; _fuseiter_8433 += 16UL) {
    vec_f32x16 __cached_0;
    __cached_0 = vec_f32x16::load(&__ins_0[((((fused_0fused_0fused_0fused_0__itr_0____itr_1_2468____itr_2_2469____itr_3_2470____itr_4_2471 / 8UL) * 512UL) + ((fused_0fused_0fused_0fused_0__itr_0____itr_1_2468____itr_2_2469____itr_3_2470____itr_4_2471 % 8UL) * 64UL)) + _fuseiter_8433)]);
    float __cached_1;
    __cached_1 = __ins_1[0];
    vec_f32x16 __cached_2;
    __cached_2 = (__cached_0 * vec_f32x16(__cached_1));
    vec_f32x16::store(__cached_2, &__outs_0[((((fused_0fused_0fused_0fused_0__itr_0____itr_1_2468____itr_2_2469____itr_3_2470____itr_4_2471 / 8UL) * 512UL) + ((fused_0fused_0fused_0fused_0__itr_0____itr_1_2468____itr_2_2469____itr_3_2470____itr_4_2471 % 8UL) * 64UL)) + _fuseiter_8433)]);
  }
}

static void mul__6140_closure_33_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept{
  mul__6140_closure_33(i, (float*)(args[0UL].v_ptr), (float*)(args[1UL].v_ptr), (float*)(args[2UL].v_ptr));
}

static void reorder__4760_closure_34(uint64_t fused_0fused_0fused_0fused_0_fuseiter_8435___fuseiter_8436_2472___fuseiter_8437_2473___fuseiter_8438_2474___fuseiter_8439_2475, float* __restrict__ __ins_0, float* __restrict__ __outs_0) noexcept{
  for (uint64_t _fuseiter_8440 = 0UL; _fuseiter_8440 < 64UL; _fuseiter_8440 += 1UL) {
    float __cached_0;
    __cached_0 = __ins_0[(((fused_0fused_0fused_0fused_0_fuseiter_8435___fuseiter_8436_2472___fuseiter_8437_2473___fuseiter_8438_2474___fuseiter_8439_2475 / 16UL) * 1024UL) + (_fuseiter_8440 + ((fused_0fused_0fused_0fused_0_fuseiter_8435___fuseiter_8436_2472___fuseiter_8437_2473___fuseiter_8438_2474___fuseiter_8439_2475 % 16UL) * 64UL)))];
    float __cached_1;
    __cached_1 = __cached_0;
    __outs_0[(((fused_0fused_0fused_0fused_0_fuseiter_8435___fuseiter_8436_2472___fuseiter_8437_2473___fuseiter_8438_2474___fuseiter_8439_2475 / 16UL) * 1024UL) + (((fused_0fused_0fused_0fused_0_fuseiter_8435___fuseiter_8436_2472___fuseiter_8437_2473___fuseiter_8438_2474___fuseiter_8439_2475 % 16UL) * 64UL) + _fuseiter_8440))] = __cached_1;
  }
}

static void reorder__4760_closure_34_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept{
  reorder__4760_closure_34(i, (float*)(args[0UL].v_ptr), (float*)(args[1UL].v_ptr));
}

static void mul__6160_closure_35(uint64_t fused_0fused_0fused_0fused_0__itr_0____itr_1_2476____itr_2_2477____itr_3_2478____itr_4_2479, float* __restrict__ __ins_0, float* __restrict__ __ins_1, float* __restrict__ __outs_0) noexcept{
  for (uint64_t _fuseiter_8446 = 0UL; _fuseiter_8446 < 64UL; _fuseiter_8446 += 16UL) {
    vec_f32x16 __cached_0;
    __cached_0 = vec_f32x16::load(&__ins_0[((((fused_0fused_0fused_0fused_0__itr_0____itr_1_2476____itr_2_2477____itr_3_2478____itr_4_2479 / 16UL) * 1024UL) + ((fused_0fused_0fused_0fused_0__itr_0____itr_1_2476____itr_2_2477____itr_3_2478____itr_4_2479 % 16UL) * 64UL)) + _fuseiter_8446)]);
    float __cached_1;
    __cached_1 = __ins_1[0];
    vec_f32x16 __cached_2;
    __cached_2 = (__cached_0 * vec_f32x16(__cached_1));
    vec_f32x16::store(__cached_2, &__outs_0[((((fused_0fused_0fused_0fused_0__itr_0____itr_1_2476____itr_2_2477____itr_3_2478____itr_4_2479 / 16UL) * 1024UL) + ((fused_0fused_0fused_0fused_0__itr_0____itr_1_2476____itr_2_2477____itr_3_2478____itr_4_2479 % 16UL) * 64UL)) + _fuseiter_8446)]);
  }
}

static void mul__6160_closure_35_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept{
  mul__6160_closure_35(i, (float*)(args[0UL].v_ptr), (float*)(args[1UL].v_ptr), (float*)(args[2UL].v_ptr));
}

static void reorder__4790_closure_36(uint64_t fused_0fused_0fused_0fused_0_fuseiter_8448___fuseiter_8449_2480___fuseiter_8450_2481___fuseiter_8451_2482___fuseiter_8452_2483, float* __restrict__ __ins_0, float* __restrict__ __outs_0) noexcept{
  for (uint64_t _fuseiter_8453 = 0UL; _fuseiter_8453 < 64UL; _fuseiter_8453 += 1UL) {
    float __cached_0;
    __cached_0 = __ins_0[(((fused_0fused_0fused_0fused_0_fuseiter_8448___fuseiter_8449_2480___fuseiter_8450_2481___fuseiter_8451_2482___fuseiter_8452_2483 / 4UL) * 256UL) + (_fuseiter_8453 + ((fused_0fused_0fused_0fused_0_fuseiter_8448___fuseiter_8449_2480___fuseiter_8450_2481___fuseiter_8451_2482___fuseiter_8452_2483 % 4UL) * 64UL)))];
    float __cached_1;
    __cached_1 = __cached_0;
    __outs_0[(((fused_0fused_0fused_0fused_0_fuseiter_8448___fuseiter_8449_2480___fuseiter_8450_2481___fuseiter_8451_2482___fuseiter_8452_2483 / 4UL) * 256UL) + (((fused_0fused_0fused_0fused_0_fuseiter_8448___fuseiter_8449_2480___fuseiter_8450_2481___fuseiter_8451_2482___fuseiter_8452_2483 % 4UL) * 64UL) + _fuseiter_8453))] = __cached_1;
  }
}

static void reorder__4790_closure_36_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept{
  reorder__4790_closure_36(i, (float*)(args[0UL].v_ptr), (float*)(args[1UL].v_ptr));
}

static void mul__6180_closure_37(uint64_t fused_0fused_0fused_0fused_0__itr_0____itr_1_2484____itr_2_2485____itr_3_2486____itr_4_2487, float* __restrict__ __ins_0, float* __restrict__ __ins_1, float* __restrict__ __outs_0) noexcept{
  for (uint64_t _fuseiter_8459 = 0UL; _fuseiter_8459 < 64UL; _fuseiter_8459 += 16UL) {
    vec_f32x16 __cached_0;
    __cached_0 = vec_f32x16::load(&__ins_0[((((fused_0fused_0fused_0fused_0__itr_0____itr_1_2484____itr_2_2485____itr_3_2486____itr_4_2487 / 4UL) * 256UL) + ((fused_0fused_0fused_0fused_0__itr_0____itr_1_2484____itr_2_2485____itr_3_2486____itr_4_2487 % 4UL) * 64UL)) + _fuseiter_8459)]);
    float __cached_1;
    __cached_1 = __ins_1[0];
    vec_f32x16 __cached_2;
    __cached_2 = (__cached_0 * vec_f32x16(__cached_1));
    vec_f32x16::store(__cached_2, &__outs_0[((((fused_0fused_0fused_0fused_0__itr_0____itr_1_2484____itr_2_2485____itr_3_2486____itr_4_2487 / 4UL) * 256UL) + ((fused_0fused_0fused_0fused_0__itr_0____itr_1_2484____itr_2_2485____itr_3_2486____itr_4_2487 % 4UL) * 64UL)) + _fuseiter_8459)]);
  }
}

static void mul__6180_closure_37_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept{
  mul__6180_closure_37(i, (float*)(args[0UL].v_ptr), (float*)(args[1UL].v_ptr), (float*)(args[2UL].v_ptr));
}

static void reorder__4820_closure_38(uint64_t fused_0fused_0fused_0fused_0_fuseiter_8461___fuseiter_8462_2488___fuseiter_8463_2489___fuseiter_8464_2490___fuseiter_8465_2491, float* __restrict__ __ins_0, float* __restrict__ __outs_0) noexcept{
  for (uint64_t _fuseiter_8466 = 0UL; _fuseiter_8466 < 64UL; _fuseiter_8466 += 1UL) {
    float __cached_0;
    __cached_0 = __ins_0[(((fused_0fused_0fused_0fused_0_fuseiter_8461___fuseiter_8462_2488___fuseiter_8463_2489___fuseiter_8464_2490___fuseiter_8465_2491 / 4UL) * 256UL) + (_fuseiter_8466 + ((fused_0fused_0fused_0fused_0_fuseiter_8461___fuseiter_8462_2488___fuseiter_8463_2489___fuseiter_8464_2490___fuseiter_8465_2491 % 4UL) * 64UL)))];
    float __cached_1;
    __cached_1 = __cached_0;
    __outs_0[(((fused_0fused_0fused_0fused_0_fuseiter_8461___fuseiter_8462_2488___fuseiter_8463_2489___fuseiter_8464_2490___fuseiter_8465_2491 / 4UL) * 256UL) + (((fused_0fused_0fused_0fused_0_fuseiter_8461___fuseiter_8462_2488___fuseiter_8463_2489___fuseiter_8464_2490___fuseiter_8465_2491 % 4UL) * 64UL) + _fuseiter_8466))] = __cached_1;
  }
}

static void reorder__4820_closure_38_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept{
  reorder__4820_closure_38(i, (float*)(args[0UL].v_ptr), (float*)(args[1UL].v_ptr));
}

static void mul__6200_closure_39(uint64_t fused_0fused_0fused_0fused_0__itr_0____itr_1_2492____itr_2_2493____itr_3_2494____itr_4_2495, float* __restrict__ __ins_0, float* __restrict__ __ins_1, float* __restrict__ __outs_0) noexcept{
  for (uint64_t _fuseiter_8472 = 0UL; _fuseiter_8472 < 64UL; _fuseiter_8472 += 16UL) {
    vec_f32x16 __cached_0;
    __cached_0 = vec_f32x16::load(&__ins_0[((((fused_0fused_0fused_0fused_0__itr_0____itr_1_2492____itr_2_2493____itr_3_2494____itr_4_2495 / 4UL) * 256UL) + ((fused_0fused_0fused_0fused_0__itr_0____itr_1_2492____itr_2_2493____itr_3_2494____itr_4_2495 % 4UL) * 64UL)) + _fuseiter_8472)]);
    float __cached_1;
    __cached_1 = __ins_1[0];
    vec_f32x16 __cached_2;
    __cached_2 = (__cached_0 * vec_f32x16(__cached_1));
    vec_f32x16::store(__cached_2, &__outs_0[((((fused_0fused_0fused_0fused_0__itr_0____itr_1_2492____itr_2_2493____itr_3_2494____itr_4_2495 / 4UL) * 256UL) + ((fused_0fused_0fused_0fused_0__itr_0____itr_1_2492____itr_2_2493____itr_3_2494____itr_4_2495 % 4UL) * 64UL)) + _fuseiter_8472)]);
  }
}

static void mul__6200_closure_39_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept{
  mul__6200_closure_39(i, (float*)(args[0UL].v_ptr), (float*)(args[1UL].v_ptr), (float*)(args[2UL].v_ptr));
}

static void reorder__4850_closure_40(uint64_t fused_0fused_0fused_0fused_0_fuseiter_8474___fuseiter_8475_2496___fuseiter_8476_2497___fuseiter_8477_2498___fuseiter_8478_2499, float* __restrict__ __ins_0, float* __restrict__ __outs_0) noexcept{
  for (uint64_t _fuseiter_8479 = 0UL; _fuseiter_8479 < 64UL; _fuseiter_8479 += 1UL) {
    float __cached_0;
    __cached_0 = __ins_0[(((fused_0fused_0fused_0fused_0_fuseiter_8474___fuseiter_8475_2496___fuseiter_8476_2497___fuseiter_8477_2498___fuseiter_8478_2499 / 16UL) * 1024UL) + (_fuseiter_8479 + ((fused_0fused_0fused_0fused_0_fuseiter_8474___fuseiter_8475_2496___fuseiter_8476_2497___fuseiter_8477_2498___fuseiter_8478_2499 % 16UL) * 64UL)))];
    float __cached_1;
    __cached_1 = __cached_0;
    __outs_0[(((fused_0fused_0fused_0fused_0_fuseiter_8474___fuseiter_8475_2496___fuseiter_8476_2497___fuseiter_8477_2498___fuseiter_8478_2499 / 16UL) * 1024UL) + (((fused_0fused_0fused_0fused_0_fuseiter_8474___fuseiter_8475_2496___fuseiter_8476_2497___fuseiter_8477_2498___fuseiter_8478_2499 % 16UL) * 64UL) + _fuseiter_8479))] = __cached_1;
  }
}

static void reorder__4850_closure_40_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept{
  reorder__4850_closure_40(i, (float*)(args[0UL].v_ptr), (float*)(args[1UL].v_ptr));
}

static void mul__6220_closure_41(uint64_t fused_0fused_0fused_0fused_0__itr_0____itr_1_2500____itr_2_2501____itr_3_2502____itr_4_2503, float* __restrict__ __ins_0, float* __restrict__ __ins_1, float* __restrict__ __outs_0) noexcept{
  for (uint64_t _fuseiter_8485 = 0UL; _fuseiter_8485 < 64UL; _fuseiter_8485 += 16UL) {
    vec_f32x16 __cached_0;
    __cached_0 = vec_f32x16::load(&__ins_0[((((fused_0fused_0fused_0fused_0__itr_0____itr_1_2500____itr_2_2501____itr_3_2502____itr_4_2503 / 16UL) * 1024UL) + ((fused_0fused_0fused_0fused_0__itr_0____itr_1_2500____itr_2_2501____itr_3_2502____itr_4_2503 % 16UL) * 64UL)) + _fuseiter_8485)]);
    float __cached_1;
    __cached_1 = __ins_1[0];
    vec_f32x16 __cached_2;
    __cached_2 = (__cached_0 * vec_f32x16(__cached_1));
    vec_f32x16::store(__cached_2, &__outs_0[((((fused_0fused_0fused_0fused_0__itr_0____itr_1_2500____itr_2_2501____itr_3_2502____itr_4_2503 / 16UL) * 1024UL) + ((fused_0fused_0fused_0fused_0__itr_0____itr_1_2500____itr_2_2501____itr_3_2502____itr_4_2503 % 16UL) * 64UL)) + _fuseiter_8485)]);
  }
}

static void mul__6220_closure_41_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept{
  mul__6220_closure_41(i, (float*)(args[0UL].v_ptr), (float*)(args[1UL].v_ptr), (float*)(args[2UL].v_ptr));
}

static void reorder__4880_closure_42(uint64_t fused_0fused_0fused_0fused_0_fuseiter_8487___fuseiter_8488_2504___fuseiter_8489_2505___fuseiter_8490_2506___fuseiter_8491_2507, float* __restrict__ __ins_0, float* __restrict__ __outs_0) noexcept{
  for (uint64_t _fuseiter_8492 = 0UL; _fuseiter_8492 < 64UL; _fuseiter_8492 += 1UL) {
    float __cached_0;
    __cached_0 = __ins_0[(((fused_0fused_0fused_0fused_0_fuseiter_8487___fuseiter_8488_2504___fuseiter_8489_2505___fuseiter_8490_2506___fuseiter_8491_2507 / 4UL) * 256UL) + (_fuseiter_8492 + ((fused_0fused_0fused_0fused_0_fuseiter_8487___fuseiter_8488_2504___fuseiter_8489_2505___fuseiter_8490_2506___fuseiter_8491_2507 % 4UL) * 64UL)))];
    float __cached_1;
    __cached_1 = __cached_0;
    __outs_0[(((fused_0fused_0fused_0fused_0_fuseiter_8487___fuseiter_8488_2504___fuseiter_8489_2505___fuseiter_8490_2506___fuseiter_8491_2507 / 4UL) * 256UL) + (((fused_0fused_0fused_0fused_0_fuseiter_8487___fuseiter_8488_2504___fuseiter_8489_2505___fuseiter_8490_2506___fuseiter_8491_2507 % 4UL) * 64UL) + _fuseiter_8492))] = __cached_1;
  }
}

static void reorder__4880_closure_42_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept{
  reorder__4880_closure_42(i, (float*)(args[0UL].v_ptr), (float*)(args[1UL].v_ptr));
}

static void mul__6240_closure_43(uint64_t fused_0fused_0fused_0fused_0__itr_0____itr_1_2508____itr_2_2509____itr_3_2510____itr_4_2511, float* __restrict__ __ins_0, float* __restrict__ __ins_1, float* __restrict__ __outs_0) noexcept{
  for (uint64_t _fuseiter_8498 = 0UL; _fuseiter_8498 < 64UL; _fuseiter_8498 += 16UL) {
    vec_f32x16 __cached_0;
    __cached_0 = vec_f32x16::load(&__ins_0[((((fused_0fused_0fused_0fused_0__itr_0____itr_1_2508____itr_2_2509____itr_3_2510____itr_4_2511 / 4UL) * 256UL) + ((fused_0fused_0fused_0fused_0__itr_0____itr_1_2508____itr_2_2509____itr_3_2510____itr_4_2511 % 4UL) * 64UL)) + _fuseiter_8498)]);
    float __cached_1;
    __cached_1 = __ins_1[0];
    vec_f32x16 __cached_2;
    __cached_2 = (__cached_0 * vec_f32x16(__cached_1));
    vec_f32x16::store(__cached_2, &__outs_0[((((fused_0fused_0fused_0fused_0__itr_0____itr_1_2508____itr_2_2509____itr_3_2510____itr_4_2511 / 4UL) * 256UL) + ((fused_0fused_0fused_0fused_0__itr_0____itr_1_2508____itr_2_2509____itr_3_2510____itr_4_2511 % 4UL) * 64UL)) + _fuseiter_8498)]);
  }
}

static void mul__6240_closure_43_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept{
  mul__6240_closure_43(i, (float*)(args[0UL].v_ptr), (float*)(args[1UL].v_ptr), (float*)(args[2UL].v_ptr));
}

static void reorder__4910_closure_44(uint64_t fused_0fused_0fused_0fused_0_fuseiter_8500___fuseiter_8501_2512___fuseiter_8502_2513___fuseiter_8503_2514___fuseiter_8504_2515, float* __restrict__ __ins_0, float* __restrict__ __outs_0) noexcept{
  for (uint64_t _fuseiter_8505 = 0UL; _fuseiter_8505 < 64UL; _fuseiter_8505 += 1UL) {
    float __cached_0;
    __cached_0 = __ins_0[(((fused_0fused_0fused_0fused_0_fuseiter_8500___fuseiter_8501_2512___fuseiter_8502_2513___fuseiter_8503_2514___fuseiter_8504_2515 / 4UL) * 256UL) + (_fuseiter_8505 + ((fused_0fused_0fused_0fused_0_fuseiter_8500___fuseiter_8501_2512___fuseiter_8502_2513___fuseiter_8503_2514___fuseiter_8504_2515 % 4UL) * 64UL)))];
    float __cached_1;
    __cached_1 = __cached_0;
    __outs_0[(((fused_0fused_0fused_0fused_0_fuseiter_8500___fuseiter_8501_2512___fuseiter_8502_2513___fuseiter_8503_2514___fuseiter_8504_2515 / 4UL) * 256UL) + (((fused_0fused_0fused_0fused_0_fuseiter_8500___fuseiter_8501_2512___fuseiter_8502_2513___fuseiter_8503_2514___fuseiter_8504_2515 % 4UL) * 64UL) + _fuseiter_8505))] = __cached_1;
  }
}

static void reorder__4910_closure_44_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept{
  reorder__4910_closure_44(i, (float*)(args[0UL].v_ptr), (float*)(args[1UL].v_ptr));
}

static void mul__6260_closure_45(uint64_t fused_0fused_0fused_0fused_0__itr_0____itr_1_2516____itr_2_2517____itr_3_2518____itr_4_2519, float* __restrict__ __ins_0, float* __restrict__ __ins_1, float* __restrict__ __outs_0) noexcept{
  for (uint64_t _fuseiter_8511 = 0UL; _fuseiter_8511 < 64UL; _fuseiter_8511 += 16UL) {
    vec_f32x16 __cached_0;
    __cached_0 = vec_f32x16::load(&__ins_0[((((fused_0fused_0fused_0fused_0__itr_0____itr_1_2516____itr_2_2517____itr_3_2518____itr_4_2519 / 4UL) * 256UL) + ((fused_0fused_0fused_0fused_0__itr_0____itr_1_2516____itr_2_2517____itr_3_2518____itr_4_2519 % 4UL) * 64UL)) + _fuseiter_8511)]);
    float __cached_1;
    __cached_1 = __ins_1[0];
    vec_f32x16 __cached_2;
    __cached_2 = (__cached_0 * vec_f32x16(__cached_1));
    vec_f32x16::store(__cached_2, &__outs_0[((((fused_0fused_0fused_0fused_0__itr_0____itr_1_2516____itr_2_2517____itr_3_2518____itr_4_2519 / 4UL) * 256UL) + ((fused_0fused_0fused_0fused_0__itr_0____itr_1_2516____itr_2_2517____itr_3_2518____itr_4_2519 % 4UL) * 64UL)) + _fuseiter_8511)]);
  }
}

static void mul__6260_closure_45_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept{
  mul__6260_closure_45(i, (float*)(args[0UL].v_ptr), (float*)(args[1UL].v_ptr), (float*)(args[2UL].v_ptr));
}

static void reorder__4940_closure_46(uint64_t fused_0fused_0fused_0fused_0_fuseiter_8513___fuseiter_8514_2520___fuseiter_8515_2521___fuseiter_8516_2522___fuseiter_8517_2523, float* __restrict__ __ins_0, float* __restrict__ __outs_0) noexcept{
  for (uint64_t _fuseiter_8518 = 0UL; _fuseiter_8518 < 64UL; _fuseiter_8518 += 1UL) {
    float __cached_0;
    __cached_0 = __ins_0[(((fused_0fused_0fused_0fused_0_fuseiter_8513___fuseiter_8514_2520___fuseiter_8515_2521___fuseiter_8516_2522___fuseiter_8517_2523 / 16UL) * 1024UL) + (_fuseiter_8518 + ((fused_0fused_0fused_0fused_0_fuseiter_8513___fuseiter_8514_2520___fuseiter_8515_2521___fuseiter_8516_2522___fuseiter_8517_2523 % 16UL) * 64UL)))];
    float __cached_1;
    __cached_1 = __cached_0;
    __outs_0[(((fused_0fused_0fused_0fused_0_fuseiter_8513___fuseiter_8514_2520___fuseiter_8515_2521___fuseiter_8516_2522___fuseiter_8517_2523 / 16UL) * 1024UL) + (((fused_0fused_0fused_0fused_0_fuseiter_8513___fuseiter_8514_2520___fuseiter_8515_2521___fuseiter_8516_2522___fuseiter_8517_2523 % 16UL) * 64UL) + _fuseiter_8518))] = __cached_1;
  }
}

static void reorder__4940_closure_46_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept{
  reorder__4940_closure_46(i, (float*)(args[0UL].v_ptr), (float*)(args[1UL].v_ptr));
}

static void mul__6280_closure_47(uint64_t fused_0fused_0fused_0fused_0__itr_0____itr_1_2524____itr_2_2525____itr_3_2526____itr_4_2527, float* __restrict__ __ins_0, float* __restrict__ __ins_1, float* __restrict__ __outs_0) noexcept{
  for (uint64_t _fuseiter_8524 = 0UL; _fuseiter_8524 < 64UL; _fuseiter_8524 += 16UL) {
    vec_f32x16 __cached_0;
    __cached_0 = vec_f32x16::load(&__ins_0[((((fused_0fused_0fused_0fused_0__itr_0____itr_1_2524____itr_2_2525____itr_3_2526____itr_4_2527 / 16UL) * 1024UL) + ((fused_0fused_0fused_0fused_0__itr_0____itr_1_2524____itr_2_2525____itr_3_2526____itr_4_2527 % 16UL) * 64UL)) + _fuseiter_8524)]);
    float __cached_1;
    __cached_1 = __ins_1[0];
    vec_f32x16 __cached_2;
    __cached_2 = (__cached_0 * vec_f32x16(__cached_1));
    vec_f32x16::store(__cached_2, &__outs_0[((((fused_0fused_0fused_0fused_0__itr_0____itr_1_2524____itr_2_2525____itr_3_2526____itr_4_2527 / 16UL) * 1024UL) + ((fused_0fused_0fused_0fused_0__itr_0____itr_1_2524____itr_2_2525____itr_3_2526____itr_4_2527 % 16UL) * 64UL)) + _fuseiter_8524)]);
  }
}

static void mul__6280_closure_47_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept{
  mul__6280_closure_47(i, (float*)(args[0UL].v_ptr), (float*)(args[1UL].v_ptr), (float*)(args[2UL].v_ptr));
}

static void reorder__4970_closure_48(uint64_t fused_0fused_0fused_0fused_0_fuseiter_8526___fuseiter_8527_2528___fuseiter_8528_2529___fuseiter_8529_2530___fuseiter_8530_2531, float* __restrict__ __ins_0, float* __restrict__ __outs_0) noexcept{
  for (uint64_t _fuseiter_8531 = 0UL; _fuseiter_8531 < 64UL; _fuseiter_8531 += 1UL) {
    float __cached_0;
    __cached_0 = __ins_0[(((fused_0fused_0fused_0fused_0_fuseiter_8526___fuseiter_8527_2528___fuseiter_8528_2529___fuseiter_8529_2530___fuseiter_8530_2531 / 4UL) * 256UL) + (_fuseiter_8531 + ((fused_0fused_0fused_0fused_0_fuseiter_8526___fuseiter_8527_2528___fuseiter_8528_2529___fuseiter_8529_2530___fuseiter_8530_2531 % 4UL) * 64UL)))];
    float __cached_1;
    __cached_1 = __cached_0;
    __outs_0[(((fused_0fused_0fused_0fused_0_fuseiter_8526___fuseiter_8527_2528___fuseiter_8528_2529___fuseiter_8529_2530___fuseiter_8530_2531 / 4UL) * 256UL) + (((fused_0fused_0fused_0fused_0_fuseiter_8526___fuseiter_8527_2528___fuseiter_8528_2529___fuseiter_8529_2530___fuseiter_8530_2531 % 4UL) * 64UL) + _fuseiter_8531))] = __cached_1;
  }
}

static void reorder__4970_closure_48_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept{
  reorder__4970_closure_48(i, (float*)(args[0UL].v_ptr), (float*)(args[1UL].v_ptr));
}

static void mul__6300_closure_49(uint64_t fused_0fused_0fused_0fused_0__itr_0____itr_1_2532____itr_2_2533____itr_3_2534____itr_4_2535, float* __restrict__ __ins_0, float* __restrict__ __ins_1, float* __restrict__ __outs_0) noexcept{
  for (uint64_t _fuseiter_8537 = 0UL; _fuseiter_8537 < 64UL; _fuseiter_8537 += 16UL) {
    vec_f32x16 __cached_0;
    __cached_0 = vec_f32x16::load(&__ins_0[((((fused_0fused_0fused_0fused_0__itr_0____itr_1_2532____itr_2_2533____itr_3_2534____itr_4_2535 / 4UL) * 256UL) + ((fused_0fused_0fused_0fused_0__itr_0____itr_1_2532____itr_2_2533____itr_3_2534____itr_4_2535 % 4UL) * 64UL)) + _fuseiter_8537)]);
    float __cached_1;
    __cached_1 = __ins_1[0];
    vec_f32x16 __cached_2;
    __cached_2 = (__cached_0 * vec_f32x16(__cached_1));
    vec_f32x16::store(__cached_2, &__outs_0[((((fused_0fused_0fused_0fused_0__itr_0____itr_1_2532____itr_2_2533____itr_3_2534____itr_4_2535 / 4UL) * 256UL) + ((fused_0fused_0fused_0fused_0__itr_0____itr_1_2532____itr_2_2533____itr_3_2534____itr_4_2535 % 4UL) * 64UL)) + _fuseiter_8537)]);
  }
}

static void mul__6300_closure_49_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept{
  mul__6300_closure_49(i, (float*)(args[0UL].v_ptr), (float*)(args[1UL].v_ptr), (float*)(args[2UL].v_ptr));
}

static void reorder__5000_closure_50(uint64_t fused_0fused_0fused_0fused_0_fuseiter_8539___fuseiter_8540_2536___fuseiter_8541_2537___fuseiter_8542_2538___fuseiter_8543_2539, float* __restrict__ __ins_0, float* __restrict__ __outs_0) noexcept{
  for (uint64_t _fuseiter_8544 = 0UL; _fuseiter_8544 < 64UL; _fuseiter_8544 += 1UL) {
    float __cached_0;
    __cached_0 = __ins_0[(((fused_0fused_0fused_0fused_0_fuseiter_8539___fuseiter_8540_2536___fuseiter_8541_2537___fuseiter_8542_2538___fuseiter_8543_2539 / 4UL) * 256UL) + (_fuseiter_8544 + ((fused_0fused_0fused_0fused_0_fuseiter_8539___fuseiter_8540_2536___fuseiter_8541_2537___fuseiter_8542_2538___fuseiter_8543_2539 % 4UL) * 64UL)))];
    float __cached_1;
    __cached_1 = __cached_0;
    __outs_0[(((fused_0fused_0fused_0fused_0_fuseiter_8539___fuseiter_8540_2536___fuseiter_8541_2537___fuseiter_8542_2538___fuseiter_8543_2539 / 4UL) * 256UL) + (((fused_0fused_0fused_0fused_0_fuseiter_8539___fuseiter_8540_2536___fuseiter_8541_2537___fuseiter_8542_2538___fuseiter_8543_2539 % 4UL) * 64UL) + _fuseiter_8544))] = __cached_1;
  }
}

static void reorder__5000_closure_50_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept{
  reorder__5000_closure_50(i, (float*)(args[0UL].v_ptr), (float*)(args[1UL].v_ptr));
}

static void mul__6320_closure_51(uint64_t fused_0fused_0fused_0fused_0__itr_0____itr_1_2540____itr_2_2541____itr_3_2542____itr_4_2543, float* __restrict__ __ins_0, float* __restrict__ __ins_1, float* __restrict__ __outs_0) noexcept{
  for (uint64_t _fuseiter_8550 = 0UL; _fuseiter_8550 < 64UL; _fuseiter_8550 += 16UL) {
    vec_f32x16 __cached_0;
    __cached_0 = vec_f32x16::load(&__ins_0[((((fused_0fused_0fused_0fused_0__itr_0____itr_1_2540____itr_2_2541____itr_3_2542____itr_4_2543 / 4UL) * 256UL) + ((fused_0fused_0fused_0fused_0__itr_0____itr_1_2540____itr_2_2541____itr_3_2542____itr_4_2543 % 4UL) * 64UL)) + _fuseiter_8550)]);
    float __cached_1;
    __cached_1 = __ins_1[0];
    vec_f32x16 __cached_2;
    __cached_2 = (__cached_0 * vec_f32x16(__cached_1));
    vec_f32x16::store(__cached_2, &__outs_0[((((fused_0fused_0fused_0fused_0__itr_0____itr_1_2540____itr_2_2541____itr_3_2542____itr_4_2543 / 4UL) * 256UL) + ((fused_0fused_0fused_0fused_0__itr_0____itr_1_2540____itr_2_2541____itr_3_2542____itr_4_2543 % 4UL) * 64UL)) + _fuseiter_8550)]);
  }
}

static void mul__6320_closure_51_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept{
  mul__6320_closure_51(i, (float*)(args[0UL].v_ptr), (float*)(args[1UL].v_ptr), (float*)(args[2UL].v_ptr));
}

static void reorder__5030_closure_52(uint64_t fused_0fused_0fused_0fused_0_fuseiter_8552___fuseiter_8553_2544___fuseiter_8554_2545___fuseiter_8555_2546___fuseiter_8556_2547, float* __restrict__ __ins_0, float* __restrict__ __outs_0) noexcept{
  for (uint64_t _fuseiter_8557 = 0UL; _fuseiter_8557 < 64UL; _fuseiter_8557 += 1UL) {
    float __cached_0;
    __cached_0 = __ins_0[(((fused_0fused_0fused_0fused_0_fuseiter_8552___fuseiter_8553_2544___fuseiter_8554_2545___fuseiter_8555_2546___fuseiter_8556_2547 / 16UL) * 1024UL) + (_fuseiter_8557 + ((fused_0fused_0fused_0fused_0_fuseiter_8552___fuseiter_8553_2544___fuseiter_8554_2545___fuseiter_8555_2546___fuseiter_8556_2547 % 16UL) * 64UL)))];
    float __cached_1;
    __cached_1 = __cached_0;
    __outs_0[(((fused_0fused_0fused_0fused_0_fuseiter_8552___fuseiter_8553_2544___fuseiter_8554_2545___fuseiter_8555_2546___fuseiter_8556_2547 / 16UL) * 1024UL) + (((fused_0fused_0fused_0fused_0_fuseiter_8552___fuseiter_8553_2544___fuseiter_8554_2545___fuseiter_8555_2546___fuseiter_8556_2547 % 16UL) * 64UL) + _fuseiter_8557))] = __cached_1;
  }
}

static void reorder__5030_closure_52_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept{
  reorder__5030_closure_52(i, (float*)(args[0UL].v_ptr), (float*)(args[1UL].v_ptr));
}

static void mul__6340_closure_53(uint64_t fused_0fused_0fused_0fused_0__itr_0____itr_1_2548____itr_2_2549____itr_3_2550____itr_4_2551, float* __restrict__ __ins_0, float* __restrict__ __ins_1, float* __restrict__ __outs_0) noexcept{
  for (uint64_t _fuseiter_8563 = 0UL; _fuseiter_8563 < 64UL; _fuseiter_8563 += 16UL) {
    vec_f32x16 __cached_0;
    __cached_0 = vec_f32x16::load(&__ins_0[((((fused_0fused_0fused_0fused_0__itr_0____itr_1_2548____itr_2_2549____itr_3_2550____itr_4_2551 / 16UL) * 1024UL) + ((fused_0fused_0fused_0fused_0__itr_0____itr_1_2548____itr_2_2549____itr_3_2550____itr_4_2551 % 16UL) * 64UL)) + _fuseiter_8563)]);
    float __cached_1;
    __cached_1 = __ins_1[0];
    vec_f32x16 __cached_2;
    __cached_2 = (__cached_0 * vec_f32x16(__cached_1));
    vec_f32x16::store(__cached_2, &__outs_0[((((fused_0fused_0fused_0fused_0__itr_0____itr_1_2548____itr_2_2549____itr_3_2550____itr_4_2551 / 16UL) * 1024UL) + ((fused_0fused_0fused_0fused_0__itr_0____itr_1_2548____itr_2_2549____itr_3_2550____itr_4_2551 % 16UL) * 64UL)) + _fuseiter_8563)]);
  }
}

static void mul__6340_closure_53_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept{
  mul__6340_closure_53(i, (float*)(args[0UL].v_ptr), (float*)(args[1UL].v_ptr), (float*)(args[2UL].v_ptr));
}

static void reorder__5060_closure_54(uint64_t fused_0fused_0fused_0fused_0_fuseiter_8565___fuseiter_8566_2552___fuseiter_8567_2553___fuseiter_8568_2554___fuseiter_8569_2555, float* __restrict__ __ins_0, float* __restrict__ __outs_0) noexcept{
  for (uint64_t _fuseiter_8570 = 0UL; _fuseiter_8570 < 64UL; _fuseiter_8570 += 1UL) {
    float __cached_0;
    __cached_0 = __ins_0[(((fused_0fused_0fused_0fused_0_fuseiter_8565___fuseiter_8566_2552___fuseiter_8567_2553___fuseiter_8568_2554___fuseiter_8569_2555 / 4UL) * 256UL) + (_fuseiter_8570 + ((fused_0fused_0fused_0fused_0_fuseiter_8565___fuseiter_8566_2552___fuseiter_8567_2553___fuseiter_8568_2554___fuseiter_8569_2555 % 4UL) * 64UL)))];
    float __cached_1;
    __cached_1 = __cached_0;
    __outs_0[(((fused_0fused_0fused_0fused_0_fuseiter_8565___fuseiter_8566_2552___fuseiter_8567_2553___fuseiter_8568_2554___fuseiter_8569_2555 / 4UL) * 256UL) + (((fused_0fused_0fused_0fused_0_fuseiter_8565___fuseiter_8566_2552___fuseiter_8567_2553___fuseiter_8568_2554___fuseiter_8569_2555 % 4UL) * 64UL) + _fuseiter_8570))] = __cached_1;
  }
}

static void reorder__5060_closure_54_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept{
  reorder__5060_closure_54(i, (float*)(args[0UL].v_ptr), (float*)(args[1UL].v_ptr));
}

static void mul__6360_closure_55(uint64_t fused_0fused_0fused_0fused_0__itr_0____itr_1_2556____itr_2_2557____itr_3_2558____itr_4_2559, float* __restrict__ __ins_0, float* __restrict__ __ins_1, float* __restrict__ __outs_0) noexcept{
  for (uint64_t _fuseiter_8576 = 0UL; _fuseiter_8576 < 64UL; _fuseiter_8576 += 16UL) {
    vec_f32x16 __cached_0;
    __cached_0 = vec_f32x16::load(&__ins_0[((((fused_0fused_0fused_0fused_0__itr_0____itr_1_2556____itr_2_2557____itr_3_2558____itr_4_2559 / 4UL) * 256UL) + ((fused_0fused_0fused_0fused_0__itr_0____itr_1_2556____itr_2_2557____itr_3_2558____itr_4_2559 % 4UL) * 64UL)) + _fuseiter_8576)]);
    float __cached_1;
    __cached_1 = __ins_1[0];
    vec_f32x16 __cached_2;
    __cached_2 = (__cached_0 * vec_f32x16(__cached_1));
    vec_f32x16::store(__cached_2, &__outs_0[((((fused_0fused_0fused_0fused_0__itr_0____itr_1_2556____itr_2_2557____itr_3_2558____itr_4_2559 / 4UL) * 256UL) + ((fused_0fused_0fused_0fused_0__itr_0____itr_1_2556____itr_2_2557____itr_3_2558____itr_4_2559 % 4UL) * 64UL)) + _fuseiter_8576)]);
  }
}

static void mul__6360_closure_55_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept{
  mul__6360_closure_55(i, (float*)(args[0UL].v_ptr), (float*)(args[1UL].v_ptr), (float*)(args[2UL].v_ptr));
}

static void reorder__5090_closure_56(uint64_t fused_0fused_0fused_0fused_0_fuseiter_8578___fuseiter_8579_2560___fuseiter_8580_2561___fuseiter_8581_2562___fuseiter_8582_2563, float* __restrict__ __ins_0, float* __restrict__ __outs_0) noexcept{
  for (uint64_t _fuseiter_8583 = 0UL; _fuseiter_8583 < 64UL; _fuseiter_8583 += 1UL) {
    float __cached_0;
    __cached_0 = __ins_0[(((fused_0fused_0fused_0fused_0_fuseiter_8578___fuseiter_8579_2560___fuseiter_8580_2561___fuseiter_8581_2562___fuseiter_8582_2563 / 4UL) * 256UL) + (_fuseiter_8583 + ((fused_0fused_0fused_0fused_0_fuseiter_8578___fuseiter_8579_2560___fuseiter_8580_2561___fuseiter_8581_2562___fuseiter_8582_2563 % 4UL) * 64UL)))];
    float __cached_1;
    __cached_1 = __cached_0;
    __outs_0[(((fused_0fused_0fused_0fused_0_fuseiter_8578___fuseiter_8579_2560___fuseiter_8580_2561___fuseiter_8581_2562___fuseiter_8582_2563 / 4UL) * 256UL) + (((fused_0fused_0fused_0fused_0_fuseiter_8578___fuseiter_8579_2560___fuseiter_8580_2561___fuseiter_8581_2562___fuseiter_8582_2563 % 4UL) * 64UL) + _fuseiter_8583))] = __cached_1;
  }
}

static void reorder__5090_closure_56_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept{
  reorder__5090_closure_56(i, (float*)(args[0UL].v_ptr), (float*)(args[1UL].v_ptr));
}

static void mul__6380_closure_57(uint64_t fused_0fused_0fused_0fused_0__itr_0____itr_1_2564____itr_2_2565____itr_3_2566____itr_4_2567, float* __restrict__ __ins_0, float* __restrict__ __ins_1, float* __restrict__ __outs_0) noexcept{
  for (uint64_t _fuseiter_8589 = 0UL; _fuseiter_8589 < 64UL; _fuseiter_8589 += 16UL) {
    vec_f32x16 __cached_0;
    __cached_0 = vec_f32x16::load(&__ins_0[((((fused_0fused_0fused_0fused_0__itr_0____itr_1_2564____itr_2_2565____itr_3_2566____itr_4_2567 / 4UL) * 256UL) + ((fused_0fused_0fused_0fused_0__itr_0____itr_1_2564____itr_2_2565____itr_3_2566____itr_4_2567 % 4UL) * 64UL)) + _fuseiter_8589)]);
    float __cached_1;
    __cached_1 = __ins_1[0];
    vec_f32x16 __cached_2;
    __cached_2 = (__cached_0 * vec_f32x16(__cached_1));
    vec_f32x16::store(__cached_2, &__outs_0[((((fused_0fused_0fused_0fused_0__itr_0____itr_1_2564____itr_2_2565____itr_3_2566____itr_4_2567 / 4UL) * 256UL) + ((fused_0fused_0fused_0fused_0__itr_0____itr_1_2564____itr_2_2565____itr_3_2566____itr_4_2567 % 4UL) * 64UL)) + _fuseiter_8589)]);
  }
}

static void mul__6380_closure_57_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept{
  mul__6380_closure_57(i, (float*)(args[0UL].v_ptr), (float*)(args[1UL].v_ptr), (float*)(args[2UL].v_ptr));
}

static void reorder__5120_closure_58(uint64_t fused_0fused_0fused_0fused_0_fuseiter_8591___fuseiter_8592_2568___fuseiter_8593_2569___fuseiter_8594_2570___fuseiter_8595_2571, float* __restrict__ __ins_0, float* __restrict__ __outs_0) noexcept{
  for (uint64_t _fuseiter_8596 = 0UL; _fuseiter_8596 < 64UL; _fuseiter_8596 += 1UL) {
    float __cached_0;
    __cached_0 = __ins_0[(((fused_0fused_0fused_0fused_0_fuseiter_8591___fuseiter_8592_2568___fuseiter_8593_2569___fuseiter_8594_2570___fuseiter_8595_2571 / 16UL) * 1024UL) + (_fuseiter_8596 + ((fused_0fused_0fused_0fused_0_fuseiter_8591___fuseiter_8592_2568___fuseiter_8593_2569___fuseiter_8594_2570___fuseiter_8595_2571 % 16UL) * 64UL)))];
    float __cached_1;
    __cached_1 = __cached_0;
    __outs_0[(((fused_0fused_0fused_0fused_0_fuseiter_8591___fuseiter_8592_2568___fuseiter_8593_2569___fuseiter_8594_2570___fuseiter_8595_2571 / 16UL) * 1024UL) + (((fused_0fused_0fused_0fused_0_fuseiter_8591___fuseiter_8592_2568___fuseiter_8593_2569___fuseiter_8594_2570___fuseiter_8595_2571 % 16UL) * 64UL) + _fuseiter_8596))] = __cached_1;
  }
}

static void reorder__5120_closure_58_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept{
  reorder__5120_closure_58(i, (float*)(args[0UL].v_ptr), (float*)(args[1UL].v_ptr));
}

static void mul__6400_closure_59(uint64_t fused_0fused_0fused_0fused_0__itr_0____itr_1_2572____itr_2_2573____itr_3_2574____itr_4_2575, float* __restrict__ __ins_0, float* __restrict__ __ins_1, float* __restrict__ __outs_0) noexcept{
  for (uint64_t _fuseiter_8602 = 0UL; _fuseiter_8602 < 64UL; _fuseiter_8602 += 16UL) {
    vec_f32x16 __cached_0;
    __cached_0 = vec_f32x16::load(&__ins_0[((((fused_0fused_0fused_0fused_0__itr_0____itr_1_2572____itr_2_2573____itr_3_2574____itr_4_2575 / 16UL) * 1024UL) + ((fused_0fused_0fused_0fused_0__itr_0____itr_1_2572____itr_2_2573____itr_3_2574____itr_4_2575 % 16UL) * 64UL)) + _fuseiter_8602)]);
    float __cached_1;
    __cached_1 = __ins_1[0];
    vec_f32x16 __cached_2;
    __cached_2 = (__cached_0 * vec_f32x16(__cached_1));
    vec_f32x16::store(__cached_2, &__outs_0[((((fused_0fused_0fused_0fused_0__itr_0____itr_1_2572____itr_2_2573____itr_3_2574____itr_4_2575 / 16UL) * 1024UL) + ((fused_0fused_0fused_0fused_0__itr_0____itr_1_2572____itr_2_2573____itr_3_2574____itr_4_2575 % 16UL) * 64UL)) + _fuseiter_8602)]);
  }
}

static void mul__6400_closure_59_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept{
  mul__6400_closure_59(i, (float*)(args[0UL].v_ptr), (float*)(args[1UL].v_ptr), (float*)(args[2UL].v_ptr));
}

static void reorder__5150_closure_60(uint64_t fused_0fused_0fused_0fused_0_fuseiter_8604___fuseiter_8605_2576___fuseiter_8606_2577___fuseiter_8607_2578___fuseiter_8608_2579, float* __restrict__ __ins_0, float* __restrict__ __outs_0) noexcept{
  for (uint64_t _fuseiter_8609 = 0UL; _fuseiter_8609 < 64UL; _fuseiter_8609 += 1UL) {
    float __cached_0;
    __cached_0 = __ins_0[(((fused_0fused_0fused_0fused_0_fuseiter_8604___fuseiter_8605_2576___fuseiter_8606_2577___fuseiter_8607_2578___fuseiter_8608_2579 / 4UL) * 256UL) + (_fuseiter_8609 + ((fused_0fused_0fused_0fused_0_fuseiter_8604___fuseiter_8605_2576___fuseiter_8606_2577___fuseiter_8607_2578___fuseiter_8608_2579 % 4UL) * 64UL)))];
    float __cached_1;
    __cached_1 = __cached_0;
    __outs_0[(((fused_0fused_0fused_0fused_0_fuseiter_8604___fuseiter_8605_2576___fuseiter_8606_2577___fuseiter_8607_2578___fuseiter_8608_2579 / 4UL) * 256UL) + (((fused_0fused_0fused_0fused_0_fuseiter_8604___fuseiter_8605_2576___fuseiter_8606_2577___fuseiter_8607_2578___fuseiter_8608_2579 % 4UL) * 64UL) + _fuseiter_8609))] = __cached_1;
  }
}

static void reorder__5150_closure_60_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept{
  reorder__5150_closure_60(i, (float*)(args[0UL].v_ptr), (float*)(args[1UL].v_ptr));
}

static void mul__6420_closure_61(uint64_t fused_0fused_0fused_0fused_0__itr_0____itr_1_2580____itr_2_2581____itr_3_2582____itr_4_2583, float* __restrict__ __ins_0, float* __restrict__ __ins_1, float* __restrict__ __outs_0) noexcept{
  for (uint64_t _fuseiter_8615 = 0UL; _fuseiter_8615 < 64UL; _fuseiter_8615 += 16UL) {
    vec_f32x16 __cached_0;
    __cached_0 = vec_f32x16::load(&__ins_0[((((fused_0fused_0fused_0fused_0__itr_0____itr_1_2580____itr_2_2581____itr_3_2582____itr_4_2583 / 4UL) * 256UL) + ((fused_0fused_0fused_0fused_0__itr_0____itr_1_2580____itr_2_2581____itr_3_2582____itr_4_2583 % 4UL) * 64UL)) + _fuseiter_8615)]);
    float __cached_1;
    __cached_1 = __ins_1[0];
    vec_f32x16 __cached_2;
    __cached_2 = (__cached_0 * vec_f32x16(__cached_1));
    vec_f32x16::store(__cached_2, &__outs_0[((((fused_0fused_0fused_0fused_0__itr_0____itr_1_2580____itr_2_2581____itr_3_2582____itr_4_2583 / 4UL) * 256UL) + ((fused_0fused_0fused_0fused_0__itr_0____itr_1_2580____itr_2_2581____itr_3_2582____itr_4_2583 % 4UL) * 64UL)) + _fuseiter_8615)]);
  }
}

static void mul__6420_closure_61_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept{
  mul__6420_closure_61(i, (float*)(args[0UL].v_ptr), (float*)(args[1UL].v_ptr), (float*)(args[2UL].v_ptr));
}

static void reorder__5180_closure_62(uint64_t fused_0fused_0fused_0fused_0_fuseiter_8617___fuseiter_8618_2584___fuseiter_8619_2585___fuseiter_8620_2586___fuseiter_8621_2587, float* __restrict__ __ins_0, float* __restrict__ __outs_0) noexcept{
  for (uint64_t _fuseiter_8622 = 0UL; _fuseiter_8622 < 64UL; _fuseiter_8622 += 1UL) {
    float __cached_0;
    __cached_0 = __ins_0[(((fused_0fused_0fused_0fused_0_fuseiter_8617___fuseiter_8618_2584___fuseiter_8619_2585___fuseiter_8620_2586___fuseiter_8621_2587 / 4UL) * 256UL) + (_fuseiter_8622 + ((fused_0fused_0fused_0fused_0_fuseiter_8617___fuseiter_8618_2584___fuseiter_8619_2585___fuseiter_8620_2586___fuseiter_8621_2587 % 4UL) * 64UL)))];
    float __cached_1;
    __cached_1 = __cached_0;
    __outs_0[(((fused_0fused_0fused_0fused_0_fuseiter_8617___fuseiter_8618_2584___fuseiter_8619_2585___fuseiter_8620_2586___fuseiter_8621_2587 / 4UL) * 256UL) + (((fused_0fused_0fused_0fused_0_fuseiter_8617___fuseiter_8618_2584___fuseiter_8619_2585___fuseiter_8620_2586___fuseiter_8621_2587 % 4UL) * 64UL) + _fuseiter_8622))] = __cached_1;
  }
}

static void reorder__5180_closure_62_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept{
  reorder__5180_closure_62(i, (float*)(args[0UL].v_ptr), (float*)(args[1UL].v_ptr));
}

static void mul__6440_closure_63(uint64_t fused_0fused_0fused_0fused_0__itr_0____itr_1_2588____itr_2_2589____itr_3_2590____itr_4_2591, float* __restrict__ __ins_0, float* __restrict__ __ins_1, float* __restrict__ __outs_0) noexcept{
  for (uint64_t _fuseiter_8628 = 0UL; _fuseiter_8628 < 64UL; _fuseiter_8628 += 16UL) {
    vec_f32x16 __cached_0;
    __cached_0 = vec_f32x16::load(&__ins_0[((((fused_0fused_0fused_0fused_0__itr_0____itr_1_2588____itr_2_2589____itr_3_2590____itr_4_2591 / 4UL) * 256UL) + ((fused_0fused_0fused_0fused_0__itr_0____itr_1_2588____itr_2_2589____itr_3_2590____itr_4_2591 % 4UL) * 64UL)) + _fuseiter_8628)]);
    float __cached_1;
    __cached_1 = __ins_1[0];
    vec_f32x16 __cached_2;
    __cached_2 = (__cached_0 * vec_f32x16(__cached_1));
    vec_f32x16::store(__cached_2, &__outs_0[((((fused_0fused_0fused_0fused_0__itr_0____itr_1_2588____itr_2_2589____itr_3_2590____itr_4_2591 / 4UL) * 256UL) + ((fused_0fused_0fused_0fused_0__itr_0____itr_1_2588____itr_2_2589____itr_3_2590____itr_4_2591 % 4UL) * 64UL)) + _fuseiter_8628)]);
  }
}

static void mul__6440_closure_63_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept{
  mul__6440_closure_63(i, (float*)(args[0UL].v_ptr), (float*)(args[1UL].v_ptr), (float*)(args[2UL].v_ptr));
}

static void reorder__5210_closure_64(uint64_t fused_0fused_0fused_0fused_0_fuseiter_8630___fuseiter_8631_2592___fuseiter_8632_2593___fuseiter_8633_2594___fuseiter_8634_2595, float* __restrict__ __ins_0, float* __restrict__ __outs_0) noexcept{
  for (uint64_t _fuseiter_8635 = 0UL; _fuseiter_8635 < 64UL; _fuseiter_8635 += 1UL) {
    float __cached_0;
    __cached_0 = __ins_0[(((fused_0fused_0fused_0fused_0_fuseiter_8630___fuseiter_8631_2592___fuseiter_8632_2593___fuseiter_8633_2594___fuseiter_8634_2595 / 16UL) * 1024UL) + (_fuseiter_8635 + ((fused_0fused_0fused_0fused_0_fuseiter_8630___fuseiter_8631_2592___fuseiter_8632_2593___fuseiter_8633_2594___fuseiter_8634_2595 % 16UL) * 64UL)))];
    float __cached_1;
    __cached_1 = __cached_0;
    __outs_0[(((fused_0fused_0fused_0fused_0_fuseiter_8630___fuseiter_8631_2592___fuseiter_8632_2593___fuseiter_8633_2594___fuseiter_8634_2595 / 16UL) * 1024UL) + (((fused_0fused_0fused_0fused_0_fuseiter_8630___fuseiter_8631_2592___fuseiter_8632_2593___fuseiter_8633_2594___fuseiter_8634_2595 % 16UL) * 64UL) + _fuseiter_8635))] = __cached_1;
  }
}

static void reorder__5210_closure_64_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept{
  reorder__5210_closure_64(i, (float*)(args[0UL].v_ptr), (float*)(args[1UL].v_ptr));
}

static void mul__6460_closure_65(uint64_t fused_0fused_0fused_0fused_0__itr_0____itr_1_2596____itr_2_2597____itr_3_2598____itr_4_2599, float* __restrict__ __ins_0, float* __restrict__ __ins_1, float* __restrict__ __outs_0) noexcept{
  for (uint64_t _fuseiter_8641 = 0UL; _fuseiter_8641 < 64UL; _fuseiter_8641 += 16UL) {
    vec_f32x16 __cached_0;
    __cached_0 = vec_f32x16::load(&__ins_0[((((fused_0fused_0fused_0fused_0__itr_0____itr_1_2596____itr_2_2597____itr_3_2598____itr_4_2599 / 16UL) * 1024UL) + ((fused_0fused_0fused_0fused_0__itr_0____itr_1_2596____itr_2_2597____itr_3_2598____itr_4_2599 % 16UL) * 64UL)) + _fuseiter_8641)]);
    float __cached_1;
    __cached_1 = __ins_1[0];
    vec_f32x16 __cached_2;
    __cached_2 = (__cached_0 * vec_f32x16(__cached_1));
    vec_f32x16::store(__cached_2, &__outs_0[((((fused_0fused_0fused_0fused_0__itr_0____itr_1_2596____itr_2_2597____itr_3_2598____itr_4_2599 / 16UL) * 1024UL) + ((fused_0fused_0fused_0fused_0__itr_0____itr_1_2596____itr_2_2597____itr_3_2598____itr_4_2599 % 16UL) * 64UL)) + _fuseiter_8641)]);
  }
}

static void mul__6460_closure_65_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept{
  mul__6460_closure_65(i, (float*)(args[0UL].v_ptr), (float*)(args[1UL].v_ptr), (float*)(args[2UL].v_ptr));
}

static void reorder__5240_closure_66(uint64_t fused_0fused_0fused_0fused_0_fuseiter_8643___fuseiter_8644_2600___fuseiter_8645_2601___fuseiter_8646_2602___fuseiter_8647_2603, float* __restrict__ __ins_0, float* __restrict__ __outs_0) noexcept{
  for (uint64_t _fuseiter_8648 = 0UL; _fuseiter_8648 < 64UL; _fuseiter_8648 += 1UL) {
    float __cached_0;
    __cached_0 = __ins_0[(((fused_0fused_0fused_0fused_0_fuseiter_8643___fuseiter_8644_2600___fuseiter_8645_2601___fuseiter_8646_2602___fuseiter_8647_2603 / 4UL) * 256UL) + (_fuseiter_8648 + ((fused_0fused_0fused_0fused_0_fuseiter_8643___fuseiter_8644_2600___fuseiter_8645_2601___fuseiter_8646_2602___fuseiter_8647_2603 % 4UL) * 64UL)))];
    float __cached_1;
    __cached_1 = __cached_0;
    __outs_0[(((fused_0fused_0fused_0fused_0_fuseiter_8643___fuseiter_8644_2600___fuseiter_8645_2601___fuseiter_8646_2602___fuseiter_8647_2603 / 4UL) * 256UL) + (((fused_0fused_0fused_0fused_0_fuseiter_8643___fuseiter_8644_2600___fuseiter_8645_2601___fuseiter_8646_2602___fuseiter_8647_2603 % 4UL) * 64UL) + _fuseiter_8648))] = __cached_1;
  }
}

static void reorder__5240_closure_66_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept{
  reorder__5240_closure_66(i, (float*)(args[0UL].v_ptr), (float*)(args[1UL].v_ptr));
}

static void mul__6480_closure_67(uint64_t fused_0fused_0fused_0fused_0__itr_0____itr_1_2604____itr_2_2605____itr_3_2606____itr_4_2607, float* __restrict__ __ins_0, float* __restrict__ __ins_1, float* __restrict__ __outs_0) noexcept{
  for (uint64_t _fuseiter_8654 = 0UL; _fuseiter_8654 < 64UL; _fuseiter_8654 += 16UL) {
    vec_f32x16 __cached_0;
    __cached_0 = vec_f32x16::load(&__ins_0[((((fused_0fused_0fused_0fused_0__itr_0____itr_1_2604____itr_2_2605____itr_3_2606____itr_4_2607 / 4UL) * 256UL) + ((fused_0fused_0fused_0fused_0__itr_0____itr_1_2604____itr_2_2605____itr_3_2606____itr_4_2607 % 4UL) * 64UL)) + _fuseiter_8654)]);
    float __cached_1;
    __cached_1 = __ins_1[0];
    vec_f32x16 __cached_2;
    __cached_2 = (__cached_0 * vec_f32x16(__cached_1));
    vec_f32x16::store(__cached_2, &__outs_0[((((fused_0fused_0fused_0fused_0__itr_0____itr_1_2604____itr_2_2605____itr_3_2606____itr_4_2607 / 4UL) * 256UL) + ((fused_0fused_0fused_0fused_0__itr_0____itr_1_2604____itr_2_2605____itr_3_2606____itr_4_2607 % 4UL) * 64UL)) + _fuseiter_8654)]);
  }
}

static void mul__6480_closure_67_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept{
  mul__6480_closure_67(i, (float*)(args[0UL].v_ptr), (float*)(args[1UL].v_ptr), (float*)(args[2UL].v_ptr));
}

static void reorder__5270_closure_68(uint64_t fused_0fused_0fused_0fused_0_fuseiter_8656___fuseiter_8657_2608___fuseiter_8658_2609___fuseiter_8659_2610___fuseiter_8660_2611, float* __restrict__ __ins_0, float* __restrict__ __outs_0) noexcept{
  for (uint64_t _fuseiter_8661 = 0UL; _fuseiter_8661 < 64UL; _fuseiter_8661 += 1UL) {
    float __cached_0;
    __cached_0 = __ins_0[(((fused_0fused_0fused_0fused_0_fuseiter_8656___fuseiter_8657_2608___fuseiter_8658_2609___fuseiter_8659_2610___fuseiter_8660_2611 / 4UL) * 256UL) + (_fuseiter_8661 + ((fused_0fused_0fused_0fused_0_fuseiter_8656___fuseiter_8657_2608___fuseiter_8658_2609___fuseiter_8659_2610___fuseiter_8660_2611 % 4UL) * 64UL)))];
    float __cached_1;
    __cached_1 = __cached_0;
    __outs_0[(((fused_0fused_0fused_0fused_0_fuseiter_8656___fuseiter_8657_2608___fuseiter_8658_2609___fuseiter_8659_2610___fuseiter_8660_2611 / 4UL) * 256UL) + (((fused_0fused_0fused_0fused_0_fuseiter_8656___fuseiter_8657_2608___fuseiter_8658_2609___fuseiter_8659_2610___fuseiter_8660_2611 % 4UL) * 64UL) + _fuseiter_8661))] = __cached_1;
  }
}

static void reorder__5270_closure_68_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept{
  reorder__5270_closure_68(i, (float*)(args[0UL].v_ptr), (float*)(args[1UL].v_ptr));
}

static void mul__6500_closure_69(uint64_t fused_0fused_0fused_0fused_0__itr_0____itr_1_2612____itr_2_2613____itr_3_2614____itr_4_2615, float* __restrict__ __ins_0, float* __restrict__ __ins_1, float* __restrict__ __outs_0) noexcept{
  for (uint64_t _fuseiter_8667 = 0UL; _fuseiter_8667 < 64UL; _fuseiter_8667 += 16UL) {
    vec_f32x16 __cached_0;
    __cached_0 = vec_f32x16::load(&__ins_0[((((fused_0fused_0fused_0fused_0__itr_0____itr_1_2612____itr_2_2613____itr_3_2614____itr_4_2615 / 4UL) * 256UL) + ((fused_0fused_0fused_0fused_0__itr_0____itr_1_2612____itr_2_2613____itr_3_2614____itr_4_2615 % 4UL) * 64UL)) + _fuseiter_8667)]);
    float __cached_1;
    __cached_1 = __ins_1[0];
    vec_f32x16 __cached_2;
    __cached_2 = (__cached_0 * vec_f32x16(__cached_1));
    vec_f32x16::store(__cached_2, &__outs_0[((((fused_0fused_0fused_0fused_0__itr_0____itr_1_2612____itr_2_2613____itr_3_2614____itr_4_2615 / 4UL) * 256UL) + ((fused_0fused_0fused_0fused_0__itr_0____itr_1_2612____itr_2_2613____itr_3_2614____itr_4_2615 % 4UL) * 64UL)) + _fuseiter_8667)]);
  }
}

static void mul__6500_closure_69_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept{
  mul__6500_closure_69(i, (float*)(args[0UL].v_ptr), (float*)(args[1UL].v_ptr), (float*)(args[2UL].v_ptr));
}

static void reorder__5300_closure_70(uint64_t fused_0fused_0fused_0fused_0_fuseiter_8669___fuseiter_8670_2616___fuseiter_8671_2617___fuseiter_8672_2618___fuseiter_8673_2619, float* __restrict__ __ins_0, float* __restrict__ __outs_0) noexcept{
  for (uint64_t _fuseiter_8674 = 0UL; _fuseiter_8674 < 64UL; _fuseiter_8674 += 1UL) {
    float __cached_0;
    __cached_0 = __ins_0[(((fused_0fused_0fused_0fused_0_fuseiter_8669___fuseiter_8670_2616___fuseiter_8671_2617___fuseiter_8672_2618___fuseiter_8673_2619 / 16UL) * 1024UL) + (_fuseiter_8674 + ((fused_0fused_0fused_0fused_0_fuseiter_8669___fuseiter_8670_2616___fuseiter_8671_2617___fuseiter_8672_2618___fuseiter_8673_2619 % 16UL) * 64UL)))];
    float __cached_1;
    __cached_1 = __cached_0;
    __outs_0[(((fused_0fused_0fused_0fused_0_fuseiter_8669___fuseiter_8670_2616___fuseiter_8671_2617___fuseiter_8672_2618___fuseiter_8673_2619 / 16UL) * 1024UL) + (((fused_0fused_0fused_0fused_0_fuseiter_8669___fuseiter_8670_2616___fuseiter_8671_2617___fuseiter_8672_2618___fuseiter_8673_2619 % 16UL) * 64UL) + _fuseiter_8674))] = __cached_1;
  }
}

static void reorder__5300_closure_70_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept{
  reorder__5300_closure_70(i, (float*)(args[0UL].v_ptr), (float*)(args[1UL].v_ptr));
}

static void mul__6520_closure_71(uint64_t fused_0fused_0fused_0fused_0__itr_0____itr_1_2620____itr_2_2621____itr_3_2622____itr_4_2623, float* __restrict__ __ins_0, float* __restrict__ __ins_1, float* __restrict__ __outs_0) noexcept{
  for (uint64_t _fuseiter_8680 = 0UL; _fuseiter_8680 < 64UL; _fuseiter_8680 += 16UL) {
    vec_f32x16 __cached_0;
    __cached_0 = vec_f32x16::load(&__ins_0[((((fused_0fused_0fused_0fused_0__itr_0____itr_1_2620____itr_2_2621____itr_3_2622____itr_4_2623 / 16UL) * 1024UL) + ((fused_0fused_0fused_0fused_0__itr_0____itr_1_2620____itr_2_2621____itr_3_2622____itr_4_2623 % 16UL) * 64UL)) + _fuseiter_8680)]);
    float __cached_1;
    __cached_1 = __ins_1[0];
    vec_f32x16 __cached_2;
    __cached_2 = (__cached_0 * vec_f32x16(__cached_1));
    vec_f32x16::store(__cached_2, &__outs_0[((((fused_0fused_0fused_0fused_0__itr_0____itr_1_2620____itr_2_2621____itr_3_2622____itr_4_2623 / 16UL) * 1024UL) + ((fused_0fused_0fused_0fused_0__itr_0____itr_1_2620____itr_2_2621____itr_3_2622____itr_4_2623 % 16UL) * 64UL)) + _fuseiter_8680)]);
  }
}

static void mul__6520_closure_71_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept{
  mul__6520_closure_71(i, (float*)(args[0UL].v_ptr), (float*)(args[1UL].v_ptr), (float*)(args[2UL].v_ptr));
}

static void reorder__5330_closure_72(uint64_t fused_0fused_0fused_0fused_0_fuseiter_8682___fuseiter_8683_2624___fuseiter_8684_2625___fuseiter_8685_2626___fuseiter_8686_2627, float* __restrict__ __ins_0, float* __restrict__ __outs_0) noexcept{
  for (uint64_t _fuseiter_8687 = 0UL; _fuseiter_8687 < 512UL; _fuseiter_8687 += 1UL) {
    float __cached_0;
    __cached_0 = __ins_0[(((fused_0fused_0fused_0fused_0_fuseiter_8682___fuseiter_8683_2624___fuseiter_8684_2625___fuseiter_8685_2626___fuseiter_8686_2627 / 4UL) * 2048UL) + (_fuseiter_8687 + ((fused_0fused_0fused_0fused_0_fuseiter_8682___fuseiter_8683_2624___fuseiter_8684_2625___fuseiter_8685_2626___fuseiter_8686_2627 % 4UL) * 512UL)))];
    float __cached_1;
    __cached_1 = __cached_0;
    __outs_0[(((fused_0fused_0fused_0fused_0_fuseiter_8682___fuseiter_8683_2624___fuseiter_8684_2625___fuseiter_8685_2626___fuseiter_8686_2627 / 4UL) * 2048UL) + (((fused_0fused_0fused_0fused_0_fuseiter_8682___fuseiter_8683_2624___fuseiter_8684_2625___fuseiter_8685_2626___fuseiter_8686_2627 % 4UL) * 512UL) + _fuseiter_8687))] = __cached_1;
  }
}

static void reorder__5330_closure_72_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept{
  reorder__5330_closure_72(i, (float*)(args[0UL].v_ptr), (float*)(args[1UL].v_ptr));
}

static void mul__6540_closure_73(uint64_t fused_0fused_0fused_0fused_0__itr_0____itr_1_2628____itr_2_2629____itr_3_2630____itr_4_2631, float* __restrict__ __ins_0, float* __restrict__ __ins_1, float* __restrict__ __outs_0) noexcept{
  for (uint64_t _fuseiter_8693 = 0UL; _fuseiter_8693 < 512UL; _fuseiter_8693 += 16UL) {
    vec_f32x16 __cached_0;
    __cached_0 = vec_f32x16::load(&__ins_0[((((fused_0fused_0fused_0fused_0__itr_0____itr_1_2628____itr_2_2629____itr_3_2630____itr_4_2631 / 4UL) * 2048UL) + ((fused_0fused_0fused_0fused_0__itr_0____itr_1_2628____itr_2_2629____itr_3_2630____itr_4_2631 % 4UL) * 512UL)) + _fuseiter_8693)]);
    float __cached_1;
    __cached_1 = __ins_1[0];
    vec_f32x16 __cached_2;
    __cached_2 = (__cached_0 * vec_f32x16(__cached_1));
    vec_f32x16::store(__cached_2, &__outs_0[((((fused_0fused_0fused_0fused_0__itr_0____itr_1_2628____itr_2_2629____itr_3_2630____itr_4_2631 / 4UL) * 2048UL) + ((fused_0fused_0fused_0fused_0__itr_0____itr_1_2628____itr_2_2629____itr_3_2630____itr_4_2631 % 4UL) * 512UL)) + _fuseiter_8693)]);
  }
}

static void mul__6540_closure_73_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept{
  mul__6540_closure_73(i, (float*)(args[0UL].v_ptr), (float*)(args[1UL].v_ptr), (float*)(args[2UL].v_ptr));
}

static void reorder__5370_closure_74(uint64_t fused_0fused_0fused_0fused_0_fuseiter_8702___fuseiter_8703_2636___fuseiter_8704_2637___fuseiter_8705_2638___fuseiter_8706_2639, float* __restrict__ __ins_0, float* __restrict__ __outs_0) noexcept{
  for (uint64_t _fuseiter_8707 = 0UL; _fuseiter_8707 < 256UL; _fuseiter_8707 += 1UL) {
    float __cached_0;
    __cached_0 = __ins_0[(((fused_0fused_0fused_0fused_0_fuseiter_8702___fuseiter_8703_2636___fuseiter_8704_2637___fuseiter_8705_2638___fuseiter_8706_2639 / 2UL) * 512UL) + (_fuseiter_8707 + ((fused_0fused_0fused_0fused_0_fuseiter_8702___fuseiter_8703_2636___fuseiter_8704_2637___fuseiter_8705_2638___fuseiter_8706_2639 % 2UL) * 256UL)))];
    float __cached_1;
    __cached_1 = __cached_0;
    __outs_0[(((fused_0fused_0fused_0fused_0_fuseiter_8702___fuseiter_8703_2636___fuseiter_8704_2637___fuseiter_8705_2638___fuseiter_8706_2639 / 2UL) * 512UL) + (((fused_0fused_0fused_0fused_0_fuseiter_8702___fuseiter_8703_2636___fuseiter_8704_2637___fuseiter_8705_2638___fuseiter_8706_2639 % 2UL) * 256UL) + _fuseiter_8707))] = __cached_1;
  }
}

static void reorder__5370_closure_74_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept{
  reorder__5370_closure_74(i, (float*)(args[0UL].v_ptr), (float*)(args[1UL].v_ptr));
}

static void mul__6580_closure_75(uint64_t fused_0fused_0fused_0fused_0__itr_0____itr_1_2640____itr_2_2641____itr_3_2642____itr_4_2643, float* __restrict__ __ins_0, float* __restrict__ __ins_1, float* __restrict__ __outs_0) noexcept{
  for (uint64_t _fuseiter_8713 = 0UL; _fuseiter_8713 < 256UL; _fuseiter_8713 += 16UL) {
    vec_f32x16 __cached_0;
    __cached_0 = vec_f32x16::load(&__ins_0[((((fused_0fused_0fused_0fused_0__itr_0____itr_1_2640____itr_2_2641____itr_3_2642____itr_4_2643 / 2UL) * 512UL) + ((fused_0fused_0fused_0fused_0__itr_0____itr_1_2640____itr_2_2641____itr_3_2642____itr_4_2643 % 2UL) * 256UL)) + _fuseiter_8713)]);
    float __cached_1;
    __cached_1 = __ins_1[0];
    vec_f32x16 __cached_2;
    __cached_2 = (__cached_0 * vec_f32x16(__cached_1));
    vec_f32x16::store(__cached_2, &__outs_0[((((fused_0fused_0fused_0fused_0__itr_0____itr_1_2640____itr_2_2641____itr_3_2642____itr_4_2643 / 2UL) * 512UL) + ((fused_0fused_0fused_0fused_0__itr_0____itr_1_2640____itr_2_2641____itr_3_2642____itr_4_2643 % 2UL) * 256UL)) + _fuseiter_8713)]);
  }
}

static void mul__6580_closure_75_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept{
  mul__6580_closure_75(i, (float*)(args[0UL].v_ptr), (float*)(args[1UL].v_ptr), (float*)(args[2UL].v_ptr));
}

static void reorder__5400_closure_76(uint64_t fused_0fused_0fused_0fused_0_fuseiter_8715___fuseiter_8716_2644___fuseiter_8717_2645___fuseiter_8718_2646___fuseiter_8719_2647, float* __restrict__ __ins_0, float* __restrict__ __outs_0) noexcept{
  for (uint64_t _fuseiter_8720 = 0UL; _fuseiter_8720 < 512UL; _fuseiter_8720 += 1UL) {
    float __cached_0;
    __cached_0 = __ins_0[(((fused_0fused_0fused_0fused_0_fuseiter_8715___fuseiter_8716_2644___fuseiter_8717_2645___fuseiter_8718_2646___fuseiter_8719_2647 / 4UL) * 2048UL) + (_fuseiter_8720 + ((fused_0fused_0fused_0fused_0_fuseiter_8715___fuseiter_8716_2644___fuseiter_8717_2645___fuseiter_8718_2646___fuseiter_8719_2647 % 4UL) * 512UL)))];
    float __cached_1;
    __cached_1 = __cached_0;
    __outs_0[(((fused_0fused_0fused_0fused_0_fuseiter_8715___fuseiter_8716_2644___fuseiter_8717_2645___fuseiter_8718_2646___fuseiter_8719_2647 / 4UL) * 2048UL) + (((fused_0fused_0fused_0fused_0_fuseiter_8715___fuseiter_8716_2644___fuseiter_8717_2645___fuseiter_8718_2646___fuseiter_8719_2647 % 4UL) * 512UL) + _fuseiter_8720))] = __cached_1;
  }
}

static void reorder__5400_closure_76_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept{
  reorder__5400_closure_76(i, (float*)(args[0UL].v_ptr), (float*)(args[1UL].v_ptr));
}

static void mul__6600_closure_77(uint64_t fused_0fused_0fused_0fused_0__itr_0____itr_1_2648____itr_2_2649____itr_3_2650____itr_4_2651, float* __restrict__ __ins_0, float* __restrict__ __ins_1, float* __restrict__ __outs_0) noexcept{
  for (uint64_t _fuseiter_8726 = 0UL; _fuseiter_8726 < 512UL; _fuseiter_8726 += 16UL) {
    vec_f32x16 __cached_0;
    __cached_0 = vec_f32x16::load(&__ins_0[((((fused_0fused_0fused_0fused_0__itr_0____itr_1_2648____itr_2_2649____itr_3_2650____itr_4_2651 / 4UL) * 2048UL) + ((fused_0fused_0fused_0fused_0__itr_0____itr_1_2648____itr_2_2649____itr_3_2650____itr_4_2651 % 4UL) * 512UL)) + _fuseiter_8726)]);
    float __cached_1;
    __cached_1 = __ins_1[0];
    vec_f32x16 __cached_2;
    __cached_2 = (__cached_0 * vec_f32x16(__cached_1));
    vec_f32x16::store(__cached_2, &__outs_0[((((fused_0fused_0fused_0fused_0__itr_0____itr_1_2648____itr_2_2649____itr_3_2650____itr_4_2651 / 4UL) * 2048UL) + ((fused_0fused_0fused_0fused_0__itr_0____itr_1_2648____itr_2_2649____itr_3_2650____itr_4_2651 % 4UL) * 512UL)) + _fuseiter_8726)]);
  }
}

static void mul__6600_closure_77_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept{
  mul__6600_closure_77(i, (float*)(args[0UL].v_ptr), (float*)(args[1UL].v_ptr), (float*)(args[2UL].v_ptr));
}

static void reorder__5430_closure_78(uint64_t fused_0fused_0fused_0fused_0_fuseiter_8728___fuseiter_8729_2652___fuseiter_8730_2653___fuseiter_8731_2654___fuseiter_8732_2655, float* __restrict__ __ins_0, float* __restrict__ __outs_0) noexcept{
  for (uint64_t _fuseiter_8733 = 0UL; _fuseiter_8733 < 64UL; _fuseiter_8733 += 1UL) {
    float __cached_0;
    __cached_0 = __ins_0[(((fused_0fused_0fused_0fused_0_fuseiter_8728___fuseiter_8729_2652___fuseiter_8730_2653___fuseiter_8731_2654___fuseiter_8732_2655 / 8UL) * 512UL) + (_fuseiter_8733 + ((fused_0fused_0fused_0fused_0_fuseiter_8728___fuseiter_8729_2652___fuseiter_8730_2653___fuseiter_8731_2654___fuseiter_8732_2655 % 8UL) * 64UL)))];
    float __cached_1;
    __cached_1 = __cached_0;
    __outs_0[(((fused_0fused_0fused_0fused_0_fuseiter_8728___fuseiter_8729_2652___fuseiter_8730_2653___fuseiter_8731_2654___fuseiter_8732_2655 / 8UL) * 512UL) + (((fused_0fused_0fused_0fused_0_fuseiter_8728___fuseiter_8729_2652___fuseiter_8730_2653___fuseiter_8731_2654___fuseiter_8732_2655 % 8UL) * 64UL) + _fuseiter_8733))] = __cached_1;
  }
}

static void reorder__5430_closure_78_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept{
  reorder__5430_closure_78(i, (float*)(args[0UL].v_ptr), (float*)(args[1UL].v_ptr));
}

static void mul__6620_closure_79(uint64_t fused_0fused_0fused_0fused_0__itr_0____itr_1_2656____itr_2_2657____itr_3_2658____itr_4_2659, float* __restrict__ __ins_0, float* __restrict__ __ins_1, float* __restrict__ __outs_0) noexcept{
  for (uint64_t _fuseiter_8739 = 0UL; _fuseiter_8739 < 64UL; _fuseiter_8739 += 16UL) {
    vec_f32x16 __cached_0;
    __cached_0 = vec_f32x16::load(&__ins_0[((((fused_0fused_0fused_0fused_0__itr_0____itr_1_2656____itr_2_2657____itr_3_2658____itr_4_2659 / 8UL) * 512UL) + ((fused_0fused_0fused_0fused_0__itr_0____itr_1_2656____itr_2_2657____itr_3_2658____itr_4_2659 % 8UL) * 64UL)) + _fuseiter_8739)]);
    float __cached_1;
    __cached_1 = __ins_1[0];
    vec_f32x16 __cached_2;
    __cached_2 = (__cached_0 * vec_f32x16(__cached_1));
    vec_f32x16::store(__cached_2, &__outs_0[((((fused_0fused_0fused_0fused_0__itr_0____itr_1_2656____itr_2_2657____itr_3_2658____itr_4_2659 / 8UL) * 512UL) + ((fused_0fused_0fused_0fused_0__itr_0____itr_1_2656____itr_2_2657____itr_3_2658____itr_4_2659 % 8UL) * 64UL)) + _fuseiter_8739)]);
  }
}

static void mul__6620_closure_79_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept{
  mul__6620_closure_79(i, (float*)(args[0UL].v_ptr), (float*)(args[1UL].v_ptr), (float*)(args[2UL].v_ptr));
}

static void reorder__5460_closure_80(uint64_t fused_0fused_0fused_0fused_0_fuseiter_8741___fuseiter_8742_2660___fuseiter_8743_2661___fuseiter_8744_2662___fuseiter_8745_2663, float* __restrict__ __ins_0, float* __restrict__ __outs_0) noexcept{
  for (uint64_t _fuseiter_8746 = 0UL; _fuseiter_8746 < 128UL; _fuseiter_8746 += 1UL) {
    float __cached_0;
    __cached_0 = __ins_0[(((fused_0fused_0fused_0fused_0_fuseiter_8741___fuseiter_8742_2660___fuseiter_8743_2661___fuseiter_8744_2662___fuseiter_8745_2663 / 4UL) * 512UL) + (_fuseiter_8746 + ((fused_0fused_0fused_0fused_0_fuseiter_8741___fuseiter_8742_2660___fuseiter_8743_2661___fuseiter_8744_2662___fuseiter_8745_2663 % 4UL) * 128UL)))];
    float __cached_1;
    __cached_1 = __cached_0;
    __outs_0[(((fused_0fused_0fused_0fused_0_fuseiter_8741___fuseiter_8742_2660___fuseiter_8743_2661___fuseiter_8744_2662___fuseiter_8745_2663 / 4UL) * 512UL) + (((fused_0fused_0fused_0fused_0_fuseiter_8741___fuseiter_8742_2660___fuseiter_8743_2661___fuseiter_8744_2662___fuseiter_8745_2663 % 4UL) * 128UL) + _fuseiter_8746))] = __cached_1;
  }
}

static void reorder__5460_closure_80_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept{
  reorder__5460_closure_80(i, (float*)(args[0UL].v_ptr), (float*)(args[1UL].v_ptr));
}

static void mul__6640_closure_81(uint64_t fused_0fused_0fused_0fused_0__itr_0____itr_1_2664____itr_2_2665____itr_3_2666____itr_4_2667, float* __restrict__ __ins_0, float* __restrict__ __ins_1, float* __restrict__ __outs_0) noexcept{
  for (uint64_t _fuseiter_8752 = 0UL; _fuseiter_8752 < 128UL; _fuseiter_8752 += 16UL) {
    vec_f32x16 __cached_0;
    __cached_0 = vec_f32x16::load(&__ins_0[((((fused_0fused_0fused_0fused_0__itr_0____itr_1_2664____itr_2_2665____itr_3_2666____itr_4_2667 / 4UL) * 512UL) + ((fused_0fused_0fused_0fused_0__itr_0____itr_1_2664____itr_2_2665____itr_3_2666____itr_4_2667 % 4UL) * 128UL)) + _fuseiter_8752)]);
    float __cached_1;
    __cached_1 = __ins_1[0];
    vec_f32x16 __cached_2;
    __cached_2 = (__cached_0 * vec_f32x16(__cached_1));
    vec_f32x16::store(__cached_2, &__outs_0[((((fused_0fused_0fused_0fused_0__itr_0____itr_1_2664____itr_2_2665____itr_3_2666____itr_4_2667 / 4UL) * 512UL) + ((fused_0fused_0fused_0fused_0__itr_0____itr_1_2664____itr_2_2665____itr_3_2666____itr_4_2667 % 4UL) * 128UL)) + _fuseiter_8752)]);
  }
}

static void mul__6640_closure_81_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept{
  mul__6640_closure_81(i, (float*)(args[0UL].v_ptr), (float*)(args[1UL].v_ptr), (float*)(args[2UL].v_ptr));
}

static void reorder__5490_closure_82(uint64_t fused_0fused_0fused_0fused_0_fuseiter_8754___fuseiter_8755_2668___fuseiter_8756_2669___fuseiter_8757_2670___fuseiter_8758_2671, float* __restrict__ __ins_0, float* __restrict__ __outs_0) noexcept{
  for (uint64_t _fuseiter_8759 = 0UL; _fuseiter_8759 < 512UL; _fuseiter_8759 += 1UL) {
    float __cached_0;
    __cached_0 = __ins_0[(((fused_0fused_0fused_0fused_0_fuseiter_8754___fuseiter_8755_2668___fuseiter_8756_2669___fuseiter_8757_2670___fuseiter_8758_2671 / 4UL) * 2048UL) + (_fuseiter_8759 + ((fused_0fused_0fused_0fused_0_fuseiter_8754___fuseiter_8755_2668___fuseiter_8756_2669___fuseiter_8757_2670___fuseiter_8758_2671 % 4UL) * 512UL)))];
    float __cached_1;
    __cached_1 = __cached_0;
    __outs_0[(((fused_0fused_0fused_0fused_0_fuseiter_8754___fuseiter_8755_2668___fuseiter_8756_2669___fuseiter_8757_2670___fuseiter_8758_2671 / 4UL) * 2048UL) + (((fused_0fused_0fused_0fused_0_fuseiter_8754___fuseiter_8755_2668___fuseiter_8756_2669___fuseiter_8757_2670___fuseiter_8758_2671 % 4UL) * 512UL) + _fuseiter_8759))] = __cached_1;
  }
}

static void reorder__5490_closure_82_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept{
  reorder__5490_closure_82(i, (float*)(args[0UL].v_ptr), (float*)(args[1UL].v_ptr));
}

static void mul__6660_closure_83(uint64_t fused_0fused_0fused_0fused_0__itr_0____itr_1_2672____itr_2_2673____itr_3_2674____itr_4_2675, float* __restrict__ __ins_0, float* __restrict__ __ins_1, float* __restrict__ __outs_0) noexcept{
  for (uint64_t _fuseiter_8765 = 0UL; _fuseiter_8765 < 512UL; _fuseiter_8765 += 16UL) {
    vec_f32x16 __cached_0;
    __cached_0 = vec_f32x16::load(&__ins_0[((((fused_0fused_0fused_0fused_0__itr_0____itr_1_2672____itr_2_2673____itr_3_2674____itr_4_2675 / 4UL) * 2048UL) + ((fused_0fused_0fused_0fused_0__itr_0____itr_1_2672____itr_2_2673____itr_3_2674____itr_4_2675 % 4UL) * 512UL)) + _fuseiter_8765)]);
    float __cached_1;
    __cached_1 = __ins_1[0];
    vec_f32x16 __cached_2;
    __cached_2 = (__cached_0 * vec_f32x16(__cached_1));
    vec_f32x16::store(__cached_2, &__outs_0[((((fused_0fused_0fused_0fused_0__itr_0____itr_1_2672____itr_2_2673____itr_3_2674____itr_4_2675 / 4UL) * 2048UL) + ((fused_0fused_0fused_0fused_0__itr_0____itr_1_2672____itr_2_2673____itr_3_2674____itr_4_2675 % 4UL) * 512UL)) + _fuseiter_8765)]);
  }
}

static void mul__6660_closure_83_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept{
  mul__6660_closure_83(i, (float*)(args[0UL].v_ptr), (float*)(args[1UL].v_ptr), (float*)(args[2UL].v_ptr));
}

static void reorder__5520_closure_84(uint64_t fused_0fused_0fused_0fused_0_fuseiter_8767___fuseiter_8768_2676___fuseiter_8769_2677___fuseiter_8770_2678___fuseiter_8771_2679, float* __restrict__ __ins_0, float* __restrict__ __outs_0) noexcept{
  for (uint64_t _fuseiter_8772 = 0UL; _fuseiter_8772 < 256UL; _fuseiter_8772 += 1UL) {
    float __cached_0;
    __cached_0 = __ins_0[(((fused_0fused_0fused_0fused_0_fuseiter_8767___fuseiter_8768_2676___fuseiter_8769_2677___fuseiter_8770_2678___fuseiter_8771_2679 / 2UL) * 512UL) + (_fuseiter_8772 + ((fused_0fused_0fused_0fused_0_fuseiter_8767___fuseiter_8768_2676___fuseiter_8769_2677___fuseiter_8770_2678___fuseiter_8771_2679 % 2UL) * 256UL)))];
    float __cached_1;
    __cached_1 = __cached_0;
    __outs_0[(((fused_0fused_0fused_0fused_0_fuseiter_8767___fuseiter_8768_2676___fuseiter_8769_2677___fuseiter_8770_2678___fuseiter_8771_2679 / 2UL) * 512UL) + (((fused_0fused_0fused_0fused_0_fuseiter_8767___fuseiter_8768_2676___fuseiter_8769_2677___fuseiter_8770_2678___fuseiter_8771_2679 % 2UL) * 256UL) + _fuseiter_8772))] = __cached_1;
  }
}

static void reorder__5520_closure_84_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept{
  reorder__5520_closure_84(i, (float*)(args[0UL].v_ptr), (float*)(args[1UL].v_ptr));
}

static void mul__6680_closure_85(uint64_t fused_0fused_0fused_0fused_0__itr_0____itr_1_2680____itr_2_2681____itr_3_2682____itr_4_2683, float* __restrict__ __ins_0, float* __restrict__ __ins_1, float* __restrict__ __outs_0) noexcept{
  for (uint64_t _fuseiter_8778 = 0UL; _fuseiter_8778 < 256UL; _fuseiter_8778 += 16UL) {
    vec_f32x16 __cached_0;
    __cached_0 = vec_f32x16::load(&__ins_0[((((fused_0fused_0fused_0fused_0__itr_0____itr_1_2680____itr_2_2681____itr_3_2682____itr_4_2683 / 2UL) * 512UL) + ((fused_0fused_0fused_0fused_0__itr_0____itr_1_2680____itr_2_2681____itr_3_2682____itr_4_2683 % 2UL) * 256UL)) + _fuseiter_8778)]);
    float __cached_1;
    __cached_1 = __ins_1[0];
    vec_f32x16 __cached_2;
    __cached_2 = (__cached_0 * vec_f32x16(__cached_1));
    vec_f32x16::store(__cached_2, &__outs_0[((((fused_0fused_0fused_0fused_0__itr_0____itr_1_2680____itr_2_2681____itr_3_2682____itr_4_2683 / 2UL) * 512UL) + ((fused_0fused_0fused_0fused_0__itr_0____itr_1_2680____itr_2_2681____itr_3_2682____itr_4_2683 % 2UL) * 256UL)) + _fuseiter_8778)]);
  }
}

static void mul__6680_closure_85_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept{
  mul__6680_closure_85(i, (float*)(args[0UL].v_ptr), (float*)(args[1UL].v_ptr), (float*)(args[2UL].v_ptr));
}

static void reorder__5550_closure_86(uint64_t fused_0fused_0fused_0fused_0_fuseiter_8780___fuseiter_8781_2684___fuseiter_8782_2685___fuseiter_8783_2686___fuseiter_8784_2687, float* __restrict__ __ins_0, float* __restrict__ __outs_0) noexcept{
  for (uint64_t _fuseiter_8785 = 0UL; _fuseiter_8785 < 64UL; _fuseiter_8785 += 1UL) {
    float __cached_0;
    __cached_0 = __ins_0[(((fused_0fused_0fused_0fused_0_fuseiter_8780___fuseiter_8781_2684___fuseiter_8782_2685___fuseiter_8783_2686___fuseiter_8784_2687 / 8UL) * 512UL) + (_fuseiter_8785 + ((fused_0fused_0fused_0fused_0_fuseiter_8780___fuseiter_8781_2684___fuseiter_8782_2685___fuseiter_8783_2686___fuseiter_8784_2687 % 8UL) * 64UL)))];
    float __cached_1;
    __cached_1 = __cached_0;
    __outs_0[(((fused_0fused_0fused_0fused_0_fuseiter_8780___fuseiter_8781_2684___fuseiter_8782_2685___fuseiter_8783_2686___fuseiter_8784_2687 / 8UL) * 512UL) + (((fused_0fused_0fused_0fused_0_fuseiter_8780___fuseiter_8781_2684___fuseiter_8782_2685___fuseiter_8783_2686___fuseiter_8784_2687 % 8UL) * 64UL) + _fuseiter_8785))] = __cached_1;
  }
}

static void reorder__5550_closure_86_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept{
  reorder__5550_closure_86(i, (float*)(args[0UL].v_ptr), (float*)(args[1UL].v_ptr));
}

static void mul__6700_closure_87(uint64_t fused_0fused_0fused_0fused_0__itr_0____itr_1_2688____itr_2_2689____itr_3_2690____itr_4_2691, float* __restrict__ __ins_0, float* __restrict__ __ins_1, float* __restrict__ __outs_0) noexcept{
  for (uint64_t _fuseiter_8791 = 0UL; _fuseiter_8791 < 64UL; _fuseiter_8791 += 16UL) {
    vec_f32x16 __cached_0;
    __cached_0 = vec_f32x16::load(&__ins_0[((((fused_0fused_0fused_0fused_0__itr_0____itr_1_2688____itr_2_2689____itr_3_2690____itr_4_2691 / 8UL) * 512UL) + ((fused_0fused_0fused_0fused_0__itr_0____itr_1_2688____itr_2_2689____itr_3_2690____itr_4_2691 % 8UL) * 64UL)) + _fuseiter_8791)]);
    float __cached_1;
    __cached_1 = __ins_1[0];
    vec_f32x16 __cached_2;
    __cached_2 = (__cached_0 * vec_f32x16(__cached_1));
    vec_f32x16::store(__cached_2, &__outs_0[((((fused_0fused_0fused_0fused_0__itr_0____itr_1_2688____itr_2_2689____itr_3_2690____itr_4_2691 / 8UL) * 512UL) + ((fused_0fused_0fused_0fused_0__itr_0____itr_1_2688____itr_2_2689____itr_3_2690____itr_4_2691 % 8UL) * 64UL)) + _fuseiter_8791)]);
  }
}

static void mul__6700_closure_87_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept{
  mul__6700_closure_87(i, (float*)(args[0UL].v_ptr), (float*)(args[1UL].v_ptr), (float*)(args[2UL].v_ptr));
}

static void reorder__5580_closure_88(uint64_t fused_0fused_0fused_0fused_0_fuseiter_8793___fuseiter_8794_2692___fuseiter_8795_2693___fuseiter_8796_2694___fuseiter_8797_2695, float* __restrict__ __ins_0, float* __restrict__ __outs_0) noexcept{
  for (uint64_t _fuseiter_8798 = 0UL; _fuseiter_8798 < 512UL; _fuseiter_8798 += 1UL) {
    float __cached_0;
    __cached_0 = __ins_0[(((fused_0fused_0fused_0fused_0_fuseiter_8793___fuseiter_8794_2692___fuseiter_8795_2693___fuseiter_8796_2694___fuseiter_8797_2695 / 4UL) * 2048UL) + (_fuseiter_8798 + ((fused_0fused_0fused_0fused_0_fuseiter_8793___fuseiter_8794_2692___fuseiter_8795_2693___fuseiter_8796_2694___fuseiter_8797_2695 % 4UL) * 512UL)))];
    float __cached_1;
    __cached_1 = __cached_0;
    __outs_0[(((fused_0fused_0fused_0fused_0_fuseiter_8793___fuseiter_8794_2692___fuseiter_8795_2693___fuseiter_8796_2694___fuseiter_8797_2695 / 4UL) * 2048UL) + (((fused_0fused_0fused_0fused_0_fuseiter_8793___fuseiter_8794_2692___fuseiter_8795_2693___fuseiter_8796_2694___fuseiter_8797_2695 % 4UL) * 512UL) + _fuseiter_8798))] = __cached_1;
  }
}

static void reorder__5580_closure_88_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept{
  reorder__5580_closure_88(i, (float*)(args[0UL].v_ptr), (float*)(args[1UL].v_ptr));
}

static void mul__6720_closure_89(uint64_t fused_0fused_0fused_0fused_0__itr_0____itr_1_2696____itr_2_2697____itr_3_2698____itr_4_2699, float* __restrict__ __ins_0, float* __restrict__ __ins_1, float* __restrict__ __outs_0) noexcept{
  for (uint64_t _fuseiter_8804 = 0UL; _fuseiter_8804 < 512UL; _fuseiter_8804 += 16UL) {
    vec_f32x16 __cached_0;
    __cached_0 = vec_f32x16::load(&__ins_0[((((fused_0fused_0fused_0fused_0__itr_0____itr_1_2696____itr_2_2697____itr_3_2698____itr_4_2699 / 4UL) * 2048UL) + ((fused_0fused_0fused_0fused_0__itr_0____itr_1_2696____itr_2_2697____itr_3_2698____itr_4_2699 % 4UL) * 512UL)) + _fuseiter_8804)]);
    float __cached_1;
    __cached_1 = __ins_1[0];
    vec_f32x16 __cached_2;
    __cached_2 = (__cached_0 * vec_f32x16(__cached_1));
    vec_f32x16::store(__cached_2, &__outs_0[((((fused_0fused_0fused_0fused_0__itr_0____itr_1_2696____itr_2_2697____itr_3_2698____itr_4_2699 / 4UL) * 2048UL) + ((fused_0fused_0fused_0fused_0__itr_0____itr_1_2696____itr_2_2697____itr_3_2698____itr_4_2699 % 4UL) * 512UL)) + _fuseiter_8804)]);
  }
}

static void mul__6720_closure_89_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept{
  mul__6720_closure_89(i, (float*)(args[0UL].v_ptr), (float*)(args[1UL].v_ptr), (float*)(args[2UL].v_ptr));
}

static void reorder__4410_closure_90(uint64_t fused_0fused_0fused_0fused_0_fuseiter_8848___fuseiter_8849_2724___fuseiter_8850_2725___fuseiter_8851_2726___fuseiter_8852_2727, float* __restrict__ __ins_0, float* __restrict__ __outs_0) noexcept{
  for (uint64_t _fuseiter_8853 = 0UL; _fuseiter_8853 < 64UL; _fuseiter_8853 += 16UL) {
    vec_f32x16 __cached_0;
    __cached_0 = vec_f32x16::load(&__ins_0[(((fused_0fused_0fused_0fused_0_fuseiter_8848___fuseiter_8849_2724___fuseiter_8850_2725___fuseiter_8851_2726___fuseiter_8852_2727 / 2UL) * 128UL) + (_fuseiter_8853 + ((fused_0fused_0fused_0fused_0_fuseiter_8848___fuseiter_8849_2724___fuseiter_8850_2725___fuseiter_8851_2726___fuseiter_8852_2727 % 2UL) * 64UL)))]);
    vec_f32x16 __cached_1;
    __cached_1 = __cached_0;
    vec_f32x16::store(__cached_1, &__outs_0[(((fused_0fused_0fused_0fused_0_fuseiter_8848___fuseiter_8849_2724___fuseiter_8850_2725___fuseiter_8851_2726___fuseiter_8852_2727 / 2UL) * 128UL) + (((fused_0fused_0fused_0fused_0_fuseiter_8848___fuseiter_8849_2724___fuseiter_8850_2725___fuseiter_8851_2726___fuseiter_8852_2727 % 2UL) * 64UL) + _fuseiter_8853))]);
  }
}

static void reorder__4410_closure_90_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept{
  reorder__4410_closure_90(i, (float*)(args[0UL].v_ptr), (float*)(args[1UL].v_ptr));
}

static void mul__5930_closure_91(uint64_t fused_0fused_0fused_0fused_0__itr_0____itr_1_2728____itr_2_2729____itr_3_2730____itr_4_2731, float* __restrict__ __ins_0, float* __restrict__ __ins_1, float* __restrict__ __outs_0) noexcept{
  for (uint64_t _fuseiter_8859 = 0UL; _fuseiter_8859 < 64UL; _fuseiter_8859 += 16UL) {
    vec_f32x16 __cached_0;
    __cached_0 = vec_f32x16::load(&__ins_0[((((fused_0fused_0fused_0fused_0__itr_0____itr_1_2728____itr_2_2729____itr_3_2730____itr_4_2731 / 2UL) * 128UL) + ((fused_0fused_0fused_0fused_0__itr_0____itr_1_2728____itr_2_2729____itr_3_2730____itr_4_2731 % 2UL) * 64UL)) + _fuseiter_8859)]);
    float __cached_1;
    __cached_1 = __ins_1[0];
    vec_f32x16 __cached_2;
    __cached_2 = (__cached_0 * vec_f32x16(__cached_1));
    vec_f32x16::store(__cached_2, &__outs_0[((((fused_0fused_0fused_0fused_0__itr_0____itr_1_2728____itr_2_2729____itr_3_2730____itr_4_2731 / 2UL) * 128UL) + ((fused_0fused_0fused_0fused_0__itr_0____itr_1_2728____itr_2_2729____itr_3_2730____itr_4_2731 % 2UL) * 64UL)) + _fuseiter_8859)]);
  }
}

static void mul__5930_closure_91_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept{
  mul__5930_closure_91(i, (float*)(args[0UL].v_ptr), (float*)(args[1UL].v_ptr), (float*)(args[2UL].v_ptr));
}

static void reorder__4440_closure_92(uint64_t fused_0fused_0fused_0fused_0_fuseiter_8861___fuseiter_8862_2732___fuseiter_8863_2733___fuseiter_8864_2734___fuseiter_8865_2735, float* __restrict__ __ins_0, float* __restrict__ __outs_0) noexcept{
  for (uint64_t _fuseiter_8866 = 0UL; _fuseiter_8866 < 64UL; _fuseiter_8866 += 16UL) {
    vec_f32x16 __cached_0;
    __cached_0 = vec_f32x16::load(&__ins_0[(((fused_0fused_0fused_0fused_0_fuseiter_8861___fuseiter_8862_2732___fuseiter_8863_2733___fuseiter_8864_2734___fuseiter_8865_2735 / 2UL) * 128UL) + (_fuseiter_8866 + ((fused_0fused_0fused_0fused_0_fuseiter_8861___fuseiter_8862_2732___fuseiter_8863_2733___fuseiter_8864_2734___fuseiter_8865_2735 % 2UL) * 64UL)))]);
    vec_f32x16 __cached_1;
    __cached_1 = __cached_0;
    vec_f32x16::store(__cached_1, &__outs_0[(((fused_0fused_0fused_0fused_0_fuseiter_8861___fuseiter_8862_2732___fuseiter_8863_2733___fuseiter_8864_2734___fuseiter_8865_2735 / 2UL) * 128UL) + (((fused_0fused_0fused_0fused_0_fuseiter_8861___fuseiter_8862_2732___fuseiter_8863_2733___fuseiter_8864_2734___fuseiter_8865_2735 % 2UL) * 64UL) + _fuseiter_8866))]);
  }
}

static void reorder__4440_closure_92_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept{
  reorder__4440_closure_92(i, (float*)(args[0UL].v_ptr), (float*)(args[1UL].v_ptr));
}

static void mul__5950_closure_93(uint64_t fused_0fused_0fused_0fused_0__itr_0____itr_1_2736____itr_2_2737____itr_3_2738____itr_4_2739, float* __restrict__ __ins_0, float* __restrict__ __ins_1, float* __restrict__ __outs_0) noexcept{
  for (uint64_t _fuseiter_8872 = 0UL; _fuseiter_8872 < 64UL; _fuseiter_8872 += 16UL) {
    vec_f32x16 __cached_0;
    __cached_0 = vec_f32x16::load(&__ins_0[((((fused_0fused_0fused_0fused_0__itr_0____itr_1_2736____itr_2_2737____itr_3_2738____itr_4_2739 / 2UL) * 128UL) + ((fused_0fused_0fused_0fused_0__itr_0____itr_1_2736____itr_2_2737____itr_3_2738____itr_4_2739 % 2UL) * 64UL)) + _fuseiter_8872)]);
    float __cached_1;
    __cached_1 = __ins_1[0];
    vec_f32x16 __cached_2;
    __cached_2 = (__cached_0 * vec_f32x16(__cached_1));
    vec_f32x16::store(__cached_2, &__outs_0[((((fused_0fused_0fused_0fused_0__itr_0____itr_1_2736____itr_2_2737____itr_3_2738____itr_4_2739 / 2UL) * 128UL) + ((fused_0fused_0fused_0fused_0__itr_0____itr_1_2736____itr_2_2737____itr_3_2738____itr_4_2739 % 2UL) * 64UL)) + _fuseiter_8872)]);
  }
}

static void mul__5950_closure_93_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept{
  mul__5950_closure_93(i, (float*)(args[0UL].v_ptr), (float*)(args[1UL].v_ptr), (float*)(args[2UL].v_ptr));
}

static void reorder__4500_closure_94(uint64_t fused_0fused_0fused_0fused_0_fuseiter_8874___fuseiter_8875_2740___fuseiter_8876_2741___fuseiter_8877_2742___fuseiter_8878_2743, float* __restrict__ __ins_0, float* __restrict__ __outs_0) noexcept{
  for (uint64_t _fuseiter_8879 = 0UL; _fuseiter_8879 < 64UL; _fuseiter_8879 += 16UL) {
    vec_f32x16 __cached_0;
    __cached_0 = vec_f32x16::load(&__ins_0[(((fused_0fused_0fused_0fused_0_fuseiter_8874___fuseiter_8875_2740___fuseiter_8876_2741___fuseiter_8877_2742___fuseiter_8878_2743 / 2UL) * 128UL) + (_fuseiter_8879 + ((fused_0fused_0fused_0fused_0_fuseiter_8874___fuseiter_8875_2740___fuseiter_8876_2741___fuseiter_8877_2742___fuseiter_8878_2743 % 2UL) * 64UL)))]);
    vec_f32x16 __cached_1;
    __cached_1 = __cached_0;
    vec_f32x16::store(__cached_1, &__outs_0[(((fused_0fused_0fused_0fused_0_fuseiter_8874___fuseiter_8875_2740___fuseiter_8876_2741___fuseiter_8877_2742___fuseiter_8878_2743 / 2UL) * 128UL) + (((fused_0fused_0fused_0fused_0_fuseiter_8874___fuseiter_8875_2740___fuseiter_8876_2741___fuseiter_8877_2742___fuseiter_8878_2743 % 2UL) * 64UL) + _fuseiter_8879))]);
  }
}

static void reorder__4500_closure_94_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept{
  reorder__4500_closure_94(i, (float*)(args[0UL].v_ptr), (float*)(args[1UL].v_ptr));
}

static void mul__5990_closure_95(uint64_t fused_0fused_0fused_0fused_0__itr_0____itr_1_2744____itr_2_2745____itr_3_2746____itr_4_2747, float* __restrict__ __ins_0, float* __restrict__ __ins_1, float* __restrict__ __outs_0) noexcept{
  for (uint64_t _fuseiter_8885 = 0UL; _fuseiter_8885 < 64UL; _fuseiter_8885 += 16UL) {
    vec_f32x16 __cached_0;
    __cached_0 = vec_f32x16::load(&__ins_0[((((fused_0fused_0fused_0fused_0__itr_0____itr_1_2744____itr_2_2745____itr_3_2746____itr_4_2747 / 2UL) * 128UL) + ((fused_0fused_0fused_0fused_0__itr_0____itr_1_2744____itr_2_2745____itr_3_2746____itr_4_2747 % 2UL) * 64UL)) + _fuseiter_8885)]);
    float __cached_1;
    __cached_1 = __ins_1[0];
    vec_f32x16 __cached_2;
    __cached_2 = (__cached_0 * vec_f32x16(__cached_1));
    vec_f32x16::store(__cached_2, &__outs_0[((((fused_0fused_0fused_0fused_0__itr_0____itr_1_2744____itr_2_2745____itr_3_2746____itr_4_2747 / 2UL) * 128UL) + ((fused_0fused_0fused_0fused_0__itr_0____itr_1_2744____itr_2_2745____itr_3_2746____itr_4_2747 % 2UL) * 64UL)) + _fuseiter_8885)]);
  }
}

static void mul__5990_closure_95_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept{
  mul__5990_closure_95(i, (float*)(args[0UL].v_ptr), (float*)(args[1UL].v_ptr), (float*)(args[2UL].v_ptr));
}

static void reorder__4530_closure_96(uint64_t fused_0fused_0fused_0fused_0_fuseiter_8887___fuseiter_8888_2748___fuseiter_8889_2749___fuseiter_8890_2750___fuseiter_8891_2751, float* __restrict__ __ins_0, float* __restrict__ __outs_0) noexcept{
  for (uint64_t _fuseiter_8892 = 0UL; _fuseiter_8892 < 64UL; _fuseiter_8892 += 16UL) {
    vec_f32x16 __cached_0;
    __cached_0 = vec_f32x16::load(&__ins_0[(((fused_0fused_0fused_0fused_0_fuseiter_8887___fuseiter_8888_2748___fuseiter_8889_2749___fuseiter_8890_2750___fuseiter_8891_2751 / 2UL) * 128UL) + (_fuseiter_8892 + ((fused_0fused_0fused_0fused_0_fuseiter_8887___fuseiter_8888_2748___fuseiter_8889_2749___fuseiter_8890_2750___fuseiter_8891_2751 % 2UL) * 64UL)))]);
    vec_f32x16 __cached_1;
    __cached_1 = __cached_0;
    vec_f32x16::store(__cached_1, &__outs_0[(((fused_0fused_0fused_0fused_0_fuseiter_8887___fuseiter_8888_2748___fuseiter_8889_2749___fuseiter_8890_2750___fuseiter_8891_2751 / 2UL) * 128UL) + (((fused_0fused_0fused_0fused_0_fuseiter_8887___fuseiter_8888_2748___fuseiter_8889_2749___fuseiter_8890_2750___fuseiter_8891_2751 % 2UL) * 64UL) + _fuseiter_8892))]);
  }
}

static void reorder__4530_closure_96_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept{
  reorder__4530_closure_96(i, (float*)(args[0UL].v_ptr), (float*)(args[1UL].v_ptr));
}

static void mul__6010_closure_97(uint64_t fused_0fused_0fused_0fused_0__itr_0____itr_1_2752____itr_2_2753____itr_3_2754____itr_4_2755, float* __restrict__ __ins_0, float* __restrict__ __ins_1, float* __restrict__ __outs_0) noexcept{
  for (uint64_t _fuseiter_8898 = 0UL; _fuseiter_8898 < 64UL; _fuseiter_8898 += 16UL) {
    vec_f32x16 __cached_0;
    __cached_0 = vec_f32x16::load(&__ins_0[((((fused_0fused_0fused_0fused_0__itr_0____itr_1_2752____itr_2_2753____itr_3_2754____itr_4_2755 / 2UL) * 128UL) + ((fused_0fused_0fused_0fused_0__itr_0____itr_1_2752____itr_2_2753____itr_3_2754____itr_4_2755 % 2UL) * 64UL)) + _fuseiter_8898)]);
    float __cached_1;
    __cached_1 = __ins_1[0];
    vec_f32x16 __cached_2;
    __cached_2 = (__cached_0 * vec_f32x16(__cached_1));
    vec_f32x16::store(__cached_2, &__outs_0[((((fused_0fused_0fused_0fused_0__itr_0____itr_1_2752____itr_2_2753____itr_3_2754____itr_4_2755 / 2UL) * 128UL) + ((fused_0fused_0fused_0fused_0__itr_0____itr_1_2752____itr_2_2753____itr_3_2754____itr_4_2755 % 2UL) * 64UL)) + _fuseiter_8898)]);
  }
}

static void mul__6010_closure_97_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept{
  mul__6010_closure_97(i, (float*)(args[0UL].v_ptr), (float*)(args[1UL].v_ptr), (float*)(args[2UL].v_ptr));
}

static void reorder__4590_closure_98(uint64_t fused_0fused_0fused_0fused_0_fuseiter_8900___fuseiter_8901_2756___fuseiter_8902_2757___fuseiter_8903_2758___fuseiter_8904_2759, float* __restrict__ __ins_0, float* __restrict__ __outs_0) noexcept{
  for (uint64_t _fuseiter_8905 = 0UL; _fuseiter_8905 < 64UL; _fuseiter_8905 += 16UL) {
    vec_f32x16 __cached_0;
    __cached_0 = vec_f32x16::load(&__ins_0[(((fused_0fused_0fused_0fused_0_fuseiter_8900___fuseiter_8901_2756___fuseiter_8902_2757___fuseiter_8903_2758___fuseiter_8904_2759 / 2UL) * 128UL) + (_fuseiter_8905 + ((fused_0fused_0fused_0fused_0_fuseiter_8900___fuseiter_8901_2756___fuseiter_8902_2757___fuseiter_8903_2758___fuseiter_8904_2759 % 2UL) * 64UL)))]);
    vec_f32x16 __cached_1;
    __cached_1 = __cached_0;
    vec_f32x16::store(__cached_1, &__outs_0[(((fused_0fused_0fused_0fused_0_fuseiter_8900___fuseiter_8901_2756___fuseiter_8902_2757___fuseiter_8903_2758___fuseiter_8904_2759 / 2UL) * 128UL) + (((fused_0fused_0fused_0fused_0_fuseiter_8900___fuseiter_8901_2756___fuseiter_8902_2757___fuseiter_8903_2758___fuseiter_8904_2759 % 2UL) * 64UL) + _fuseiter_8905))]);
  }
}

static void reorder__4590_closure_98_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept{
  reorder__4590_closure_98(i, (float*)(args[0UL].v_ptr), (float*)(args[1UL].v_ptr));
}

static void mul__6050_closure_99(uint64_t fused_0fused_0fused_0fused_0__itr_0____itr_1_2760____itr_2_2761____itr_3_2762____itr_4_2763, float* __restrict__ __ins_0, float* __restrict__ __ins_1, float* __restrict__ __outs_0) noexcept{
  for (uint64_t _fuseiter_8911 = 0UL; _fuseiter_8911 < 64UL; _fuseiter_8911 += 16UL) {
    vec_f32x16 __cached_0;
    __cached_0 = vec_f32x16::load(&__ins_0[((((fused_0fused_0fused_0fused_0__itr_0____itr_1_2760____itr_2_2761____itr_3_2762____itr_4_2763 / 2UL) * 128UL) + ((fused_0fused_0fused_0fused_0__itr_0____itr_1_2760____itr_2_2761____itr_3_2762____itr_4_2763 % 2UL) * 64UL)) + _fuseiter_8911)]);
    float __cached_1;
    __cached_1 = __ins_1[0];
    vec_f32x16 __cached_2;
    __cached_2 = (__cached_0 * vec_f32x16(__cached_1));
    vec_f32x16::store(__cached_2, &__outs_0[((((fused_0fused_0fused_0fused_0__itr_0____itr_1_2760____itr_2_2761____itr_3_2762____itr_4_2763 / 2UL) * 128UL) + ((fused_0fused_0fused_0fused_0__itr_0____itr_1_2760____itr_2_2761____itr_3_2762____itr_4_2763 % 2UL) * 64UL)) + _fuseiter_8911)]);
  }
}

static void mul__6050_closure_99_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept{
  mul__6050_closure_99(i, (float*)(args[0UL].v_ptr), (float*)(args[1UL].v_ptr), (float*)(args[2UL].v_ptr));
}

static void reorder__4620_closure_100(uint64_t fused_0fused_0fused_0fused_0_fuseiter_8913___fuseiter_8914_2764___fuseiter_8915_2765___fuseiter_8916_2766___fuseiter_8917_2767, float* __restrict__ __ins_0, float* __restrict__ __outs_0) noexcept{
  for (uint64_t _fuseiter_8918 = 0UL; _fuseiter_8918 < 64UL; _fuseiter_8918 += 16UL) {
    vec_f32x16 __cached_0;
    __cached_0 = vec_f32x16::load(&__ins_0[(((fused_0fused_0fused_0fused_0_fuseiter_8913___fuseiter_8914_2764___fuseiter_8915_2765___fuseiter_8916_2766___fuseiter_8917_2767 / 2UL) * 128UL) + (_fuseiter_8918 + ((fused_0fused_0fused_0fused_0_fuseiter_8913___fuseiter_8914_2764___fuseiter_8915_2765___fuseiter_8916_2766___fuseiter_8917_2767 % 2UL) * 64UL)))]);
    vec_f32x16 __cached_1;
    __cached_1 = __cached_0;
    vec_f32x16::store(__cached_1, &__outs_0[(((fused_0fused_0fused_0fused_0_fuseiter_8913___fuseiter_8914_2764___fuseiter_8915_2765___fuseiter_8916_2766___fuseiter_8917_2767 / 2UL) * 128UL) + (((fused_0fused_0fused_0fused_0_fuseiter_8913___fuseiter_8914_2764___fuseiter_8915_2765___fuseiter_8916_2766___fuseiter_8917_2767 % 2UL) * 64UL) + _fuseiter_8918))]);
  }
}

static void reorder__4620_closure_100_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept{
  reorder__4620_closure_100(i, (float*)(args[0UL].v_ptr), (float*)(args[1UL].v_ptr));
}

static void mul__6070_closure_101(uint64_t fused_0fused_0fused_0fused_0__itr_0____itr_1_2768____itr_2_2769____itr_3_2770____itr_4_2771, float* __restrict__ __ins_0, float* __restrict__ __ins_1, float* __restrict__ __outs_0) noexcept{
  for (uint64_t _fuseiter_8924 = 0UL; _fuseiter_8924 < 64UL; _fuseiter_8924 += 16UL) {
    vec_f32x16 __cached_0;
    __cached_0 = vec_f32x16::load(&__ins_0[((((fused_0fused_0fused_0fused_0__itr_0____itr_1_2768____itr_2_2769____itr_3_2770____itr_4_2771 / 2UL) * 128UL) + ((fused_0fused_0fused_0fused_0__itr_0____itr_1_2768____itr_2_2769____itr_3_2770____itr_4_2771 % 2UL) * 64UL)) + _fuseiter_8924)]);
    float __cached_1;
    __cached_1 = __ins_1[0];
    vec_f32x16 __cached_2;
    __cached_2 = (__cached_0 * vec_f32x16(__cached_1));
    vec_f32x16::store(__cached_2, &__outs_0[((((fused_0fused_0fused_0fused_0__itr_0____itr_1_2768____itr_2_2769____itr_3_2770____itr_4_2771 / 2UL) * 128UL) + ((fused_0fused_0fused_0fused_0__itr_0____itr_1_2768____itr_2_2769____itr_3_2770____itr_4_2771 % 2UL) * 64UL)) + _fuseiter_8924)]);
  }
}

static void mul__6070_closure_101_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept{
  mul__6070_closure_101(i, (float*)(args[0UL].v_ptr), (float*)(args[1UL].v_ptr), (float*)(args[2UL].v_ptr));
}

static void reorder__4680_closure_102(uint64_t fused_0fused_0fused_0fused_0_fuseiter_8926___fuseiter_8927_2772___fuseiter_8928_2773___fuseiter_8929_2774___fuseiter_8930_2775, float* __restrict__ __ins_0, float* __restrict__ __outs_0) noexcept{
  for (uint64_t _fuseiter_8931 = 0UL; _fuseiter_8931 < 64UL; _fuseiter_8931 += 16UL) {
    vec_f32x16 __cached_0;
    __cached_0 = vec_f32x16::load(&__ins_0[(((fused_0fused_0fused_0fused_0_fuseiter_8926___fuseiter_8927_2772___fuseiter_8928_2773___fuseiter_8929_2774___fuseiter_8930_2775 / 2UL) * 128UL) + (_fuseiter_8931 + ((fused_0fused_0fused_0fused_0_fuseiter_8926___fuseiter_8927_2772___fuseiter_8928_2773___fuseiter_8929_2774___fuseiter_8930_2775 % 2UL) * 64UL)))]);
    vec_f32x16 __cached_1;
    __cached_1 = __cached_0;
    vec_f32x16::store(__cached_1, &__outs_0[(((fused_0fused_0fused_0fused_0_fuseiter_8926___fuseiter_8927_2772___fuseiter_8928_2773___fuseiter_8929_2774___fuseiter_8930_2775 / 2UL) * 128UL) + (((fused_0fused_0fused_0fused_0_fuseiter_8926___fuseiter_8927_2772___fuseiter_8928_2773___fuseiter_8929_2774___fuseiter_8930_2775 % 2UL) * 64UL) + _fuseiter_8931))]);
  }
}

static void reorder__4680_closure_102_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept{
  reorder__4680_closure_102(i, (float*)(args[0UL].v_ptr), (float*)(args[1UL].v_ptr));
}

static void mul__6110_closure_103(uint64_t fused_0fused_0fused_0fused_0__itr_0____itr_1_2776____itr_2_2777____itr_3_2778____itr_4_2779, float* __restrict__ __ins_0, float* __restrict__ __ins_1, float* __restrict__ __outs_0) noexcept{
  for (uint64_t _fuseiter_8937 = 0UL; _fuseiter_8937 < 64UL; _fuseiter_8937 += 16UL) {
    vec_f32x16 __cached_0;
    __cached_0 = vec_f32x16::load(&__ins_0[((((fused_0fused_0fused_0fused_0__itr_0____itr_1_2776____itr_2_2777____itr_3_2778____itr_4_2779 / 2UL) * 128UL) + ((fused_0fused_0fused_0fused_0__itr_0____itr_1_2776____itr_2_2777____itr_3_2778____itr_4_2779 % 2UL) * 64UL)) + _fuseiter_8937)]);
    float __cached_1;
    __cached_1 = __ins_1[0];
    vec_f32x16 __cached_2;
    __cached_2 = (__cached_0 * vec_f32x16(__cached_1));
    vec_f32x16::store(__cached_2, &__outs_0[((((fused_0fused_0fused_0fused_0__itr_0____itr_1_2776____itr_2_2777____itr_3_2778____itr_4_2779 / 2UL) * 128UL) + ((fused_0fused_0fused_0fused_0__itr_0____itr_1_2776____itr_2_2777____itr_3_2778____itr_4_2779 % 2UL) * 64UL)) + _fuseiter_8937)]);
  }
}

static void mul__6110_closure_103_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept{
  mul__6110_closure_103(i, (float*)(args[0UL].v_ptr), (float*)(args[1UL].v_ptr), (float*)(args[2UL].v_ptr));
}

static void reorder__4710_closure_104(uint64_t fused_0fused_0fused_0fused_0_fuseiter_8939___fuseiter_8940_2780___fuseiter_8941_2781___fuseiter_8942_2782___fuseiter_8943_2783, float* __restrict__ __ins_0, float* __restrict__ __outs_0) noexcept{
  for (uint64_t _fuseiter_8944 = 0UL; _fuseiter_8944 < 64UL; _fuseiter_8944 += 16UL) {
    vec_f32x16 __cached_0;
    __cached_0 = vec_f32x16::load(&__ins_0[(((fused_0fused_0fused_0fused_0_fuseiter_8939___fuseiter_8940_2780___fuseiter_8941_2781___fuseiter_8942_2782___fuseiter_8943_2783 / 2UL) * 128UL) + (_fuseiter_8944 + ((fused_0fused_0fused_0fused_0_fuseiter_8939___fuseiter_8940_2780___fuseiter_8941_2781___fuseiter_8942_2782___fuseiter_8943_2783 % 2UL) * 64UL)))]);
    vec_f32x16 __cached_1;
    __cached_1 = __cached_0;
    vec_f32x16::store(__cached_1, &__outs_0[(((fused_0fused_0fused_0fused_0_fuseiter_8939___fuseiter_8940_2780___fuseiter_8941_2781___fuseiter_8942_2782___fuseiter_8943_2783 / 2UL) * 128UL) + (((fused_0fused_0fused_0fused_0_fuseiter_8939___fuseiter_8940_2780___fuseiter_8941_2781___fuseiter_8942_2782___fuseiter_8943_2783 % 2UL) * 64UL) + _fuseiter_8944))]);
  }
}

static void reorder__4710_closure_104_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept{
  reorder__4710_closure_104(i, (float*)(args[0UL].v_ptr), (float*)(args[1UL].v_ptr));
}

static void mul__6130_closure_105(uint64_t fused_0fused_0fused_0fused_0__itr_0____itr_1_2784____itr_2_2785____itr_3_2786____itr_4_2787, float* __restrict__ __ins_0, float* __restrict__ __ins_1, float* __restrict__ __outs_0) noexcept{
  for (uint64_t _fuseiter_8950 = 0UL; _fuseiter_8950 < 64UL; _fuseiter_8950 += 16UL) {
    vec_f32x16 __cached_0;
    __cached_0 = vec_f32x16::load(&__ins_0[((((fused_0fused_0fused_0fused_0__itr_0____itr_1_2784____itr_2_2785____itr_3_2786____itr_4_2787 / 2UL) * 128UL) + ((fused_0fused_0fused_0fused_0__itr_0____itr_1_2784____itr_2_2785____itr_3_2786____itr_4_2787 % 2UL) * 64UL)) + _fuseiter_8950)]);
    float __cached_1;
    __cached_1 = __ins_1[0];
    vec_f32x16 __cached_2;
    __cached_2 = (__cached_0 * vec_f32x16(__cached_1));
    vec_f32x16::store(__cached_2, &__outs_0[((((fused_0fused_0fused_0fused_0__itr_0____itr_1_2784____itr_2_2785____itr_3_2786____itr_4_2787 / 2UL) * 128UL) + ((fused_0fused_0fused_0fused_0__itr_0____itr_1_2784____itr_2_2785____itr_3_2786____itr_4_2787 % 2UL) * 64UL)) + _fuseiter_8950)]);
  }
}

static void mul__6130_closure_105_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept{
  mul__6130_closure_105(i, (float*)(args[0UL].v_ptr), (float*)(args[1UL].v_ptr), (float*)(args[2UL].v_ptr));
}

static void reorder__4200_closure_106(uint64_t fused_0fused_0fused_0fused_0_fuseiter_8952___fuseiter_8953_2788___fuseiter_8954_2789___fuseiter_8955_2790___fuseiter_8956_2791, float* __restrict__ __ins_0, float* __restrict__ __outs_0) noexcept{
  for (uint64_t _fuseiter_8957 = 0UL; _fuseiter_8957 < 64UL; _fuseiter_8957 += 16UL) {
    vec_f32x16 __cached_0;
    __cached_0 = vec_f32x16::load(&__ins_0[(((fused_0fused_0fused_0fused_0_fuseiter_8952___fuseiter_8953_2788___fuseiter_8954_2789___fuseiter_8955_2790___fuseiter_8956_2791 / 4UL) * 256UL) + (_fuseiter_8957 + ((fused_0fused_0fused_0fused_0_fuseiter_8952___fuseiter_8953_2788___fuseiter_8954_2789___fuseiter_8955_2790___fuseiter_8956_2791 % 4UL) * 64UL)))]);
    vec_f32x16 __cached_1;
    __cached_1 = __cached_0;
    vec_f32x16::store(__cached_1, &__outs_0[(((fused_0fused_0fused_0fused_0_fuseiter_8952___fuseiter_8953_2788___fuseiter_8954_2789___fuseiter_8955_2790___fuseiter_8956_2791 / 4UL) * 256UL) + (((fused_0fused_0fused_0fused_0_fuseiter_8952___fuseiter_8953_2788___fuseiter_8954_2789___fuseiter_8955_2790___fuseiter_8956_2791 % 4UL) * 64UL) + _fuseiter_8957))]);
  }
}

static void reorder__4200_closure_106_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept{
  reorder__4200_closure_106(i, (float*)(args[0UL].v_ptr), (float*)(args[1UL].v_ptr));
}

static void mul__5710_closure_107(uint64_t fused_0fused_0fused_0fused_0__itr_0____itr_1_2792____itr_2_2793____itr_3_2794____itr_4_2795, float* __restrict__ __ins_0, float* __restrict__ __ins_1, float* __restrict__ __outs_0) noexcept{
  for (uint64_t _fuseiter_8963 = 0UL; _fuseiter_8963 < 64UL; _fuseiter_8963 += 16UL) {
    vec_f32x16 __cached_0;
    __cached_0 = vec_f32x16::load(&__ins_0[((((fused_0fused_0fused_0fused_0__itr_0____itr_1_2792____itr_2_2793____itr_3_2794____itr_4_2795 / 4UL) * 256UL) + ((fused_0fused_0fused_0fused_0__itr_0____itr_1_2792____itr_2_2793____itr_3_2794____itr_4_2795 % 4UL) * 64UL)) + _fuseiter_8963)]);
    float __cached_1;
    __cached_1 = __ins_1[0];
    vec_f32x16 __cached_2;
    __cached_2 = (__cached_0 * vec_f32x16(__cached_1));
    vec_f32x16::store(__cached_2, &__outs_0[((((fused_0fused_0fused_0fused_0__itr_0____itr_1_2792____itr_2_2793____itr_3_2794____itr_4_2795 / 4UL) * 256UL) + ((fused_0fused_0fused_0fused_0__itr_0____itr_1_2792____itr_2_2793____itr_3_2794____itr_4_2795 % 4UL) * 64UL)) + _fuseiter_8963)]);
  }
}

static void mul__5710_closure_107_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept{
  mul__5710_closure_107(i, (float*)(args[0UL].v_ptr), (float*)(args[1UL].v_ptr), (float*)(args[2UL].v_ptr));
}

static void reorder__4250_closure_108(uint64_t fused_0fused_0fused_0fused_0_fuseiter_8965___fuseiter_8966_2796___fuseiter_8967_2797___fuseiter_8968_2798___fuseiter_8969_2799, float* __restrict__ __ins_0, float* __restrict__ __outs_0) noexcept{
  for (uint64_t _fuseiter_8970 = 0UL; _fuseiter_8970 < 64UL; _fuseiter_8970 += 16UL) {
    vec_f32x16 __cached_0;
    __cached_0 = vec_f32x16::load(&__ins_0[(((fused_0fused_0fused_0fused_0_fuseiter_8965___fuseiter_8966_2796___fuseiter_8967_2797___fuseiter_8968_2798___fuseiter_8969_2799 / 4UL) * 256UL) + (_fuseiter_8970 + ((fused_0fused_0fused_0fused_0_fuseiter_8965___fuseiter_8966_2796___fuseiter_8967_2797___fuseiter_8968_2798___fuseiter_8969_2799 % 4UL) * 64UL)))]);
    vec_f32x16 __cached_1;
    __cached_1 = __cached_0;
    vec_f32x16::store(__cached_1, &__outs_0[(((fused_0fused_0fused_0fused_0_fuseiter_8965___fuseiter_8966_2796___fuseiter_8967_2797___fuseiter_8968_2798___fuseiter_8969_2799 / 4UL) * 256UL) + (((fused_0fused_0fused_0fused_0_fuseiter_8965___fuseiter_8966_2796___fuseiter_8967_2797___fuseiter_8968_2798___fuseiter_8969_2799 % 4UL) * 64UL) + _fuseiter_8970))]);
  }
}

static void reorder__4250_closure_108_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept{
  reorder__4250_closure_108(i, (float*)(args[0UL].v_ptr), (float*)(args[1UL].v_ptr));
}

static void mul__5770_closure_109(uint64_t fused_0fused_0fused_0fused_0__itr_0____itr_1_2800____itr_2_2801____itr_3_2802____itr_4_2803, float* __restrict__ __ins_0, float* __restrict__ __ins_1, float* __restrict__ __outs_0) noexcept{
  for (uint64_t _fuseiter_8976 = 0UL; _fuseiter_8976 < 64UL; _fuseiter_8976 += 16UL) {
    vec_f32x16 __cached_0;
    __cached_0 = vec_f32x16::load(&__ins_0[((((fused_0fused_0fused_0fused_0__itr_0____itr_1_2800____itr_2_2801____itr_3_2802____itr_4_2803 / 4UL) * 256UL) + ((fused_0fused_0fused_0fused_0__itr_0____itr_1_2800____itr_2_2801____itr_3_2802____itr_4_2803 % 4UL) * 64UL)) + _fuseiter_8976)]);
    float __cached_1;
    __cached_1 = __ins_1[0];
    vec_f32x16 __cached_2;
    __cached_2 = (__cached_0 * vec_f32x16(__cached_1));
    vec_f32x16::store(__cached_2, &__outs_0[((((fused_0fused_0fused_0fused_0__itr_0____itr_1_2800____itr_2_2801____itr_3_2802____itr_4_2803 / 4UL) * 256UL) + ((fused_0fused_0fused_0fused_0__itr_0____itr_1_2800____itr_2_2801____itr_3_2802____itr_4_2803 % 4UL) * 64UL)) + _fuseiter_8976)]);
  }
}

static void mul__5770_closure_109_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept{
  mul__5770_closure_109(i, (float*)(args[0UL].v_ptr), (float*)(args[1UL].v_ptr), (float*)(args[2UL].v_ptr));
}

static void reorder__4300_closure_110(uint64_t fused_0fused_0fused_0fused_0_fuseiter_8978___fuseiter_8979_2804___fuseiter_8980_2805___fuseiter_8981_2806___fuseiter_8982_2807, float* __restrict__ __ins_0, float* __restrict__ __outs_0) noexcept{
  for (uint64_t _fuseiter_8983 = 0UL; _fuseiter_8983 < 64UL; _fuseiter_8983 += 16UL) {
    vec_f32x16 __cached_0;
    __cached_0 = vec_f32x16::load(&__ins_0[(((fused_0fused_0fused_0fused_0_fuseiter_8978___fuseiter_8979_2804___fuseiter_8980_2805___fuseiter_8981_2806___fuseiter_8982_2807 / 4UL) * 256UL) + (_fuseiter_8983 + ((fused_0fused_0fused_0fused_0_fuseiter_8978___fuseiter_8979_2804___fuseiter_8980_2805___fuseiter_8981_2806___fuseiter_8982_2807 % 4UL) * 64UL)))]);
    vec_f32x16 __cached_1;
    __cached_1 = __cached_0;
    vec_f32x16::store(__cached_1, &__outs_0[(((fused_0fused_0fused_0fused_0_fuseiter_8978___fuseiter_8979_2804___fuseiter_8980_2805___fuseiter_8981_2806___fuseiter_8982_2807 / 4UL) * 256UL) + (((fused_0fused_0fused_0fused_0_fuseiter_8978___fuseiter_8979_2804___fuseiter_8980_2805___fuseiter_8981_2806___fuseiter_8982_2807 % 4UL) * 64UL) + _fuseiter_8983))]);
  }
}

static void reorder__4300_closure_110_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept{
  reorder__4300_closure_110(i, (float*)(args[0UL].v_ptr), (float*)(args[1UL].v_ptr));
}

static void mul__5830_closure_111(uint64_t fused_0fused_0fused_0fused_0__itr_0____itr_1_2808____itr_2_2809____itr_3_2810____itr_4_2811, float* __restrict__ __ins_0, float* __restrict__ __ins_1, float* __restrict__ __outs_0) noexcept{
  for (uint64_t _fuseiter_8989 = 0UL; _fuseiter_8989 < 64UL; _fuseiter_8989 += 16UL) {
    vec_f32x16 __cached_0;
    __cached_0 = vec_f32x16::load(&__ins_0[((((fused_0fused_0fused_0fused_0__itr_0____itr_1_2808____itr_2_2809____itr_3_2810____itr_4_2811 / 4UL) * 256UL) + ((fused_0fused_0fused_0fused_0__itr_0____itr_1_2808____itr_2_2809____itr_3_2810____itr_4_2811 % 4UL) * 64UL)) + _fuseiter_8989)]);
    float __cached_1;
    __cached_1 = __ins_1[0];
    vec_f32x16 __cached_2;
    __cached_2 = (__cached_0 * vec_f32x16(__cached_1));
    vec_f32x16::store(__cached_2, &__outs_0[((((fused_0fused_0fused_0fused_0__itr_0____itr_1_2808____itr_2_2809____itr_3_2810____itr_4_2811 / 4UL) * 256UL) + ((fused_0fused_0fused_0fused_0__itr_0____itr_1_2808____itr_2_2809____itr_3_2810____itr_4_2811 % 4UL) * 64UL)) + _fuseiter_8989)]);
  }
}

static void mul__5830_closure_111_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept{
  mul__5830_closure_111(i, (float*)(args[0UL].v_ptr), (float*)(args[1UL].v_ptr), (float*)(args[2UL].v_ptr));
}

static void reorder__4350_closure_112(uint64_t fused_0fused_0fused_0fused_0_fuseiter_8991___fuseiter_8992_2812___fuseiter_8993_2813___fuseiter_8994_2814___fuseiter_8995_2815, float* __restrict__ __ins_0, float* __restrict__ __outs_0) noexcept{
  for (uint64_t _fuseiter_8996 = 0UL; _fuseiter_8996 < 64UL; _fuseiter_8996 += 16UL) {
    vec_f32x16 __cached_0;
    __cached_0 = vec_f32x16::load(&__ins_0[(((fused_0fused_0fused_0fused_0_fuseiter_8991___fuseiter_8992_2812___fuseiter_8993_2813___fuseiter_8994_2814___fuseiter_8995_2815 / 4UL) * 256UL) + (_fuseiter_8996 + ((fused_0fused_0fused_0fused_0_fuseiter_8991___fuseiter_8992_2812___fuseiter_8993_2813___fuseiter_8994_2814___fuseiter_8995_2815 % 4UL) * 64UL)))]);
    vec_f32x16 __cached_1;
    __cached_1 = __cached_0;
    vec_f32x16::store(__cached_1, &__outs_0[(((fused_0fused_0fused_0fused_0_fuseiter_8991___fuseiter_8992_2812___fuseiter_8993_2813___fuseiter_8994_2814___fuseiter_8995_2815 / 4UL) * 256UL) + (((fused_0fused_0fused_0fused_0_fuseiter_8991___fuseiter_8992_2812___fuseiter_8993_2813___fuseiter_8994_2814___fuseiter_8995_2815 % 4UL) * 64UL) + _fuseiter_8996))]);
  }
}

static void reorder__4350_closure_112_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept{
  reorder__4350_closure_112(i, (float*)(args[0UL].v_ptr), (float*)(args[1UL].v_ptr));
}

static void mul__5890_closure_113(uint64_t fused_0fused_0fused_0fused_0__itr_0____itr_1_2816____itr_2_2817____itr_3_2818____itr_4_2819, float* __restrict__ __ins_0, float* __restrict__ __ins_1, float* __restrict__ __outs_0) noexcept{
  for (uint64_t _fuseiter_9002 = 0UL; _fuseiter_9002 < 64UL; _fuseiter_9002 += 16UL) {
    vec_f32x16 __cached_0;
    __cached_0 = vec_f32x16::load(&__ins_0[((((fused_0fused_0fused_0fused_0__itr_0____itr_1_2816____itr_2_2817____itr_3_2818____itr_4_2819 / 4UL) * 256UL) + ((fused_0fused_0fused_0fused_0__itr_0____itr_1_2816____itr_2_2817____itr_3_2818____itr_4_2819 % 4UL) * 64UL)) + _fuseiter_9002)]);
    float __cached_1;
    __cached_1 = __ins_1[0];
    vec_f32x16 __cached_2;
    __cached_2 = (__cached_0 * vec_f32x16(__cached_1));
    vec_f32x16::store(__cached_2, &__outs_0[((((fused_0fused_0fused_0fused_0__itr_0____itr_1_2816____itr_2_2817____itr_3_2818____itr_4_2819 / 4UL) * 256UL) + ((fused_0fused_0fused_0fused_0__itr_0____itr_1_2816____itr_2_2817____itr_3_2818____itr_4_2819 % 4UL) * 64UL)) + _fuseiter_9002)]);
  }
}

static void mul__5890_closure_113_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept{
  mul__5890_closure_113(i, (float*)(args[0UL].v_ptr), (float*)(args[1UL].v_ptr), (float*)(args[2UL].v_ptr));
}

static void reorder__4800_closure_114(uint64_t fused_0fused_0fused_0fused_0_fuseiter_9004___fuseiter_9005_2820___fuseiter_9006_2821___fuseiter_9007_2822___fuseiter_9008_2823, float* __restrict__ __ins_0, float* __restrict__ __outs_0) noexcept{
  for (uint64_t _fuseiter_9009 = 0UL; _fuseiter_9009 < 64UL; _fuseiter_9009 += 16UL) {
    vec_f32x16 __cached_0;
    __cached_0 = vec_f32x16::load(&__ins_0[(((fused_0fused_0fused_0fused_0_fuseiter_9004___fuseiter_9005_2820___fuseiter_9006_2821___fuseiter_9007_2822___fuseiter_9008_2823 / 4UL) * 256UL) + (_fuseiter_9009 + ((fused_0fused_0fused_0fused_0_fuseiter_9004___fuseiter_9005_2820___fuseiter_9006_2821___fuseiter_9007_2822___fuseiter_9008_2823 % 4UL) * 64UL)))]);
    vec_f32x16 __cached_1;
    __cached_1 = __cached_0;
    vec_f32x16::store(__cached_1, &__outs_0[(((fused_0fused_0fused_0fused_0_fuseiter_9004___fuseiter_9005_2820___fuseiter_9006_2821___fuseiter_9007_2822___fuseiter_9008_2823 / 4UL) * 256UL) + (((fused_0fused_0fused_0fused_0_fuseiter_9004___fuseiter_9005_2820___fuseiter_9006_2821___fuseiter_9007_2822___fuseiter_9008_2823 % 4UL) * 64UL) + _fuseiter_9009))]);
  }
}

static void reorder__4800_closure_114_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept{
  reorder__4800_closure_114(i, (float*)(args[0UL].v_ptr), (float*)(args[1UL].v_ptr));
}

static void mul__6190_closure_115(uint64_t fused_0fused_0fused_0fused_0__itr_0____itr_1_2824____itr_2_2825____itr_3_2826____itr_4_2827, float* __restrict__ __ins_0, float* __restrict__ __ins_1, float* __restrict__ __outs_0) noexcept{
  for (uint64_t _fuseiter_9015 = 0UL; _fuseiter_9015 < 64UL; _fuseiter_9015 += 16UL) {
    vec_f32x16 __cached_0;
    __cached_0 = vec_f32x16::load(&__ins_0[((((fused_0fused_0fused_0fused_0__itr_0____itr_1_2824____itr_2_2825____itr_3_2826____itr_4_2827 / 4UL) * 256UL) + ((fused_0fused_0fused_0fused_0__itr_0____itr_1_2824____itr_2_2825____itr_3_2826____itr_4_2827 % 4UL) * 64UL)) + _fuseiter_9015)]);
    float __cached_1;
    __cached_1 = __ins_1[0];
    vec_f32x16 __cached_2;
    __cached_2 = (__cached_0 * vec_f32x16(__cached_1));
    vec_f32x16::store(__cached_2, &__outs_0[((((fused_0fused_0fused_0fused_0__itr_0____itr_1_2824____itr_2_2825____itr_3_2826____itr_4_2827 / 4UL) * 256UL) + ((fused_0fused_0fused_0fused_0__itr_0____itr_1_2824____itr_2_2825____itr_3_2826____itr_4_2827 % 4UL) * 64UL)) + _fuseiter_9015)]);
  }
}

static void mul__6190_closure_115_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept{
  mul__6190_closure_115(i, (float*)(args[0UL].v_ptr), (float*)(args[1UL].v_ptr), (float*)(args[2UL].v_ptr));
}

static void reorder__4830_closure_116(uint64_t fused_0fused_0fused_0fused_0_fuseiter_9017___fuseiter_9018_2828___fuseiter_9019_2829___fuseiter_9020_2830___fuseiter_9021_2831, float* __restrict__ __ins_0, float* __restrict__ __outs_0) noexcept{
  for (uint64_t _fuseiter_9022 = 0UL; _fuseiter_9022 < 64UL; _fuseiter_9022 += 16UL) {
    vec_f32x16 __cached_0;
    __cached_0 = vec_f32x16::load(&__ins_0[(((fused_0fused_0fused_0fused_0_fuseiter_9017___fuseiter_9018_2828___fuseiter_9019_2829___fuseiter_9020_2830___fuseiter_9021_2831 / 4UL) * 256UL) + (_fuseiter_9022 + ((fused_0fused_0fused_0fused_0_fuseiter_9017___fuseiter_9018_2828___fuseiter_9019_2829___fuseiter_9020_2830___fuseiter_9021_2831 % 4UL) * 64UL)))]);
    vec_f32x16 __cached_1;
    __cached_1 = __cached_0;
    vec_f32x16::store(__cached_1, &__outs_0[(((fused_0fused_0fused_0fused_0_fuseiter_9017___fuseiter_9018_2828___fuseiter_9019_2829___fuseiter_9020_2830___fuseiter_9021_2831 / 4UL) * 256UL) + (((fused_0fused_0fused_0fused_0_fuseiter_9017___fuseiter_9018_2828___fuseiter_9019_2829___fuseiter_9020_2830___fuseiter_9021_2831 % 4UL) * 64UL) + _fuseiter_9022))]);
  }
}

static void reorder__4830_closure_116_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept{
  reorder__4830_closure_116(i, (float*)(args[0UL].v_ptr), (float*)(args[1UL].v_ptr));
}

static void mul__6210_closure_117(uint64_t fused_0fused_0fused_0fused_0__itr_0____itr_1_2832____itr_2_2833____itr_3_2834____itr_4_2835, float* __restrict__ __ins_0, float* __restrict__ __ins_1, float* __restrict__ __outs_0) noexcept{
  for (uint64_t _fuseiter_9028 = 0UL; _fuseiter_9028 < 64UL; _fuseiter_9028 += 16UL) {
    vec_f32x16 __cached_0;
    __cached_0 = vec_f32x16::load(&__ins_0[((((fused_0fused_0fused_0fused_0__itr_0____itr_1_2832____itr_2_2833____itr_3_2834____itr_4_2835 / 4UL) * 256UL) + ((fused_0fused_0fused_0fused_0__itr_0____itr_1_2832____itr_2_2833____itr_3_2834____itr_4_2835 % 4UL) * 64UL)) + _fuseiter_9028)]);
    float __cached_1;
    __cached_1 = __ins_1[0];
    vec_f32x16 __cached_2;
    __cached_2 = (__cached_0 * vec_f32x16(__cached_1));
    vec_f32x16::store(__cached_2, &__outs_0[((((fused_0fused_0fused_0fused_0__itr_0____itr_1_2832____itr_2_2833____itr_3_2834____itr_4_2835 / 4UL) * 256UL) + ((fused_0fused_0fused_0fused_0__itr_0____itr_1_2832____itr_2_2833____itr_3_2834____itr_4_2835 % 4UL) * 64UL)) + _fuseiter_9028)]);
  }
}

static void mul__6210_closure_117_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept{
  mul__6210_closure_117(i, (float*)(args[0UL].v_ptr), (float*)(args[1UL].v_ptr), (float*)(args[2UL].v_ptr));
}

static void reorder__4890_closure_118(uint64_t fused_0fused_0fused_0fused_0_fuseiter_9030___fuseiter_9031_2836___fuseiter_9032_2837___fuseiter_9033_2838___fuseiter_9034_2839, float* __restrict__ __ins_0, float* __restrict__ __outs_0) noexcept{
  for (uint64_t _fuseiter_9035 = 0UL; _fuseiter_9035 < 64UL; _fuseiter_9035 += 16UL) {
    vec_f32x16 __cached_0;
    __cached_0 = vec_f32x16::load(&__ins_0[(((fused_0fused_0fused_0fused_0_fuseiter_9030___fuseiter_9031_2836___fuseiter_9032_2837___fuseiter_9033_2838___fuseiter_9034_2839 / 4UL) * 256UL) + (_fuseiter_9035 + ((fused_0fused_0fused_0fused_0_fuseiter_9030___fuseiter_9031_2836___fuseiter_9032_2837___fuseiter_9033_2838___fuseiter_9034_2839 % 4UL) * 64UL)))]);
    vec_f32x16 __cached_1;
    __cached_1 = __cached_0;
    vec_f32x16::store(__cached_1, &__outs_0[(((fused_0fused_0fused_0fused_0_fuseiter_9030___fuseiter_9031_2836___fuseiter_9032_2837___fuseiter_9033_2838___fuseiter_9034_2839 / 4UL) * 256UL) + (((fused_0fused_0fused_0fused_0_fuseiter_9030___fuseiter_9031_2836___fuseiter_9032_2837___fuseiter_9033_2838___fuseiter_9034_2839 % 4UL) * 64UL) + _fuseiter_9035))]);
  }
}

static void reorder__4890_closure_118_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept{
  reorder__4890_closure_118(i, (float*)(args[0UL].v_ptr), (float*)(args[1UL].v_ptr));
}

static void mul__6250_closure_119(uint64_t fused_0fused_0fused_0fused_0__itr_0____itr_1_2840____itr_2_2841____itr_3_2842____itr_4_2843, float* __restrict__ __ins_0, float* __restrict__ __ins_1, float* __restrict__ __outs_0) noexcept{
  for (uint64_t _fuseiter_9041 = 0UL; _fuseiter_9041 < 64UL; _fuseiter_9041 += 16UL) {
    vec_f32x16 __cached_0;
    __cached_0 = vec_f32x16::load(&__ins_0[((((fused_0fused_0fused_0fused_0__itr_0____itr_1_2840____itr_2_2841____itr_3_2842____itr_4_2843 / 4UL) * 256UL) + ((fused_0fused_0fused_0fused_0__itr_0____itr_1_2840____itr_2_2841____itr_3_2842____itr_4_2843 % 4UL) * 64UL)) + _fuseiter_9041)]);
    float __cached_1;
    __cached_1 = __ins_1[0];
    vec_f32x16 __cached_2;
    __cached_2 = (__cached_0 * vec_f32x16(__cached_1));
    vec_f32x16::store(__cached_2, &__outs_0[((((fused_0fused_0fused_0fused_0__itr_0____itr_1_2840____itr_2_2841____itr_3_2842____itr_4_2843 / 4UL) * 256UL) + ((fused_0fused_0fused_0fused_0__itr_0____itr_1_2840____itr_2_2841____itr_3_2842____itr_4_2843 % 4UL) * 64UL)) + _fuseiter_9041)]);
  }
}

static void mul__6250_closure_119_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept{
  mul__6250_closure_119(i, (float*)(args[0UL].v_ptr), (float*)(args[1UL].v_ptr), (float*)(args[2UL].v_ptr));
}

static void reorder__4920_closure_120(uint64_t fused_0fused_0fused_0fused_0_fuseiter_9043___fuseiter_9044_2844___fuseiter_9045_2845___fuseiter_9046_2846___fuseiter_9047_2847, float* __restrict__ __ins_0, float* __restrict__ __outs_0) noexcept{
  for (uint64_t _fuseiter_9048 = 0UL; _fuseiter_9048 < 64UL; _fuseiter_9048 += 16UL) {
    vec_f32x16 __cached_0;
    __cached_0 = vec_f32x16::load(&__ins_0[(((fused_0fused_0fused_0fused_0_fuseiter_9043___fuseiter_9044_2844___fuseiter_9045_2845___fuseiter_9046_2846___fuseiter_9047_2847 / 4UL) * 256UL) + (_fuseiter_9048 + ((fused_0fused_0fused_0fused_0_fuseiter_9043___fuseiter_9044_2844___fuseiter_9045_2845___fuseiter_9046_2846___fuseiter_9047_2847 % 4UL) * 64UL)))]);
    vec_f32x16 __cached_1;
    __cached_1 = __cached_0;
    vec_f32x16::store(__cached_1, &__outs_0[(((fused_0fused_0fused_0fused_0_fuseiter_9043___fuseiter_9044_2844___fuseiter_9045_2845___fuseiter_9046_2846___fuseiter_9047_2847 / 4UL) * 256UL) + (((fused_0fused_0fused_0fused_0_fuseiter_9043___fuseiter_9044_2844___fuseiter_9045_2845___fuseiter_9046_2846___fuseiter_9047_2847 % 4UL) * 64UL) + _fuseiter_9048))]);
  }
}

static void reorder__4920_closure_120_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept{
  reorder__4920_closure_120(i, (float*)(args[0UL].v_ptr), (float*)(args[1UL].v_ptr));
}

static void mul__6270_closure_121(uint64_t fused_0fused_0fused_0fused_0__itr_0____itr_1_2848____itr_2_2849____itr_3_2850____itr_4_2851, float* __restrict__ __ins_0, float* __restrict__ __ins_1, float* __restrict__ __outs_0) noexcept{
  for (uint64_t _fuseiter_9054 = 0UL; _fuseiter_9054 < 64UL; _fuseiter_9054 += 16UL) {
    vec_f32x16 __cached_0;
    __cached_0 = vec_f32x16::load(&__ins_0[((((fused_0fused_0fused_0fused_0__itr_0____itr_1_2848____itr_2_2849____itr_3_2850____itr_4_2851 / 4UL) * 256UL) + ((fused_0fused_0fused_0fused_0__itr_0____itr_1_2848____itr_2_2849____itr_3_2850____itr_4_2851 % 4UL) * 64UL)) + _fuseiter_9054)]);
    float __cached_1;
    __cached_1 = __ins_1[0];
    vec_f32x16 __cached_2;
    __cached_2 = (__cached_0 * vec_f32x16(__cached_1));
    vec_f32x16::store(__cached_2, &__outs_0[((((fused_0fused_0fused_0fused_0__itr_0____itr_1_2848____itr_2_2849____itr_3_2850____itr_4_2851 / 4UL) * 256UL) + ((fused_0fused_0fused_0fused_0__itr_0____itr_1_2848____itr_2_2849____itr_3_2850____itr_4_2851 % 4UL) * 64UL)) + _fuseiter_9054)]);
  }
}

static void mul__6270_closure_121_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept{
  mul__6270_closure_121(i, (float*)(args[0UL].v_ptr), (float*)(args[1UL].v_ptr), (float*)(args[2UL].v_ptr));
}

static void reorder__4980_closure_122(uint64_t fused_0fused_0fused_0fused_0_fuseiter_9056___fuseiter_9057_2852___fuseiter_9058_2853___fuseiter_9059_2854___fuseiter_9060_2855, float* __restrict__ __ins_0, float* __restrict__ __outs_0) noexcept{
  for (uint64_t _fuseiter_9061 = 0UL; _fuseiter_9061 < 64UL; _fuseiter_9061 += 16UL) {
    vec_f32x16 __cached_0;
    __cached_0 = vec_f32x16::load(&__ins_0[(((fused_0fused_0fused_0fused_0_fuseiter_9056___fuseiter_9057_2852___fuseiter_9058_2853___fuseiter_9059_2854___fuseiter_9060_2855 / 4UL) * 256UL) + (_fuseiter_9061 + ((fused_0fused_0fused_0fused_0_fuseiter_9056___fuseiter_9057_2852___fuseiter_9058_2853___fuseiter_9059_2854___fuseiter_9060_2855 % 4UL) * 64UL)))]);
    vec_f32x16 __cached_1;
    __cached_1 = __cached_0;
    vec_f32x16::store(__cached_1, &__outs_0[(((fused_0fused_0fused_0fused_0_fuseiter_9056___fuseiter_9057_2852___fuseiter_9058_2853___fuseiter_9059_2854___fuseiter_9060_2855 / 4UL) * 256UL) + (((fused_0fused_0fused_0fused_0_fuseiter_9056___fuseiter_9057_2852___fuseiter_9058_2853___fuseiter_9059_2854___fuseiter_9060_2855 % 4UL) * 64UL) + _fuseiter_9061))]);
  }
}

static void reorder__4980_closure_122_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept{
  reorder__4980_closure_122(i, (float*)(args[0UL].v_ptr), (float*)(args[1UL].v_ptr));
}

static void mul__6310_closure_123(uint64_t fused_0fused_0fused_0fused_0__itr_0____itr_1_2856____itr_2_2857____itr_3_2858____itr_4_2859, float* __restrict__ __ins_0, float* __restrict__ __ins_1, float* __restrict__ __outs_0) noexcept{
  for (uint64_t _fuseiter_9067 = 0UL; _fuseiter_9067 < 64UL; _fuseiter_9067 += 16UL) {
    vec_f32x16 __cached_0;
    __cached_0 = vec_f32x16::load(&__ins_0[((((fused_0fused_0fused_0fused_0__itr_0____itr_1_2856____itr_2_2857____itr_3_2858____itr_4_2859 / 4UL) * 256UL) + ((fused_0fused_0fused_0fused_0__itr_0____itr_1_2856____itr_2_2857____itr_3_2858____itr_4_2859 % 4UL) * 64UL)) + _fuseiter_9067)]);
    float __cached_1;
    __cached_1 = __ins_1[0];
    vec_f32x16 __cached_2;
    __cached_2 = (__cached_0 * vec_f32x16(__cached_1));
    vec_f32x16::store(__cached_2, &__outs_0[((((fused_0fused_0fused_0fused_0__itr_0____itr_1_2856____itr_2_2857____itr_3_2858____itr_4_2859 / 4UL) * 256UL) + ((fused_0fused_0fused_0fused_0__itr_0____itr_1_2856____itr_2_2857____itr_3_2858____itr_4_2859 % 4UL) * 64UL)) + _fuseiter_9067)]);
  }
}

static void mul__6310_closure_123_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept{
  mul__6310_closure_123(i, (float*)(args[0UL].v_ptr), (float*)(args[1UL].v_ptr), (float*)(args[2UL].v_ptr));
}

static void reorder__5010_closure_124(uint64_t fused_0fused_0fused_0fused_0_fuseiter_9069___fuseiter_9070_2860___fuseiter_9071_2861___fuseiter_9072_2862___fuseiter_9073_2863, float* __restrict__ __ins_0, float* __restrict__ __outs_0) noexcept{
  for (uint64_t _fuseiter_9074 = 0UL; _fuseiter_9074 < 64UL; _fuseiter_9074 += 16UL) {
    vec_f32x16 __cached_0;
    __cached_0 = vec_f32x16::load(&__ins_0[(((fused_0fused_0fused_0fused_0_fuseiter_9069___fuseiter_9070_2860___fuseiter_9071_2861___fuseiter_9072_2862___fuseiter_9073_2863 / 4UL) * 256UL) + (_fuseiter_9074 + ((fused_0fused_0fused_0fused_0_fuseiter_9069___fuseiter_9070_2860___fuseiter_9071_2861___fuseiter_9072_2862___fuseiter_9073_2863 % 4UL) * 64UL)))]);
    vec_f32x16 __cached_1;
    __cached_1 = __cached_0;
    vec_f32x16::store(__cached_1, &__outs_0[(((fused_0fused_0fused_0fused_0_fuseiter_9069___fuseiter_9070_2860___fuseiter_9071_2861___fuseiter_9072_2862___fuseiter_9073_2863 / 4UL) * 256UL) + (((fused_0fused_0fused_0fused_0_fuseiter_9069___fuseiter_9070_2860___fuseiter_9071_2861___fuseiter_9072_2862___fuseiter_9073_2863 % 4UL) * 64UL) + _fuseiter_9074))]);
  }
}

static void reorder__5010_closure_124_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept{
  reorder__5010_closure_124(i, (float*)(args[0UL].v_ptr), (float*)(args[1UL].v_ptr));
}

static void mul__6330_closure_125(uint64_t fused_0fused_0fused_0fused_0__itr_0____itr_1_2864____itr_2_2865____itr_3_2866____itr_4_2867, float* __restrict__ __ins_0, float* __restrict__ __ins_1, float* __restrict__ __outs_0) noexcept{
  for (uint64_t _fuseiter_9080 = 0UL; _fuseiter_9080 < 64UL; _fuseiter_9080 += 16UL) {
    vec_f32x16 __cached_0;
    __cached_0 = vec_f32x16::load(&__ins_0[((((fused_0fused_0fused_0fused_0__itr_0____itr_1_2864____itr_2_2865____itr_3_2866____itr_4_2867 / 4UL) * 256UL) + ((fused_0fused_0fused_0fused_0__itr_0____itr_1_2864____itr_2_2865____itr_3_2866____itr_4_2867 % 4UL) * 64UL)) + _fuseiter_9080)]);
    float __cached_1;
    __cached_1 = __ins_1[0];
    vec_f32x16 __cached_2;
    __cached_2 = (__cached_0 * vec_f32x16(__cached_1));
    vec_f32x16::store(__cached_2, &__outs_0[((((fused_0fused_0fused_0fused_0__itr_0____itr_1_2864____itr_2_2865____itr_3_2866____itr_4_2867 / 4UL) * 256UL) + ((fused_0fused_0fused_0fused_0__itr_0____itr_1_2864____itr_2_2865____itr_3_2866____itr_4_2867 % 4UL) * 64UL)) + _fuseiter_9080)]);
  }
}

static void mul__6330_closure_125_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept{
  mul__6330_closure_125(i, (float*)(args[0UL].v_ptr), (float*)(args[1UL].v_ptr), (float*)(args[2UL].v_ptr));
}

static void reorder__5070_closure_126(uint64_t fused_0fused_0fused_0fused_0_fuseiter_9082___fuseiter_9083_2868___fuseiter_9084_2869___fuseiter_9085_2870___fuseiter_9086_2871, float* __restrict__ __ins_0, float* __restrict__ __outs_0) noexcept{
  for (uint64_t _fuseiter_9087 = 0UL; _fuseiter_9087 < 64UL; _fuseiter_9087 += 16UL) {
    vec_f32x16 __cached_0;
    __cached_0 = vec_f32x16::load(&__ins_0[(((fused_0fused_0fused_0fused_0_fuseiter_9082___fuseiter_9083_2868___fuseiter_9084_2869___fuseiter_9085_2870___fuseiter_9086_2871 / 4UL) * 256UL) + (_fuseiter_9087 + ((fused_0fused_0fused_0fused_0_fuseiter_9082___fuseiter_9083_2868___fuseiter_9084_2869___fuseiter_9085_2870___fuseiter_9086_2871 % 4UL) * 64UL)))]);
    vec_f32x16 __cached_1;
    __cached_1 = __cached_0;
    vec_f32x16::store(__cached_1, &__outs_0[(((fused_0fused_0fused_0fused_0_fuseiter_9082___fuseiter_9083_2868___fuseiter_9084_2869___fuseiter_9085_2870___fuseiter_9086_2871 / 4UL) * 256UL) + (((fused_0fused_0fused_0fused_0_fuseiter_9082___fuseiter_9083_2868___fuseiter_9084_2869___fuseiter_9085_2870___fuseiter_9086_2871 % 4UL) * 64UL) + _fuseiter_9087))]);
  }
}

static void reorder__5070_closure_126_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept{
  reorder__5070_closure_126(i, (float*)(args[0UL].v_ptr), (float*)(args[1UL].v_ptr));
}

static void mul__6370_closure_127(uint64_t fused_0fused_0fused_0fused_0__itr_0____itr_1_2872____itr_2_2873____itr_3_2874____itr_4_2875, float* __restrict__ __ins_0, float* __restrict__ __ins_1, float* __restrict__ __outs_0) noexcept{
  for (uint64_t _fuseiter_9093 = 0UL; _fuseiter_9093 < 64UL; _fuseiter_9093 += 16UL) {
    vec_f32x16 __cached_0;
    __cached_0 = vec_f32x16::load(&__ins_0[((((fused_0fused_0fused_0fused_0__itr_0____itr_1_2872____itr_2_2873____itr_3_2874____itr_4_2875 / 4UL) * 256UL) + ((fused_0fused_0fused_0fused_0__itr_0____itr_1_2872____itr_2_2873____itr_3_2874____itr_4_2875 % 4UL) * 64UL)) + _fuseiter_9093)]);
    float __cached_1;
    __cached_1 = __ins_1[0];
    vec_f32x16 __cached_2;
    __cached_2 = (__cached_0 * vec_f32x16(__cached_1));
    vec_f32x16::store(__cached_2, &__outs_0[((((fused_0fused_0fused_0fused_0__itr_0____itr_1_2872____itr_2_2873____itr_3_2874____itr_4_2875 / 4UL) * 256UL) + ((fused_0fused_0fused_0fused_0__itr_0____itr_1_2872____itr_2_2873____itr_3_2874____itr_4_2875 % 4UL) * 64UL)) + _fuseiter_9093)]);
  }
}

static void mul__6370_closure_127_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept{
  mul__6370_closure_127(i, (float*)(args[0UL].v_ptr), (float*)(args[1UL].v_ptr), (float*)(args[2UL].v_ptr));
}

static void reorder__5100_closure_128(uint64_t fused_0fused_0fused_0fused_0_fuseiter_9095___fuseiter_9096_2876___fuseiter_9097_2877___fuseiter_9098_2878___fuseiter_9099_2879, float* __restrict__ __ins_0, float* __restrict__ __outs_0) noexcept{
  for (uint64_t _fuseiter_9100 = 0UL; _fuseiter_9100 < 64UL; _fuseiter_9100 += 16UL) {
    vec_f32x16 __cached_0;
    __cached_0 = vec_f32x16::load(&__ins_0[(((fused_0fused_0fused_0fused_0_fuseiter_9095___fuseiter_9096_2876___fuseiter_9097_2877___fuseiter_9098_2878___fuseiter_9099_2879 / 4UL) * 256UL) + (_fuseiter_9100 + ((fused_0fused_0fused_0fused_0_fuseiter_9095___fuseiter_9096_2876___fuseiter_9097_2877___fuseiter_9098_2878___fuseiter_9099_2879 % 4UL) * 64UL)))]);
    vec_f32x16 __cached_1;
    __cached_1 = __cached_0;
    vec_f32x16::store(__cached_1, &__outs_0[(((fused_0fused_0fused_0fused_0_fuseiter_9095___fuseiter_9096_2876___fuseiter_9097_2877___fuseiter_9098_2878___fuseiter_9099_2879 / 4UL) * 256UL) + (((fused_0fused_0fused_0fused_0_fuseiter_9095___fuseiter_9096_2876___fuseiter_9097_2877___fuseiter_9098_2878___fuseiter_9099_2879 % 4UL) * 64UL) + _fuseiter_9100))]);
  }
}

static void reorder__5100_closure_128_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept{
  reorder__5100_closure_128(i, (float*)(args[0UL].v_ptr), (float*)(args[1UL].v_ptr));
}

static void mul__6390_closure_129(uint64_t fused_0fused_0fused_0fused_0__itr_0____itr_1_2880____itr_2_2881____itr_3_2882____itr_4_2883, float* __restrict__ __ins_0, float* __restrict__ __ins_1, float* __restrict__ __outs_0) noexcept{
  for (uint64_t _fuseiter_9106 = 0UL; _fuseiter_9106 < 64UL; _fuseiter_9106 += 16UL) {
    vec_f32x16 __cached_0;
    __cached_0 = vec_f32x16::load(&__ins_0[((((fused_0fused_0fused_0fused_0__itr_0____itr_1_2880____itr_2_2881____itr_3_2882____itr_4_2883 / 4UL) * 256UL) + ((fused_0fused_0fused_0fused_0__itr_0____itr_1_2880____itr_2_2881____itr_3_2882____itr_4_2883 % 4UL) * 64UL)) + _fuseiter_9106)]);
    float __cached_1;
    __cached_1 = __ins_1[0];
    vec_f32x16 __cached_2;
    __cached_2 = (__cached_0 * vec_f32x16(__cached_1));
    vec_f32x16::store(__cached_2, &__outs_0[((((fused_0fused_0fused_0fused_0__itr_0____itr_1_2880____itr_2_2881____itr_3_2882____itr_4_2883 / 4UL) * 256UL) + ((fused_0fused_0fused_0fused_0__itr_0____itr_1_2880____itr_2_2881____itr_3_2882____itr_4_2883 % 4UL) * 64UL)) + _fuseiter_9106)]);
  }
}

static void mul__6390_closure_129_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept{
  mul__6390_closure_129(i, (float*)(args[0UL].v_ptr), (float*)(args[1UL].v_ptr), (float*)(args[2UL].v_ptr));
}

static void reorder__5160_closure_130(uint64_t fused_0fused_0fused_0fused_0_fuseiter_9108___fuseiter_9109_2884___fuseiter_9110_2885___fuseiter_9111_2886___fuseiter_9112_2887, float* __restrict__ __ins_0, float* __restrict__ __outs_0) noexcept{
  for (uint64_t _fuseiter_9113 = 0UL; _fuseiter_9113 < 64UL; _fuseiter_9113 += 16UL) {
    vec_f32x16 __cached_0;
    __cached_0 = vec_f32x16::load(&__ins_0[(((fused_0fused_0fused_0fused_0_fuseiter_9108___fuseiter_9109_2884___fuseiter_9110_2885___fuseiter_9111_2886___fuseiter_9112_2887 / 4UL) * 256UL) + (_fuseiter_9113 + ((fused_0fused_0fused_0fused_0_fuseiter_9108___fuseiter_9109_2884___fuseiter_9110_2885___fuseiter_9111_2886___fuseiter_9112_2887 % 4UL) * 64UL)))]);
    vec_f32x16 __cached_1;
    __cached_1 = __cached_0;
    vec_f32x16::store(__cached_1, &__outs_0[(((fused_0fused_0fused_0fused_0_fuseiter_9108___fuseiter_9109_2884___fuseiter_9110_2885___fuseiter_9111_2886___fuseiter_9112_2887 / 4UL) * 256UL) + (((fused_0fused_0fused_0fused_0_fuseiter_9108___fuseiter_9109_2884___fuseiter_9110_2885___fuseiter_9111_2886___fuseiter_9112_2887 % 4UL) * 64UL) + _fuseiter_9113))]);
  }
}

static void reorder__5160_closure_130_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept{
  reorder__5160_closure_130(i, (float*)(args[0UL].v_ptr), (float*)(args[1UL].v_ptr));
}

static void mul__6430_closure_131(uint64_t fused_0fused_0fused_0fused_0__itr_0____itr_1_2888____itr_2_2889____itr_3_2890____itr_4_2891, float* __restrict__ __ins_0, float* __restrict__ __ins_1, float* __restrict__ __outs_0) noexcept{
  for (uint64_t _fuseiter_9119 = 0UL; _fuseiter_9119 < 64UL; _fuseiter_9119 += 16UL) {
    vec_f32x16 __cached_0;
    __cached_0 = vec_f32x16::load(&__ins_0[((((fused_0fused_0fused_0fused_0__itr_0____itr_1_2888____itr_2_2889____itr_3_2890____itr_4_2891 / 4UL) * 256UL) + ((fused_0fused_0fused_0fused_0__itr_0____itr_1_2888____itr_2_2889____itr_3_2890____itr_4_2891 % 4UL) * 64UL)) + _fuseiter_9119)]);
    float __cached_1;
    __cached_1 = __ins_1[0];
    vec_f32x16 __cached_2;
    __cached_2 = (__cached_0 * vec_f32x16(__cached_1));
    vec_f32x16::store(__cached_2, &__outs_0[((((fused_0fused_0fused_0fused_0__itr_0____itr_1_2888____itr_2_2889____itr_3_2890____itr_4_2891 / 4UL) * 256UL) + ((fused_0fused_0fused_0fused_0__itr_0____itr_1_2888____itr_2_2889____itr_3_2890____itr_4_2891 % 4UL) * 64UL)) + _fuseiter_9119)]);
  }
}

static void mul__6430_closure_131_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept{
  mul__6430_closure_131(i, (float*)(args[0UL].v_ptr), (float*)(args[1UL].v_ptr), (float*)(args[2UL].v_ptr));
}

static void reorder__5190_closure_132(uint64_t fused_0fused_0fused_0fused_0_fuseiter_9121___fuseiter_9122_2892___fuseiter_9123_2893___fuseiter_9124_2894___fuseiter_9125_2895, float* __restrict__ __ins_0, float* __restrict__ __outs_0) noexcept{
  for (uint64_t _fuseiter_9126 = 0UL; _fuseiter_9126 < 64UL; _fuseiter_9126 += 16UL) {
    vec_f32x16 __cached_0;
    __cached_0 = vec_f32x16::load(&__ins_0[(((fused_0fused_0fused_0fused_0_fuseiter_9121___fuseiter_9122_2892___fuseiter_9123_2893___fuseiter_9124_2894___fuseiter_9125_2895 / 4UL) * 256UL) + (_fuseiter_9126 + ((fused_0fused_0fused_0fused_0_fuseiter_9121___fuseiter_9122_2892___fuseiter_9123_2893___fuseiter_9124_2894___fuseiter_9125_2895 % 4UL) * 64UL)))]);
    vec_f32x16 __cached_1;
    __cached_1 = __cached_0;
    vec_f32x16::store(__cached_1, &__outs_0[(((fused_0fused_0fused_0fused_0_fuseiter_9121___fuseiter_9122_2892___fuseiter_9123_2893___fuseiter_9124_2894___fuseiter_9125_2895 / 4UL) * 256UL) + (((fused_0fused_0fused_0fused_0_fuseiter_9121___fuseiter_9122_2892___fuseiter_9123_2893___fuseiter_9124_2894___fuseiter_9125_2895 % 4UL) * 64UL) + _fuseiter_9126))]);
  }
}

static void reorder__5190_closure_132_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept{
  reorder__5190_closure_132(i, (float*)(args[0UL].v_ptr), (float*)(args[1UL].v_ptr));
}

static void mul__6450_closure_133(uint64_t fused_0fused_0fused_0fused_0__itr_0____itr_1_2896____itr_2_2897____itr_3_2898____itr_4_2899, float* __restrict__ __ins_0, float* __restrict__ __ins_1, float* __restrict__ __outs_0) noexcept{
  for (uint64_t _fuseiter_9132 = 0UL; _fuseiter_9132 < 64UL; _fuseiter_9132 += 16UL) {
    vec_f32x16 __cached_0;
    __cached_0 = vec_f32x16::load(&__ins_0[((((fused_0fused_0fused_0fused_0__itr_0____itr_1_2896____itr_2_2897____itr_3_2898____itr_4_2899 / 4UL) * 256UL) + ((fused_0fused_0fused_0fused_0__itr_0____itr_1_2896____itr_2_2897____itr_3_2898____itr_4_2899 % 4UL) * 64UL)) + _fuseiter_9132)]);
    float __cached_1;
    __cached_1 = __ins_1[0];
    vec_f32x16 __cached_2;
    __cached_2 = (__cached_0 * vec_f32x16(__cached_1));
    vec_f32x16::store(__cached_2, &__outs_0[((((fused_0fused_0fused_0fused_0__itr_0____itr_1_2896____itr_2_2897____itr_3_2898____itr_4_2899 / 4UL) * 256UL) + ((fused_0fused_0fused_0fused_0__itr_0____itr_1_2896____itr_2_2897____itr_3_2898____itr_4_2899 % 4UL) * 64UL)) + _fuseiter_9132)]);
  }
}

static void mul__6450_closure_133_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept{
  mul__6450_closure_133(i, (float*)(args[0UL].v_ptr), (float*)(args[1UL].v_ptr), (float*)(args[2UL].v_ptr));
}

static void reorder__5250_closure_134(uint64_t fused_0fused_0fused_0fused_0_fuseiter_9134___fuseiter_9135_2900___fuseiter_9136_2901___fuseiter_9137_2902___fuseiter_9138_2903, float* __restrict__ __ins_0, float* __restrict__ __outs_0) noexcept{
  for (uint64_t _fuseiter_9139 = 0UL; _fuseiter_9139 < 64UL; _fuseiter_9139 += 16UL) {
    vec_f32x16 __cached_0;
    __cached_0 = vec_f32x16::load(&__ins_0[(((fused_0fused_0fused_0fused_0_fuseiter_9134___fuseiter_9135_2900___fuseiter_9136_2901___fuseiter_9137_2902___fuseiter_9138_2903 / 4UL) * 256UL) + (_fuseiter_9139 + ((fused_0fused_0fused_0fused_0_fuseiter_9134___fuseiter_9135_2900___fuseiter_9136_2901___fuseiter_9137_2902___fuseiter_9138_2903 % 4UL) * 64UL)))]);
    vec_f32x16 __cached_1;
    __cached_1 = __cached_0;
    vec_f32x16::store(__cached_1, &__outs_0[(((fused_0fused_0fused_0fused_0_fuseiter_9134___fuseiter_9135_2900___fuseiter_9136_2901___fuseiter_9137_2902___fuseiter_9138_2903 / 4UL) * 256UL) + (((fused_0fused_0fused_0fused_0_fuseiter_9134___fuseiter_9135_2900___fuseiter_9136_2901___fuseiter_9137_2902___fuseiter_9138_2903 % 4UL) * 64UL) + _fuseiter_9139))]);
  }
}

static void reorder__5250_closure_134_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept{
  reorder__5250_closure_134(i, (float*)(args[0UL].v_ptr), (float*)(args[1UL].v_ptr));
}

static void mul__6490_closure_135(uint64_t fused_0fused_0fused_0fused_0__itr_0____itr_1_2904____itr_2_2905____itr_3_2906____itr_4_2907, float* __restrict__ __ins_0, float* __restrict__ __ins_1, float* __restrict__ __outs_0) noexcept{
  for (uint64_t _fuseiter_9145 = 0UL; _fuseiter_9145 < 64UL; _fuseiter_9145 += 16UL) {
    vec_f32x16 __cached_0;
    __cached_0 = vec_f32x16::load(&__ins_0[((((fused_0fused_0fused_0fused_0__itr_0____itr_1_2904____itr_2_2905____itr_3_2906____itr_4_2907 / 4UL) * 256UL) + ((fused_0fused_0fused_0fused_0__itr_0____itr_1_2904____itr_2_2905____itr_3_2906____itr_4_2907 % 4UL) * 64UL)) + _fuseiter_9145)]);
    float __cached_1;
    __cached_1 = __ins_1[0];
    vec_f32x16 __cached_2;
    __cached_2 = (__cached_0 * vec_f32x16(__cached_1));
    vec_f32x16::store(__cached_2, &__outs_0[((((fused_0fused_0fused_0fused_0__itr_0____itr_1_2904____itr_2_2905____itr_3_2906____itr_4_2907 / 4UL) * 256UL) + ((fused_0fused_0fused_0fused_0__itr_0____itr_1_2904____itr_2_2905____itr_3_2906____itr_4_2907 % 4UL) * 64UL)) + _fuseiter_9145)]);
  }
}

static void mul__6490_closure_135_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept{
  mul__6490_closure_135(i, (float*)(args[0UL].v_ptr), (float*)(args[1UL].v_ptr), (float*)(args[2UL].v_ptr));
}

static void reorder__5280_closure_136(uint64_t fused_0fused_0fused_0fused_0_fuseiter_9147___fuseiter_9148_2908___fuseiter_9149_2909___fuseiter_9150_2910___fuseiter_9151_2911, float* __restrict__ __ins_0, float* __restrict__ __outs_0) noexcept{
  for (uint64_t _fuseiter_9152 = 0UL; _fuseiter_9152 < 64UL; _fuseiter_9152 += 16UL) {
    vec_f32x16 __cached_0;
    __cached_0 = vec_f32x16::load(&__ins_0[(((fused_0fused_0fused_0fused_0_fuseiter_9147___fuseiter_9148_2908___fuseiter_9149_2909___fuseiter_9150_2910___fuseiter_9151_2911 / 4UL) * 256UL) + (_fuseiter_9152 + ((fused_0fused_0fused_0fused_0_fuseiter_9147___fuseiter_9148_2908___fuseiter_9149_2909___fuseiter_9150_2910___fuseiter_9151_2911 % 4UL) * 64UL)))]);
    vec_f32x16 __cached_1;
    __cached_1 = __cached_0;
    vec_f32x16::store(__cached_1, &__outs_0[(((fused_0fused_0fused_0fused_0_fuseiter_9147___fuseiter_9148_2908___fuseiter_9149_2909___fuseiter_9150_2910___fuseiter_9151_2911 / 4UL) * 256UL) + (((fused_0fused_0fused_0fused_0_fuseiter_9147___fuseiter_9148_2908___fuseiter_9149_2909___fuseiter_9150_2910___fuseiter_9151_2911 % 4UL) * 64UL) + _fuseiter_9152))]);
  }
}

static void reorder__5280_closure_136_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept{
  reorder__5280_closure_136(i, (float*)(args[0UL].v_ptr), (float*)(args[1UL].v_ptr));
}

static void mul__6510_closure_137(uint64_t fused_0fused_0fused_0fused_0__itr_0____itr_1_2912____itr_2_2913____itr_3_2914____itr_4_2915, float* __restrict__ __ins_0, float* __restrict__ __ins_1, float* __restrict__ __outs_0) noexcept{
  for (uint64_t _fuseiter_9158 = 0UL; _fuseiter_9158 < 64UL; _fuseiter_9158 += 16UL) {
    vec_f32x16 __cached_0;
    __cached_0 = vec_f32x16::load(&__ins_0[((((fused_0fused_0fused_0fused_0__itr_0____itr_1_2912____itr_2_2913____itr_3_2914____itr_4_2915 / 4UL) * 256UL) + ((fused_0fused_0fused_0fused_0__itr_0____itr_1_2912____itr_2_2913____itr_3_2914____itr_4_2915 % 4UL) * 64UL)) + _fuseiter_9158)]);
    float __cached_1;
    __cached_1 = __ins_1[0];
    vec_f32x16 __cached_2;
    __cached_2 = (__cached_0 * vec_f32x16(__cached_1));
    vec_f32x16::store(__cached_2, &__outs_0[((((fused_0fused_0fused_0fused_0__itr_0____itr_1_2912____itr_2_2913____itr_3_2914____itr_4_2915 / 4UL) * 256UL) + ((fused_0fused_0fused_0fused_0__itr_0____itr_1_2912____itr_2_2913____itr_3_2914____itr_4_2915 % 4UL) * 64UL)) + _fuseiter_9158)]);
  }
}

static void mul__6510_closure_137_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept{
  mul__6510_closure_137(i, (float*)(args[0UL].v_ptr), (float*)(args[1UL].v_ptr), (float*)(args[2UL].v_ptr));
}

static void reorder__4380_closure_138(uint64_t fused_0fused_0fused_0fused_0_fuseiter_9160___fuseiter_9161_2916___fuseiter_9162_2917___fuseiter_9163_2918___fuseiter_9164_2919, float* __restrict__ __ins_0, float* __restrict__ __outs_0) noexcept{
  for (uint64_t _fuseiter_9165 = 0UL; _fuseiter_9165 < 64UL; _fuseiter_9165 += 16UL) {
    vec_f32x16 __cached_0;
    __cached_0 = vec_f32x16::load(&__ins_0[(((fused_0fused_0fused_0fused_0_fuseiter_9160___fuseiter_9161_2916___fuseiter_9162_2917___fuseiter_9163_2918___fuseiter_9164_2919 / 8UL) * 512UL) + (_fuseiter_9165 + ((fused_0fused_0fused_0fused_0_fuseiter_9160___fuseiter_9161_2916___fuseiter_9162_2917___fuseiter_9163_2918___fuseiter_9164_2919 % 8UL) * 64UL)))]);
    vec_f32x16 __cached_1;
    __cached_1 = __cached_0;
    vec_f32x16::store(__cached_1, &__outs_0[(((fused_0fused_0fused_0fused_0_fuseiter_9160___fuseiter_9161_2916___fuseiter_9162_2917___fuseiter_9163_2918___fuseiter_9164_2919 / 8UL) * 512UL) + (((fused_0fused_0fused_0fused_0_fuseiter_9160___fuseiter_9161_2916___fuseiter_9162_2917___fuseiter_9163_2918___fuseiter_9164_2919 % 8UL) * 64UL) + _fuseiter_9165))]);
  }
}

static void reorder__4380_closure_138_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept{
  reorder__4380_closure_138(i, (float*)(args[0UL].v_ptr), (float*)(args[1UL].v_ptr));
}

static void mul__5910_closure_139(uint64_t fused_0fused_0fused_0fused_0__itr_0____itr_1_2920____itr_2_2921____itr_3_2922____itr_4_2923, float* __restrict__ __ins_0, float* __restrict__ __ins_1, float* __restrict__ __outs_0) noexcept{
  for (uint64_t _fuseiter_9171 = 0UL; _fuseiter_9171 < 64UL; _fuseiter_9171 += 16UL) {
    vec_f32x16 __cached_0;
    __cached_0 = vec_f32x16::load(&__ins_0[((((fused_0fused_0fused_0fused_0__itr_0____itr_1_2920____itr_2_2921____itr_3_2922____itr_4_2923 / 8UL) * 512UL) + ((fused_0fused_0fused_0fused_0__itr_0____itr_1_2920____itr_2_2921____itr_3_2922____itr_4_2923 % 8UL) * 64UL)) + _fuseiter_9171)]);
    float __cached_1;
    __cached_1 = __ins_1[0];
    vec_f32x16 __cached_2;
    __cached_2 = (__cached_0 * vec_f32x16(__cached_1));
    vec_f32x16::store(__cached_2, &__outs_0[((((fused_0fused_0fused_0fused_0__itr_0____itr_1_2920____itr_2_2921____itr_3_2922____itr_4_2923 / 8UL) * 512UL) + ((fused_0fused_0fused_0fused_0__itr_0____itr_1_2920____itr_2_2921____itr_3_2922____itr_4_2923 % 8UL) * 64UL)) + _fuseiter_9171)]);
  }
}

static void mul__5910_closure_139_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept{
  mul__5910_closure_139(i, (float*)(args[0UL].v_ptr), (float*)(args[1UL].v_ptr), (float*)(args[2UL].v_ptr));
}

static void reorder__4470_closure_140(uint64_t fused_0fused_0fused_0fused_0_fuseiter_9173___fuseiter_9174_2924___fuseiter_9175_2925___fuseiter_9176_2926___fuseiter_9177_2927, float* __restrict__ __ins_0, float* __restrict__ __outs_0) noexcept{
  for (uint64_t _fuseiter_9178 = 0UL; _fuseiter_9178 < 64UL; _fuseiter_9178 += 16UL) {
    vec_f32x16 __cached_0;
    __cached_0 = vec_f32x16::load(&__ins_0[(((fused_0fused_0fused_0fused_0_fuseiter_9173___fuseiter_9174_2924___fuseiter_9175_2925___fuseiter_9176_2926___fuseiter_9177_2927 / 8UL) * 512UL) + (_fuseiter_9178 + ((fused_0fused_0fused_0fused_0_fuseiter_9173___fuseiter_9174_2924___fuseiter_9175_2925___fuseiter_9176_2926___fuseiter_9177_2927 % 8UL) * 64UL)))]);
    vec_f32x16 __cached_1;
    __cached_1 = __cached_0;
    vec_f32x16::store(__cached_1, &__outs_0[(((fused_0fused_0fused_0fused_0_fuseiter_9173___fuseiter_9174_2924___fuseiter_9175_2925___fuseiter_9176_2926___fuseiter_9177_2927 / 8UL) * 512UL) + (((fused_0fused_0fused_0fused_0_fuseiter_9173___fuseiter_9174_2924___fuseiter_9175_2925___fuseiter_9176_2926___fuseiter_9177_2927 % 8UL) * 64UL) + _fuseiter_9178))]);
  }
}

static void reorder__4470_closure_140_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept{
  reorder__4470_closure_140(i, (float*)(args[0UL].v_ptr), (float*)(args[1UL].v_ptr));
}

static void mul__5970_closure_141(uint64_t fused_0fused_0fused_0fused_0__itr_0____itr_1_2928____itr_2_2929____itr_3_2930____itr_4_2931, float* __restrict__ __ins_0, float* __restrict__ __ins_1, float* __restrict__ __outs_0) noexcept{
  for (uint64_t _fuseiter_9184 = 0UL; _fuseiter_9184 < 64UL; _fuseiter_9184 += 16UL) {
    vec_f32x16 __cached_0;
    __cached_0 = vec_f32x16::load(&__ins_0[((((fused_0fused_0fused_0fused_0__itr_0____itr_1_2928____itr_2_2929____itr_3_2930____itr_4_2931 / 8UL) * 512UL) + ((fused_0fused_0fused_0fused_0__itr_0____itr_1_2928____itr_2_2929____itr_3_2930____itr_4_2931 % 8UL) * 64UL)) + _fuseiter_9184)]);
    float __cached_1;
    __cached_1 = __ins_1[0];
    vec_f32x16 __cached_2;
    __cached_2 = (__cached_0 * vec_f32x16(__cached_1));
    vec_f32x16::store(__cached_2, &__outs_0[((((fused_0fused_0fused_0fused_0__itr_0____itr_1_2928____itr_2_2929____itr_3_2930____itr_4_2931 / 8UL) * 512UL) + ((fused_0fused_0fused_0fused_0__itr_0____itr_1_2928____itr_2_2929____itr_3_2930____itr_4_2931 % 8UL) * 64UL)) + _fuseiter_9184)]);
  }
}

static void mul__5970_closure_141_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept{
  mul__5970_closure_141(i, (float*)(args[0UL].v_ptr), (float*)(args[1UL].v_ptr), (float*)(args[2UL].v_ptr));
}

static void reorder__4560_closure_142(uint64_t fused_0fused_0fused_0fused_0_fuseiter_9186___fuseiter_9187_2932___fuseiter_9188_2933___fuseiter_9189_2934___fuseiter_9190_2935, float* __restrict__ __ins_0, float* __restrict__ __outs_0) noexcept{
  for (uint64_t _fuseiter_9191 = 0UL; _fuseiter_9191 < 64UL; _fuseiter_9191 += 16UL) {
    vec_f32x16 __cached_0;
    __cached_0 = vec_f32x16::load(&__ins_0[(((fused_0fused_0fused_0fused_0_fuseiter_9186___fuseiter_9187_2932___fuseiter_9188_2933___fuseiter_9189_2934___fuseiter_9190_2935 / 8UL) * 512UL) + (_fuseiter_9191 + ((fused_0fused_0fused_0fused_0_fuseiter_9186___fuseiter_9187_2932___fuseiter_9188_2933___fuseiter_9189_2934___fuseiter_9190_2935 % 8UL) * 64UL)))]);
    vec_f32x16 __cached_1;
    __cached_1 = __cached_0;
    vec_f32x16::store(__cached_1, &__outs_0[(((fused_0fused_0fused_0fused_0_fuseiter_9186___fuseiter_9187_2932___fuseiter_9188_2933___fuseiter_9189_2934___fuseiter_9190_2935 / 8UL) * 512UL) + (((fused_0fused_0fused_0fused_0_fuseiter_9186___fuseiter_9187_2932___fuseiter_9188_2933___fuseiter_9189_2934___fuseiter_9190_2935 % 8UL) * 64UL) + _fuseiter_9191))]);
  }
}

static void reorder__4560_closure_142_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept{
  reorder__4560_closure_142(i, (float*)(args[0UL].v_ptr), (float*)(args[1UL].v_ptr));
}

static void mul__6030_closure_143(uint64_t fused_0fused_0fused_0fused_0__itr_0____itr_1_2936____itr_2_2937____itr_3_2938____itr_4_2939, float* __restrict__ __ins_0, float* __restrict__ __ins_1, float* __restrict__ __outs_0) noexcept{
  for (uint64_t _fuseiter_9197 = 0UL; _fuseiter_9197 < 64UL; _fuseiter_9197 += 16UL) {
    vec_f32x16 __cached_0;
    __cached_0 = vec_f32x16::load(&__ins_0[((((fused_0fused_0fused_0fused_0__itr_0____itr_1_2936____itr_2_2937____itr_3_2938____itr_4_2939 / 8UL) * 512UL) + ((fused_0fused_0fused_0fused_0__itr_0____itr_1_2936____itr_2_2937____itr_3_2938____itr_4_2939 % 8UL) * 64UL)) + _fuseiter_9197)]);
    float __cached_1;
    __cached_1 = __ins_1[0];
    vec_f32x16 __cached_2;
    __cached_2 = (__cached_0 * vec_f32x16(__cached_1));
    vec_f32x16::store(__cached_2, &__outs_0[((((fused_0fused_0fused_0fused_0__itr_0____itr_1_2936____itr_2_2937____itr_3_2938____itr_4_2939 / 8UL) * 512UL) + ((fused_0fused_0fused_0fused_0__itr_0____itr_1_2936____itr_2_2937____itr_3_2938____itr_4_2939 % 8UL) * 64UL)) + _fuseiter_9197)]);
  }
}

static void mul__6030_closure_143_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept{
  mul__6030_closure_143(i, (float*)(args[0UL].v_ptr), (float*)(args[1UL].v_ptr), (float*)(args[2UL].v_ptr));
}

static void reorder__4650_closure_144(uint64_t fused_0fused_0fused_0fused_0_fuseiter_9199___fuseiter_9200_2940___fuseiter_9201_2941___fuseiter_9202_2942___fuseiter_9203_2943, float* __restrict__ __ins_0, float* __restrict__ __outs_0) noexcept{
  for (uint64_t _fuseiter_9204 = 0UL; _fuseiter_9204 < 64UL; _fuseiter_9204 += 16UL) {
    vec_f32x16 __cached_0;
    __cached_0 = vec_f32x16::load(&__ins_0[(((fused_0fused_0fused_0fused_0_fuseiter_9199___fuseiter_9200_2940___fuseiter_9201_2941___fuseiter_9202_2942___fuseiter_9203_2943 / 8UL) * 512UL) + (_fuseiter_9204 + ((fused_0fused_0fused_0fused_0_fuseiter_9199___fuseiter_9200_2940___fuseiter_9201_2941___fuseiter_9202_2942___fuseiter_9203_2943 % 8UL) * 64UL)))]);
    vec_f32x16 __cached_1;
    __cached_1 = __cached_0;
    vec_f32x16::store(__cached_1, &__outs_0[(((fused_0fused_0fused_0fused_0_fuseiter_9199___fuseiter_9200_2940___fuseiter_9201_2941___fuseiter_9202_2942___fuseiter_9203_2943 / 8UL) * 512UL) + (((fused_0fused_0fused_0fused_0_fuseiter_9199___fuseiter_9200_2940___fuseiter_9201_2941___fuseiter_9202_2942___fuseiter_9203_2943 % 8UL) * 64UL) + _fuseiter_9204))]);
  }
}

static void reorder__4650_closure_144_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept{
  reorder__4650_closure_144(i, (float*)(args[0UL].v_ptr), (float*)(args[1UL].v_ptr));
}

static void mul__6090_closure_145(uint64_t fused_0fused_0fused_0fused_0__itr_0____itr_1_2944____itr_2_2945____itr_3_2946____itr_4_2947, float* __restrict__ __ins_0, float* __restrict__ __ins_1, float* __restrict__ __outs_0) noexcept{
  for (uint64_t _fuseiter_9210 = 0UL; _fuseiter_9210 < 64UL; _fuseiter_9210 += 16UL) {
    vec_f32x16 __cached_0;
    __cached_0 = vec_f32x16::load(&__ins_0[((((fused_0fused_0fused_0fused_0__itr_0____itr_1_2944____itr_2_2945____itr_3_2946____itr_4_2947 / 8UL) * 512UL) + ((fused_0fused_0fused_0fused_0__itr_0____itr_1_2944____itr_2_2945____itr_3_2946____itr_4_2947 % 8UL) * 64UL)) + _fuseiter_9210)]);
    float __cached_1;
    __cached_1 = __ins_1[0];
    vec_f32x16 __cached_2;
    __cached_2 = (__cached_0 * vec_f32x16(__cached_1));
    vec_f32x16::store(__cached_2, &__outs_0[((((fused_0fused_0fused_0fused_0__itr_0____itr_1_2944____itr_2_2945____itr_3_2946____itr_4_2947 / 8UL) * 512UL) + ((fused_0fused_0fused_0fused_0__itr_0____itr_1_2944____itr_2_2945____itr_3_2946____itr_4_2947 % 8UL) * 64UL)) + _fuseiter_9210)]);
  }
}

static void mul__6090_closure_145_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept{
  mul__6090_closure_145(i, (float*)(args[0UL].v_ptr), (float*)(args[1UL].v_ptr), (float*)(args[2UL].v_ptr));
}

static void reorder__4740_closure_146(uint64_t fused_0fused_0fused_0fused_0_fuseiter_9212___fuseiter_9213_2948___fuseiter_9214_2949___fuseiter_9215_2950___fuseiter_9216_2951, float* __restrict__ __ins_0, float* __restrict__ __outs_0) noexcept{
  for (uint64_t _fuseiter_9217 = 0UL; _fuseiter_9217 < 64UL; _fuseiter_9217 += 16UL) {
    vec_f32x16 __cached_0;
    __cached_0 = vec_f32x16::load(&__ins_0[(((fused_0fused_0fused_0fused_0_fuseiter_9212___fuseiter_9213_2948___fuseiter_9214_2949___fuseiter_9215_2950___fuseiter_9216_2951 / 8UL) * 512UL) + (_fuseiter_9217 + ((fused_0fused_0fused_0fused_0_fuseiter_9212___fuseiter_9213_2948___fuseiter_9214_2949___fuseiter_9215_2950___fuseiter_9216_2951 % 8UL) * 64UL)))]);
    vec_f32x16 __cached_1;
    __cached_1 = __cached_0;
    vec_f32x16::store(__cached_1, &__outs_0[(((fused_0fused_0fused_0fused_0_fuseiter_9212___fuseiter_9213_2948___fuseiter_9214_2949___fuseiter_9215_2950___fuseiter_9216_2951 / 8UL) * 512UL) + (((fused_0fused_0fused_0fused_0_fuseiter_9212___fuseiter_9213_2948___fuseiter_9214_2949___fuseiter_9215_2950___fuseiter_9216_2951 % 8UL) * 64UL) + _fuseiter_9217))]);
  }
}

static void reorder__4740_closure_146_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept{
  reorder__4740_closure_146(i, (float*)(args[0UL].v_ptr), (float*)(args[1UL].v_ptr));
}

static void mul__6150_closure_147(uint64_t fused_0fused_0fused_0fused_0__itr_0____itr_1_2952____itr_2_2953____itr_3_2954____itr_4_2955, float* __restrict__ __ins_0, float* __restrict__ __ins_1, float* __restrict__ __outs_0) noexcept{
  for (uint64_t _fuseiter_9223 = 0UL; _fuseiter_9223 < 64UL; _fuseiter_9223 += 16UL) {
    vec_f32x16 __cached_0;
    __cached_0 = vec_f32x16::load(&__ins_0[((((fused_0fused_0fused_0fused_0__itr_0____itr_1_2952____itr_2_2953____itr_3_2954____itr_4_2955 / 8UL) * 512UL) + ((fused_0fused_0fused_0fused_0__itr_0____itr_1_2952____itr_2_2953____itr_3_2954____itr_4_2955 % 8UL) * 64UL)) + _fuseiter_9223)]);
    float __cached_1;
    __cached_1 = __ins_1[0];
    vec_f32x16 __cached_2;
    __cached_2 = (__cached_0 * vec_f32x16(__cached_1));
    vec_f32x16::store(__cached_2, &__outs_0[((((fused_0fused_0fused_0fused_0__itr_0____itr_1_2952____itr_2_2953____itr_3_2954____itr_4_2955 / 8UL) * 512UL) + ((fused_0fused_0fused_0fused_0__itr_0____itr_1_2952____itr_2_2953____itr_3_2954____itr_4_2955 % 8UL) * 64UL)) + _fuseiter_9223)]);
  }
}

static void mul__6150_closure_147_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept{
  mul__6150_closure_147(i, (float*)(args[0UL].v_ptr), (float*)(args[1UL].v_ptr), (float*)(args[2UL].v_ptr));
}

static void reorder__5380_closure_148(uint64_t fused_0fused_0fused_0fused_0_fuseiter_9232___fuseiter_9233_2960___fuseiter_9234_2961___fuseiter_9235_2962___fuseiter_9236_2963, float* __restrict__ __ins_0, float* __restrict__ __outs_0) noexcept{
  for (uint64_t _fuseiter_9237 = 0UL; _fuseiter_9237 < 256UL; _fuseiter_9237 += 16UL) {
    vec_f32x16 __cached_0;
    __cached_0 = vec_f32x16::load(&__ins_0[(((fused_0fused_0fused_0fused_0_fuseiter_9232___fuseiter_9233_2960___fuseiter_9234_2961___fuseiter_9235_2962___fuseiter_9236_2963 / 2UL) * 512UL) + (_fuseiter_9237 + ((fused_0fused_0fused_0fused_0_fuseiter_9232___fuseiter_9233_2960___fuseiter_9234_2961___fuseiter_9235_2962___fuseiter_9236_2963 % 2UL) * 256UL)))]);
    vec_f32x16 __cached_1;
    __cached_1 = __cached_0;
    vec_f32x16::store(__cached_1, &__outs_0[(((fused_0fused_0fused_0fused_0_fuseiter_9232___fuseiter_9233_2960___fuseiter_9234_2961___fuseiter_9235_2962___fuseiter_9236_2963 / 2UL) * 512UL) + (((fused_0fused_0fused_0fused_0_fuseiter_9232___fuseiter_9233_2960___fuseiter_9234_2961___fuseiter_9235_2962___fuseiter_9236_2963 % 2UL) * 256UL) + _fuseiter_9237))]);
  }
}

static void reorder__5380_closure_148_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept{
  reorder__5380_closure_148(i, (float*)(args[0UL].v_ptr), (float*)(args[1UL].v_ptr));
}

static void mul__6590_closure_149(uint64_t fused_0fused_0fused_0fused_0__itr_0____itr_1_2964____itr_2_2965____itr_3_2966____itr_4_2967, float* __restrict__ __ins_0, float* __restrict__ __ins_1, float* __restrict__ __outs_0) noexcept{
  for (uint64_t _fuseiter_9243 = 0UL; _fuseiter_9243 < 256UL; _fuseiter_9243 += 16UL) {
    vec_f32x16 __cached_0;
    __cached_0 = vec_f32x16::load(&__ins_0[((((fused_0fused_0fused_0fused_0__itr_0____itr_1_2964____itr_2_2965____itr_3_2966____itr_4_2967 / 2UL) * 512UL) + ((fused_0fused_0fused_0fused_0__itr_0____itr_1_2964____itr_2_2965____itr_3_2966____itr_4_2967 % 2UL) * 256UL)) + _fuseiter_9243)]);
    float __cached_1;
    __cached_1 = __ins_1[0];
    vec_f32x16 __cached_2;
    __cached_2 = (__cached_0 * vec_f32x16(__cached_1));
    vec_f32x16::store(__cached_2, &__outs_0[((((fused_0fused_0fused_0fused_0__itr_0____itr_1_2964____itr_2_2965____itr_3_2966____itr_4_2967 / 2UL) * 512UL) + ((fused_0fused_0fused_0fused_0__itr_0____itr_1_2964____itr_2_2965____itr_3_2966____itr_4_2967 % 2UL) * 256UL)) + _fuseiter_9243)]);
  }
}

static void mul__6590_closure_149_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept{
  mul__6590_closure_149(i, (float*)(args[0UL].v_ptr), (float*)(args[1UL].v_ptr), (float*)(args[2UL].v_ptr));
}

static void reorder__5440_closure_150(uint64_t fused_0fused_0fused_0fused_0_fuseiter_9245___fuseiter_9246_2968___fuseiter_9247_2969___fuseiter_9248_2970___fuseiter_9249_2971, float* __restrict__ __ins_0, float* __restrict__ __outs_0) noexcept{
  for (uint64_t _fuseiter_9250 = 0UL; _fuseiter_9250 < 64UL; _fuseiter_9250 += 16UL) {
    vec_f32x16 __cached_0;
    __cached_0 = vec_f32x16::load(&__ins_0[(((fused_0fused_0fused_0fused_0_fuseiter_9245___fuseiter_9246_2968___fuseiter_9247_2969___fuseiter_9248_2970___fuseiter_9249_2971 / 8UL) * 512UL) + (_fuseiter_9250 + ((fused_0fused_0fused_0fused_0_fuseiter_9245___fuseiter_9246_2968___fuseiter_9247_2969___fuseiter_9248_2970___fuseiter_9249_2971 % 8UL) * 64UL)))]);
    vec_f32x16 __cached_1;
    __cached_1 = __cached_0;
    vec_f32x16::store(__cached_1, &__outs_0[(((fused_0fused_0fused_0fused_0_fuseiter_9245___fuseiter_9246_2968___fuseiter_9247_2969___fuseiter_9248_2970___fuseiter_9249_2971 / 8UL) * 512UL) + (((fused_0fused_0fused_0fused_0_fuseiter_9245___fuseiter_9246_2968___fuseiter_9247_2969___fuseiter_9248_2970___fuseiter_9249_2971 % 8UL) * 64UL) + _fuseiter_9250))]);
  }
}

static void reorder__5440_closure_150_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept{
  reorder__5440_closure_150(i, (float*)(args[0UL].v_ptr), (float*)(args[1UL].v_ptr));
}

static void mul__6630_closure_151(uint64_t fused_0fused_0fused_0fused_0__itr_0____itr_1_2972____itr_2_2973____itr_3_2974____itr_4_2975, float* __restrict__ __ins_0, float* __restrict__ __ins_1, float* __restrict__ __outs_0) noexcept{
  for (uint64_t _fuseiter_9256 = 0UL; _fuseiter_9256 < 64UL; _fuseiter_9256 += 16UL) {
    vec_f32x16 __cached_0;
    __cached_0 = vec_f32x16::load(&__ins_0[((((fused_0fused_0fused_0fused_0__itr_0____itr_1_2972____itr_2_2973____itr_3_2974____itr_4_2975 / 8UL) * 512UL) + ((fused_0fused_0fused_0fused_0__itr_0____itr_1_2972____itr_2_2973____itr_3_2974____itr_4_2975 % 8UL) * 64UL)) + _fuseiter_9256)]);
    float __cached_1;
    __cached_1 = __ins_1[0];
    vec_f32x16 __cached_2;
    __cached_2 = (__cached_0 * vec_f32x16(__cached_1));
    vec_f32x16::store(__cached_2, &__outs_0[((((fused_0fused_0fused_0fused_0__itr_0____itr_1_2972____itr_2_2973____itr_3_2974____itr_4_2975 / 8UL) * 512UL) + ((fused_0fused_0fused_0fused_0__itr_0____itr_1_2972____itr_2_2973____itr_3_2974____itr_4_2975 % 8UL) * 64UL)) + _fuseiter_9256)]);
  }
}

static void mul__6630_closure_151_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept{
  mul__6630_closure_151(i, (float*)(args[0UL].v_ptr), (float*)(args[1UL].v_ptr), (float*)(args[2UL].v_ptr));
}

static void reorder__5470_closure_152(uint64_t fused_0fused_0fused_0fused_0_fuseiter_9258___fuseiter_9259_2976___fuseiter_9260_2977___fuseiter_9261_2978___fuseiter_9262_2979, float* __restrict__ __ins_0, float* __restrict__ __outs_0) noexcept{
  for (uint64_t _fuseiter_9263 = 0UL; _fuseiter_9263 < 128UL; _fuseiter_9263 += 16UL) {
    vec_f32x16 __cached_0;
    __cached_0 = vec_f32x16::load(&__ins_0[(((fused_0fused_0fused_0fused_0_fuseiter_9258___fuseiter_9259_2976___fuseiter_9260_2977___fuseiter_9261_2978___fuseiter_9262_2979 / 4UL) * 512UL) + (_fuseiter_9263 + ((fused_0fused_0fused_0fused_0_fuseiter_9258___fuseiter_9259_2976___fuseiter_9260_2977___fuseiter_9261_2978___fuseiter_9262_2979 % 4UL) * 128UL)))]);
    vec_f32x16 __cached_1;
    __cached_1 = __cached_0;
    vec_f32x16::store(__cached_1, &__outs_0[(((fused_0fused_0fused_0fused_0_fuseiter_9258___fuseiter_9259_2976___fuseiter_9260_2977___fuseiter_9261_2978___fuseiter_9262_2979 / 4UL) * 512UL) + (((fused_0fused_0fused_0fused_0_fuseiter_9258___fuseiter_9259_2976___fuseiter_9260_2977___fuseiter_9261_2978___fuseiter_9262_2979 % 4UL) * 128UL) + _fuseiter_9263))]);
  }
}

static void reorder__5470_closure_152_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept{
  reorder__5470_closure_152(i, (float*)(args[0UL].v_ptr), (float*)(args[1UL].v_ptr));
}

static void mul__6650_closure_153(uint64_t fused_0fused_0fused_0fused_0__itr_0____itr_1_2980____itr_2_2981____itr_3_2982____itr_4_2983, float* __restrict__ __ins_0, float* __restrict__ __ins_1, float* __restrict__ __outs_0) noexcept{
  for (uint64_t _fuseiter_9269 = 0UL; _fuseiter_9269 < 128UL; _fuseiter_9269 += 16UL) {
    vec_f32x16 __cached_0;
    __cached_0 = vec_f32x16::load(&__ins_0[((((fused_0fused_0fused_0fused_0__itr_0____itr_1_2980____itr_2_2981____itr_3_2982____itr_4_2983 / 4UL) * 512UL) + ((fused_0fused_0fused_0fused_0__itr_0____itr_1_2980____itr_2_2981____itr_3_2982____itr_4_2983 % 4UL) * 128UL)) + _fuseiter_9269)]);
    float __cached_1;
    __cached_1 = __ins_1[0];
    vec_f32x16 __cached_2;
    __cached_2 = (__cached_0 * vec_f32x16(__cached_1));
    vec_f32x16::store(__cached_2, &__outs_0[((((fused_0fused_0fused_0fused_0__itr_0____itr_1_2980____itr_2_2981____itr_3_2982____itr_4_2983 / 4UL) * 512UL) + ((fused_0fused_0fused_0fused_0__itr_0____itr_1_2980____itr_2_2981____itr_3_2982____itr_4_2983 % 4UL) * 128UL)) + _fuseiter_9269)]);
  }
}

static void mul__6650_closure_153_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept{
  mul__6650_closure_153(i, (float*)(args[0UL].v_ptr), (float*)(args[1UL].v_ptr), (float*)(args[2UL].v_ptr));
}

static void reorder__5530_closure_154(uint64_t fused_0fused_0fused_0fused_0_fuseiter_9271___fuseiter_9272_2984___fuseiter_9273_2985___fuseiter_9274_2986___fuseiter_9275_2987, float* __restrict__ __ins_0, float* __restrict__ __outs_0) noexcept{
  for (uint64_t _fuseiter_9276 = 0UL; _fuseiter_9276 < 256UL; _fuseiter_9276 += 16UL) {
    vec_f32x16 __cached_0;
    __cached_0 = vec_f32x16::load(&__ins_0[(((fused_0fused_0fused_0fused_0_fuseiter_9271___fuseiter_9272_2984___fuseiter_9273_2985___fuseiter_9274_2986___fuseiter_9275_2987 / 2UL) * 512UL) + (_fuseiter_9276 + ((fused_0fused_0fused_0fused_0_fuseiter_9271___fuseiter_9272_2984___fuseiter_9273_2985___fuseiter_9274_2986___fuseiter_9275_2987 % 2UL) * 256UL)))]);
    vec_f32x16 __cached_1;
    __cached_1 = __cached_0;
    vec_f32x16::store(__cached_1, &__outs_0[(((fused_0fused_0fused_0fused_0_fuseiter_9271___fuseiter_9272_2984___fuseiter_9273_2985___fuseiter_9274_2986___fuseiter_9275_2987 / 2UL) * 512UL) + (((fused_0fused_0fused_0fused_0_fuseiter_9271___fuseiter_9272_2984___fuseiter_9273_2985___fuseiter_9274_2986___fuseiter_9275_2987 % 2UL) * 256UL) + _fuseiter_9276))]);
  }
}

static void reorder__5530_closure_154_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept{
  reorder__5530_closure_154(i, (float*)(args[0UL].v_ptr), (float*)(args[1UL].v_ptr));
}

static void mul__6690_closure_155(uint64_t fused_0fused_0fused_0fused_0__itr_0____itr_1_2988____itr_2_2989____itr_3_2990____itr_4_2991, float* __restrict__ __ins_0, float* __restrict__ __ins_1, float* __restrict__ __outs_0) noexcept{
  for (uint64_t _fuseiter_9282 = 0UL; _fuseiter_9282 < 256UL; _fuseiter_9282 += 16UL) {
    vec_f32x16 __cached_0;
    __cached_0 = vec_f32x16::load(&__ins_0[((((fused_0fused_0fused_0fused_0__itr_0____itr_1_2988____itr_2_2989____itr_3_2990____itr_4_2991 / 2UL) * 512UL) + ((fused_0fused_0fused_0fused_0__itr_0____itr_1_2988____itr_2_2989____itr_3_2990____itr_4_2991 % 2UL) * 256UL)) + _fuseiter_9282)]);
    float __cached_1;
    __cached_1 = __ins_1[0];
    vec_f32x16 __cached_2;
    __cached_2 = (__cached_0 * vec_f32x16(__cached_1));
    vec_f32x16::store(__cached_2, &__outs_0[((((fused_0fused_0fused_0fused_0__itr_0____itr_1_2988____itr_2_2989____itr_3_2990____itr_4_2991 / 2UL) * 512UL) + ((fused_0fused_0fused_0fused_0__itr_0____itr_1_2988____itr_2_2989____itr_3_2990____itr_4_2991 % 2UL) * 256UL)) + _fuseiter_9282)]);
  }
}

static void mul__6690_closure_155_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept{
  mul__6690_closure_155(i, (float*)(args[0UL].v_ptr), (float*)(args[1UL].v_ptr), (float*)(args[2UL].v_ptr));
}

static void reorder__5560_closure_156(uint64_t fused_0fused_0fused_0fused_0_fuseiter_9284___fuseiter_9285_2992___fuseiter_9286_2993___fuseiter_9287_2994___fuseiter_9288_2995, float* __restrict__ __ins_0, float* __restrict__ __outs_0) noexcept{
  for (uint64_t _fuseiter_9289 = 0UL; _fuseiter_9289 < 64UL; _fuseiter_9289 += 16UL) {
    vec_f32x16 __cached_0;
    __cached_0 = vec_f32x16::load(&__ins_0[(((fused_0fused_0fused_0fused_0_fuseiter_9284___fuseiter_9285_2992___fuseiter_9286_2993___fuseiter_9287_2994___fuseiter_9288_2995 / 8UL) * 512UL) + (_fuseiter_9289 + ((fused_0fused_0fused_0fused_0_fuseiter_9284___fuseiter_9285_2992___fuseiter_9286_2993___fuseiter_9287_2994___fuseiter_9288_2995 % 8UL) * 64UL)))]);
    vec_f32x16 __cached_1;
    __cached_1 = __cached_0;
    vec_f32x16::store(__cached_1, &__outs_0[(((fused_0fused_0fused_0fused_0_fuseiter_9284___fuseiter_9285_2992___fuseiter_9286_2993___fuseiter_9287_2994___fuseiter_9288_2995 / 8UL) * 512UL) + (((fused_0fused_0fused_0fused_0_fuseiter_9284___fuseiter_9285_2992___fuseiter_9286_2993___fuseiter_9287_2994___fuseiter_9288_2995 % 8UL) * 64UL) + _fuseiter_9289))]);
  }
}

static void reorder__5560_closure_156_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept{
  reorder__5560_closure_156(i, (float*)(args[0UL].v_ptr), (float*)(args[1UL].v_ptr));
}

static void mul__6710_closure_157(uint64_t fused_0fused_0fused_0fused_0__itr_0____itr_1_2996____itr_2_2997____itr_3_2998____itr_4_2999, float* __restrict__ __ins_0, float* __restrict__ __ins_1, float* __restrict__ __outs_0) noexcept{
  for (uint64_t _fuseiter_9295 = 0UL; _fuseiter_9295 < 64UL; _fuseiter_9295 += 16UL) {
    vec_f32x16 __cached_0;
    __cached_0 = vec_f32x16::load(&__ins_0[((((fused_0fused_0fused_0fused_0__itr_0____itr_1_2996____itr_2_2997____itr_3_2998____itr_4_2999 / 8UL) * 512UL) + ((fused_0fused_0fused_0fused_0__itr_0____itr_1_2996____itr_2_2997____itr_3_2998____itr_4_2999 % 8UL) * 64UL)) + _fuseiter_9295)]);
    float __cached_1;
    __cached_1 = __ins_1[0];
    vec_f32x16 __cached_2;
    __cached_2 = (__cached_0 * vec_f32x16(__cached_1));
    vec_f32x16::store(__cached_2, &__outs_0[((((fused_0fused_0fused_0fused_0__itr_0____itr_1_2996____itr_2_2997____itr_3_2998____itr_4_2999 / 8UL) * 512UL) + ((fused_0fused_0fused_0fused_0__itr_0____itr_1_2996____itr_2_2997____itr_3_2998____itr_4_2999 % 8UL) * 64UL)) + _fuseiter_9295)]);
  }
}

static void mul__6710_closure_157_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept{
  mul__6710_closure_157(i, (float*)(args[0UL].v_ptr), (float*)(args[1UL].v_ptr), (float*)(args[2UL].v_ptr));
}

static void reorder__4770_closure_158(uint64_t fused_0fused_0fused_0fused_0_fuseiter_9297___fuseiter_9298_3000___fuseiter_9299_3001___fuseiter_9300_3002___fuseiter_9301_3003, float* __restrict__ __ins_0, float* __restrict__ __outs_0) noexcept{
  for (uint64_t _fuseiter_9302 = 0UL; _fuseiter_9302 < 64UL; _fuseiter_9302 += 16UL) {
    vec_f32x16 __cached_0;
    __cached_0 = vec_f32x16::load(&__ins_0[(((fused_0fused_0fused_0fused_0_fuseiter_9297___fuseiter_9298_3000___fuseiter_9299_3001___fuseiter_9300_3002___fuseiter_9301_3003 / 16UL) * 1024UL) + (_fuseiter_9302 + ((fused_0fused_0fused_0fused_0_fuseiter_9297___fuseiter_9298_3000___fuseiter_9299_3001___fuseiter_9300_3002___fuseiter_9301_3003 % 16UL) * 64UL)))]);
    vec_f32x16 __cached_1;
    __cached_1 = __cached_0;
    vec_f32x16::store(__cached_1, &__outs_0[(((fused_0fused_0fused_0fused_0_fuseiter_9297___fuseiter_9298_3000___fuseiter_9299_3001___fuseiter_9300_3002___fuseiter_9301_3003 / 16UL) * 1024UL) + (((fused_0fused_0fused_0fused_0_fuseiter_9297___fuseiter_9298_3000___fuseiter_9299_3001___fuseiter_9300_3002___fuseiter_9301_3003 % 16UL) * 64UL) + _fuseiter_9302))]);
  }
}

static void reorder__4770_closure_158_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept{
  reorder__4770_closure_158(i, (float*)(args[0UL].v_ptr), (float*)(args[1UL].v_ptr));
}

static void mul__6170_closure_159(uint64_t fused_0fused_0fused_0fused_0__itr_0____itr_1_3004____itr_2_3005____itr_3_3006____itr_4_3007, float* __restrict__ __ins_0, float* __restrict__ __ins_1, float* __restrict__ __outs_0) noexcept{
  for (uint64_t _fuseiter_9308 = 0UL; _fuseiter_9308 < 64UL; _fuseiter_9308 += 16UL) {
    vec_f32x16 __cached_0;
    __cached_0 = vec_f32x16::load(&__ins_0[((((fused_0fused_0fused_0fused_0__itr_0____itr_1_3004____itr_2_3005____itr_3_3006____itr_4_3007 / 16UL) * 1024UL) + ((fused_0fused_0fused_0fused_0__itr_0____itr_1_3004____itr_2_3005____itr_3_3006____itr_4_3007 % 16UL) * 64UL)) + _fuseiter_9308)]);
    float __cached_1;
    __cached_1 = __ins_1[0];
    vec_f32x16 __cached_2;
    __cached_2 = (__cached_0 * vec_f32x16(__cached_1));
    vec_f32x16::store(__cached_2, &__outs_0[((((fused_0fused_0fused_0fused_0__itr_0____itr_1_3004____itr_2_3005____itr_3_3006____itr_4_3007 / 16UL) * 1024UL) + ((fused_0fused_0fused_0fused_0__itr_0____itr_1_3004____itr_2_3005____itr_3_3006____itr_4_3007 % 16UL) * 64UL)) + _fuseiter_9308)]);
  }
}

static void mul__6170_closure_159_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept{
  mul__6170_closure_159(i, (float*)(args[0UL].v_ptr), (float*)(args[1UL].v_ptr), (float*)(args[2UL].v_ptr));
}

static void reorder__4860_closure_160(uint64_t fused_0fused_0fused_0fused_0_fuseiter_9310___fuseiter_9311_3008___fuseiter_9312_3009___fuseiter_9313_3010___fuseiter_9314_3011, float* __restrict__ __ins_0, float* __restrict__ __outs_0) noexcept{
  for (uint64_t _fuseiter_9315 = 0UL; _fuseiter_9315 < 64UL; _fuseiter_9315 += 16UL) {
    vec_f32x16 __cached_0;
    __cached_0 = vec_f32x16::load(&__ins_0[(((fused_0fused_0fused_0fused_0_fuseiter_9310___fuseiter_9311_3008___fuseiter_9312_3009___fuseiter_9313_3010___fuseiter_9314_3011 / 16UL) * 1024UL) + (_fuseiter_9315 + ((fused_0fused_0fused_0fused_0_fuseiter_9310___fuseiter_9311_3008___fuseiter_9312_3009___fuseiter_9313_3010___fuseiter_9314_3011 % 16UL) * 64UL)))]);
    vec_f32x16 __cached_1;
    __cached_1 = __cached_0;
    vec_f32x16::store(__cached_1, &__outs_0[(((fused_0fused_0fused_0fused_0_fuseiter_9310___fuseiter_9311_3008___fuseiter_9312_3009___fuseiter_9313_3010___fuseiter_9314_3011 / 16UL) * 1024UL) + (((fused_0fused_0fused_0fused_0_fuseiter_9310___fuseiter_9311_3008___fuseiter_9312_3009___fuseiter_9313_3010___fuseiter_9314_3011 % 16UL) * 64UL) + _fuseiter_9315))]);
  }
}

static void reorder__4860_closure_160_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept{
  reorder__4860_closure_160(i, (float*)(args[0UL].v_ptr), (float*)(args[1UL].v_ptr));
}

static void mul__6230_closure_161(uint64_t fused_0fused_0fused_0fused_0__itr_0____itr_1_3012____itr_2_3013____itr_3_3014____itr_4_3015, float* __restrict__ __ins_0, float* __restrict__ __ins_1, float* __restrict__ __outs_0) noexcept{
  for (uint64_t _fuseiter_9321 = 0UL; _fuseiter_9321 < 64UL; _fuseiter_9321 += 16UL) {
    vec_f32x16 __cached_0;
    __cached_0 = vec_f32x16::load(&__ins_0[((((fused_0fused_0fused_0fused_0__itr_0____itr_1_3012____itr_2_3013____itr_3_3014____itr_4_3015 / 16UL) * 1024UL) + ((fused_0fused_0fused_0fused_0__itr_0____itr_1_3012____itr_2_3013____itr_3_3014____itr_4_3015 % 16UL) * 64UL)) + _fuseiter_9321)]);
    float __cached_1;
    __cached_1 = __ins_1[0];
    vec_f32x16 __cached_2;
    __cached_2 = (__cached_0 * vec_f32x16(__cached_1));
    vec_f32x16::store(__cached_2, &__outs_0[((((fused_0fused_0fused_0fused_0__itr_0____itr_1_3012____itr_2_3013____itr_3_3014____itr_4_3015 / 16UL) * 1024UL) + ((fused_0fused_0fused_0fused_0__itr_0____itr_1_3012____itr_2_3013____itr_3_3014____itr_4_3015 % 16UL) * 64UL)) + _fuseiter_9321)]);
  }
}

static void mul__6230_closure_161_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept{
  mul__6230_closure_161(i, (float*)(args[0UL].v_ptr), (float*)(args[1UL].v_ptr), (float*)(args[2UL].v_ptr));
}

static void reorder__4950_closure_162(uint64_t fused_0fused_0fused_0fused_0_fuseiter_9323___fuseiter_9324_3016___fuseiter_9325_3017___fuseiter_9326_3018___fuseiter_9327_3019, float* __restrict__ __ins_0, float* __restrict__ __outs_0) noexcept{
  for (uint64_t _fuseiter_9328 = 0UL; _fuseiter_9328 < 64UL; _fuseiter_9328 += 16UL) {
    vec_f32x16 __cached_0;
    __cached_0 = vec_f32x16::load(&__ins_0[(((fused_0fused_0fused_0fused_0_fuseiter_9323___fuseiter_9324_3016___fuseiter_9325_3017___fuseiter_9326_3018___fuseiter_9327_3019 / 16UL) * 1024UL) + (_fuseiter_9328 + ((fused_0fused_0fused_0fused_0_fuseiter_9323___fuseiter_9324_3016___fuseiter_9325_3017___fuseiter_9326_3018___fuseiter_9327_3019 % 16UL) * 64UL)))]);
    vec_f32x16 __cached_1;
    __cached_1 = __cached_0;
    vec_f32x16::store(__cached_1, &__outs_0[(((fused_0fused_0fused_0fused_0_fuseiter_9323___fuseiter_9324_3016___fuseiter_9325_3017___fuseiter_9326_3018___fuseiter_9327_3019 / 16UL) * 1024UL) + (((fused_0fused_0fused_0fused_0_fuseiter_9323___fuseiter_9324_3016___fuseiter_9325_3017___fuseiter_9326_3018___fuseiter_9327_3019 % 16UL) * 64UL) + _fuseiter_9328))]);
  }
}

static void reorder__4950_closure_162_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept{
  reorder__4950_closure_162(i, (float*)(args[0UL].v_ptr), (float*)(args[1UL].v_ptr));
}

static void mul__6290_closure_163(uint64_t fused_0fused_0fused_0fused_0__itr_0____itr_1_3020____itr_2_3021____itr_3_3022____itr_4_3023, float* __restrict__ __ins_0, float* __restrict__ __ins_1, float* __restrict__ __outs_0) noexcept{
  for (uint64_t _fuseiter_9334 = 0UL; _fuseiter_9334 < 64UL; _fuseiter_9334 += 16UL) {
    vec_f32x16 __cached_0;
    __cached_0 = vec_f32x16::load(&__ins_0[((((fused_0fused_0fused_0fused_0__itr_0____itr_1_3020____itr_2_3021____itr_3_3022____itr_4_3023 / 16UL) * 1024UL) + ((fused_0fused_0fused_0fused_0__itr_0____itr_1_3020____itr_2_3021____itr_3_3022____itr_4_3023 % 16UL) * 64UL)) + _fuseiter_9334)]);
    float __cached_1;
    __cached_1 = __ins_1[0];
    vec_f32x16 __cached_2;
    __cached_2 = (__cached_0 * vec_f32x16(__cached_1));
    vec_f32x16::store(__cached_2, &__outs_0[((((fused_0fused_0fused_0fused_0__itr_0____itr_1_3020____itr_2_3021____itr_3_3022____itr_4_3023 / 16UL) * 1024UL) + ((fused_0fused_0fused_0fused_0__itr_0____itr_1_3020____itr_2_3021____itr_3_3022____itr_4_3023 % 16UL) * 64UL)) + _fuseiter_9334)]);
  }
}

static void mul__6290_closure_163_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept{
  mul__6290_closure_163(i, (float*)(args[0UL].v_ptr), (float*)(args[1UL].v_ptr), (float*)(args[2UL].v_ptr));
}

static void reorder__5040_closure_164(uint64_t fused_0fused_0fused_0fused_0_fuseiter_9336___fuseiter_9337_3024___fuseiter_9338_3025___fuseiter_9339_3026___fuseiter_9340_3027, float* __restrict__ __ins_0, float* __restrict__ __outs_0) noexcept{
  for (uint64_t _fuseiter_9341 = 0UL; _fuseiter_9341 < 64UL; _fuseiter_9341 += 16UL) {
    vec_f32x16 __cached_0;
    __cached_0 = vec_f32x16::load(&__ins_0[(((fused_0fused_0fused_0fused_0_fuseiter_9336___fuseiter_9337_3024___fuseiter_9338_3025___fuseiter_9339_3026___fuseiter_9340_3027 / 16UL) * 1024UL) + (_fuseiter_9341 + ((fused_0fused_0fused_0fused_0_fuseiter_9336___fuseiter_9337_3024___fuseiter_9338_3025___fuseiter_9339_3026___fuseiter_9340_3027 % 16UL) * 64UL)))]);
    vec_f32x16 __cached_1;
    __cached_1 = __cached_0;
    vec_f32x16::store(__cached_1, &__outs_0[(((fused_0fused_0fused_0fused_0_fuseiter_9336___fuseiter_9337_3024___fuseiter_9338_3025___fuseiter_9339_3026___fuseiter_9340_3027 / 16UL) * 1024UL) + (((fused_0fused_0fused_0fused_0_fuseiter_9336___fuseiter_9337_3024___fuseiter_9338_3025___fuseiter_9339_3026___fuseiter_9340_3027 % 16UL) * 64UL) + _fuseiter_9341))]);
  }
}

static void reorder__5040_closure_164_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept{
  reorder__5040_closure_164(i, (float*)(args[0UL].v_ptr), (float*)(args[1UL].v_ptr));
}

static void mul__6350_closure_165(uint64_t fused_0fused_0fused_0fused_0__itr_0____itr_1_3028____itr_2_3029____itr_3_3030____itr_4_3031, float* __restrict__ __ins_0, float* __restrict__ __ins_1, float* __restrict__ __outs_0) noexcept{
  for (uint64_t _fuseiter_9347 = 0UL; _fuseiter_9347 < 64UL; _fuseiter_9347 += 16UL) {
    vec_f32x16 __cached_0;
    __cached_0 = vec_f32x16::load(&__ins_0[((((fused_0fused_0fused_0fused_0__itr_0____itr_1_3028____itr_2_3029____itr_3_3030____itr_4_3031 / 16UL) * 1024UL) + ((fused_0fused_0fused_0fused_0__itr_0____itr_1_3028____itr_2_3029____itr_3_3030____itr_4_3031 % 16UL) * 64UL)) + _fuseiter_9347)]);
    float __cached_1;
    __cached_1 = __ins_1[0];
    vec_f32x16 __cached_2;
    __cached_2 = (__cached_0 * vec_f32x16(__cached_1));
    vec_f32x16::store(__cached_2, &__outs_0[((((fused_0fused_0fused_0fused_0__itr_0____itr_1_3028____itr_2_3029____itr_3_3030____itr_4_3031 / 16UL) * 1024UL) + ((fused_0fused_0fused_0fused_0__itr_0____itr_1_3028____itr_2_3029____itr_3_3030____itr_4_3031 % 16UL) * 64UL)) + _fuseiter_9347)]);
  }
}

static void mul__6350_closure_165_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept{
  mul__6350_closure_165(i, (float*)(args[0UL].v_ptr), (float*)(args[1UL].v_ptr), (float*)(args[2UL].v_ptr));
}

static void reorder__5130_closure_166(uint64_t fused_0fused_0fused_0fused_0_fuseiter_9349___fuseiter_9350_3032___fuseiter_9351_3033___fuseiter_9352_3034___fuseiter_9353_3035, float* __restrict__ __ins_0, float* __restrict__ __outs_0) noexcept{
  for (uint64_t _fuseiter_9354 = 0UL; _fuseiter_9354 < 64UL; _fuseiter_9354 += 16UL) {
    vec_f32x16 __cached_0;
    __cached_0 = vec_f32x16::load(&__ins_0[(((fused_0fused_0fused_0fused_0_fuseiter_9349___fuseiter_9350_3032___fuseiter_9351_3033___fuseiter_9352_3034___fuseiter_9353_3035 / 16UL) * 1024UL) + (_fuseiter_9354 + ((fused_0fused_0fused_0fused_0_fuseiter_9349___fuseiter_9350_3032___fuseiter_9351_3033___fuseiter_9352_3034___fuseiter_9353_3035 % 16UL) * 64UL)))]);
    vec_f32x16 __cached_1;
    __cached_1 = __cached_0;
    vec_f32x16::store(__cached_1, &__outs_0[(((fused_0fused_0fused_0fused_0_fuseiter_9349___fuseiter_9350_3032___fuseiter_9351_3033___fuseiter_9352_3034___fuseiter_9353_3035 / 16UL) * 1024UL) + (((fused_0fused_0fused_0fused_0_fuseiter_9349___fuseiter_9350_3032___fuseiter_9351_3033___fuseiter_9352_3034___fuseiter_9353_3035 % 16UL) * 64UL) + _fuseiter_9354))]);
  }
}

static void reorder__5130_closure_166_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept{
  reorder__5130_closure_166(i, (float*)(args[0UL].v_ptr), (float*)(args[1UL].v_ptr));
}

static void mul__6410_closure_167(uint64_t fused_0fused_0fused_0fused_0__itr_0____itr_1_3036____itr_2_3037____itr_3_3038____itr_4_3039, float* __restrict__ __ins_0, float* __restrict__ __ins_1, float* __restrict__ __outs_0) noexcept{
  for (uint64_t _fuseiter_9360 = 0UL; _fuseiter_9360 < 64UL; _fuseiter_9360 += 16UL) {
    vec_f32x16 __cached_0;
    __cached_0 = vec_f32x16::load(&__ins_0[((((fused_0fused_0fused_0fused_0__itr_0____itr_1_3036____itr_2_3037____itr_3_3038____itr_4_3039 / 16UL) * 1024UL) + ((fused_0fused_0fused_0fused_0__itr_0____itr_1_3036____itr_2_3037____itr_3_3038____itr_4_3039 % 16UL) * 64UL)) + _fuseiter_9360)]);
    float __cached_1;
    __cached_1 = __ins_1[0];
    vec_f32x16 __cached_2;
    __cached_2 = (__cached_0 * vec_f32x16(__cached_1));
    vec_f32x16::store(__cached_2, &__outs_0[((((fused_0fused_0fused_0fused_0__itr_0____itr_1_3036____itr_2_3037____itr_3_3038____itr_4_3039 / 16UL) * 1024UL) + ((fused_0fused_0fused_0fused_0__itr_0____itr_1_3036____itr_2_3037____itr_3_3038____itr_4_3039 % 16UL) * 64UL)) + _fuseiter_9360)]);
  }
}

static void mul__6410_closure_167_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept{
  mul__6410_closure_167(i, (float*)(args[0UL].v_ptr), (float*)(args[1UL].v_ptr), (float*)(args[2UL].v_ptr));
}

static void reorder__5220_closure_168(uint64_t fused_0fused_0fused_0fused_0_fuseiter_9362___fuseiter_9363_3040___fuseiter_9364_3041___fuseiter_9365_3042___fuseiter_9366_3043, float* __restrict__ __ins_0, float* __restrict__ __outs_0) noexcept{
  for (uint64_t _fuseiter_9367 = 0UL; _fuseiter_9367 < 64UL; _fuseiter_9367 += 16UL) {
    vec_f32x16 __cached_0;
    __cached_0 = vec_f32x16::load(&__ins_0[(((fused_0fused_0fused_0fused_0_fuseiter_9362___fuseiter_9363_3040___fuseiter_9364_3041___fuseiter_9365_3042___fuseiter_9366_3043 / 16UL) * 1024UL) + (_fuseiter_9367 + ((fused_0fused_0fused_0fused_0_fuseiter_9362___fuseiter_9363_3040___fuseiter_9364_3041___fuseiter_9365_3042___fuseiter_9366_3043 % 16UL) * 64UL)))]);
    vec_f32x16 __cached_1;
    __cached_1 = __cached_0;
    vec_f32x16::store(__cached_1, &__outs_0[(((fused_0fused_0fused_0fused_0_fuseiter_9362___fuseiter_9363_3040___fuseiter_9364_3041___fuseiter_9365_3042___fuseiter_9366_3043 / 16UL) * 1024UL) + (((fused_0fused_0fused_0fused_0_fuseiter_9362___fuseiter_9363_3040___fuseiter_9364_3041___fuseiter_9365_3042___fuseiter_9366_3043 % 16UL) * 64UL) + _fuseiter_9367))]);
  }
}

static void reorder__5220_closure_168_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept{
  reorder__5220_closure_168(i, (float*)(args[0UL].v_ptr), (float*)(args[1UL].v_ptr));
}

static void mul__6470_closure_169(uint64_t fused_0fused_0fused_0fused_0__itr_0____itr_1_3044____itr_2_3045____itr_3_3046____itr_4_3047, float* __restrict__ __ins_0, float* __restrict__ __ins_1, float* __restrict__ __outs_0) noexcept{
  for (uint64_t _fuseiter_9373 = 0UL; _fuseiter_9373 < 64UL; _fuseiter_9373 += 16UL) {
    vec_f32x16 __cached_0;
    __cached_0 = vec_f32x16::load(&__ins_0[((((fused_0fused_0fused_0fused_0__itr_0____itr_1_3044____itr_2_3045____itr_3_3046____itr_4_3047 / 16UL) * 1024UL) + ((fused_0fused_0fused_0fused_0__itr_0____itr_1_3044____itr_2_3045____itr_3_3046____itr_4_3047 % 16UL) * 64UL)) + _fuseiter_9373)]);
    float __cached_1;
    __cached_1 = __ins_1[0];
    vec_f32x16 __cached_2;
    __cached_2 = (__cached_0 * vec_f32x16(__cached_1));
    vec_f32x16::store(__cached_2, &__outs_0[((((fused_0fused_0fused_0fused_0__itr_0____itr_1_3044____itr_2_3045____itr_3_3046____itr_4_3047 / 16UL) * 1024UL) + ((fused_0fused_0fused_0fused_0__itr_0____itr_1_3044____itr_2_3045____itr_3_3046____itr_4_3047 % 16UL) * 64UL)) + _fuseiter_9373)]);
  }
}

static void mul__6470_closure_169_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept{
  mul__6470_closure_169(i, (float*)(args[0UL].v_ptr), (float*)(args[1UL].v_ptr), (float*)(args[2UL].v_ptr));
}

static void reorder__5310_closure_170(uint64_t fused_0fused_0fused_0fused_0_fuseiter_9375___fuseiter_9376_3048___fuseiter_9377_3049___fuseiter_9378_3050___fuseiter_9379_3051, float* __restrict__ __ins_0, float* __restrict__ __outs_0) noexcept{
  for (uint64_t _fuseiter_9380 = 0UL; _fuseiter_9380 < 64UL; _fuseiter_9380 += 16UL) {
    vec_f32x16 __cached_0;
    __cached_0 = vec_f32x16::load(&__ins_0[(((fused_0fused_0fused_0fused_0_fuseiter_9375___fuseiter_9376_3048___fuseiter_9377_3049___fuseiter_9378_3050___fuseiter_9379_3051 / 16UL) * 1024UL) + (_fuseiter_9380 + ((fused_0fused_0fused_0fused_0_fuseiter_9375___fuseiter_9376_3048___fuseiter_9377_3049___fuseiter_9378_3050___fuseiter_9379_3051 % 16UL) * 64UL)))]);
    vec_f32x16 __cached_1;
    __cached_1 = __cached_0;
    vec_f32x16::store(__cached_1, &__outs_0[(((fused_0fused_0fused_0fused_0_fuseiter_9375___fuseiter_9376_3048___fuseiter_9377_3049___fuseiter_9378_3050___fuseiter_9379_3051 / 16UL) * 1024UL) + (((fused_0fused_0fused_0fused_0_fuseiter_9375___fuseiter_9376_3048___fuseiter_9377_3049___fuseiter_9378_3050___fuseiter_9379_3051 % 16UL) * 64UL) + _fuseiter_9380))]);
  }
}

static void reorder__5310_closure_170_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept{
  reorder__5310_closure_170(i, (float*)(args[0UL].v_ptr), (float*)(args[1UL].v_ptr));
}

static void mul__6530_closure_171(uint64_t fused_0fused_0fused_0fused_0__itr_0____itr_1_3052____itr_2_3053____itr_3_3054____itr_4_3055, float* __restrict__ __ins_0, float* __restrict__ __ins_1, float* __restrict__ __outs_0) noexcept{
  for (uint64_t _fuseiter_9386 = 0UL; _fuseiter_9386 < 64UL; _fuseiter_9386 += 16UL) {
    vec_f32x16 __cached_0;
    __cached_0 = vec_f32x16::load(&__ins_0[((((fused_0fused_0fused_0fused_0__itr_0____itr_1_3052____itr_2_3053____itr_3_3054____itr_4_3055 / 16UL) * 1024UL) + ((fused_0fused_0fused_0fused_0__itr_0____itr_1_3052____itr_2_3053____itr_3_3054____itr_4_3055 % 16UL) * 64UL)) + _fuseiter_9386)]);
    float __cached_1;
    __cached_1 = __ins_1[0];
    vec_f32x16 __cached_2;
    __cached_2 = (__cached_0 * vec_f32x16(__cached_1));
    vec_f32x16::store(__cached_2, &__outs_0[((((fused_0fused_0fused_0fused_0__itr_0____itr_1_3052____itr_2_3053____itr_3_3054____itr_4_3055 / 16UL) * 1024UL) + ((fused_0fused_0fused_0fused_0__itr_0____itr_1_3052____itr_2_3053____itr_3_3054____itr_4_3055 % 16UL) * 64UL)) + _fuseiter_9386)]);
  }
}

static void mul__6530_closure_171_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept{
  mul__6530_closure_171(i, (float*)(args[0UL].v_ptr), (float*)(args[1UL].v_ptr), (float*)(args[2UL].v_ptr));
}

static void reorder__5340_closure_172(uint64_t fused_0fused_0fused_0fused_0_fuseiter_9388___fuseiter_9389_3056___fuseiter_9390_3057___fuseiter_9391_3058___fuseiter_9392_3059, float* __restrict__ __ins_0, float* __restrict__ __outs_0) noexcept{
  for (uint64_t _fuseiter_9393 = 0UL; _fuseiter_9393 < 512UL; _fuseiter_9393 += 16UL) {
    vec_f32x16 __cached_0;
    __cached_0 = vec_f32x16::load(&__ins_0[(((fused_0fused_0fused_0fused_0_fuseiter_9388___fuseiter_9389_3056___fuseiter_9390_3057___fuseiter_9391_3058___fuseiter_9392_3059 / 4UL) * 2048UL) + (_fuseiter_9393 + ((fused_0fused_0fused_0fused_0_fuseiter_9388___fuseiter_9389_3056___fuseiter_9390_3057___fuseiter_9391_3058___fuseiter_9392_3059 % 4UL) * 512UL)))]);
    vec_f32x16 __cached_1;
    __cached_1 = __cached_0;
    vec_f32x16::store(__cached_1, &__outs_0[(((fused_0fused_0fused_0fused_0_fuseiter_9388___fuseiter_9389_3056___fuseiter_9390_3057___fuseiter_9391_3058___fuseiter_9392_3059 / 4UL) * 2048UL) + (((fused_0fused_0fused_0fused_0_fuseiter_9388___fuseiter_9389_3056___fuseiter_9390_3057___fuseiter_9391_3058___fuseiter_9392_3059 % 4UL) * 512UL) + _fuseiter_9393))]);
  }
}

static void reorder__5340_closure_172_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept{
  reorder__5340_closure_172(i, (float*)(args[0UL].v_ptr), (float*)(args[1UL].v_ptr));
}

static void mul__6550_closure_173(uint64_t fused_0fused_0fused_0fused_0__itr_0____itr_1_3060____itr_2_3061____itr_3_3062____itr_4_3063, float* __restrict__ __ins_0, float* __restrict__ __ins_1, float* __restrict__ __outs_0) noexcept{
  for (uint64_t _fuseiter_9399 = 0UL; _fuseiter_9399 < 512UL; _fuseiter_9399 += 16UL) {
    vec_f32x16 __cached_0;
    __cached_0 = vec_f32x16::load(&__ins_0[((((fused_0fused_0fused_0fused_0__itr_0____itr_1_3060____itr_2_3061____itr_3_3062____itr_4_3063 / 4UL) * 2048UL) + ((fused_0fused_0fused_0fused_0__itr_0____itr_1_3060____itr_2_3061____itr_3_3062____itr_4_3063 % 4UL) * 512UL)) + _fuseiter_9399)]);
    float __cached_1;
    __cached_1 = __ins_1[0];
    vec_f32x16 __cached_2;
    __cached_2 = (__cached_0 * vec_f32x16(__cached_1));
    vec_f32x16::store(__cached_2, &__outs_0[((((fused_0fused_0fused_0fused_0__itr_0____itr_1_3060____itr_2_3061____itr_3_3062____itr_4_3063 / 4UL) * 2048UL) + ((fused_0fused_0fused_0fused_0__itr_0____itr_1_3060____itr_2_3061____itr_3_3062____itr_4_3063 % 4UL) * 512UL)) + _fuseiter_9399)]);
  }
}

static void mul__6550_closure_173_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept{
  mul__6550_closure_173(i, (float*)(args[0UL].v_ptr), (float*)(args[1UL].v_ptr), (float*)(args[2UL].v_ptr));
}

static void reorder__5410_closure_174(uint64_t fused_0fused_0fused_0fused_0_fuseiter_9401___fuseiter_9402_3064___fuseiter_9403_3065___fuseiter_9404_3066___fuseiter_9405_3067, float* __restrict__ __ins_0, float* __restrict__ __outs_0) noexcept{
  for (uint64_t _fuseiter_9406 = 0UL; _fuseiter_9406 < 512UL; _fuseiter_9406 += 16UL) {
    vec_f32x16 __cached_0;
    __cached_0 = vec_f32x16::load(&__ins_0[(((fused_0fused_0fused_0fused_0_fuseiter_9401___fuseiter_9402_3064___fuseiter_9403_3065___fuseiter_9404_3066___fuseiter_9405_3067 / 4UL) * 2048UL) + (_fuseiter_9406 + ((fused_0fused_0fused_0fused_0_fuseiter_9401___fuseiter_9402_3064___fuseiter_9403_3065___fuseiter_9404_3066___fuseiter_9405_3067 % 4UL) * 512UL)))]);
    vec_f32x16 __cached_1;
    __cached_1 = __cached_0;
    vec_f32x16::store(__cached_1, &__outs_0[(((fused_0fused_0fused_0fused_0_fuseiter_9401___fuseiter_9402_3064___fuseiter_9403_3065___fuseiter_9404_3066___fuseiter_9405_3067 / 4UL) * 2048UL) + (((fused_0fused_0fused_0fused_0_fuseiter_9401___fuseiter_9402_3064___fuseiter_9403_3065___fuseiter_9404_3066___fuseiter_9405_3067 % 4UL) * 512UL) + _fuseiter_9406))]);
  }
}

static void reorder__5410_closure_174_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept{
  reorder__5410_closure_174(i, (float*)(args[0UL].v_ptr), (float*)(args[1UL].v_ptr));
}

static void mul__6610_closure_175(uint64_t fused_0fused_0fused_0fused_0__itr_0____itr_1_3068____itr_2_3069____itr_3_3070____itr_4_3071, float* __restrict__ __ins_0, float* __restrict__ __ins_1, float* __restrict__ __outs_0) noexcept{
  for (uint64_t _fuseiter_9412 = 0UL; _fuseiter_9412 < 512UL; _fuseiter_9412 += 16UL) {
    vec_f32x16 __cached_0;
    __cached_0 = vec_f32x16::load(&__ins_0[((((fused_0fused_0fused_0fused_0__itr_0____itr_1_3068____itr_2_3069____itr_3_3070____itr_4_3071 / 4UL) * 2048UL) + ((fused_0fused_0fused_0fused_0__itr_0____itr_1_3068____itr_2_3069____itr_3_3070____itr_4_3071 % 4UL) * 512UL)) + _fuseiter_9412)]);
    float __cached_1;
    __cached_1 = __ins_1[0];
    vec_f32x16 __cached_2;
    __cached_2 = (__cached_0 * vec_f32x16(__cached_1));
    vec_f32x16::store(__cached_2, &__outs_0[((((fused_0fused_0fused_0fused_0__itr_0____itr_1_3068____itr_2_3069____itr_3_3070____itr_4_3071 / 4UL) * 2048UL) + ((fused_0fused_0fused_0fused_0__itr_0____itr_1_3068____itr_2_3069____itr_3_3070____itr_4_3071 % 4UL) * 512UL)) + _fuseiter_9412)]);
  }
}

static void mul__6610_closure_175_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept{
  mul__6610_closure_175(i, (float*)(args[0UL].v_ptr), (float*)(args[1UL].v_ptr), (float*)(args[2UL].v_ptr));
}

static void reorder__5500_closure_176(uint64_t fused_0fused_0fused_0fused_0_fuseiter_9414___fuseiter_9415_3072___fuseiter_9416_3073___fuseiter_9417_3074___fuseiter_9418_3075, float* __restrict__ __ins_0, float* __restrict__ __outs_0) noexcept{
  for (uint64_t _fuseiter_9419 = 0UL; _fuseiter_9419 < 512UL; _fuseiter_9419 += 16UL) {
    vec_f32x16 __cached_0;
    __cached_0 = vec_f32x16::load(&__ins_0[(((fused_0fused_0fused_0fused_0_fuseiter_9414___fuseiter_9415_3072___fuseiter_9416_3073___fuseiter_9417_3074___fuseiter_9418_3075 / 4UL) * 2048UL) + (_fuseiter_9419 + ((fused_0fused_0fused_0fused_0_fuseiter_9414___fuseiter_9415_3072___fuseiter_9416_3073___fuseiter_9417_3074___fuseiter_9418_3075 % 4UL) * 512UL)))]);
    vec_f32x16 __cached_1;
    __cached_1 = __cached_0;
    vec_f32x16::store(__cached_1, &__outs_0[(((fused_0fused_0fused_0fused_0_fuseiter_9414___fuseiter_9415_3072___fuseiter_9416_3073___fuseiter_9417_3074___fuseiter_9418_3075 / 4UL) * 2048UL) + (((fused_0fused_0fused_0fused_0_fuseiter_9414___fuseiter_9415_3072___fuseiter_9416_3073___fuseiter_9417_3074___fuseiter_9418_3075 % 4UL) * 512UL) + _fuseiter_9419))]);
  }
}

static void reorder__5500_closure_176_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept{
  reorder__5500_closure_176(i, (float*)(args[0UL].v_ptr), (float*)(args[1UL].v_ptr));
}

static void mul__6670_closure_177(uint64_t fused_0fused_0fused_0fused_0__itr_0____itr_1_3076____itr_2_3077____itr_3_3078____itr_4_3079, float* __restrict__ __ins_0, float* __restrict__ __ins_1, float* __restrict__ __outs_0) noexcept{
  for (uint64_t _fuseiter_9425 = 0UL; _fuseiter_9425 < 512UL; _fuseiter_9425 += 16UL) {
    vec_f32x16 __cached_0;
    __cached_0 = vec_f32x16::load(&__ins_0[((((fused_0fused_0fused_0fused_0__itr_0____itr_1_3076____itr_2_3077____itr_3_3078____itr_4_3079 / 4UL) * 2048UL) + ((fused_0fused_0fused_0fused_0__itr_0____itr_1_3076____itr_2_3077____itr_3_3078____itr_4_3079 % 4UL) * 512UL)) + _fuseiter_9425)]);
    float __cached_1;
    __cached_1 = __ins_1[0];
    vec_f32x16 __cached_2;
    __cached_2 = (__cached_0 * vec_f32x16(__cached_1));
    vec_f32x16::store(__cached_2, &__outs_0[((((fused_0fused_0fused_0fused_0__itr_0____itr_1_3076____itr_2_3077____itr_3_3078____itr_4_3079 / 4UL) * 2048UL) + ((fused_0fused_0fused_0fused_0__itr_0____itr_1_3076____itr_2_3077____itr_3_3078____itr_4_3079 % 4UL) * 512UL)) + _fuseiter_9425)]);
  }
}

static void mul__6670_closure_177_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept{
  mul__6670_closure_177(i, (float*)(args[0UL].v_ptr), (float*)(args[1UL].v_ptr), (float*)(args[2UL].v_ptr));
}

static void reorder__5590_closure_178(uint64_t fused_0fused_0fused_0fused_0_fuseiter_9427___fuseiter_9428_3080___fuseiter_9429_3081___fuseiter_9430_3082___fuseiter_9431_3083, float* __restrict__ __ins_0, float* __restrict__ __outs_0) noexcept{
  for (uint64_t _fuseiter_9432 = 0UL; _fuseiter_9432 < 512UL; _fuseiter_9432 += 16UL) {
    vec_f32x16 __cached_0;
    __cached_0 = vec_f32x16::load(&__ins_0[(((fused_0fused_0fused_0fused_0_fuseiter_9427___fuseiter_9428_3080___fuseiter_9429_3081___fuseiter_9430_3082___fuseiter_9431_3083 / 4UL) * 2048UL) + (_fuseiter_9432 + ((fused_0fused_0fused_0fused_0_fuseiter_9427___fuseiter_9428_3080___fuseiter_9429_3081___fuseiter_9430_3082___fuseiter_9431_3083 % 4UL) * 512UL)))]);
    vec_f32x16 __cached_1;
    __cached_1 = __cached_0;
    vec_f32x16::store(__cached_1, &__outs_0[(((fused_0fused_0fused_0fused_0_fuseiter_9427___fuseiter_9428_3080___fuseiter_9429_3081___fuseiter_9430_3082___fuseiter_9431_3083 / 4UL) * 2048UL) + (((fused_0fused_0fused_0fused_0_fuseiter_9427___fuseiter_9428_3080___fuseiter_9429_3081___fuseiter_9430_3082___fuseiter_9431_3083 % 4UL) * 512UL) + _fuseiter_9432))]);
  }
}

static void reorder__5590_closure_178_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept{
  reorder__5590_closure_178(i, (float*)(args[0UL].v_ptr), (float*)(args[1UL].v_ptr));
}

static void mul__6730_closure_179(uint64_t fused_0fused_0fused_0fused_0__itr_0____itr_1_3084____itr_2_3085____itr_3_3086____itr_4_3087, float* __restrict__ __ins_0, float* __restrict__ __ins_1, float* __restrict__ __outs_0) noexcept{
  for (uint64_t _fuseiter_9438 = 0UL; _fuseiter_9438 < 512UL; _fuseiter_9438 += 16UL) {
    vec_f32x16 __cached_0;
    __cached_0 = vec_f32x16::load(&__ins_0[((((fused_0fused_0fused_0fused_0__itr_0____itr_1_3084____itr_2_3085____itr_3_3086____itr_4_3087 / 4UL) * 2048UL) + ((fused_0fused_0fused_0fused_0__itr_0____itr_1_3084____itr_2_3085____itr_3_3086____itr_4_3087 % 4UL) * 512UL)) + _fuseiter_9438)]);
    float __cached_1;
    __cached_1 = __ins_1[0];
    vec_f32x16 __cached_2;
    __cached_2 = (__cached_0 * vec_f32x16(__cached_1));
    vec_f32x16::store(__cached_2, &__outs_0[((((fused_0fused_0fused_0fused_0__itr_0____itr_1_3084____itr_2_3085____itr_3_3086____itr_4_3087 / 4UL) * 2048UL) + ((fused_0fused_0fused_0fused_0__itr_0____itr_1_3084____itr_2_3085____itr_3_3086____itr_4_3087 % 4UL) * 512UL)) + _fuseiter_9438)]);
  }
}

static void mul__6730_closure_179_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept{
  mul__6730_closure_179(i, (float*)(args[0UL].v_ptr), (float*)(args[1UL].v_ptr), (float*)(args[2UL].v_ptr));
}

static void mul__1100_closure_180(uint64_t fused_0fused_0__itr_0____itr_1_3088____itr_2_3089, float* __restrict__ __ins_0, float* __restrict__ __ins_1, float* __restrict__ __outs_0) noexcept{
  float __cached_0;
  __cached_0 = __ins_0[(((fused_0fused_0__itr_0____itr_1_3088____itr_2_3089 / 64UL) * 64UL) + (fused_0fused_0__itr_0____itr_1_3088____itr_2_3089 % 64UL))];
  float __cached_1;
  __cached_1 = __ins_1[(fused_0fused_0__itr_0____itr_1_3088____itr_2_3089 / 64UL)];
  float __cached_2;
  __cached_2 = (__cached_0 * __cached_1);
  __outs_0[(((fused_0fused_0__itr_0____itr_1_3088____itr_2_3089 / 64UL) * 64UL) + (fused_0fused_0__itr_0____itr_1_3088____itr_2_3089 % 64UL))] = __cached_2;
}

static void mul__1100_closure_180_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept{
  mul__1100_closure_180(i, (float*)(args[0UL].v_ptr), (float*)(args[1UL].v_ptr), (float*)(args[2UL].v_ptr));
}

static void cast__1110_closure_181(uint64_t fused_0fused_0__itr_0____itr_1_3090____itr_2_3091, float* __restrict__ __ins_0, int8_t* __restrict__ __outs_0) noexcept{
  float __cached_0;
  __cached_0 = __ins_0[(((fused_0fused_0__itr_0____itr_1_3090____itr_2_3091 / 64UL) * 64UL) + (fused_0fused_0__itr_0____itr_1_3090____itr_2_3091 % 64UL))];
  int8_t __cached_1;
  __cached_1 = (int8_t)sc_max(sc_min(sc_round_and_cast<int32_t>(__cached_0), 127), -128);
  __outs_0[(((fused_0fused_0__itr_0____itr_1_3090____itr_2_3091 / 64UL) * 64UL) + (fused_0fused_0__itr_0____itr_1_3090____itr_2_3091 % 64UL))] = __cached_1;
}

static void cast__1110_closure_181_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept{
  cast__1110_closure_181(i, (float*)(args[0UL].v_ptr), (int8_t*)(args[1UL].v_ptr));
}

static void reorder__4210_closure_182(uint64_t fused_0fused_0fused_0fused_0fused_0_fuseiter_9450___fuseiter_9451_3092___fuseiter_9452_3093___fuseiter_9453_3094___fuseiter_9454_3095___fuseiter_9455_3096, int8_t* __restrict__ __ins_0, int8_t* __restrict__ __outs_0) noexcept{
  for (uint64_t _fuseiter_9456 = 0UL; _fuseiter_9456 < 4UL; _fuseiter_9456 += 1UL) {
    int8_t __cached_0;
    __cached_0 = __ins_0[((((fused_0fused_0fused_0fused_0fused_0_fuseiter_9450___fuseiter_9451_3092___fuseiter_9452_3093___fuseiter_9453_3094___fuseiter_9454_3095___fuseiter_9455_3096 % 64UL) + ((fused_0fused_0fused_0fused_0fused_0_fuseiter_9450___fuseiter_9451_3092___fuseiter_9452_3093___fuseiter_9453_3094___fuseiter_9454_3095___fuseiter_9455_3096 / 1024UL) * 64UL)) * 64UL) + (_fuseiter_9456 + (((fused_0fused_0fused_0fused_0fused_0_fuseiter_9450___fuseiter_9451_3092___fuseiter_9452_3093___fuseiter_9453_3094___fuseiter_9454_3095___fuseiter_9455_3096 / 64UL) % 16UL) * 4UL)))];
    int8_t __cached_1;
    __cached_1 = __cached_0;
    __outs_0[(((fused_0fused_0fused_0fused_0fused_0_fuseiter_9450___fuseiter_9451_3092___fuseiter_9452_3093___fuseiter_9453_3094___fuseiter_9454_3095___fuseiter_9455_3096 / 1024UL) * 4096UL) + ((((fused_0fused_0fused_0fused_0fused_0_fuseiter_9450___fuseiter_9451_3092___fuseiter_9452_3093___fuseiter_9453_3094___fuseiter_9454_3095___fuseiter_9455_3096 / 64UL) % 16UL) * 256UL) + (((fused_0fused_0fused_0fused_0fused_0_fuseiter_9450___fuseiter_9451_3092___fuseiter_9452_3093___fuseiter_9453_3094___fuseiter_9454_3095___fuseiter_9455_3096 % 64UL) * 4UL) + _fuseiter_9456)))] = __cached_1;
  }
}

static void reorder__4210_closure_182_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept{
  reorder__4210_closure_182(i, (int8_t*)(args[0UL].v_ptr), (int8_t*)(args[1UL].v_ptr));
}

static void mul__1070_closure_183(uint64_t fused_0fused_0__itr_0____itr_1_3097____itr_2_3098, float* __restrict__ __ins_0, float* __restrict__ __ins_1, float* __restrict__ __outs_0) noexcept{
  float __cached_0;
  __cached_0 = __ins_0[(((fused_0fused_0__itr_0____itr_1_3097____itr_2_3098 / 64UL) * 64UL) + (fused_0fused_0__itr_0____itr_1_3097____itr_2_3098 % 64UL))];
  float __cached_1;
  __cached_1 = __ins_1[(fused_0fused_0__itr_0____itr_1_3097____itr_2_3098 / 64UL)];
  float __cached_2;
  __cached_2 = (__cached_0 * __cached_1);
  __outs_0[(((fused_0fused_0__itr_0____itr_1_3097____itr_2_3098 / 64UL) * 64UL) + (fused_0fused_0__itr_0____itr_1_3097____itr_2_3098 % 64UL))] = __cached_2;
}

static void mul__1070_closure_183_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept{
  mul__1070_closure_183(i, (float*)(args[0UL].v_ptr), (float*)(args[1UL].v_ptr), (float*)(args[2UL].v_ptr));
}

static void cast__1080_closure_184(uint64_t fused_0fused_0__itr_0____itr_1_3099____itr_2_3100, float* __restrict__ __ins_0, int8_t* __restrict__ __outs_0) noexcept{
  float __cached_0;
  __cached_0 = __ins_0[(((fused_0fused_0__itr_0____itr_1_3099____itr_2_3100 / 64UL) * 64UL) + (fused_0fused_0__itr_0____itr_1_3099____itr_2_3100 % 64UL))];
  int8_t __cached_1;
  __cached_1 = (int8_t)sc_max(sc_min(sc_round_and_cast<int32_t>(__cached_0), 127), -128);
  __outs_0[(((fused_0fused_0__itr_0____itr_1_3099____itr_2_3100 / 64UL) * 64UL) + (fused_0fused_0__itr_0____itr_1_3099____itr_2_3100 % 64UL))] = __cached_1;
}

static void cast__1080_closure_184_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept{
  cast__1080_closure_184(i, (float*)(args[0UL].v_ptr), (int8_t*)(args[1UL].v_ptr));
}

static void reorder__4180_closure_185(uint64_t fused_0fused_0fused_0fused_0_fuseiter_9467___fuseiter_9468_3101___fuseiter_9469_3102___fuseiter_9470_3103___fuseiter_9471_3104, int8_t* __restrict__ __ins_0, int8_t* __restrict__ __outs_0) noexcept{
  for (uint64_t _fuseiter_9472 = 0UL; _fuseiter_9472 < 64UL; _fuseiter_9472 += 1UL) {
    for (uint64_t _fuseiter_9473 = 0UL; _fuseiter_9473 < 4UL; _fuseiter_9473 += 1UL) {
      int8_t __cached_0;
      __cached_0 = __ins_0[(((_fuseiter_9472 + ((fused_0fused_0fused_0fused_0_fuseiter_9467___fuseiter_9468_3101___fuseiter_9469_3102___fuseiter_9470_3103___fuseiter_9471_3104 / 16UL) * 64UL)) * 64UL) + (_fuseiter_9473 + ((fused_0fused_0fused_0fused_0_fuseiter_9467___fuseiter_9468_3101___fuseiter_9469_3102___fuseiter_9470_3103___fuseiter_9471_3104 % 16UL) * 4UL)))];
      int8_t __cached_1;
      __cached_1 = __cached_0;
      __outs_0[(((fused_0fused_0fused_0fused_0_fuseiter_9467___fuseiter_9468_3101___fuseiter_9469_3102___fuseiter_9470_3103___fuseiter_9471_3104 / 16UL) * 4096UL) + (((fused_0fused_0fused_0fused_0_fuseiter_9467___fuseiter_9468_3101___fuseiter_9469_3102___fuseiter_9470_3103___fuseiter_9471_3104 % 16UL) * 256UL) + ((_fuseiter_9472 * 4UL) + _fuseiter_9473)))] = __cached_1;
    }
  }
}

static void reorder__4180_closure_185_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept{
  reorder__4180_closure_185(i, (int8_t*)(args[0UL].v_ptr), (int8_t*)(args[1UL].v_ptr));
}

static void mul__1160_closure_186(uint64_t fused_0fused_0__itr_0____itr_1_3105____itr_2_3106, float* __restrict__ __ins_0, float* __restrict__ __ins_1, float* __restrict__ __outs_0) noexcept{
  float __cached_0;
  __cached_0 = __ins_0[(((fused_0fused_0__itr_0____itr_1_3105____itr_2_3106 / 64UL) * 64UL) + (fused_0fused_0__itr_0____itr_1_3105____itr_2_3106 % 64UL))];
  float __cached_1;
  __cached_1 = __ins_1[(fused_0fused_0__itr_0____itr_1_3105____itr_2_3106 / 64UL)];
  float __cached_2;
  __cached_2 = (__cached_0 * __cached_1);
  __outs_0[(((fused_0fused_0__itr_0____itr_1_3105____itr_2_3106 / 64UL) * 64UL) + (fused_0fused_0__itr_0____itr_1_3105____itr_2_3106 % 64UL))] = __cached_2;
}

static void mul__1160_closure_186_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept{
  mul__1160_closure_186(i, (float*)(args[0UL].v_ptr), (float*)(args[1UL].v_ptr), (float*)(args[2UL].v_ptr));
}

static void cast__1170_closure_187(uint64_t fused_0fused_0__itr_0____itr_1_3107____itr_2_3108, float* __restrict__ __ins_0, int8_t* __restrict__ __outs_0) noexcept{
  float __cached_0;
  __cached_0 = __ins_0[(((fused_0fused_0__itr_0____itr_1_3107____itr_2_3108 / 64UL) * 64UL) + (fused_0fused_0__itr_0____itr_1_3107____itr_2_3108 % 64UL))];
  int8_t __cached_1;
  __cached_1 = (int8_t)sc_max(sc_min(sc_round_and_cast<int32_t>(__cached_0), 127), -128);
  __outs_0[(((fused_0fused_0__itr_0____itr_1_3107____itr_2_3108 / 64UL) * 64UL) + (fused_0fused_0__itr_0____itr_1_3107____itr_2_3108 % 64UL))] = __cached_1;
}

static void cast__1170_closure_187_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept{
  cast__1170_closure_187(i, (float*)(args[0UL].v_ptr), (int8_t*)(args[1UL].v_ptr));
}

static void reorder__4230_closure_188(uint64_t fused_0fused_0fused_0fused_0_fuseiter_9484___fuseiter_9485_3109___fuseiter_9486_3110___fuseiter_9487_3111___fuseiter_9488_3112, int8_t* __restrict__ __ins_0, int8_t* __restrict__ __outs_0) noexcept{
  for (uint64_t _fuseiter_9489 = 0UL; _fuseiter_9489 < 64UL; _fuseiter_9489 += 1UL) {
    for (uint64_t _fuseiter_9490 = 0UL; _fuseiter_9490 < 4UL; _fuseiter_9490 += 1UL) {
      int8_t __cached_0;
      __cached_0 = __ins_0[(((_fuseiter_9489 + ((fused_0fused_0fused_0fused_0_fuseiter_9484___fuseiter_9485_3109___fuseiter_9486_3110___fuseiter_9487_3111___fuseiter_9488_3112 / 16UL) * 64UL)) * 64UL) + (_fuseiter_9490 + ((fused_0fused_0fused_0fused_0_fuseiter_9484___fuseiter_9485_3109___fuseiter_9486_3110___fuseiter_9487_3111___fuseiter_9488_3112 % 16UL) * 4UL)))];
      int8_t __cached_1;
      __cached_1 = __cached_0;
      __outs_0[(((fused_0fused_0fused_0fused_0_fuseiter_9484___fuseiter_9485_3109___fuseiter_9486_3110___fuseiter_9487_3111___fuseiter_9488_3112 / 16UL) * 4096UL) + (((fused_0fused_0fused_0fused_0_fuseiter_9484___fuseiter_9485_3109___fuseiter_9486_3110___fuseiter_9487_3111___fuseiter_9488_3112 % 16UL) * 256UL) + ((_fuseiter_9489 * 4UL) + _fuseiter_9490)))] = __cached_1;
    }
  }
}

static void reorder__4230_closure_188_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept{
  reorder__4230_closure_188(i, (int8_t*)(args[0UL].v_ptr), (int8_t*)(args[1UL].v_ptr));
}

static void mul__1250_closure_189(uint64_t fused_0fused_0__itr_0____itr_1_3113____itr_2_3114, float* __restrict__ __ins_0, float* __restrict__ __ins_1, float* __restrict__ __outs_0) noexcept{
  float __cached_0;
  __cached_0 = __ins_0[(((fused_0fused_0__itr_0____itr_1_3113____itr_2_3114 / 64UL) * 64UL) + (fused_0fused_0__itr_0____itr_1_3113____itr_2_3114 % 64UL))];
  float __cached_1;
  __cached_1 = __ins_1[(fused_0fused_0__itr_0____itr_1_3113____itr_2_3114 / 64UL)];
  float __cached_2;
  __cached_2 = (__cached_0 * __cached_1);
  __outs_0[(((fused_0fused_0__itr_0____itr_1_3113____itr_2_3114 / 64UL) * 64UL) + (fused_0fused_0__itr_0____itr_1_3113____itr_2_3114 % 64UL))] = __cached_2;
}

static void mul__1250_closure_189_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept{
  mul__1250_closure_189(i, (float*)(args[0UL].v_ptr), (float*)(args[1UL].v_ptr), (float*)(args[2UL].v_ptr));
}

static void cast__1260_closure_190(uint64_t fused_0fused_0__itr_0____itr_1_3115____itr_2_3116, float* __restrict__ __ins_0, int8_t* __restrict__ __outs_0) noexcept{
  float __cached_0;
  __cached_0 = __ins_0[(((fused_0fused_0__itr_0____itr_1_3115____itr_2_3116 / 64UL) * 64UL) + (fused_0fused_0__itr_0____itr_1_3115____itr_2_3116 % 64UL))];
  int8_t __cached_1;
  __cached_1 = (int8_t)sc_max(sc_min(sc_round_and_cast<int32_t>(__cached_0), 127), -128);
  __outs_0[(((fused_0fused_0__itr_0____itr_1_3115____itr_2_3116 / 64UL) * 64UL) + (fused_0fused_0__itr_0____itr_1_3115____itr_2_3116 % 64UL))] = __cached_1;
}

static void cast__1260_closure_190_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept{
  cast__1260_closure_190(i, (float*)(args[0UL].v_ptr), (int8_t*)(args[1UL].v_ptr));
}

static void reorder__4280_closure_191(uint64_t fused_0fused_0fused_0fused_0_fuseiter_9501___fuseiter_9502_3117___fuseiter_9503_3118___fuseiter_9504_3119___fuseiter_9505_3120, int8_t* __restrict__ __ins_0, int8_t* __restrict__ __outs_0) noexcept{
  for (uint64_t _fuseiter_9506 = 0UL; _fuseiter_9506 < 64UL; _fuseiter_9506 += 1UL) {
    for (uint64_t _fuseiter_9507 = 0UL; _fuseiter_9507 < 4UL; _fuseiter_9507 += 1UL) {
      int8_t __cached_0;
      __cached_0 = __ins_0[(((_fuseiter_9506 + ((fused_0fused_0fused_0fused_0_fuseiter_9501___fuseiter_9502_3117___fuseiter_9503_3118___fuseiter_9504_3119___fuseiter_9505_3120 / 16UL) * 64UL)) * 64UL) + (_fuseiter_9507 + ((fused_0fused_0fused_0fused_0_fuseiter_9501___fuseiter_9502_3117___fuseiter_9503_3118___fuseiter_9504_3119___fuseiter_9505_3120 % 16UL) * 4UL)))];
      int8_t __cached_1;
      __cached_1 = __cached_0;
      __outs_0[(((fused_0fused_0fused_0fused_0_fuseiter_9501___fuseiter_9502_3117___fuseiter_9503_3118___fuseiter_9504_3119___fuseiter_9505_3120 / 16UL) * 4096UL) + (((fused_0fused_0fused_0fused_0_fuseiter_9501___fuseiter_9502_3117___fuseiter_9503_3118___fuseiter_9504_3119___fuseiter_9505_3120 % 16UL) * 256UL) + ((_fuseiter_9506 * 4UL) + _fuseiter_9507)))] = __cached_1;
    }
  }
}

static void reorder__4280_closure_191_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept{
  reorder__4280_closure_191(i, (int8_t*)(args[0UL].v_ptr), (int8_t*)(args[1UL].v_ptr));
}

static void mul__1340_closure_192(uint64_t fused_0fused_0__itr_0____itr_1_3121____itr_2_3122, float* __restrict__ __ins_0, float* __restrict__ __ins_1, float* __restrict__ __outs_0) noexcept{
  float __cached_0;
  __cached_0 = __ins_0[(((fused_0fused_0__itr_0____itr_1_3121____itr_2_3122 / 64UL) * 64UL) + (fused_0fused_0__itr_0____itr_1_3121____itr_2_3122 % 64UL))];
  float __cached_1;
  __cached_1 = __ins_1[(fused_0fused_0__itr_0____itr_1_3121____itr_2_3122 / 64UL)];
  float __cached_2;
  __cached_2 = (__cached_0 * __cached_1);
  __outs_0[(((fused_0fused_0__itr_0____itr_1_3121____itr_2_3122 / 64UL) * 64UL) + (fused_0fused_0__itr_0____itr_1_3121____itr_2_3122 % 64UL))] = __cached_2;
}

static void mul__1340_closure_192_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept{
  mul__1340_closure_192(i, (float*)(args[0UL].v_ptr), (float*)(args[1UL].v_ptr), (float*)(args[2UL].v_ptr));
}

static void cast__1350_closure_193(uint64_t fused_0fused_0__itr_0____itr_1_3123____itr_2_3124, float* __restrict__ __ins_0, int8_t* __restrict__ __outs_0) noexcept{
  float __cached_0;
  __cached_0 = __ins_0[(((fused_0fused_0__itr_0____itr_1_3123____itr_2_3124 / 64UL) * 64UL) + (fused_0fused_0__itr_0____itr_1_3123____itr_2_3124 % 64UL))];
  int8_t __cached_1;
  __cached_1 = (int8_t)sc_max(sc_min(sc_round_and_cast<int32_t>(__cached_0), 127), -128);
  __outs_0[(((fused_0fused_0__itr_0____itr_1_3123____itr_2_3124 / 64UL) * 64UL) + (fused_0fused_0__itr_0____itr_1_3123____itr_2_3124 % 64UL))] = __cached_1;
}

static void cast__1350_closure_193_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept{
  cast__1350_closure_193(i, (float*)(args[0UL].v_ptr), (int8_t*)(args[1UL].v_ptr));
}

static void reorder__4330_closure_194(uint64_t fused_0fused_0fused_0fused_0_fuseiter_9518___fuseiter_9519_3125___fuseiter_9520_3126___fuseiter_9521_3127___fuseiter_9522_3128, int8_t* __restrict__ __ins_0, int8_t* __restrict__ __outs_0) noexcept{
  for (uint64_t _fuseiter_9523 = 0UL; _fuseiter_9523 < 64UL; _fuseiter_9523 += 1UL) {
    for (uint64_t _fuseiter_9524 = 0UL; _fuseiter_9524 < 4UL; _fuseiter_9524 += 1UL) {
      int8_t __cached_0;
      __cached_0 = __ins_0[(((_fuseiter_9523 + ((fused_0fused_0fused_0fused_0_fuseiter_9518___fuseiter_9519_3125___fuseiter_9520_3126___fuseiter_9521_3127___fuseiter_9522_3128 / 16UL) * 64UL)) * 64UL) + (_fuseiter_9524 + ((fused_0fused_0fused_0fused_0_fuseiter_9518___fuseiter_9519_3125___fuseiter_9520_3126___fuseiter_9521_3127___fuseiter_9522_3128 % 16UL) * 4UL)))];
      int8_t __cached_1;
      __cached_1 = __cached_0;
      __outs_0[(((fused_0fused_0fused_0fused_0_fuseiter_9518___fuseiter_9519_3125___fuseiter_9520_3126___fuseiter_9521_3127___fuseiter_9522_3128 / 16UL) * 4096UL) + (((fused_0fused_0fused_0fused_0_fuseiter_9518___fuseiter_9519_3125___fuseiter_9520_3126___fuseiter_9521_3127___fuseiter_9522_3128 % 16UL) * 256UL) + ((_fuseiter_9523 * 4UL) + _fuseiter_9524)))] = __cached_1;
    }
  }
}

static void reorder__4330_closure_194_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept{
  reorder__4330_closure_194(i, (int8_t*)(args[0UL].v_ptr), (int8_t*)(args[1UL].v_ptr));
}

static void mul__1190_closure_195(uint64_t fused_0fused_0__itr_0____itr_1_3129____itr_2_3130, float* __restrict__ __ins_0, float* __restrict__ __ins_1, float* __restrict__ __outs_0) noexcept{
  float __cached_0;
  __cached_0 = __ins_0[(((fused_0fused_0__itr_0____itr_1_3129____itr_2_3130 / 256UL) * 256UL) + (fused_0fused_0__itr_0____itr_1_3129____itr_2_3130 % 256UL))];
  float __cached_1;
  __cached_1 = __ins_1[(fused_0fused_0__itr_0____itr_1_3129____itr_2_3130 / 256UL)];
  float __cached_2;
  __cached_2 = (__cached_0 * __cached_1);
  __outs_0[(((fused_0fused_0__itr_0____itr_1_3129____itr_2_3130 / 256UL) * 256UL) + (fused_0fused_0__itr_0____itr_1_3129____itr_2_3130 % 256UL))] = __cached_2;
}

static void mul__1190_closure_195_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept{
  mul__1190_closure_195(i, (float*)(args[0UL].v_ptr), (float*)(args[1UL].v_ptr), (float*)(args[2UL].v_ptr));
}

static void cast__1200_closure_196(uint64_t fused_0fused_0__itr_0____itr_1_3131____itr_2_3132, float* __restrict__ __ins_0, int8_t* __restrict__ __outs_0) noexcept{
  float __cached_0;
  __cached_0 = __ins_0[(((fused_0fused_0__itr_0____itr_1_3131____itr_2_3132 / 256UL) * 256UL) + (fused_0fused_0__itr_0____itr_1_3131____itr_2_3132 % 256UL))];
  int8_t __cached_1;
  __cached_1 = (int8_t)sc_max(sc_min(sc_round_and_cast<int32_t>(__cached_0), 127), -128);
  __outs_0[(((fused_0fused_0__itr_0____itr_1_3131____itr_2_3132 / 256UL) * 256UL) + (fused_0fused_0__itr_0____itr_1_3131____itr_2_3132 % 256UL))] = __cached_1;
}

static void cast__1200_closure_196_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept{
  cast__1200_closure_196(i, (float*)(args[0UL].v_ptr), (int8_t*)(args[1UL].v_ptr));
}

static void reorder__4260_closure_197(uint64_t fused_0fused_0fused_0fused_0_fuseiter_9535___fuseiter_9536_3133___fuseiter_9537_3134___fuseiter_9538_3135___fuseiter_9539_3136, int8_t* __restrict__ __ins_0, int8_t* __restrict__ __outs_0) noexcept{
  for (uint64_t _fuseiter_9540 = 0UL; _fuseiter_9540 < 64UL; _fuseiter_9540 += 1UL) {
    for (uint64_t _fuseiter_9541 = 0UL; _fuseiter_9541 < 4UL; _fuseiter_9541 += 1UL) {
      int8_t __cached_0;
      __cached_0 = __ins_0[(((_fuseiter_9540 + ((fused_0fused_0fused_0fused_0_fuseiter_9535___fuseiter_9536_3133___fuseiter_9537_3134___fuseiter_9538_3135___fuseiter_9539_3136 / 64UL) * 64UL)) * 256UL) + ((_fuseiter_9541 + ((fused_0fused_0fused_0fused_0_fuseiter_9535___fuseiter_9536_3133___fuseiter_9537_3134___fuseiter_9538_3135___fuseiter_9539_3136 % 16UL) * 4UL)) + (((fused_0fused_0fused_0fused_0_fuseiter_9535___fuseiter_9536_3133___fuseiter_9537_3134___fuseiter_9538_3135___fuseiter_9539_3136 / 16UL) % 4UL) * 64UL)))];
      int8_t __cached_1;
      __cached_1 = __cached_0;
      __outs_0[(((fused_0fused_0fused_0fused_0_fuseiter_9535___fuseiter_9536_3133___fuseiter_9537_3134___fuseiter_9538_3135___fuseiter_9539_3136 / 64UL) * 16384UL) + ((((fused_0fused_0fused_0fused_0_fuseiter_9535___fuseiter_9536_3133___fuseiter_9537_3134___fuseiter_9538_3135___fuseiter_9539_3136 / 16UL) % 4UL) * 4096UL) + (((fused_0fused_0fused_0fused_0_fuseiter_9535___fuseiter_9536_3133___fuseiter_9537_3134___fuseiter_9538_3135___fuseiter_9539_3136 % 16UL) * 256UL) + ((_fuseiter_9540 * 4UL) + _fuseiter_9541))))] = __cached_1;
    }
  }
}

static void reorder__4260_closure_197_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept{
  reorder__4260_closure_197(i, (int8_t*)(args[0UL].v_ptr), (int8_t*)(args[1UL].v_ptr));
}

static void mul__1280_closure_198(uint64_t fused_0fused_0__itr_0____itr_1_3137____itr_2_3138, float* __restrict__ __ins_0, float* __restrict__ __ins_1, float* __restrict__ __outs_0) noexcept{
  float __cached_0;
  __cached_0 = __ins_0[(((fused_0fused_0__itr_0____itr_1_3137____itr_2_3138 / 256UL) * 256UL) + (fused_0fused_0__itr_0____itr_1_3137____itr_2_3138 % 256UL))];
  float __cached_1;
  __cached_1 = __ins_1[(fused_0fused_0__itr_0____itr_1_3137____itr_2_3138 / 256UL)];
  float __cached_2;
  __cached_2 = (__cached_0 * __cached_1);
  __outs_0[(((fused_0fused_0__itr_0____itr_1_3137____itr_2_3138 / 256UL) * 256UL) + (fused_0fused_0__itr_0____itr_1_3137____itr_2_3138 % 256UL))] = __cached_2;
}

static void mul__1280_closure_198_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept{
  mul__1280_closure_198(i, (float*)(args[0UL].v_ptr), (float*)(args[1UL].v_ptr), (float*)(args[2UL].v_ptr));
}

static void cast__1290_closure_199(uint64_t fused_0fused_0__itr_0____itr_1_3139____itr_2_3140, float* __restrict__ __ins_0, int8_t* __restrict__ __outs_0) noexcept{
  float __cached_0;
  __cached_0 = __ins_0[(((fused_0fused_0__itr_0____itr_1_3139____itr_2_3140 / 256UL) * 256UL) + (fused_0fused_0__itr_0____itr_1_3139____itr_2_3140 % 256UL))];
  int8_t __cached_1;
  __cached_1 = (int8_t)sc_max(sc_min(sc_round_and_cast<int32_t>(__cached_0), 127), -128);
  __outs_0[(((fused_0fused_0__itr_0____itr_1_3139____itr_2_3140 / 256UL) * 256UL) + (fused_0fused_0__itr_0____itr_1_3139____itr_2_3140 % 256UL))] = __cached_1;
}

static void cast__1290_closure_199_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept{
  cast__1290_closure_199(i, (float*)(args[0UL].v_ptr), (int8_t*)(args[1UL].v_ptr));
}

static void reorder__4310_closure_200(uint64_t fused_0fused_0fused_0fused_0_fuseiter_9552___fuseiter_9553_3141___fuseiter_9554_3142___fuseiter_9555_3143___fuseiter_9556_3144, int8_t* __restrict__ __ins_0, int8_t* __restrict__ __outs_0) noexcept{
  for (uint64_t _fuseiter_9557 = 0UL; _fuseiter_9557 < 64UL; _fuseiter_9557 += 1UL) {
    for (uint64_t _fuseiter_9558 = 0UL; _fuseiter_9558 < 4UL; _fuseiter_9558 += 1UL) {
      int8_t __cached_0;
      __cached_0 = __ins_0[(((_fuseiter_9557 + ((fused_0fused_0fused_0fused_0_fuseiter_9552___fuseiter_9553_3141___fuseiter_9554_3142___fuseiter_9555_3143___fuseiter_9556_3144 / 64UL) * 64UL)) * 256UL) + ((_fuseiter_9558 + ((fused_0fused_0fused_0fused_0_fuseiter_9552___fuseiter_9553_3141___fuseiter_9554_3142___fuseiter_9555_3143___fuseiter_9556_3144 % 16UL) * 4UL)) + (((fused_0fused_0fused_0fused_0_fuseiter_9552___fuseiter_9553_3141___fuseiter_9554_3142___fuseiter_9555_3143___fuseiter_9556_3144 / 16UL) % 4UL) * 64UL)))];
      int8_t __cached_1;
      __cached_1 = __cached_0;
      __outs_0[(((fused_0fused_0fused_0fused_0_fuseiter_9552___fuseiter_9553_3141___fuseiter_9554_3142___fuseiter_9555_3143___fuseiter_9556_3144 / 64UL) * 16384UL) + ((((fused_0fused_0fused_0fused_0_fuseiter_9552___fuseiter_9553_3141___fuseiter_9554_3142___fuseiter_9555_3143___fuseiter_9556_3144 / 16UL) % 4UL) * 4096UL) + (((fused_0fused_0fused_0fused_0_fuseiter_9552___fuseiter_9553_3141___fuseiter_9554_3142___fuseiter_9555_3143___fuseiter_9556_3144 % 16UL) * 256UL) + ((_fuseiter_9557 * 4UL) + _fuseiter_9558))))] = __cached_1;
    }
  }
}

static void reorder__4310_closure_200_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept{
  reorder__4310_closure_200(i, (int8_t*)(args[0UL].v_ptr), (int8_t*)(args[1UL].v_ptr));
}

static void mul__1400_closure_201(uint64_t fused_0fused_0__itr_0____itr_1_3145____itr_2_3146, float* __restrict__ __ins_0, float* __restrict__ __ins_1, float* __restrict__ __outs_0) noexcept{
  float __cached_0;
  __cached_0 = __ins_0[(((fused_0fused_0__itr_0____itr_1_3145____itr_2_3146 / 256UL) * 256UL) + (fused_0fused_0__itr_0____itr_1_3145____itr_2_3146 % 256UL))];
  float __cached_1;
  __cached_1 = __ins_1[(fused_0fused_0__itr_0____itr_1_3145____itr_2_3146 / 256UL)];
  float __cached_2;
  __cached_2 = (__cached_0 * __cached_1);
  __outs_0[(((fused_0fused_0__itr_0____itr_1_3145____itr_2_3146 / 256UL) * 256UL) + (fused_0fused_0__itr_0____itr_1_3145____itr_2_3146 % 256UL))] = __cached_2;
}

static void mul__1400_closure_201_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept{
  mul__1400_closure_201(i, (float*)(args[0UL].v_ptr), (float*)(args[1UL].v_ptr), (float*)(args[2UL].v_ptr));
}

static void cast__1410_closure_202(uint64_t fused_0fused_0__itr_0____itr_1_3147____itr_2_3148, float* __restrict__ __ins_0, int8_t* __restrict__ __outs_0) noexcept{
  float __cached_0;
  __cached_0 = __ins_0[(((fused_0fused_0__itr_0____itr_1_3147____itr_2_3148 / 256UL) * 256UL) + (fused_0fused_0__itr_0____itr_1_3147____itr_2_3148 % 256UL))];
  int8_t __cached_1;
  __cached_1 = (int8_t)sc_max(sc_min(sc_round_and_cast<int32_t>(__cached_0), 127), -128);
  __outs_0[(((fused_0fused_0__itr_0____itr_1_3147____itr_2_3148 / 256UL) * 256UL) + (fused_0fused_0__itr_0____itr_1_3147____itr_2_3148 % 256UL))] = __cached_1;
}

static void cast__1410_closure_202_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept{
  cast__1410_closure_202(i, (float*)(args[0UL].v_ptr), (int8_t*)(args[1UL].v_ptr));
}

static void reorder__4390_closure_203(uint64_t fused_0fused_0fused_0fused_0_fuseiter_9569___fuseiter_9570_3149___fuseiter_9571_3150___fuseiter_9572_3151___fuseiter_9573_3152, int8_t* __restrict__ __ins_0, int8_t* __restrict__ __outs_0) noexcept{
  for (uint64_t _fuseiter_9574 = 0UL; _fuseiter_9574 < 64UL; _fuseiter_9574 += 1UL) {
    for (uint64_t _fuseiter_9575 = 0UL; _fuseiter_9575 < 4UL; _fuseiter_9575 += 1UL) {
      int8_t __cached_0;
      __cached_0 = __ins_0[(((_fuseiter_9574 + ((fused_0fused_0fused_0fused_0_fuseiter_9569___fuseiter_9570_3149___fuseiter_9571_3150___fuseiter_9572_3151___fuseiter_9573_3152 / 64UL) * 64UL)) * 256UL) + ((_fuseiter_9575 + ((fused_0fused_0fused_0fused_0_fuseiter_9569___fuseiter_9570_3149___fuseiter_9571_3150___fuseiter_9572_3151___fuseiter_9573_3152 % 16UL) * 4UL)) + (((fused_0fused_0fused_0fused_0_fuseiter_9569___fuseiter_9570_3149___fuseiter_9571_3150___fuseiter_9572_3151___fuseiter_9573_3152 / 16UL) % 4UL) * 64UL)))];
      int8_t __cached_1;
      __cached_1 = __cached_0;
      __outs_0[(((fused_0fused_0fused_0fused_0_fuseiter_9569___fuseiter_9570_3149___fuseiter_9571_3150___fuseiter_9572_3151___fuseiter_9573_3152 / 64UL) * 16384UL) + ((((fused_0fused_0fused_0fused_0_fuseiter_9569___fuseiter_9570_3149___fuseiter_9571_3150___fuseiter_9572_3151___fuseiter_9573_3152 / 16UL) % 4UL) * 4096UL) + (((fused_0fused_0fused_0fused_0_fuseiter_9569___fuseiter_9570_3149___fuseiter_9571_3150___fuseiter_9572_3151___fuseiter_9573_3152 % 16UL) * 256UL) + ((_fuseiter_9574 * 4UL) + _fuseiter_9575))))] = __cached_1;
    }
  }
}

static void reorder__4390_closure_203_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept{
  reorder__4390_closure_203(i, (int8_t*)(args[0UL].v_ptr), (int8_t*)(args[1UL].v_ptr));
}

static void mul__1130_closure_204(uint64_t fused_0fused_0__itr_0____itr_1_3153____itr_2_3154, float* __restrict__ __ins_0, float* __restrict__ __ins_1, float* __restrict__ __outs_0) noexcept{
  for (uint64_t _fuseiter_9580 = 0UL; _fuseiter_9580 < 3UL; _fuseiter_9580 += 1UL) {
    float __cached_0;
    __cached_0 = __ins_0[((((fused_0fused_0__itr_0____itr_1_3153____itr_2_3154 / 192UL) * 576UL) + ((((fused_0fused_0__itr_0____itr_1_3153____itr_2_3154 / 3UL) % 64UL) * 9UL) + ((fused_0fused_0__itr_0____itr_1_3153____itr_2_3154 % 3UL) * 3UL))) + _fuseiter_9580)];
    float __cached_1;
    __cached_1 = __ins_1[(fused_0fused_0__itr_0____itr_1_3153____itr_2_3154 / 192UL)];
    float __cached_2;
    __cached_2 = (__cached_0 * __cached_1);
    __outs_0[((((fused_0fused_0__itr_0____itr_1_3153____itr_2_3154 / 192UL) * 576UL) + ((((fused_0fused_0__itr_0____itr_1_3153____itr_2_3154 / 3UL) % 64UL) * 9UL) + ((fused_0fused_0__itr_0____itr_1_3153____itr_2_3154 % 3UL) * 3UL))) + _fuseiter_9580)] = __cached_2;
  }
}

static void mul__1130_closure_204_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept{
  mul__1130_closure_204(i, (float*)(args[0UL].v_ptr), (float*)(args[1UL].v_ptr), (float*)(args[2UL].v_ptr));
}

static void cast__1140_closure_205(uint64_t fused_0fused_0__itr_0____itr_1_3155____itr_2_3156, float* __restrict__ __ins_0, int8_t* __restrict__ __outs_0) noexcept{
  for (uint64_t _fuseiter9585 = 0UL; _fuseiter9585 < 3UL; _fuseiter9585 += 1UL) {
    float __cached_0;
    __cached_0 = __ins_0[((((fused_0fused_0__itr_0____itr_1_3155____itr_2_3156 / 192UL) * 576UL) + ((((fused_0fused_0__itr_0____itr_1_3155____itr_2_3156 / 3UL) % 64UL) * 9UL) + ((fused_0fused_0__itr_0____itr_1_3155____itr_2_3156 % 3UL) * 3UL))) + _fuseiter9585)];
    int8_t __cached_1;
    __cached_1 = (int8_t)sc_max(sc_min(sc_round_and_cast<int32_t>(__cached_0), 127), -128);
    __outs_0[((((fused_0fused_0__itr_0____itr_1_3155____itr_2_3156 / 192UL) * 576UL) + ((((fused_0fused_0__itr_0____itr_1_3155____itr_2_3156 / 3UL) % 64UL) * 9UL) + ((fused_0fused_0__itr_0____itr_1_3155____itr_2_3156 % 3UL) * 3UL))) + _fuseiter9585)] = __cached_1;
  }
}

static void cast__1140_closure_205_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept{
  cast__1140_closure_205(i, (float*)(args[0UL].v_ptr), (int8_t*)(args[1UL].v_ptr));
}

static void reorder__4220_closure_206(uint64_t fused_0fused_0fused_0fused_0_fuseiter_9586___fuseiter_9587_3157___fuseiter_9588_3158___fuseiter_9589_3159___fuseiter_9590_3160, int8_t* __restrict__ __ins_0, int8_t* __restrict__ __outs_0) noexcept{
  for (uint64_t _fuseiter_9591 = 0UL; _fuseiter_9591 < 64UL; _fuseiter_9591 += 1UL) {
    for (uint64_t _fuseiter_9592 = 0UL; _fuseiter_9592 < 4UL; _fuseiter_9592 += 1UL) {
      int8_t __cached_0;
      __cached_0 = __ins_0[(((_fuseiter_9591 + ((fused_0fused_0fused_0fused_0_fuseiter_9586___fuseiter_9587_3157___fuseiter_9588_3158___fuseiter_9589_3159___fuseiter_9590_3160 / 144UL) * 64UL)) * 576UL) + (((_fuseiter_9592 + ((fused_0fused_0fused_0fused_0_fuseiter_9586___fuseiter_9587_3157___fuseiter_9588_3158___fuseiter_9589_3159___fuseiter_9590_3160 % 16UL) * 4UL)) * 9UL) + ((((fused_0fused_0fused_0fused_0_fuseiter_9586___fuseiter_9587_3157___fuseiter_9588_3158___fuseiter_9589_3159___fuseiter_9590_3160 / 48UL) % 3UL) * 3UL) + ((fused_0fused_0fused_0fused_0_fuseiter_9586___fuseiter_9587_3157___fuseiter_9588_3158___fuseiter_9589_3159___fuseiter_9590_3160 / 16UL) % 3UL))))];
      int8_t __cached_1;
      __cached_1 = __cached_0;
      __outs_0[(((fused_0fused_0fused_0fused_0_fuseiter_9586___fuseiter_9587_3157___fuseiter_9588_3158___fuseiter_9589_3159___fuseiter_9590_3160 / 144UL) * 36864UL) + ((((fused_0fused_0fused_0fused_0_fuseiter_9586___fuseiter_9587_3157___fuseiter_9588_3158___fuseiter_9589_3159___fuseiter_9590_3160 / 48UL) % 3UL) * 12288UL) + ((((fused_0fused_0fused_0fused_0_fuseiter_9586___fuseiter_9587_3157___fuseiter_9588_3158___fuseiter_9589_3159___fuseiter_9590_3160 / 16UL) % 3UL) * 4096UL) + (((fused_0fused_0fused_0fused_0_fuseiter_9586___fuseiter_9587_3157___fuseiter_9588_3158___fuseiter_9589_3159___fuseiter_9590_3160 % 16UL) * 256UL) + ((_fuseiter_9591 * 4UL) + _fuseiter_9592)))))] = __cached_1;
    }
  }
}

static void reorder__4220_closure_206_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept{
  reorder__4220_closure_206(i, (int8_t*)(args[0UL].v_ptr), (int8_t*)(args[1UL].v_ptr));
}

static void mul__1220_closure_207(uint64_t fused_0fused_0__itr_0____itr_1_3161____itr_2_3162, float* __restrict__ __ins_0, float* __restrict__ __ins_1, float* __restrict__ __outs_0) noexcept{
  for (uint64_t _fuseiter_9597 = 0UL; _fuseiter_9597 < 3UL; _fuseiter_9597 += 1UL) {
    float __cached_0;
    __cached_0 = __ins_0[((((fused_0fused_0__itr_0____itr_1_3161____itr_2_3162 / 192UL) * 576UL) + ((((fused_0fused_0__itr_0____itr_1_3161____itr_2_3162 / 3UL) % 64UL) * 9UL) + ((fused_0fused_0__itr_0____itr_1_3161____itr_2_3162 % 3UL) * 3UL))) + _fuseiter_9597)];
    float __cached_1;
    __cached_1 = __ins_1[(fused_0fused_0__itr_0____itr_1_3161____itr_2_3162 / 192UL)];
    float __cached_2;
    __cached_2 = (__cached_0 * __cached_1);
    __outs_0[((((fused_0fused_0__itr_0____itr_1_3161____itr_2_3162 / 192UL) * 576UL) + ((((fused_0fused_0__itr_0____itr_1_3161____itr_2_3162 / 3UL) % 64UL) * 9UL) + ((fused_0fused_0__itr_0____itr_1_3161____itr_2_3162 % 3UL) * 3UL))) + _fuseiter_9597)] = __cached_2;
  }
}

static void mul__1220_closure_207_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept{
  mul__1220_closure_207(i, (float*)(args[0UL].v_ptr), (float*)(args[1UL].v_ptr), (float*)(args[2UL].v_ptr));
}

static void cast__1230_closure_208(uint64_t fused_0fused_0__itr_0____itr_1_3163____itr_2_3164, float* __restrict__ __ins_0, int8_t* __restrict__ __outs_0) noexcept{
  for (uint64_t _fuseiter9602 = 0UL; _fuseiter9602 < 3UL; _fuseiter9602 += 1UL) {
    float __cached_0;
    __cached_0 = __ins_0[((((fused_0fused_0__itr_0____itr_1_3163____itr_2_3164 / 192UL) * 576UL) + ((((fused_0fused_0__itr_0____itr_1_3163____itr_2_3164 / 3UL) % 64UL) * 9UL) + ((fused_0fused_0__itr_0____itr_1_3163____itr_2_3164 % 3UL) * 3UL))) + _fuseiter9602)];
    int8_t __cached_1;
    __cached_1 = (int8_t)sc_max(sc_min(sc_round_and_cast<int32_t>(__cached_0), 127), -128);
    __outs_0[((((fused_0fused_0__itr_0____itr_1_3163____itr_2_3164 / 192UL) * 576UL) + ((((fused_0fused_0__itr_0____itr_1_3163____itr_2_3164 / 3UL) % 64UL) * 9UL) + ((fused_0fused_0__itr_0____itr_1_3163____itr_2_3164 % 3UL) * 3UL))) + _fuseiter9602)] = __cached_1;
  }
}

static void cast__1230_closure_208_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept{
  cast__1230_closure_208(i, (float*)(args[0UL].v_ptr), (int8_t*)(args[1UL].v_ptr));
}

static void reorder__4270_closure_209(uint64_t fused_0fused_0fused_0fused_0_fuseiter_9603___fuseiter_9604_3165___fuseiter_9605_3166___fuseiter_9606_3167___fuseiter_9607_3168, int8_t* __restrict__ __ins_0, int8_t* __restrict__ __outs_0) noexcept{
  for (uint64_t _fuseiter_9608 = 0UL; _fuseiter_9608 < 64UL; _fuseiter_9608 += 1UL) {
    for (uint64_t _fuseiter_9609 = 0UL; _fuseiter_9609 < 4UL; _fuseiter_9609 += 1UL) {
      int8_t __cached_0;
      __cached_0 = __ins_0[(((_fuseiter_9608 + ((fused_0fused_0fused_0fused_0_fuseiter_9603___fuseiter_9604_3165___fuseiter_9605_3166___fuseiter_9606_3167___fuseiter_9607_3168 / 144UL) * 64UL)) * 576UL) + (((_fuseiter_9609 + ((fused_0fused_0fused_0fused_0_fuseiter_9603___fuseiter_9604_3165___fuseiter_9605_3166___fuseiter_9606_3167___fuseiter_9607_3168 % 16UL) * 4UL)) * 9UL) + ((((fused_0fused_0fused_0fused_0_fuseiter_9603___fuseiter_9604_3165___fuseiter_9605_3166___fuseiter_9606_3167___fuseiter_9607_3168 / 48UL) % 3UL) * 3UL) + ((fused_0fused_0fused_0fused_0_fuseiter_9603___fuseiter_9604_3165___fuseiter_9605_3166___fuseiter_9606_3167___fuseiter_9607_3168 / 16UL) % 3UL))))];
      int8_t __cached_1;
      __cached_1 = __cached_0;
      __outs_0[(((fused_0fused_0fused_0fused_0_fuseiter_9603___fuseiter_9604_3165___fuseiter_9605_3166___fuseiter_9606_3167___fuseiter_9607_3168 / 144UL) * 36864UL) + ((((fused_0fused_0fused_0fused_0_fuseiter_9603___fuseiter_9604_3165___fuseiter_9605_3166___fuseiter_9606_3167___fuseiter_9607_3168 / 48UL) % 3UL) * 12288UL) + ((((fused_0fused_0fused_0fused_0_fuseiter_9603___fuseiter_9604_3165___fuseiter_9605_3166___fuseiter_9606_3167___fuseiter_9607_3168 / 16UL) % 3UL) * 4096UL) + (((fused_0fused_0fused_0fused_0_fuseiter_9603___fuseiter_9604_3165___fuseiter_9605_3166___fuseiter_9606_3167___fuseiter_9607_3168 % 16UL) * 256UL) + ((_fuseiter_9608 * 4UL) + _fuseiter_9609)))))] = __cached_1;
    }
  }
}

static void reorder__4270_closure_209_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept{
  reorder__4270_closure_209(i, (int8_t*)(args[0UL].v_ptr), (int8_t*)(args[1UL].v_ptr));
}

static void mul__1310_closure_210(uint64_t fused_0fused_0__itr_0____itr_1_3169____itr_2_3170, float* __restrict__ __ins_0, float* __restrict__ __ins_1, float* __restrict__ __outs_0) noexcept{
  for (uint64_t _fuseiter_9614 = 0UL; _fuseiter_9614 < 3UL; _fuseiter_9614 += 1UL) {
    float __cached_0;
    __cached_0 = __ins_0[((((fused_0fused_0__itr_0____itr_1_3169____itr_2_3170 / 192UL) * 576UL) + ((((fused_0fused_0__itr_0____itr_1_3169____itr_2_3170 / 3UL) % 64UL) * 9UL) + ((fused_0fused_0__itr_0____itr_1_3169____itr_2_3170 % 3UL) * 3UL))) + _fuseiter_9614)];
    float __cached_1;
    __cached_1 = __ins_1[(fused_0fused_0__itr_0____itr_1_3169____itr_2_3170 / 192UL)];
    float __cached_2;
    __cached_2 = (__cached_0 * __cached_1);
    __outs_0[((((fused_0fused_0__itr_0____itr_1_3169____itr_2_3170 / 192UL) * 576UL) + ((((fused_0fused_0__itr_0____itr_1_3169____itr_2_3170 / 3UL) % 64UL) * 9UL) + ((fused_0fused_0__itr_0____itr_1_3169____itr_2_3170 % 3UL) * 3UL))) + _fuseiter_9614)] = __cached_2;
  }
}

static void mul__1310_closure_210_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept{
  mul__1310_closure_210(i, (float*)(args[0UL].v_ptr), (float*)(args[1UL].v_ptr), (float*)(args[2UL].v_ptr));
}

static void cast__1320_closure_211(uint64_t fused_0fused_0__itr_0____itr_1_3171____itr_2_3172, float* __restrict__ __ins_0, int8_t* __restrict__ __outs_0) noexcept{
  for (uint64_t _fuseiter9619 = 0UL; _fuseiter9619 < 3UL; _fuseiter9619 += 1UL) {
    float __cached_0;
    __cached_0 = __ins_0[((((fused_0fused_0__itr_0____itr_1_3171____itr_2_3172 / 192UL) * 576UL) + ((((fused_0fused_0__itr_0____itr_1_3171____itr_2_3172 / 3UL) % 64UL) * 9UL) + ((fused_0fused_0__itr_0____itr_1_3171____itr_2_3172 % 3UL) * 3UL))) + _fuseiter9619)];
    int8_t __cached_1;
    __cached_1 = (int8_t)sc_max(sc_min(sc_round_and_cast<int32_t>(__cached_0), 127), -128);
    __outs_0[((((fused_0fused_0__itr_0____itr_1_3171____itr_2_3172 / 192UL) * 576UL) + ((((fused_0fused_0__itr_0____itr_1_3171____itr_2_3172 / 3UL) % 64UL) * 9UL) + ((fused_0fused_0__itr_0____itr_1_3171____itr_2_3172 % 3UL) * 3UL))) + _fuseiter9619)] = __cached_1;
  }
}

static void cast__1320_closure_211_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept{
  cast__1320_closure_211(i, (float*)(args[0UL].v_ptr), (int8_t*)(args[1UL].v_ptr));
}

static void reorder__4320_closure_212(uint64_t fused_0fused_0fused_0fused_0_fuseiter_9620___fuseiter_9621_3173___fuseiter_9622_3174___fuseiter_9623_3175___fuseiter_9624_3176, int8_t* __restrict__ __ins_0, int8_t* __restrict__ __outs_0) noexcept{
  for (uint64_t _fuseiter_9625 = 0UL; _fuseiter_9625 < 64UL; _fuseiter_9625 += 1UL) {
    for (uint64_t _fuseiter_9626 = 0UL; _fuseiter_9626 < 4UL; _fuseiter_9626 += 1UL) {
      int8_t __cached_0;
      __cached_0 = __ins_0[(((_fuseiter_9625 + ((fused_0fused_0fused_0fused_0_fuseiter_9620___fuseiter_9621_3173___fuseiter_9622_3174___fuseiter_9623_3175___fuseiter_9624_3176 / 144UL) * 64UL)) * 576UL) + (((_fuseiter_9626 + ((fused_0fused_0fused_0fused_0_fuseiter_9620___fuseiter_9621_3173___fuseiter_9622_3174___fuseiter_9623_3175___fuseiter_9624_3176 % 16UL) * 4UL)) * 9UL) + ((((fused_0fused_0fused_0fused_0_fuseiter_9620___fuseiter_9621_3173___fuseiter_9622_3174___fuseiter_9623_3175___fuseiter_9624_3176 / 48UL) % 3UL) * 3UL) + ((fused_0fused_0fused_0fused_0_fuseiter_9620___fuseiter_9621_3173___fuseiter_9622_3174___fuseiter_9623_3175___fuseiter_9624_3176 / 16UL) % 3UL))))];
      int8_t __cached_1;
      __cached_1 = __cached_0;
      __outs_0[(((fused_0fused_0fused_0fused_0_fuseiter_9620___fuseiter_9621_3173___fuseiter_9622_3174___fuseiter_9623_3175___fuseiter_9624_3176 / 144UL) * 36864UL) + ((((fused_0fused_0fused_0fused_0_fuseiter_9620___fuseiter_9621_3173___fuseiter_9622_3174___fuseiter_9623_3175___fuseiter_9624_3176 / 48UL) % 3UL) * 12288UL) + ((((fused_0fused_0fused_0fused_0_fuseiter_9620___fuseiter_9621_3173___fuseiter_9622_3174___fuseiter_9623_3175___fuseiter_9624_3176 / 16UL) % 3UL) * 4096UL) + (((fused_0fused_0fused_0fused_0_fuseiter_9620___fuseiter_9621_3173___fuseiter_9622_3174___fuseiter_9623_3175___fuseiter_9624_3176 % 16UL) * 256UL) + ((_fuseiter_9625 * 4UL) + _fuseiter_9626)))))] = __cached_1;
    }
  }
}

static void reorder__4320_closure_212_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept{
  reorder__4320_closure_212(i, (int8_t*)(args[0UL].v_ptr), (int8_t*)(args[1UL].v_ptr));
}

static void mul__1460_closure_213(uint64_t fused_0fused_0__itr_0____itr_1_3177____itr_2_3178, float* __restrict__ __ins_0, float* __restrict__ __ins_1, float* __restrict__ __outs_0) noexcept{
  float __cached_0;
  __cached_0 = __ins_0[(((fused_0fused_0__itr_0____itr_1_3177____itr_2_3178 / 128UL) * 128UL) + (fused_0fused_0__itr_0____itr_1_3177____itr_2_3178 % 128UL))];
  float __cached_1;
  __cached_1 = __ins_1[(fused_0fused_0__itr_0____itr_1_3177____itr_2_3178 / 128UL)];
  float __cached_2;
  __cached_2 = (__cached_0 * __cached_1);
  __outs_0[(((fused_0fused_0__itr_0____itr_1_3177____itr_2_3178 / 128UL) * 128UL) + (fused_0fused_0__itr_0____itr_1_3177____itr_2_3178 % 128UL))] = __cached_2;
}

static void mul__1460_closure_213_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept{
  mul__1460_closure_213(i, (float*)(args[0UL].v_ptr), (float*)(args[1UL].v_ptr), (float*)(args[2UL].v_ptr));
}

static void cast__1470_closure_214(uint64_t fused_0fused_0__itr_0____itr_1_3179____itr_2_3180, float* __restrict__ __ins_0, int8_t* __restrict__ __outs_0) noexcept{
  float __cached_0;
  __cached_0 = __ins_0[(((fused_0fused_0__itr_0____itr_1_3179____itr_2_3180 / 128UL) * 128UL) + (fused_0fused_0__itr_0____itr_1_3179____itr_2_3180 % 128UL))];
  int8_t __cached_1;
  __cached_1 = (int8_t)sc_max(sc_min(sc_round_and_cast<int32_t>(__cached_0), 127), -128);
  __outs_0[(((fused_0fused_0__itr_0____itr_1_3179____itr_2_3180 / 128UL) * 128UL) + (fused_0fused_0__itr_0____itr_1_3179____itr_2_3180 % 128UL))] = __cached_1;
}

static void cast__1470_closure_214_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept{
  cast__1470_closure_214(i, (float*)(args[0UL].v_ptr), (int8_t*)(args[1UL].v_ptr));
}

static void reorder__4450_closure_215(uint64_t fused_0fused_0fused_0fused_0_fuseiter_9637___fuseiter_9638_3181___fuseiter_9639_3182___fuseiter_9640_3183___fuseiter_9641_3184, int8_t* __restrict__ __ins_0, int8_t* __restrict__ __outs_0) noexcept{
  for (uint64_t _fuseiter_9642 = 0UL; _fuseiter_9642 < 64UL; _fuseiter_9642 += 1UL) {
    for (uint64_t _fuseiter_9643 = 0UL; _fuseiter_9643 < 4UL; _fuseiter_9643 += 1UL) {
      int8_t __cached_0;
      __cached_0 = __ins_0[(((_fuseiter_9642 + ((fused_0fused_0fused_0fused_0_fuseiter_9637___fuseiter_9638_3181___fuseiter_9639_3182___fuseiter_9640_3183___fuseiter_9641_3184 / 32UL) * 64UL)) * 128UL) + ((_fuseiter_9643 + ((fused_0fused_0fused_0fused_0_fuseiter_9637___fuseiter_9638_3181___fuseiter_9639_3182___fuseiter_9640_3183___fuseiter_9641_3184 % 16UL) * 4UL)) + (((fused_0fused_0fused_0fused_0_fuseiter_9637___fuseiter_9638_3181___fuseiter_9639_3182___fuseiter_9640_3183___fuseiter_9641_3184 / 16UL) % 2UL) * 64UL)))];
      int8_t __cached_1;
      __cached_1 = __cached_0;
      __outs_0[(((fused_0fused_0fused_0fused_0_fuseiter_9637___fuseiter_9638_3181___fuseiter_9639_3182___fuseiter_9640_3183___fuseiter_9641_3184 / 32UL) * 8192UL) + ((((fused_0fused_0fused_0fused_0_fuseiter_9637___fuseiter_9638_3181___fuseiter_9639_3182___fuseiter_9640_3183___fuseiter_9641_3184 / 16UL) % 2UL) * 4096UL) + (((fused_0fused_0fused_0fused_0_fuseiter_9637___fuseiter_9638_3181___fuseiter_9639_3182___fuseiter_9640_3183___fuseiter_9641_3184 % 16UL) * 256UL) + ((_fuseiter_9642 * 4UL) + _fuseiter_9643))))] = __cached_1;
    }
  }
}

static void reorder__4450_closure_215_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept{
  reorder__4450_closure_215(i, (int8_t*)(args[0UL].v_ptr), (int8_t*)(args[1UL].v_ptr));
}

static void mul__1550_closure_216(uint64_t fused_0fused_0__itr_0____itr_1_3185____itr_2_3186, float* __restrict__ __ins_0, float* __restrict__ __ins_1, float* __restrict__ __outs_0) noexcept{
  float __cached_0;
  __cached_0 = __ins_0[(((fused_0fused_0__itr_0____itr_1_3185____itr_2_3186 / 128UL) * 128UL) + (fused_0fused_0__itr_0____itr_1_3185____itr_2_3186 % 128UL))];
  float __cached_1;
  __cached_1 = __ins_1[(fused_0fused_0__itr_0____itr_1_3185____itr_2_3186 / 128UL)];
  float __cached_2;
  __cached_2 = (__cached_0 * __cached_1);
  __outs_0[(((fused_0fused_0__itr_0____itr_1_3185____itr_2_3186 / 128UL) * 128UL) + (fused_0fused_0__itr_0____itr_1_3185____itr_2_3186 % 128UL))] = __cached_2;
}

static void mul__1550_closure_216_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept{
  mul__1550_closure_216(i, (float*)(args[0UL].v_ptr), (float*)(args[1UL].v_ptr), (float*)(args[2UL].v_ptr));
}

static void cast__1560_closure_217(uint64_t fused_0fused_0__itr_0____itr_1_3187____itr_2_3188, float* __restrict__ __ins_0, int8_t* __restrict__ __outs_0) noexcept{
  float __cached_0;
  __cached_0 = __ins_0[(((fused_0fused_0__itr_0____itr_1_3187____itr_2_3188 / 128UL) * 128UL) + (fused_0fused_0__itr_0____itr_1_3187____itr_2_3188 % 128UL))];
  int8_t __cached_1;
  __cached_1 = (int8_t)sc_max(sc_min(sc_round_and_cast<int32_t>(__cached_0), 127), -128);
  __outs_0[(((fused_0fused_0__itr_0____itr_1_3187____itr_2_3188 / 128UL) * 128UL) + (fused_0fused_0__itr_0____itr_1_3187____itr_2_3188 % 128UL))] = __cached_1;
}

static void cast__1560_closure_217_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept{
  cast__1560_closure_217(i, (float*)(args[0UL].v_ptr), (int8_t*)(args[1UL].v_ptr));
}

static void reorder__4540_closure_218(uint64_t fused_0fused_0fused_0fused_0_fuseiter_9654___fuseiter_9655_3189___fuseiter_9656_3190___fuseiter_9657_3191___fuseiter_9658_3192, int8_t* __restrict__ __ins_0, int8_t* __restrict__ __outs_0) noexcept{
  for (uint64_t _fuseiter_9659 = 0UL; _fuseiter_9659 < 64UL; _fuseiter_9659 += 1UL) {
    for (uint64_t _fuseiter_9660 = 0UL; _fuseiter_9660 < 4UL; _fuseiter_9660 += 1UL) {
      int8_t __cached_0;
      __cached_0 = __ins_0[(((_fuseiter_9659 + ((fused_0fused_0fused_0fused_0_fuseiter_9654___fuseiter_9655_3189___fuseiter_9656_3190___fuseiter_9657_3191___fuseiter_9658_3192 / 32UL) * 64UL)) * 128UL) + ((_fuseiter_9660 + ((fused_0fused_0fused_0fused_0_fuseiter_9654___fuseiter_9655_3189___fuseiter_9656_3190___fuseiter_9657_3191___fuseiter_9658_3192 % 16UL) * 4UL)) + (((fused_0fused_0fused_0fused_0_fuseiter_9654___fuseiter_9655_3189___fuseiter_9656_3190___fuseiter_9657_3191___fuseiter_9658_3192 / 16UL) % 2UL) * 64UL)))];
      int8_t __cached_1;
      __cached_1 = __cached_0;
      __outs_0[(((fused_0fused_0fused_0fused_0_fuseiter_9654___fuseiter_9655_3189___fuseiter_9656_3190___fuseiter_9657_3191___fuseiter_9658_3192 / 32UL) * 8192UL) + ((((fused_0fused_0fused_0fused_0_fuseiter_9654___fuseiter_9655_3189___fuseiter_9656_3190___fuseiter_9657_3191___fuseiter_9658_3192 / 16UL) % 2UL) * 4096UL) + (((fused_0fused_0fused_0fused_0_fuseiter_9654___fuseiter_9655_3189___fuseiter_9656_3190___fuseiter_9657_3191___fuseiter_9658_3192 % 16UL) * 256UL) + ((_fuseiter_9659 * 4UL) + _fuseiter_9660))))] = __cached_1;
    }
  }
}

static void reorder__4540_closure_218_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept{
  reorder__4540_closure_218(i, (int8_t*)(args[0UL].v_ptr), (int8_t*)(args[1UL].v_ptr));
}

static void mul__1640_closure_219(uint64_t fused_0fused_0__itr_0____itr_1_3193____itr_2_3194, float* __restrict__ __ins_0, float* __restrict__ __ins_1, float* __restrict__ __outs_0) noexcept{
  float __cached_0;
  __cached_0 = __ins_0[(((fused_0fused_0__itr_0____itr_1_3193____itr_2_3194 / 128UL) * 128UL) + (fused_0fused_0__itr_0____itr_1_3193____itr_2_3194 % 128UL))];
  float __cached_1;
  __cached_1 = __ins_1[(fused_0fused_0__itr_0____itr_1_3193____itr_2_3194 / 128UL)];
  float __cached_2;
  __cached_2 = (__cached_0 * __cached_1);
  __outs_0[(((fused_0fused_0__itr_0____itr_1_3193____itr_2_3194 / 128UL) * 128UL) + (fused_0fused_0__itr_0____itr_1_3193____itr_2_3194 % 128UL))] = __cached_2;
}

static void mul__1640_closure_219_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept{
  mul__1640_closure_219(i, (float*)(args[0UL].v_ptr), (float*)(args[1UL].v_ptr), (float*)(args[2UL].v_ptr));
}

static void cast__1650_closure_220(uint64_t fused_0fused_0__itr_0____itr_1_3195____itr_2_3196, float* __restrict__ __ins_0, int8_t* __restrict__ __outs_0) noexcept{
  float __cached_0;
  __cached_0 = __ins_0[(((fused_0fused_0__itr_0____itr_1_3195____itr_2_3196 / 128UL) * 128UL) + (fused_0fused_0__itr_0____itr_1_3195____itr_2_3196 % 128UL))];
  int8_t __cached_1;
  __cached_1 = (int8_t)sc_max(sc_min(sc_round_and_cast<int32_t>(__cached_0), 127), -128);
  __outs_0[(((fused_0fused_0__itr_0____itr_1_3195____itr_2_3196 / 128UL) * 128UL) + (fused_0fused_0__itr_0____itr_1_3195____itr_2_3196 % 128UL))] = __cached_1;
}

static void cast__1650_closure_220_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept{
  cast__1650_closure_220(i, (float*)(args[0UL].v_ptr), (int8_t*)(args[1UL].v_ptr));
}

static void reorder__4630_closure_221(uint64_t fused_0fused_0fused_0fused_0_fuseiter_9671___fuseiter_9672_3197___fuseiter_9673_3198___fuseiter_9674_3199___fuseiter_9675_3200, int8_t* __restrict__ __ins_0, int8_t* __restrict__ __outs_0) noexcept{
  for (uint64_t _fuseiter_9676 = 0UL; _fuseiter_9676 < 64UL; _fuseiter_9676 += 1UL) {
    for (uint64_t _fuseiter_9677 = 0UL; _fuseiter_9677 < 4UL; _fuseiter_9677 += 1UL) {
      int8_t __cached_0;
      __cached_0 = __ins_0[(((_fuseiter_9676 + ((fused_0fused_0fused_0fused_0_fuseiter_9671___fuseiter_9672_3197___fuseiter_9673_3198___fuseiter_9674_3199___fuseiter_9675_3200 / 32UL) * 64UL)) * 128UL) + ((_fuseiter_9677 + ((fused_0fused_0fused_0fused_0_fuseiter_9671___fuseiter_9672_3197___fuseiter_9673_3198___fuseiter_9674_3199___fuseiter_9675_3200 % 16UL) * 4UL)) + (((fused_0fused_0fused_0fused_0_fuseiter_9671___fuseiter_9672_3197___fuseiter_9673_3198___fuseiter_9674_3199___fuseiter_9675_3200 / 16UL) % 2UL) * 64UL)))];
      int8_t __cached_1;
      __cached_1 = __cached_0;
      __outs_0[(((fused_0fused_0fused_0fused_0_fuseiter_9671___fuseiter_9672_3197___fuseiter_9673_3198___fuseiter_9674_3199___fuseiter_9675_3200 / 32UL) * 8192UL) + ((((fused_0fused_0fused_0fused_0_fuseiter_9671___fuseiter_9672_3197___fuseiter_9673_3198___fuseiter_9674_3199___fuseiter_9675_3200 / 16UL) % 2UL) * 4096UL) + (((fused_0fused_0fused_0fused_0_fuseiter_9671___fuseiter_9672_3197___fuseiter_9673_3198___fuseiter_9674_3199___fuseiter_9675_3200 % 16UL) * 256UL) + ((_fuseiter_9676 * 4UL) + _fuseiter_9677))))] = __cached_1;
    }
  }
}

static void reorder__4630_closure_221_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept{
  reorder__4630_closure_221(i, (int8_t*)(args[0UL].v_ptr), (int8_t*)(args[1UL].v_ptr));
}

static void mul__1730_closure_222(uint64_t fused_0fused_0__itr_0____itr_1_3201____itr_2_3202, float* __restrict__ __ins_0, float* __restrict__ __ins_1, float* __restrict__ __outs_0) noexcept{
  float __cached_0;
  __cached_0 = __ins_0[(((fused_0fused_0__itr_0____itr_1_3201____itr_2_3202 / 128UL) * 128UL) + (fused_0fused_0__itr_0____itr_1_3201____itr_2_3202 % 128UL))];
  float __cached_1;
  __cached_1 = __ins_1[(fused_0fused_0__itr_0____itr_1_3201____itr_2_3202 / 128UL)];
  float __cached_2;
  __cached_2 = (__cached_0 * __cached_1);
  __outs_0[(((fused_0fused_0__itr_0____itr_1_3201____itr_2_3202 / 128UL) * 128UL) + (fused_0fused_0__itr_0____itr_1_3201____itr_2_3202 % 128UL))] = __cached_2;
}

static void mul__1730_closure_222_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept{
  mul__1730_closure_222(i, (float*)(args[0UL].v_ptr), (float*)(args[1UL].v_ptr), (float*)(args[2UL].v_ptr));
}

static void cast__1740_closure_223(uint64_t fused_0fused_0__itr_0____itr_1_3203____itr_2_3204, float* __restrict__ __ins_0, int8_t* __restrict__ __outs_0) noexcept{
  float __cached_0;
  __cached_0 = __ins_0[(((fused_0fused_0__itr_0____itr_1_3203____itr_2_3204 / 128UL) * 128UL) + (fused_0fused_0__itr_0____itr_1_3203____itr_2_3204 % 128UL))];
  int8_t __cached_1;
  __cached_1 = (int8_t)sc_max(sc_min(sc_round_and_cast<int32_t>(__cached_0), 127), -128);
  __outs_0[(((fused_0fused_0__itr_0____itr_1_3203____itr_2_3204 / 128UL) * 128UL) + (fused_0fused_0__itr_0____itr_1_3203____itr_2_3204 % 128UL))] = __cached_1;
}

static void cast__1740_closure_223_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept{
  cast__1740_closure_223(i, (float*)(args[0UL].v_ptr), (int8_t*)(args[1UL].v_ptr));
}

static void reorder__4720_closure_224(uint64_t fused_0fused_0fused_0fused_0_fuseiter_9688___fuseiter_9689_3205___fuseiter_9690_3206___fuseiter_9691_3207___fuseiter_9692_3208, int8_t* __restrict__ __ins_0, int8_t* __restrict__ __outs_0) noexcept{
  for (uint64_t _fuseiter_9693 = 0UL; _fuseiter_9693 < 64UL; _fuseiter_9693 += 1UL) {
    for (uint64_t _fuseiter_9694 = 0UL; _fuseiter_9694 < 4UL; _fuseiter_9694 += 1UL) {
      int8_t __cached_0;
      __cached_0 = __ins_0[(((_fuseiter_9693 + ((fused_0fused_0fused_0fused_0_fuseiter_9688___fuseiter_9689_3205___fuseiter_9690_3206___fuseiter_9691_3207___fuseiter_9692_3208 / 32UL) * 64UL)) * 128UL) + ((_fuseiter_9694 + ((fused_0fused_0fused_0fused_0_fuseiter_9688___fuseiter_9689_3205___fuseiter_9690_3206___fuseiter_9691_3207___fuseiter_9692_3208 % 16UL) * 4UL)) + (((fused_0fused_0fused_0fused_0_fuseiter_9688___fuseiter_9689_3205___fuseiter_9690_3206___fuseiter_9691_3207___fuseiter_9692_3208 / 16UL) % 2UL) * 64UL)))];
      int8_t __cached_1;
      __cached_1 = __cached_0;
      __outs_0[(((fused_0fused_0fused_0fused_0_fuseiter_9688___fuseiter_9689_3205___fuseiter_9690_3206___fuseiter_9691_3207___fuseiter_9692_3208 / 32UL) * 8192UL) + ((((fused_0fused_0fused_0fused_0_fuseiter_9688___fuseiter_9689_3205___fuseiter_9690_3206___fuseiter_9691_3207___fuseiter_9692_3208 / 16UL) % 2UL) * 4096UL) + (((fused_0fused_0fused_0fused_0_fuseiter_9688___fuseiter_9689_3205___fuseiter_9690_3206___fuseiter_9691_3207___fuseiter_9692_3208 % 16UL) * 256UL) + ((_fuseiter_9693 * 4UL) + _fuseiter_9694))))] = __cached_1;
    }
  }
}

static void reorder__4720_closure_224_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept{
  reorder__4720_closure_224(i, (int8_t*)(args[0UL].v_ptr), (int8_t*)(args[1UL].v_ptr));
}

static void mul__1490_closure_225(uint64_t fused_0fused_0__itr_0____itr_1_3209____itr_2_3210, float* __restrict__ __ins_0, float* __restrict__ __ins_1, float* __restrict__ __outs_0) noexcept{
  float __cached_0;
  __cached_0 = __ins_0[(((fused_0fused_0__itr_0____itr_1_3209____itr_2_3210 / 512UL) * 512UL) + (fused_0fused_0__itr_0____itr_1_3209____itr_2_3210 % 512UL))];
  float __cached_1;
  __cached_1 = __ins_1[(fused_0fused_0__itr_0____itr_1_3209____itr_2_3210 / 512UL)];
  float __cached_2;
  __cached_2 = (__cached_0 * __cached_1);
  __outs_0[(((fused_0fused_0__itr_0____itr_1_3209____itr_2_3210 / 512UL) * 512UL) + (fused_0fused_0__itr_0____itr_1_3209____itr_2_3210 % 512UL))] = __cached_2;
}

static void mul__1490_closure_225_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept{
  mul__1490_closure_225(i, (float*)(args[0UL].v_ptr), (float*)(args[1UL].v_ptr), (float*)(args[2UL].v_ptr));
}

static void cast__1500_closure_226(uint64_t fused_0fused_0__itr_0____itr_1_3211____itr_2_3212, float* __restrict__ __ins_0, int8_t* __restrict__ __outs_0) noexcept{
  float __cached_0;
  __cached_0 = __ins_0[(((fused_0fused_0__itr_0____itr_1_3211____itr_2_3212 / 512UL) * 512UL) + (fused_0fused_0__itr_0____itr_1_3211____itr_2_3212 % 512UL))];
  int8_t __cached_1;
  __cached_1 = (int8_t)sc_max(sc_min(sc_round_and_cast<int32_t>(__cached_0), 127), -128);
  __outs_0[(((fused_0fused_0__itr_0____itr_1_3211____itr_2_3212 / 512UL) * 512UL) + (fused_0fused_0__itr_0____itr_1_3211____itr_2_3212 % 512UL))] = __cached_1;
}

static void cast__1500_closure_226_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept{
  cast__1500_closure_226(i, (float*)(args[0UL].v_ptr), (int8_t*)(args[1UL].v_ptr));
}

static void reorder__4480_closure_227(uint64_t fused_0fused_0fused_0fused_0_fuseiter_9705___fuseiter_9706_3213___fuseiter_9707_3214___fuseiter_9708_3215___fuseiter_9709_3216, int8_t* __restrict__ __ins_0, int8_t* __restrict__ __outs_0) noexcept{
  for (uint64_t _fuseiter_9710 = 0UL; _fuseiter_9710 < 64UL; _fuseiter_9710 += 1UL) {
    for (uint64_t _fuseiter_9711 = 0UL; _fuseiter_9711 < 4UL; _fuseiter_9711 += 1UL) {
      int8_t __cached_0;
      __cached_0 = __ins_0[(((_fuseiter_9710 + ((fused_0fused_0fused_0fused_0_fuseiter_9705___fuseiter_9706_3213___fuseiter_9707_3214___fuseiter_9708_3215___fuseiter_9709_3216 / 128UL) * 64UL)) * 512UL) + ((_fuseiter_9711 + ((fused_0fused_0fused_0fused_0_fuseiter_9705___fuseiter_9706_3213___fuseiter_9707_3214___fuseiter_9708_3215___fuseiter_9709_3216 % 16UL) * 4UL)) + (((fused_0fused_0fused_0fused_0_fuseiter_9705___fuseiter_9706_3213___fuseiter_9707_3214___fuseiter_9708_3215___fuseiter_9709_3216 / 16UL) % 8UL) * 64UL)))];
      int8_t __cached_1;
      __cached_1 = __cached_0;
      __outs_0[(((fused_0fused_0fused_0fused_0_fuseiter_9705___fuseiter_9706_3213___fuseiter_9707_3214___fuseiter_9708_3215___fuseiter_9709_3216 / 128UL) * 32768UL) + ((((fused_0fused_0fused_0fused_0_fuseiter_9705___fuseiter_9706_3213___fuseiter_9707_3214___fuseiter_9708_3215___fuseiter_9709_3216 / 16UL) % 8UL) * 4096UL) + (((fused_0fused_0fused_0fused_0_fuseiter_9705___fuseiter_9706_3213___fuseiter_9707_3214___fuseiter_9708_3215___fuseiter_9709_3216 % 16UL) * 256UL) + ((_fuseiter_9710 * 4UL) + _fuseiter_9711))))] = __cached_1;
    }
  }
}

static void reorder__4480_closure_227_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept{
  reorder__4480_closure_227(i, (int8_t*)(args[0UL].v_ptr), (int8_t*)(args[1UL].v_ptr));
}

static void mul__1580_closure_228(uint64_t fused_0fused_0__itr_0____itr_1_3217____itr_2_3218, float* __restrict__ __ins_0, float* __restrict__ __ins_1, float* __restrict__ __outs_0) noexcept{
  float __cached_0;
  __cached_0 = __ins_0[(((fused_0fused_0__itr_0____itr_1_3217____itr_2_3218 / 512UL) * 512UL) + (fused_0fused_0__itr_0____itr_1_3217____itr_2_3218 % 512UL))];
  float __cached_1;
  __cached_1 = __ins_1[(fused_0fused_0__itr_0____itr_1_3217____itr_2_3218 / 512UL)];
  float __cached_2;
  __cached_2 = (__cached_0 * __cached_1);
  __outs_0[(((fused_0fused_0__itr_0____itr_1_3217____itr_2_3218 / 512UL) * 512UL) + (fused_0fused_0__itr_0____itr_1_3217____itr_2_3218 % 512UL))] = __cached_2;
}

static void mul__1580_closure_228_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept{
  mul__1580_closure_228(i, (float*)(args[0UL].v_ptr), (float*)(args[1UL].v_ptr), (float*)(args[2UL].v_ptr));
}

static void cast__1590_closure_229(uint64_t fused_0fused_0__itr_0____itr_1_3219____itr_2_3220, float* __restrict__ __ins_0, int8_t* __restrict__ __outs_0) noexcept{
  float __cached_0;
  __cached_0 = __ins_0[(((fused_0fused_0__itr_0____itr_1_3219____itr_2_3220 / 512UL) * 512UL) + (fused_0fused_0__itr_0____itr_1_3219____itr_2_3220 % 512UL))];
  int8_t __cached_1;
  __cached_1 = (int8_t)sc_max(sc_min(sc_round_and_cast<int32_t>(__cached_0), 127), -128);
  __outs_0[(((fused_0fused_0__itr_0____itr_1_3219____itr_2_3220 / 512UL) * 512UL) + (fused_0fused_0__itr_0____itr_1_3219____itr_2_3220 % 512UL))] = __cached_1;
}

static void cast__1590_closure_229_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept{
  cast__1590_closure_229(i, (float*)(args[0UL].v_ptr), (int8_t*)(args[1UL].v_ptr));
}

static void reorder__4570_closure_230(uint64_t fused_0fused_0fused_0fused_0_fuseiter_9722___fuseiter_9723_3221___fuseiter_9724_3222___fuseiter_9725_3223___fuseiter_9726_3224, int8_t* __restrict__ __ins_0, int8_t* __restrict__ __outs_0) noexcept{
  for (uint64_t _fuseiter_9727 = 0UL; _fuseiter_9727 < 64UL; _fuseiter_9727 += 1UL) {
    for (uint64_t _fuseiter_9728 = 0UL; _fuseiter_9728 < 4UL; _fuseiter_9728 += 1UL) {
      int8_t __cached_0;
      __cached_0 = __ins_0[(((_fuseiter_9727 + ((fused_0fused_0fused_0fused_0_fuseiter_9722___fuseiter_9723_3221___fuseiter_9724_3222___fuseiter_9725_3223___fuseiter_9726_3224 / 128UL) * 64UL)) * 512UL) + ((_fuseiter_9728 + ((fused_0fused_0fused_0fused_0_fuseiter_9722___fuseiter_9723_3221___fuseiter_9724_3222___fuseiter_9725_3223___fuseiter_9726_3224 % 16UL) * 4UL)) + (((fused_0fused_0fused_0fused_0_fuseiter_9722___fuseiter_9723_3221___fuseiter_9724_3222___fuseiter_9725_3223___fuseiter_9726_3224 / 16UL) % 8UL) * 64UL)))];
      int8_t __cached_1;
      __cached_1 = __cached_0;
      __outs_0[(((fused_0fused_0fused_0fused_0_fuseiter_9722___fuseiter_9723_3221___fuseiter_9724_3222___fuseiter_9725_3223___fuseiter_9726_3224 / 128UL) * 32768UL) + ((((fused_0fused_0fused_0fused_0_fuseiter_9722___fuseiter_9723_3221___fuseiter_9724_3222___fuseiter_9725_3223___fuseiter_9726_3224 / 16UL) % 8UL) * 4096UL) + (((fused_0fused_0fused_0fused_0_fuseiter_9722___fuseiter_9723_3221___fuseiter_9724_3222___fuseiter_9725_3223___fuseiter_9726_3224 % 16UL) * 256UL) + ((_fuseiter_9727 * 4UL) + _fuseiter_9728))))] = __cached_1;
    }
  }
}

static void reorder__4570_closure_230_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept{
  reorder__4570_closure_230(i, (int8_t*)(args[0UL].v_ptr), (int8_t*)(args[1UL].v_ptr));
}

static void mul__1670_closure_231(uint64_t fused_0fused_0__itr_0____itr_1_3225____itr_2_3226, float* __restrict__ __ins_0, float* __restrict__ __ins_1, float* __restrict__ __outs_0) noexcept{
  float __cached_0;
  __cached_0 = __ins_0[(((fused_0fused_0__itr_0____itr_1_3225____itr_2_3226 / 512UL) * 512UL) + (fused_0fused_0__itr_0____itr_1_3225____itr_2_3226 % 512UL))];
  float __cached_1;
  __cached_1 = __ins_1[(fused_0fused_0__itr_0____itr_1_3225____itr_2_3226 / 512UL)];
  float __cached_2;
  __cached_2 = (__cached_0 * __cached_1);
  __outs_0[(((fused_0fused_0__itr_0____itr_1_3225____itr_2_3226 / 512UL) * 512UL) + (fused_0fused_0__itr_0____itr_1_3225____itr_2_3226 % 512UL))] = __cached_2;
}

static void mul__1670_closure_231_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept{
  mul__1670_closure_231(i, (float*)(args[0UL].v_ptr), (float*)(args[1UL].v_ptr), (float*)(args[2UL].v_ptr));
}

static void cast__1680_closure_232(uint64_t fused_0fused_0__itr_0____itr_1_3227____itr_2_3228, float* __restrict__ __ins_0, int8_t* __restrict__ __outs_0) noexcept{
  float __cached_0;
  __cached_0 = __ins_0[(((fused_0fused_0__itr_0____itr_1_3227____itr_2_3228 / 512UL) * 512UL) + (fused_0fused_0__itr_0____itr_1_3227____itr_2_3228 % 512UL))];
  int8_t __cached_1;
  __cached_1 = (int8_t)sc_max(sc_min(sc_round_and_cast<int32_t>(__cached_0), 127), -128);
  __outs_0[(((fused_0fused_0__itr_0____itr_1_3227____itr_2_3228 / 512UL) * 512UL) + (fused_0fused_0__itr_0____itr_1_3227____itr_2_3228 % 512UL))] = __cached_1;
}

static void cast__1680_closure_232_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept{
  cast__1680_closure_232(i, (float*)(args[0UL].v_ptr), (int8_t*)(args[1UL].v_ptr));
}

static void reorder__4660_closure_233(uint64_t fused_0fused_0fused_0fused_0_fuseiter_9739___fuseiter_9740_3229___fuseiter_9741_3230___fuseiter_9742_3231___fuseiter_9743_3232, int8_t* __restrict__ __ins_0, int8_t* __restrict__ __outs_0) noexcept{
  for (uint64_t _fuseiter_9744 = 0UL; _fuseiter_9744 < 64UL; _fuseiter_9744 += 1UL) {
    for (uint64_t _fuseiter_9745 = 0UL; _fuseiter_9745 < 4UL; _fuseiter_9745 += 1UL) {
      int8_t __cached_0;
      __cached_0 = __ins_0[(((_fuseiter_9744 + ((fused_0fused_0fused_0fused_0_fuseiter_9739___fuseiter_9740_3229___fuseiter_9741_3230___fuseiter_9742_3231___fuseiter_9743_3232 / 128UL) * 64UL)) * 512UL) + ((_fuseiter_9745 + ((fused_0fused_0fused_0fused_0_fuseiter_9739___fuseiter_9740_3229___fuseiter_9741_3230___fuseiter_9742_3231___fuseiter_9743_3232 % 16UL) * 4UL)) + (((fused_0fused_0fused_0fused_0_fuseiter_9739___fuseiter_9740_3229___fuseiter_9741_3230___fuseiter_9742_3231___fuseiter_9743_3232 / 16UL) % 8UL) * 64UL)))];
      int8_t __cached_1;
      __cached_1 = __cached_0;
      __outs_0[(((fused_0fused_0fused_0fused_0_fuseiter_9739___fuseiter_9740_3229___fuseiter_9741_3230___fuseiter_9742_3231___fuseiter_9743_3232 / 128UL) * 32768UL) + ((((fused_0fused_0fused_0fused_0_fuseiter_9739___fuseiter_9740_3229___fuseiter_9741_3230___fuseiter_9742_3231___fuseiter_9743_3232 / 16UL) % 8UL) * 4096UL) + (((fused_0fused_0fused_0fused_0_fuseiter_9739___fuseiter_9740_3229___fuseiter_9741_3230___fuseiter_9742_3231___fuseiter_9743_3232 % 16UL) * 256UL) + ((_fuseiter_9744 * 4UL) + _fuseiter_9745))))] = __cached_1;
    }
  }
}

static void reorder__4660_closure_233_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept{
  reorder__4660_closure_233(i, (int8_t*)(args[0UL].v_ptr), (int8_t*)(args[1UL].v_ptr));
}

static void mul__1370_closure_234(uint64_t fused_0fused_0__itr_0____itr_1_3233____itr_2_3234, float* __restrict__ __ins_0, float* __restrict__ __ins_1, float* __restrict__ __outs_0) noexcept{
  float __cached_0;
  __cached_0 = __ins_0[(((fused_0fused_0__itr_0____itr_1_3233____itr_2_3234 / 256UL) * 256UL) + (fused_0fused_0__itr_0____itr_1_3233____itr_2_3234 % 256UL))];
  float __cached_1;
  __cached_1 = __ins_1[(fused_0fused_0__itr_0____itr_1_3233____itr_2_3234 / 256UL)];
  float __cached_2;
  __cached_2 = (__cached_0 * __cached_1);
  __outs_0[(((fused_0fused_0__itr_0____itr_1_3233____itr_2_3234 / 256UL) * 256UL) + (fused_0fused_0__itr_0____itr_1_3233____itr_2_3234 % 256UL))] = __cached_2;
}

static void mul__1370_closure_234_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept{
  mul__1370_closure_234(i, (float*)(args[0UL].v_ptr), (float*)(args[1UL].v_ptr), (float*)(args[2UL].v_ptr));
}

static void cast__1380_closure_235(uint64_t fused_0fused_0__itr_0____itr_1_3235____itr_2_3236, float* __restrict__ __ins_0, int8_t* __restrict__ __outs_0) noexcept{
  float __cached_0;
  __cached_0 = __ins_0[(((fused_0fused_0__itr_0____itr_1_3235____itr_2_3236 / 256UL) * 256UL) + (fused_0fused_0__itr_0____itr_1_3235____itr_2_3236 % 256UL))];
  int8_t __cached_1;
  __cached_1 = (int8_t)sc_max(sc_min(sc_round_and_cast<int32_t>(__cached_0), 127), -128);
  __outs_0[(((fused_0fused_0__itr_0____itr_1_3235____itr_2_3236 / 256UL) * 256UL) + (fused_0fused_0__itr_0____itr_1_3235____itr_2_3236 % 256UL))] = __cached_1;
}

static void cast__1380_closure_235_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept{
  cast__1380_closure_235(i, (float*)(args[0UL].v_ptr), (int8_t*)(args[1UL].v_ptr));
}

static void reorder__4360_closure_236(uint64_t fused_0_fuseiter_9756___fuseiter_9757_3237, int8_t* __restrict__ __ins_0, int8_t* __restrict__ __outs_0) noexcept{
  for (uint64_t _fuseiter_9760 = 0UL; _fuseiter_9760 < 16UL; _fuseiter_9760 += 1UL) {
    for (uint64_t _fuseiter_9761 = 0UL; _fuseiter_9761 < 64UL; _fuseiter_9761 += 1UL) {
      for (uint64_t _fuseiter_9762 = 0UL; _fuseiter_9762 < 4UL; _fuseiter_9762 += 1UL) {
        int8_t __cached_0;
        __cached_0 = __ins_0[(((_fuseiter_9761 + ((fused_0_fuseiter_9756___fuseiter_9757_3237 / 4UL) * 64UL)) * 256UL) + ((_fuseiter_9762 + (_fuseiter_9760 * 4UL)) + ((fused_0_fuseiter_9756___fuseiter_9757_3237 % 4UL) * 64UL)))];
        int8_t __cached_1;
        __cached_1 = __cached_0;
        __outs_0[(((fused_0_fuseiter_9756___fuseiter_9757_3237 / 4UL) * 16384UL) + (((fused_0_fuseiter_9756___fuseiter_9757_3237 % 4UL) * 4096UL) + ((_fuseiter_9760 * 256UL) + ((_fuseiter_9761 * 4UL) + _fuseiter_9762))))] = __cached_1;
      }
    }
  }
}

static void reorder__4360_closure_236_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept{
  reorder__4360_closure_236(i, (int8_t*)(args[0UL].v_ptr), (int8_t*)(args[1UL].v_ptr));
}

static void mul__1790_closure_237(uint64_t fused_0fused_0__itr_0____itr_1_3238____itr_2_3239, float* __restrict__ __ins_0, float* __restrict__ __ins_1, float* __restrict__ __outs_0) noexcept{
  float __cached_0;
  __cached_0 = __ins_0[(((fused_0fused_0__itr_0____itr_1_3238____itr_2_3239 / 512UL) * 512UL) + (fused_0fused_0__itr_0____itr_1_3238____itr_2_3239 % 512UL))];
  float __cached_1;
  __cached_1 = __ins_1[(fused_0fused_0__itr_0____itr_1_3238____itr_2_3239 / 512UL)];
  float __cached_2;
  __cached_2 = (__cached_0 * __cached_1);
  __outs_0[(((fused_0fused_0__itr_0____itr_1_3238____itr_2_3239 / 512UL) * 512UL) + (fused_0fused_0__itr_0____itr_1_3238____itr_2_3239 % 512UL))] = __cached_2;
}

static void mul__1790_closure_237_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept{
  mul__1790_closure_237(i, (float*)(args[0UL].v_ptr), (float*)(args[1UL].v_ptr), (float*)(args[2UL].v_ptr));
}

static void cast__1800_closure_238(uint64_t fused_0fused_0__itr_0____itr_1_3240____itr_2_3241, float* __restrict__ __ins_0, int8_t* __restrict__ __outs_0) noexcept{
  float __cached_0;
  __cached_0 = __ins_0[(((fused_0fused_0__itr_0____itr_1_3240____itr_2_3241 / 512UL) * 512UL) + (fused_0fused_0__itr_0____itr_1_3240____itr_2_3241 % 512UL))];
  int8_t __cached_1;
  __cached_1 = (int8_t)sc_max(sc_min(sc_round_and_cast<int32_t>(__cached_0), 127), -128);
  __outs_0[(((fused_0fused_0__itr_0____itr_1_3240____itr_2_3241 / 512UL) * 512UL) + (fused_0fused_0__itr_0____itr_1_3240____itr_2_3241 % 512UL))] = __cached_1;
}

static void cast__1800_closure_238_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept{
  cast__1800_closure_238(i, (float*)(args[0UL].v_ptr), (int8_t*)(args[1UL].v_ptr));
}

static void reorder__4780_closure_239(uint64_t fused_0_fuseiter_9773___fuseiter_9774_3242, int8_t* __restrict__ __ins_0, int8_t* __restrict__ __outs_0) noexcept{
  for (uint64_t _fuseiter_9777 = 0UL; _fuseiter_9777 < 16UL; _fuseiter_9777 += 1UL) {
    for (uint64_t _fuseiter_9778 = 0UL; _fuseiter_9778 < 64UL; _fuseiter_9778 += 1UL) {
      for (uint64_t _fuseiter_9779 = 0UL; _fuseiter_9779 < 4UL; _fuseiter_9779 += 1UL) {
        int8_t __cached_0;
        __cached_0 = __ins_0[(((_fuseiter_9778 + ((fused_0_fuseiter_9773___fuseiter_9774_3242 / 8UL) * 64UL)) * 512UL) + ((_fuseiter_9779 + (_fuseiter_9777 * 4UL)) + ((fused_0_fuseiter_9773___fuseiter_9774_3242 % 8UL) * 64UL)))];
        int8_t __cached_1;
        __cached_1 = __cached_0;
        __outs_0[(((fused_0_fuseiter_9773___fuseiter_9774_3242 / 8UL) * 32768UL) + (((fused_0_fuseiter_9773___fuseiter_9774_3242 % 8UL) * 4096UL) + ((_fuseiter_9777 * 256UL) + ((_fuseiter_9778 * 4UL) + _fuseiter_9779))))] = __cached_1;
      }
    }
  }
}

static void reorder__4780_closure_239_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept{
  reorder__4780_closure_239(i, (int8_t*)(args[0UL].v_ptr), (int8_t*)(args[1UL].v_ptr));
}

static void mul__1430_closure_240(uint64_t fused_0fused_0__itr_0____itr_1_3243____itr_2_3244, float* __restrict__ __ins_0, float* __restrict__ __ins_1, float* __restrict__ __outs_0) noexcept{
  for (uint64_t _fuseiter_9784 = 0UL; _fuseiter_9784 < 3UL; _fuseiter_9784 += 1UL) {
    float __cached_0;
    __cached_0 = __ins_0[((((fused_0fused_0__itr_0____itr_1_3243____itr_2_3244 / 384UL) * 1152UL) + ((((fused_0fused_0__itr_0____itr_1_3243____itr_2_3244 / 3UL) % 128UL) * 9UL) + ((fused_0fused_0__itr_0____itr_1_3243____itr_2_3244 % 3UL) * 3UL))) + _fuseiter_9784)];
    float __cached_1;
    __cached_1 = __ins_1[(fused_0fused_0__itr_0____itr_1_3243____itr_2_3244 / 384UL)];
    float __cached_2;
    __cached_2 = (__cached_0 * __cached_1);
    __outs_0[((((fused_0fused_0__itr_0____itr_1_3243____itr_2_3244 / 384UL) * 1152UL) + ((((fused_0fused_0__itr_0____itr_1_3243____itr_2_3244 / 3UL) % 128UL) * 9UL) + ((fused_0fused_0__itr_0____itr_1_3243____itr_2_3244 % 3UL) * 3UL))) + _fuseiter_9784)] = __cached_2;
  }
}

static void mul__1430_closure_240_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept{
  mul__1430_closure_240(i, (float*)(args[0UL].v_ptr), (float*)(args[1UL].v_ptr), (float*)(args[2UL].v_ptr));
}

static void cast__1440_closure_241(uint64_t fused_0fused_0__itr_0____itr_1_3245____itr_2_3246, float* __restrict__ __ins_0, int8_t* __restrict__ __outs_0) noexcept{
  for (uint64_t _fuseiter9789 = 0UL; _fuseiter9789 < 3UL; _fuseiter9789 += 1UL) {
    float __cached_0;
    __cached_0 = __ins_0[((((fused_0fused_0__itr_0____itr_1_3245____itr_2_3246 / 384UL) * 1152UL) + ((((fused_0fused_0__itr_0____itr_1_3245____itr_2_3246 / 3UL) % 128UL) * 9UL) + ((fused_0fused_0__itr_0____itr_1_3245____itr_2_3246 % 3UL) * 3UL))) + _fuseiter9789)];
    int8_t __cached_1;
    __cached_1 = (int8_t)sc_max(sc_min(sc_round_and_cast<int32_t>(__cached_0), 127), -128);
    __outs_0[((((fused_0fused_0__itr_0____itr_1_3245____itr_2_3246 / 384UL) * 1152UL) + ((((fused_0fused_0__itr_0____itr_1_3245____itr_2_3246 / 3UL) % 128UL) * 9UL) + ((fused_0fused_0__itr_0____itr_1_3245____itr_2_3246 % 3UL) * 3UL))) + _fuseiter9789)] = __cached_1;
  }
}

static void cast__1440_closure_241_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept{
  cast__1440_closure_241(i, (float*)(args[0UL].v_ptr), (int8_t*)(args[1UL].v_ptr));
}

static void reorder__4420_closure_242(uint64_t fused_0fused_0fused_0_fuseiter_9790___fuseiter_9791_3247___fuseiter_9792_3248___fuseiter_9793_3249, int8_t* __restrict__ __ins_0, int8_t* __restrict__ __outs_0) noexcept{
  for (uint64_t _fuseiter_9794 = 0UL; _fuseiter_9794 < 16UL; _fuseiter_9794 += 1UL) {
    for (uint64_t _fuseiter_9795 = 0UL; _fuseiter_9795 < 64UL; _fuseiter_9795 += 1UL) {
      for (uint64_t _fuseiter_9796 = 0UL; _fuseiter_9796 < 4UL; _fuseiter_9796 += 1UL) {
        int8_t __cached_0;
        __cached_0 = __ins_0[(((_fuseiter_9795 + ((fused_0fused_0fused_0_fuseiter_9790___fuseiter_9791_3247___fuseiter_9792_3248___fuseiter_9793_3249 / 18UL) * 64UL)) * 1152UL) + ((((_fuseiter_9796 + (_fuseiter_9794 * 4UL)) + (((fused_0fused_0fused_0_fuseiter_9790___fuseiter_9791_3247___fuseiter_9792_3248___fuseiter_9793_3249 / 9UL) % 2UL) * 64UL)) * 9UL) + ((((fused_0fused_0fused_0_fuseiter_9790___fuseiter_9791_3247___fuseiter_9792_3248___fuseiter_9793_3249 / 3UL) % 3UL) * 3UL) + (fused_0fused_0fused_0_fuseiter_9790___fuseiter_9791_3247___fuseiter_9792_3248___fuseiter_9793_3249 % 3UL))))];
        int8_t __cached_1;
        __cached_1 = __cached_0;
        __outs_0[(((fused_0fused_0fused_0_fuseiter_9790___fuseiter_9791_3247___fuseiter_9792_3248___fuseiter_9793_3249 / 18UL) * 73728UL) + ((((fused_0fused_0fused_0_fuseiter_9790___fuseiter_9791_3247___fuseiter_9792_3248___fuseiter_9793_3249 / 9UL) % 2UL) * 36864UL) + ((((fused_0fused_0fused_0_fuseiter_9790___fuseiter_9791_3247___fuseiter_9792_3248___fuseiter_9793_3249 / 3UL) % 3UL) * 12288UL) + (((fused_0fused_0fused_0_fuseiter_9790___fuseiter_9791_3247___fuseiter_9792_3248___fuseiter_9793_3249 % 3UL) * 4096UL) + ((_fuseiter_9794 * 256UL) + ((_fuseiter_9795 * 4UL) + _fuseiter_9796))))))] = __cached_1;
      }
    }
  }
}

static void reorder__4420_closure_242_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept{
  reorder__4420_closure_242(i, (int8_t*)(args[0UL].v_ptr), (int8_t*)(args[1UL].v_ptr));
}

static void mul__1520_closure_243(uint64_t fused_0fused_0__itr_0____itr_1_3250____itr_2_3251, float* __restrict__ __ins_0, float* __restrict__ __ins_1, float* __restrict__ __outs_0) noexcept{
  for (uint64_t _fuseiter_9801 = 0UL; _fuseiter_9801 < 3UL; _fuseiter_9801 += 1UL) {
    float __cached_0;
    __cached_0 = __ins_0[((((fused_0fused_0__itr_0____itr_1_3250____itr_2_3251 / 384UL) * 1152UL) + ((((fused_0fused_0__itr_0____itr_1_3250____itr_2_3251 / 3UL) % 128UL) * 9UL) + ((fused_0fused_0__itr_0____itr_1_3250____itr_2_3251 % 3UL) * 3UL))) + _fuseiter_9801)];
    float __cached_1;
    __cached_1 = __ins_1[(fused_0fused_0__itr_0____itr_1_3250____itr_2_3251 / 384UL)];
    float __cached_2;
    __cached_2 = (__cached_0 * __cached_1);
    __outs_0[((((fused_0fused_0__itr_0____itr_1_3250____itr_2_3251 / 384UL) * 1152UL) + ((((fused_0fused_0__itr_0____itr_1_3250____itr_2_3251 / 3UL) % 128UL) * 9UL) + ((fused_0fused_0__itr_0____itr_1_3250____itr_2_3251 % 3UL) * 3UL))) + _fuseiter_9801)] = __cached_2;
  }
}

static void mul__1520_closure_243_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept{
  mul__1520_closure_243(i, (float*)(args[0UL].v_ptr), (float*)(args[1UL].v_ptr), (float*)(args[2UL].v_ptr));
}

static void cast__1530_closure_244(uint64_t fused_0fused_0__itr_0____itr_1_3252____itr_2_3253, float* __restrict__ __ins_0, int8_t* __restrict__ __outs_0) noexcept{
  for (uint64_t _fuseiter9806 = 0UL; _fuseiter9806 < 3UL; _fuseiter9806 += 1UL) {
    float __cached_0;
    __cached_0 = __ins_0[((((fused_0fused_0__itr_0____itr_1_3252____itr_2_3253 / 384UL) * 1152UL) + ((((fused_0fused_0__itr_0____itr_1_3252____itr_2_3253 / 3UL) % 128UL) * 9UL) + ((fused_0fused_0__itr_0____itr_1_3252____itr_2_3253 % 3UL) * 3UL))) + _fuseiter9806)];
    int8_t __cached_1;
    __cached_1 = (int8_t)sc_max(sc_min(sc_round_and_cast<int32_t>(__cached_0), 127), -128);
    __outs_0[((((fused_0fused_0__itr_0____itr_1_3252____itr_2_3253 / 384UL) * 1152UL) + ((((fused_0fused_0__itr_0____itr_1_3252____itr_2_3253 / 3UL) % 128UL) * 9UL) + ((fused_0fused_0__itr_0____itr_1_3252____itr_2_3253 % 3UL) * 3UL))) + _fuseiter9806)] = __cached_1;
  }
}

static void cast__1530_closure_244_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept{
  cast__1530_closure_244(i, (float*)(args[0UL].v_ptr), (int8_t*)(args[1UL].v_ptr));
}

static void reorder__4510_closure_245(uint64_t fused_0fused_0fused_0_fuseiter_9807___fuseiter_9808_3254___fuseiter_9809_3255___fuseiter_9810_3256, int8_t* __restrict__ __ins_0, int8_t* __restrict__ __outs_0) noexcept{
  for (uint64_t _fuseiter_9811 = 0UL; _fuseiter_9811 < 16UL; _fuseiter_9811 += 1UL) {
    for (uint64_t _fuseiter_9812 = 0UL; _fuseiter_9812 < 64UL; _fuseiter_9812 += 1UL) {
      for (uint64_t _fuseiter_9813 = 0UL; _fuseiter_9813 < 4UL; _fuseiter_9813 += 1UL) {
        int8_t __cached_0;
        __cached_0 = __ins_0[(((_fuseiter_9812 + ((fused_0fused_0fused_0_fuseiter_9807___fuseiter_9808_3254___fuseiter_9809_3255___fuseiter_9810_3256 / 18UL) * 64UL)) * 1152UL) + ((((_fuseiter_9813 + (_fuseiter_9811 * 4UL)) + (((fused_0fused_0fused_0_fuseiter_9807___fuseiter_9808_3254___fuseiter_9809_3255___fuseiter_9810_3256 / 9UL) % 2UL) * 64UL)) * 9UL) + ((((fused_0fused_0fused_0_fuseiter_9807___fuseiter_9808_3254___fuseiter_9809_3255___fuseiter_9810_3256 / 3UL) % 3UL) * 3UL) + (fused_0fused_0fused_0_fuseiter_9807___fuseiter_9808_3254___fuseiter_9809_3255___fuseiter_9810_3256 % 3UL))))];
        int8_t __cached_1;
        __cached_1 = __cached_0;
        __outs_0[(((fused_0fused_0fused_0_fuseiter_9807___fuseiter_9808_3254___fuseiter_9809_3255___fuseiter_9810_3256 / 18UL) * 73728UL) + ((((fused_0fused_0fused_0_fuseiter_9807___fuseiter_9808_3254___fuseiter_9809_3255___fuseiter_9810_3256 / 9UL) % 2UL) * 36864UL) + ((((fused_0fused_0fused_0_fuseiter_9807___fuseiter_9808_3254___fuseiter_9809_3255___fuseiter_9810_3256 / 3UL) % 3UL) * 12288UL) + (((fused_0fused_0fused_0_fuseiter_9807___fuseiter_9808_3254___fuseiter_9809_3255___fuseiter_9810_3256 % 3UL) * 4096UL) + ((_fuseiter_9811 * 256UL) + ((_fuseiter_9812 * 4UL) + _fuseiter_9813))))))] = __cached_1;
      }
    }
  }
}

static void reorder__4510_closure_245_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept{
  reorder__4510_closure_245(i, (int8_t*)(args[0UL].v_ptr), (int8_t*)(args[1UL].v_ptr));
}

static void mul__1610_closure_246(uint64_t fused_0fused_0__itr_0____itr_1_3257____itr_2_3258, float* __restrict__ __ins_0, float* __restrict__ __ins_1, float* __restrict__ __outs_0) noexcept{
  for (uint64_t _fuseiter_9818 = 0UL; _fuseiter_9818 < 3UL; _fuseiter_9818 += 1UL) {
    float __cached_0;
    __cached_0 = __ins_0[((((fused_0fused_0__itr_0____itr_1_3257____itr_2_3258 / 384UL) * 1152UL) + ((((fused_0fused_0__itr_0____itr_1_3257____itr_2_3258 / 3UL) % 128UL) * 9UL) + ((fused_0fused_0__itr_0____itr_1_3257____itr_2_3258 % 3UL) * 3UL))) + _fuseiter_9818)];
    float __cached_1;
    __cached_1 = __ins_1[(fused_0fused_0__itr_0____itr_1_3257____itr_2_3258 / 384UL)];
    float __cached_2;
    __cached_2 = (__cached_0 * __cached_1);
    __outs_0[((((fused_0fused_0__itr_0____itr_1_3257____itr_2_3258 / 384UL) * 1152UL) + ((((fused_0fused_0__itr_0____itr_1_3257____itr_2_3258 / 3UL) % 128UL) * 9UL) + ((fused_0fused_0__itr_0____itr_1_3257____itr_2_3258 % 3UL) * 3UL))) + _fuseiter_9818)] = __cached_2;
  }
}

static void mul__1610_closure_246_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept{
  mul__1610_closure_246(i, (float*)(args[0UL].v_ptr), (float*)(args[1UL].v_ptr), (float*)(args[2UL].v_ptr));
}

static void cast__1620_closure_247(uint64_t fused_0fused_0__itr_0____itr_1_3259____itr_2_3260, float* __restrict__ __ins_0, int8_t* __restrict__ __outs_0) noexcept{
  for (uint64_t _fuseiter9823 = 0UL; _fuseiter9823 < 3UL; _fuseiter9823 += 1UL) {
    float __cached_0;
    __cached_0 = __ins_0[((((fused_0fused_0__itr_0____itr_1_3259____itr_2_3260 / 384UL) * 1152UL) + ((((fused_0fused_0__itr_0____itr_1_3259____itr_2_3260 / 3UL) % 128UL) * 9UL) + ((fused_0fused_0__itr_0____itr_1_3259____itr_2_3260 % 3UL) * 3UL))) + _fuseiter9823)];
    int8_t __cached_1;
    __cached_1 = (int8_t)sc_max(sc_min(sc_round_and_cast<int32_t>(__cached_0), 127), -128);
    __outs_0[((((fused_0fused_0__itr_0____itr_1_3259____itr_2_3260 / 384UL) * 1152UL) + ((((fused_0fused_0__itr_0____itr_1_3259____itr_2_3260 / 3UL) % 128UL) * 9UL) + ((fused_0fused_0__itr_0____itr_1_3259____itr_2_3260 % 3UL) * 3UL))) + _fuseiter9823)] = __cached_1;
  }
}

static void cast__1620_closure_247_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept{
  cast__1620_closure_247(i, (float*)(args[0UL].v_ptr), (int8_t*)(args[1UL].v_ptr));
}

static void reorder__4600_closure_248(uint64_t fused_0fused_0fused_0_fuseiter_9824___fuseiter_9825_3261___fuseiter_9826_3262___fuseiter_9827_3263, int8_t* __restrict__ __ins_0, int8_t* __restrict__ __outs_0) noexcept{
  for (uint64_t _fuseiter_9828 = 0UL; _fuseiter_9828 < 16UL; _fuseiter_9828 += 1UL) {
    for (uint64_t _fuseiter_9829 = 0UL; _fuseiter_9829 < 64UL; _fuseiter_9829 += 1UL) {
      for (uint64_t _fuseiter_9830 = 0UL; _fuseiter_9830 < 4UL; _fuseiter_9830 += 1UL) {
        int8_t __cached_0;
        __cached_0 = __ins_0[(((_fuseiter_9829 + ((fused_0fused_0fused_0_fuseiter_9824___fuseiter_9825_3261___fuseiter_9826_3262___fuseiter_9827_3263 / 18UL) * 64UL)) * 1152UL) + ((((_fuseiter_9830 + (_fuseiter_9828 * 4UL)) + (((fused_0fused_0fused_0_fuseiter_9824___fuseiter_9825_3261___fuseiter_9826_3262___fuseiter_9827_3263 / 9UL) % 2UL) * 64UL)) * 9UL) + ((((fused_0fused_0fused_0_fuseiter_9824___fuseiter_9825_3261___fuseiter_9826_3262___fuseiter_9827_3263 / 3UL) % 3UL) * 3UL) + (fused_0fused_0fused_0_fuseiter_9824___fuseiter_9825_3261___fuseiter_9826_3262___fuseiter_9827_3263 % 3UL))))];
        int8_t __cached_1;
        __cached_1 = __cached_0;
        __outs_0[(((fused_0fused_0fused_0_fuseiter_9824___fuseiter_9825_3261___fuseiter_9826_3262___fuseiter_9827_3263 / 18UL) * 73728UL) + ((((fused_0fused_0fused_0_fuseiter_9824___fuseiter_9825_3261___fuseiter_9826_3262___fuseiter_9827_3263 / 9UL) % 2UL) * 36864UL) + ((((fused_0fused_0fused_0_fuseiter_9824___fuseiter_9825_3261___fuseiter_9826_3262___fuseiter_9827_3263 / 3UL) % 3UL) * 12288UL) + (((fused_0fused_0fused_0_fuseiter_9824___fuseiter_9825_3261___fuseiter_9826_3262___fuseiter_9827_3263 % 3UL) * 4096UL) + ((_fuseiter_9828 * 256UL) + ((_fuseiter_9829 * 4UL) + _fuseiter_9830))))))] = __cached_1;
      }
    }
  }
}

static void reorder__4600_closure_248_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept{
  reorder__4600_closure_248(i, (int8_t*)(args[0UL].v_ptr), (int8_t*)(args[1UL].v_ptr));
}

static void mul__1700_closure_249(uint64_t fused_0fused_0__itr_0____itr_1_3264____itr_2_3265, float* __restrict__ __ins_0, float* __restrict__ __ins_1, float* __restrict__ __outs_0) noexcept{
  for (uint64_t _fuseiter_9835 = 0UL; _fuseiter_9835 < 3UL; _fuseiter_9835 += 1UL) {
    float __cached_0;
    __cached_0 = __ins_0[((((fused_0fused_0__itr_0____itr_1_3264____itr_2_3265 / 384UL) * 1152UL) + ((((fused_0fused_0__itr_0____itr_1_3264____itr_2_3265 / 3UL) % 128UL) * 9UL) + ((fused_0fused_0__itr_0____itr_1_3264____itr_2_3265 % 3UL) * 3UL))) + _fuseiter_9835)];
    float __cached_1;
    __cached_1 = __ins_1[(fused_0fused_0__itr_0____itr_1_3264____itr_2_3265 / 384UL)];
    float __cached_2;
    __cached_2 = (__cached_0 * __cached_1);
    __outs_0[((((fused_0fused_0__itr_0____itr_1_3264____itr_2_3265 / 384UL) * 1152UL) + ((((fused_0fused_0__itr_0____itr_1_3264____itr_2_3265 / 3UL) % 128UL) * 9UL) + ((fused_0fused_0__itr_0____itr_1_3264____itr_2_3265 % 3UL) * 3UL))) + _fuseiter_9835)] = __cached_2;
  }
}

static void mul__1700_closure_249_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept{
  mul__1700_closure_249(i, (float*)(args[0UL].v_ptr), (float*)(args[1UL].v_ptr), (float*)(args[2UL].v_ptr));
}

static void cast__1710_closure_250(uint64_t fused_0fused_0__itr_0____itr_1_3266____itr_2_3267, float* __restrict__ __ins_0, int8_t* __restrict__ __outs_0) noexcept{
  for (uint64_t _fuseiter9840 = 0UL; _fuseiter9840 < 3UL; _fuseiter9840 += 1UL) {
    float __cached_0;
    __cached_0 = __ins_0[((((fused_0fused_0__itr_0____itr_1_3266____itr_2_3267 / 384UL) * 1152UL) + ((((fused_0fused_0__itr_0____itr_1_3266____itr_2_3267 / 3UL) % 128UL) * 9UL) + ((fused_0fused_0__itr_0____itr_1_3266____itr_2_3267 % 3UL) * 3UL))) + _fuseiter9840)];
    int8_t __cached_1;
    __cached_1 = (int8_t)sc_max(sc_min(sc_round_and_cast<int32_t>(__cached_0), 127), -128);
    __outs_0[((((fused_0fused_0__itr_0____itr_1_3266____itr_2_3267 / 384UL) * 1152UL) + ((((fused_0fused_0__itr_0____itr_1_3266____itr_2_3267 / 3UL) % 128UL) * 9UL) + ((fused_0fused_0__itr_0____itr_1_3266____itr_2_3267 % 3UL) * 3UL))) + _fuseiter9840)] = __cached_1;
  }
}

static void cast__1710_closure_250_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept{
  cast__1710_closure_250(i, (float*)(args[0UL].v_ptr), (int8_t*)(args[1UL].v_ptr));
}

static void reorder__4690_closure_251(uint64_t fused_0fused_0fused_0_fuseiter_9841___fuseiter_9842_3268___fuseiter_9843_3269___fuseiter_9844_3270, int8_t* __restrict__ __ins_0, int8_t* __restrict__ __outs_0) noexcept{
  for (uint64_t _fuseiter_9845 = 0UL; _fuseiter_9845 < 16UL; _fuseiter_9845 += 1UL) {
    for (uint64_t _fuseiter_9846 = 0UL; _fuseiter_9846 < 64UL; _fuseiter_9846 += 1UL) {
      for (uint64_t _fuseiter_9847 = 0UL; _fuseiter_9847 < 4UL; _fuseiter_9847 += 1UL) {
        int8_t __cached_0;
        __cached_0 = __ins_0[(((_fuseiter_9846 + ((fused_0fused_0fused_0_fuseiter_9841___fuseiter_9842_3268___fuseiter_9843_3269___fuseiter_9844_3270 / 18UL) * 64UL)) * 1152UL) + ((((_fuseiter_9847 + (_fuseiter_9845 * 4UL)) + (((fused_0fused_0fused_0_fuseiter_9841___fuseiter_9842_3268___fuseiter_9843_3269___fuseiter_9844_3270 / 9UL) % 2UL) * 64UL)) * 9UL) + ((((fused_0fused_0fused_0_fuseiter_9841___fuseiter_9842_3268___fuseiter_9843_3269___fuseiter_9844_3270 / 3UL) % 3UL) * 3UL) + (fused_0fused_0fused_0_fuseiter_9841___fuseiter_9842_3268___fuseiter_9843_3269___fuseiter_9844_3270 % 3UL))))];
        int8_t __cached_1;
        __cached_1 = __cached_0;
        __outs_0[(((fused_0fused_0fused_0_fuseiter_9841___fuseiter_9842_3268___fuseiter_9843_3269___fuseiter_9844_3270 / 18UL) * 73728UL) + ((((fused_0fused_0fused_0_fuseiter_9841___fuseiter_9842_3268___fuseiter_9843_3269___fuseiter_9844_3270 / 9UL) % 2UL) * 36864UL) + ((((fused_0fused_0fused_0_fuseiter_9841___fuseiter_9842_3268___fuseiter_9843_3269___fuseiter_9844_3270 / 3UL) % 3UL) * 12288UL) + (((fused_0fused_0fused_0_fuseiter_9841___fuseiter_9842_3268___fuseiter_9843_3269___fuseiter_9844_3270 % 3UL) * 4096UL) + ((_fuseiter_9845 * 256UL) + ((_fuseiter_9846 * 4UL) + _fuseiter_9847))))))] = __cached_1;
      }
    }
  }
}

static void reorder__4690_closure_251_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept{
  reorder__4690_closure_251(i, (int8_t*)(args[0UL].v_ptr), (int8_t*)(args[1UL].v_ptr));
}

static void mul__1850_closure_252(uint64_t fused_0fused_0__itr_0____itr_1_3271____itr_2_3272, float* __restrict__ __ins_0, float* __restrict__ __ins_1, float* __restrict__ __outs_0) noexcept{
  float __cached_0;
  __cached_0 = __ins_0[(((fused_0fused_0__itr_0____itr_1_3271____itr_2_3272 / 256UL) * 256UL) + (fused_0fused_0__itr_0____itr_1_3271____itr_2_3272 % 256UL))];
  float __cached_1;
  __cached_1 = __ins_1[(fused_0fused_0__itr_0____itr_1_3271____itr_2_3272 / 256UL)];
  float __cached_2;
  __cached_2 = (__cached_0 * __cached_1);
  __outs_0[(((fused_0fused_0__itr_0____itr_1_3271____itr_2_3272 / 256UL) * 256UL) + (fused_0fused_0__itr_0____itr_1_3271____itr_2_3272 % 256UL))] = __cached_2;
}

static void mul__1850_closure_252_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept{
  mul__1850_closure_252(i, (float*)(args[0UL].v_ptr), (float*)(args[1UL].v_ptr), (float*)(args[2UL].v_ptr));
}

static void cast__1860_closure_253(uint64_t fused_0fused_0__itr_0____itr_1_3273____itr_2_3274, float* __restrict__ __ins_0, int8_t* __restrict__ __outs_0) noexcept{
  float __cached_0;
  __cached_0 = __ins_0[(((fused_0fused_0__itr_0____itr_1_3273____itr_2_3274 / 256UL) * 256UL) + (fused_0fused_0__itr_0____itr_1_3273____itr_2_3274 % 256UL))];
  int8_t __cached_1;
  __cached_1 = (int8_t)sc_max(sc_min(sc_round_and_cast<int32_t>(__cached_0), 127), -128);
  __outs_0[(((fused_0fused_0__itr_0____itr_1_3273____itr_2_3274 / 256UL) * 256UL) + (fused_0fused_0__itr_0____itr_1_3273____itr_2_3274 % 256UL))] = __cached_1;
}

static void cast__1860_closure_253_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept{
  cast__1860_closure_253(i, (float*)(args[0UL].v_ptr), (int8_t*)(args[1UL].v_ptr));
}

static void reorder__4840_closure_254(uint64_t fused_0_fuseiter_9858___fuseiter_9859_3275, int8_t* __restrict__ __ins_0, int8_t* __restrict__ __outs_0) noexcept{
  for (uint64_t _fuseiter_9862 = 0UL; _fuseiter_9862 < 16UL; _fuseiter_9862 += 1UL) {
    for (uint64_t _fuseiter_9863 = 0UL; _fuseiter_9863 < 64UL; _fuseiter_9863 += 1UL) {
      for (uint64_t _fuseiter_9864 = 0UL; _fuseiter_9864 < 4UL; _fuseiter_9864 += 1UL) {
        int8_t __cached_0;
        __cached_0 = __ins_0[(((_fuseiter_9863 + ((fused_0_fuseiter_9858___fuseiter_9859_3275 / 4UL) * 64UL)) * 256UL) + ((_fuseiter_9864 + (_fuseiter_9862 * 4UL)) + ((fused_0_fuseiter_9858___fuseiter_9859_3275 % 4UL) * 64UL)))];
        int8_t __cached_1;
        __cached_1 = __cached_0;
        __outs_0[(((fused_0_fuseiter_9858___fuseiter_9859_3275 / 4UL) * 16384UL) + (((fused_0_fuseiter_9858___fuseiter_9859_3275 % 4UL) * 4096UL) + ((_fuseiter_9862 * 256UL) + ((_fuseiter_9863 * 4UL) + _fuseiter_9864))))] = __cached_1;
      }
    }
  }
}

static void reorder__4840_closure_254_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept{
  reorder__4840_closure_254(i, (int8_t*)(args[0UL].v_ptr), (int8_t*)(args[1UL].v_ptr));
}

static void mul__1940_closure_255(uint64_t fused_0fused_0__itr_0____itr_1_3276____itr_2_3277, float* __restrict__ __ins_0, float* __restrict__ __ins_1, float* __restrict__ __outs_0) noexcept{
  float __cached_0;
  __cached_0 = __ins_0[(((fused_0fused_0__itr_0____itr_1_3276____itr_2_3277 / 256UL) * 256UL) + (fused_0fused_0__itr_0____itr_1_3276____itr_2_3277 % 256UL))];
  float __cached_1;
  __cached_1 = __ins_1[(fused_0fused_0__itr_0____itr_1_3276____itr_2_3277 / 256UL)];
  float __cached_2;
  __cached_2 = (__cached_0 * __cached_1);
  __outs_0[(((fused_0fused_0__itr_0____itr_1_3276____itr_2_3277 / 256UL) * 256UL) + (fused_0fused_0__itr_0____itr_1_3276____itr_2_3277 % 256UL))] = __cached_2;
}

static void mul__1940_closure_255_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept{
  mul__1940_closure_255(i, (float*)(args[0UL].v_ptr), (float*)(args[1UL].v_ptr), (float*)(args[2UL].v_ptr));
}

static void cast__1950_closure_256(uint64_t fused_0fused_0__itr_0____itr_1_3278____itr_2_3279, float* __restrict__ __ins_0, int8_t* __restrict__ __outs_0) noexcept{
  float __cached_0;
  __cached_0 = __ins_0[(((fused_0fused_0__itr_0____itr_1_3278____itr_2_3279 / 256UL) * 256UL) + (fused_0fused_0__itr_0____itr_1_3278____itr_2_3279 % 256UL))];
  int8_t __cached_1;
  __cached_1 = (int8_t)sc_max(sc_min(sc_round_and_cast<int32_t>(__cached_0), 127), -128);
  __outs_0[(((fused_0fused_0__itr_0____itr_1_3278____itr_2_3279 / 256UL) * 256UL) + (fused_0fused_0__itr_0____itr_1_3278____itr_2_3279 % 256UL))] = __cached_1;
}

static void cast__1950_closure_256_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept{
  cast__1950_closure_256(i, (float*)(args[0UL].v_ptr), (int8_t*)(args[1UL].v_ptr));
}

static void reorder__4930_closure_257(uint64_t fused_0_fuseiter_9875___fuseiter_9876_3280, int8_t* __restrict__ __ins_0, int8_t* __restrict__ __outs_0) noexcept{
  for (uint64_t _fuseiter_9879 = 0UL; _fuseiter_9879 < 16UL; _fuseiter_9879 += 1UL) {
    for (uint64_t _fuseiter_9880 = 0UL; _fuseiter_9880 < 64UL; _fuseiter_9880 += 1UL) {
      for (uint64_t _fuseiter_9881 = 0UL; _fuseiter_9881 < 4UL; _fuseiter_9881 += 1UL) {
        int8_t __cached_0;
        __cached_0 = __ins_0[(((_fuseiter_9880 + ((fused_0_fuseiter_9875___fuseiter_9876_3280 / 4UL) * 64UL)) * 256UL) + ((_fuseiter_9881 + (_fuseiter_9879 * 4UL)) + ((fused_0_fuseiter_9875___fuseiter_9876_3280 % 4UL) * 64UL)))];
        int8_t __cached_1;
        __cached_1 = __cached_0;
        __outs_0[(((fused_0_fuseiter_9875___fuseiter_9876_3280 / 4UL) * 16384UL) + (((fused_0_fuseiter_9875___fuseiter_9876_3280 % 4UL) * 4096UL) + ((_fuseiter_9879 * 256UL) + ((_fuseiter_9880 * 4UL) + _fuseiter_9881))))] = __cached_1;
      }
    }
  }
}

static void reorder__4930_closure_257_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept{
  reorder__4930_closure_257(i, (int8_t*)(args[0UL].v_ptr), (int8_t*)(args[1UL].v_ptr));
}

static void mul__2030_closure_258(uint64_t fused_0fused_0__itr_0____itr_1_3281____itr_2_3282, float* __restrict__ __ins_0, float* __restrict__ __ins_1, float* __restrict__ __outs_0) noexcept{
  float __cached_0;
  __cached_0 = __ins_0[(((fused_0fused_0__itr_0____itr_1_3281____itr_2_3282 / 256UL) * 256UL) + (fused_0fused_0__itr_0____itr_1_3281____itr_2_3282 % 256UL))];
  float __cached_1;
  __cached_1 = __ins_1[(fused_0fused_0__itr_0____itr_1_3281____itr_2_3282 / 256UL)];
  float __cached_2;
  __cached_2 = (__cached_0 * __cached_1);
  __outs_0[(((fused_0fused_0__itr_0____itr_1_3281____itr_2_3282 / 256UL) * 256UL) + (fused_0fused_0__itr_0____itr_1_3281____itr_2_3282 % 256UL))] = __cached_2;
}

static void mul__2030_closure_258_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept{
  mul__2030_closure_258(i, (float*)(args[0UL].v_ptr), (float*)(args[1UL].v_ptr), (float*)(args[2UL].v_ptr));
}

static void cast__2040_closure_259(uint64_t fused_0fused_0__itr_0____itr_1_3283____itr_2_3284, float* __restrict__ __ins_0, int8_t* __restrict__ __outs_0) noexcept{
  float __cached_0;
  __cached_0 = __ins_0[(((fused_0fused_0__itr_0____itr_1_3283____itr_2_3284 / 256UL) * 256UL) + (fused_0fused_0__itr_0____itr_1_3283____itr_2_3284 % 256UL))];
  int8_t __cached_1;
  __cached_1 = (int8_t)sc_max(sc_min(sc_round_and_cast<int32_t>(__cached_0), 127), -128);
  __outs_0[(((fused_0fused_0__itr_0____itr_1_3283____itr_2_3284 / 256UL) * 256UL) + (fused_0fused_0__itr_0____itr_1_3283____itr_2_3284 % 256UL))] = __cached_1;
}

static void cast__2040_closure_259_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept{
  cast__2040_closure_259(i, (float*)(args[0UL].v_ptr), (int8_t*)(args[1UL].v_ptr));
}

static void reorder__5020_closure_260(uint64_t fused_0_fuseiter_9892___fuseiter_9893_3285, int8_t* __restrict__ __ins_0, int8_t* __restrict__ __outs_0) noexcept{
  for (uint64_t _fuseiter_9896 = 0UL; _fuseiter_9896 < 16UL; _fuseiter_9896 += 1UL) {
    for (uint64_t _fuseiter_9897 = 0UL; _fuseiter_9897 < 64UL; _fuseiter_9897 += 1UL) {
      for (uint64_t _fuseiter_9898 = 0UL; _fuseiter_9898 < 4UL; _fuseiter_9898 += 1UL) {
        int8_t __cached_0;
        __cached_0 = __ins_0[(((_fuseiter_9897 + ((fused_0_fuseiter_9892___fuseiter_9893_3285 / 4UL) * 64UL)) * 256UL) + ((_fuseiter_9898 + (_fuseiter_9896 * 4UL)) + ((fused_0_fuseiter_9892___fuseiter_9893_3285 % 4UL) * 64UL)))];
        int8_t __cached_1;
        __cached_1 = __cached_0;
        __outs_0[(((fused_0_fuseiter_9892___fuseiter_9893_3285 / 4UL) * 16384UL) + (((fused_0_fuseiter_9892___fuseiter_9893_3285 % 4UL) * 4096UL) + ((_fuseiter_9896 * 256UL) + ((_fuseiter_9897 * 4UL) + _fuseiter_9898))))] = __cached_1;
      }
    }
  }
}

static void reorder__5020_closure_260_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept{
  reorder__5020_closure_260(i, (int8_t*)(args[0UL].v_ptr), (int8_t*)(args[1UL].v_ptr));
}

static void mul__2120_closure_261(uint64_t fused_0fused_0__itr_0____itr_1_3286____itr_2_3287, float* __restrict__ __ins_0, float* __restrict__ __ins_1, float* __restrict__ __outs_0) noexcept{
  float __cached_0;
  __cached_0 = __ins_0[(((fused_0fused_0__itr_0____itr_1_3286____itr_2_3287 / 256UL) * 256UL) + (fused_0fused_0__itr_0____itr_1_3286____itr_2_3287 % 256UL))];
  float __cached_1;
  __cached_1 = __ins_1[(fused_0fused_0__itr_0____itr_1_3286____itr_2_3287 / 256UL)];
  float __cached_2;
  __cached_2 = (__cached_0 * __cached_1);
  __outs_0[(((fused_0fused_0__itr_0____itr_1_3286____itr_2_3287 / 256UL) * 256UL) + (fused_0fused_0__itr_0____itr_1_3286____itr_2_3287 % 256UL))] = __cached_2;
}

static void mul__2120_closure_261_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept{
  mul__2120_closure_261(i, (float*)(args[0UL].v_ptr), (float*)(args[1UL].v_ptr), (float*)(args[2UL].v_ptr));
}

static void cast__2130_closure_262(uint64_t fused_0fused_0__itr_0____itr_1_3288____itr_2_3289, float* __restrict__ __ins_0, int8_t* __restrict__ __outs_0) noexcept{
  float __cached_0;
  __cached_0 = __ins_0[(((fused_0fused_0__itr_0____itr_1_3288____itr_2_3289 / 256UL) * 256UL) + (fused_0fused_0__itr_0____itr_1_3288____itr_2_3289 % 256UL))];
  int8_t __cached_1;
  __cached_1 = (int8_t)sc_max(sc_min(sc_round_and_cast<int32_t>(__cached_0), 127), -128);
  __outs_0[(((fused_0fused_0__itr_0____itr_1_3288____itr_2_3289 / 256UL) * 256UL) + (fused_0fused_0__itr_0____itr_1_3288____itr_2_3289 % 256UL))] = __cached_1;
}

static void cast__2130_closure_262_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept{
  cast__2130_closure_262(i, (float*)(args[0UL].v_ptr), (int8_t*)(args[1UL].v_ptr));
}

static void reorder__5110_closure_263(uint64_t fused_0_fuseiter_9909___fuseiter_9910_3290, int8_t* __restrict__ __ins_0, int8_t* __restrict__ __outs_0) noexcept{
  for (uint64_t _fuseiter_9913 = 0UL; _fuseiter_9913 < 16UL; _fuseiter_9913 += 1UL) {
    for (uint64_t _fuseiter_9914 = 0UL; _fuseiter_9914 < 64UL; _fuseiter_9914 += 1UL) {
      for (uint64_t _fuseiter_9915 = 0UL; _fuseiter_9915 < 4UL; _fuseiter_9915 += 1UL) {
        int8_t __cached_0;
        __cached_0 = __ins_0[(((_fuseiter_9914 + ((fused_0_fuseiter_9909___fuseiter_9910_3290 / 4UL) * 64UL)) * 256UL) + ((_fuseiter_9915 + (_fuseiter_9913 * 4UL)) + ((fused_0_fuseiter_9909___fuseiter_9910_3290 % 4UL) * 64UL)))];
        int8_t __cached_1;
        __cached_1 = __cached_0;
        __outs_0[(((fused_0_fuseiter_9909___fuseiter_9910_3290 / 4UL) * 16384UL) + (((fused_0_fuseiter_9909___fuseiter_9910_3290 % 4UL) * 4096UL) + ((_fuseiter_9913 * 256UL) + ((_fuseiter_9914 * 4UL) + _fuseiter_9915))))] = __cached_1;
      }
    }
  }
}

static void reorder__5110_closure_263_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept{
  reorder__5110_closure_263(i, (int8_t*)(args[0UL].v_ptr), (int8_t*)(args[1UL].v_ptr));
}

static void mul__2210_closure_264(uint64_t fused_0fused_0__itr_0____itr_1_3291____itr_2_3292, float* __restrict__ __ins_0, float* __restrict__ __ins_1, float* __restrict__ __outs_0) noexcept{
  float __cached_0;
  __cached_0 = __ins_0[(((fused_0fused_0__itr_0____itr_1_3291____itr_2_3292 / 256UL) * 256UL) + (fused_0fused_0__itr_0____itr_1_3291____itr_2_3292 % 256UL))];
  float __cached_1;
  __cached_1 = __ins_1[(fused_0fused_0__itr_0____itr_1_3291____itr_2_3292 / 256UL)];
  float __cached_2;
  __cached_2 = (__cached_0 * __cached_1);
  __outs_0[(((fused_0fused_0__itr_0____itr_1_3291____itr_2_3292 / 256UL) * 256UL) + (fused_0fused_0__itr_0____itr_1_3291____itr_2_3292 % 256UL))] = __cached_2;
}

static void mul__2210_closure_264_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept{
  mul__2210_closure_264(i, (float*)(args[0UL].v_ptr), (float*)(args[1UL].v_ptr), (float*)(args[2UL].v_ptr));
}

static void cast__2220_closure_265(uint64_t fused_0fused_0__itr_0____itr_1_3293____itr_2_3294, float* __restrict__ __ins_0, int8_t* __restrict__ __outs_0) noexcept{
  float __cached_0;
  __cached_0 = __ins_0[(((fused_0fused_0__itr_0____itr_1_3293____itr_2_3294 / 256UL) * 256UL) + (fused_0fused_0__itr_0____itr_1_3293____itr_2_3294 % 256UL))];
  int8_t __cached_1;
  __cached_1 = (int8_t)sc_max(sc_min(sc_round_and_cast<int32_t>(__cached_0), 127), -128);
  __outs_0[(((fused_0fused_0__itr_0____itr_1_3293____itr_2_3294 / 256UL) * 256UL) + (fused_0fused_0__itr_0____itr_1_3293____itr_2_3294 % 256UL))] = __cached_1;
}

static void cast__2220_closure_265_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept{
  cast__2220_closure_265(i, (float*)(args[0UL].v_ptr), (int8_t*)(args[1UL].v_ptr));
}

static void reorder__5200_closure_266(uint64_t fused_0_fuseiter_9926___fuseiter_9927_3295, int8_t* __restrict__ __ins_0, int8_t* __restrict__ __outs_0) noexcept{
  for (uint64_t _fuseiter_9930 = 0UL; _fuseiter_9930 < 16UL; _fuseiter_9930 += 1UL) {
    for (uint64_t _fuseiter_9931 = 0UL; _fuseiter_9931 < 64UL; _fuseiter_9931 += 1UL) {
      for (uint64_t _fuseiter_9932 = 0UL; _fuseiter_9932 < 4UL; _fuseiter_9932 += 1UL) {
        int8_t __cached_0;
        __cached_0 = __ins_0[(((_fuseiter_9931 + ((fused_0_fuseiter_9926___fuseiter_9927_3295 / 4UL) * 64UL)) * 256UL) + ((_fuseiter_9932 + (_fuseiter_9930 * 4UL)) + ((fused_0_fuseiter_9926___fuseiter_9927_3295 % 4UL) * 64UL)))];
        int8_t __cached_1;
        __cached_1 = __cached_0;
        __outs_0[(((fused_0_fuseiter_9926___fuseiter_9927_3295 / 4UL) * 16384UL) + (((fused_0_fuseiter_9926___fuseiter_9927_3295 % 4UL) * 4096UL) + ((_fuseiter_9930 * 256UL) + ((_fuseiter_9931 * 4UL) + _fuseiter_9932))))] = __cached_1;
      }
    }
  }
}

static void reorder__5200_closure_266_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept{
  reorder__5200_closure_266(i, (int8_t*)(args[0UL].v_ptr), (int8_t*)(args[1UL].v_ptr));
}

static void mul__2300_closure_267(uint64_t fused_0fused_0__itr_0____itr_1_3296____itr_2_3297, float* __restrict__ __ins_0, float* __restrict__ __ins_1, float* __restrict__ __outs_0) noexcept{
  float __cached_0;
  __cached_0 = __ins_0[(((fused_0fused_0__itr_0____itr_1_3296____itr_2_3297 / 256UL) * 256UL) + (fused_0fused_0__itr_0____itr_1_3296____itr_2_3297 % 256UL))];
  float __cached_1;
  __cached_1 = __ins_1[(fused_0fused_0__itr_0____itr_1_3296____itr_2_3297 / 256UL)];
  float __cached_2;
  __cached_2 = (__cached_0 * __cached_1);
  __outs_0[(((fused_0fused_0__itr_0____itr_1_3296____itr_2_3297 / 256UL) * 256UL) + (fused_0fused_0__itr_0____itr_1_3296____itr_2_3297 % 256UL))] = __cached_2;
}

static void mul__2300_closure_267_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept{
  mul__2300_closure_267(i, (float*)(args[0UL].v_ptr), (float*)(args[1UL].v_ptr), (float*)(args[2UL].v_ptr));
}

static void cast__2310_closure_268(uint64_t fused_0fused_0__itr_0____itr_1_3298____itr_2_3299, float* __restrict__ __ins_0, int8_t* __restrict__ __outs_0) noexcept{
  float __cached_0;
  __cached_0 = __ins_0[(((fused_0fused_0__itr_0____itr_1_3298____itr_2_3299 / 256UL) * 256UL) + (fused_0fused_0__itr_0____itr_1_3298____itr_2_3299 % 256UL))];
  int8_t __cached_1;
  __cached_1 = (int8_t)sc_max(sc_min(sc_round_and_cast<int32_t>(__cached_0), 127), -128);
  __outs_0[(((fused_0fused_0__itr_0____itr_1_3298____itr_2_3299 / 256UL) * 256UL) + (fused_0fused_0__itr_0____itr_1_3298____itr_2_3299 % 256UL))] = __cached_1;
}

static void cast__2310_closure_268_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept{
  cast__2310_closure_268(i, (float*)(args[0UL].v_ptr), (int8_t*)(args[1UL].v_ptr));
}

static void reorder__5290_closure_269(uint64_t fused_0_fuseiter_9943___fuseiter_9944_3300, int8_t* __restrict__ __ins_0, int8_t* __restrict__ __outs_0) noexcept{
  for (uint64_t _fuseiter_9947 = 0UL; _fuseiter_9947 < 16UL; _fuseiter_9947 += 1UL) {
    for (uint64_t _fuseiter_9948 = 0UL; _fuseiter_9948 < 64UL; _fuseiter_9948 += 1UL) {
      for (uint64_t _fuseiter_9949 = 0UL; _fuseiter_9949 < 4UL; _fuseiter_9949 += 1UL) {
        int8_t __cached_0;
        __cached_0 = __ins_0[(((_fuseiter_9948 + ((fused_0_fuseiter_9943___fuseiter_9944_3300 / 4UL) * 64UL)) * 256UL) + ((_fuseiter_9949 + (_fuseiter_9947 * 4UL)) + ((fused_0_fuseiter_9943___fuseiter_9944_3300 % 4UL) * 64UL)))];
        int8_t __cached_1;
        __cached_1 = __cached_0;
        __outs_0[(((fused_0_fuseiter_9943___fuseiter_9944_3300 / 4UL) * 16384UL) + (((fused_0_fuseiter_9943___fuseiter_9944_3300 % 4UL) * 4096UL) + ((_fuseiter_9947 * 256UL) + ((_fuseiter_9948 * 4UL) + _fuseiter_9949))))] = __cached_1;
      }
    }
  }
}

static void reorder__5290_closure_269_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept{
  reorder__5290_closure_269(i, (int8_t*)(args[0UL].v_ptr), (int8_t*)(args[1UL].v_ptr));
}

static void mul__1880_closure_270(uint64_t fused_0fused_0__itr_0____itr_1_3301____itr_2_3302, float* __restrict__ __ins_0, float* __restrict__ __ins_1, float* __restrict__ __outs_0) noexcept{
  float __cached_0;
  __cached_0 = __ins_0[(((fused_0fused_0__itr_0____itr_1_3301____itr_2_3302 / 1024UL) * 1024UL) + (fused_0fused_0__itr_0____itr_1_3301____itr_2_3302 % 1024UL))];
  float __cached_1;
  __cached_1 = __ins_1[(fused_0fused_0__itr_0____itr_1_3301____itr_2_3302 / 1024UL)];
  float __cached_2;
  __cached_2 = (__cached_0 * __cached_1);
  __outs_0[(((fused_0fused_0__itr_0____itr_1_3301____itr_2_3302 / 1024UL) * 1024UL) + (fused_0fused_0__itr_0____itr_1_3301____itr_2_3302 % 1024UL))] = __cached_2;
}

static void mul__1880_closure_270_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept{
  mul__1880_closure_270(i, (float*)(args[0UL].v_ptr), (float*)(args[1UL].v_ptr), (float*)(args[2UL].v_ptr));
}

static void cast__1890_closure_271(uint64_t fused_0fused_0__itr_0____itr_1_3303____itr_2_3304, float* __restrict__ __ins_0, int8_t* __restrict__ __outs_0) noexcept{
  float __cached_0;
  __cached_0 = __ins_0[(((fused_0fused_0__itr_0____itr_1_3303____itr_2_3304 / 1024UL) * 1024UL) + (fused_0fused_0__itr_0____itr_1_3303____itr_2_3304 % 1024UL))];
  int8_t __cached_1;
  __cached_1 = (int8_t)sc_max(sc_min(sc_round_and_cast<int32_t>(__cached_0), 127), -128);
  __outs_0[(((fused_0fused_0__itr_0____itr_1_3303____itr_2_3304 / 1024UL) * 1024UL) + (fused_0fused_0__itr_0____itr_1_3303____itr_2_3304 % 1024UL))] = __cached_1;
}

static void cast__1890_closure_271_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept{
  cast__1890_closure_271(i, (float*)(args[0UL].v_ptr), (int8_t*)(args[1UL].v_ptr));
}

static void reorder__4870_closure_272(uint64_t fused_0_fuseiter_9960___fuseiter_9961_3305, int8_t* __restrict__ __ins_0, int8_t* __restrict__ __outs_0) noexcept{
  for (uint64_t _fuseiter_9964 = 0UL; _fuseiter_9964 < 16UL; _fuseiter_9964 += 1UL) {
    for (uint64_t _fuseiter_9965 = 0UL; _fuseiter_9965 < 64UL; _fuseiter_9965 += 1UL) {
      for (uint64_t _fuseiter_9966 = 0UL; _fuseiter_9966 < 4UL; _fuseiter_9966 += 1UL) {
        int8_t __cached_0;
        __cached_0 = __ins_0[(((_fuseiter_9965 + ((fused_0_fuseiter_9960___fuseiter_9961_3305 / 16UL) * 64UL)) * 1024UL) + ((_fuseiter_9966 + (_fuseiter_9964 * 4UL)) + ((fused_0_fuseiter_9960___fuseiter_9961_3305 % 16UL) * 64UL)))];
        int8_t __cached_1;
        __cached_1 = __cached_0;
        __outs_0[(((fused_0_fuseiter_9960___fuseiter_9961_3305 / 16UL) * 65536UL) + (((fused_0_fuseiter_9960___fuseiter_9961_3305 % 16UL) * 4096UL) + ((_fuseiter_9964 * 256UL) + ((_fuseiter_9965 * 4UL) + _fuseiter_9966))))] = __cached_1;
      }
    }
  }
}

static void reorder__4870_closure_272_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept{
  reorder__4870_closure_272(i, (int8_t*)(args[0UL].v_ptr), (int8_t*)(args[1UL].v_ptr));
}

static void mul__1970_closure_273(uint64_t fused_0fused_0__itr_0____itr_1_3306____itr_2_3307, float* __restrict__ __ins_0, float* __restrict__ __ins_1, float* __restrict__ __outs_0) noexcept{
  float __cached_0;
  __cached_0 = __ins_0[(((fused_0fused_0__itr_0____itr_1_3306____itr_2_3307 / 1024UL) * 1024UL) + (fused_0fused_0__itr_0____itr_1_3306____itr_2_3307 % 1024UL))];
  float __cached_1;
  __cached_1 = __ins_1[(fused_0fused_0__itr_0____itr_1_3306____itr_2_3307 / 1024UL)];
  float __cached_2;
  __cached_2 = (__cached_0 * __cached_1);
  __outs_0[(((fused_0fused_0__itr_0____itr_1_3306____itr_2_3307 / 1024UL) * 1024UL) + (fused_0fused_0__itr_0____itr_1_3306____itr_2_3307 % 1024UL))] = __cached_2;
}

static void mul__1970_closure_273_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept{
  mul__1970_closure_273(i, (float*)(args[0UL].v_ptr), (float*)(args[1UL].v_ptr), (float*)(args[2UL].v_ptr));
}

static void cast__1980_closure_274(uint64_t fused_0fused_0__itr_0____itr_1_3308____itr_2_3309, float* __restrict__ __ins_0, int8_t* __restrict__ __outs_0) noexcept{
  float __cached_0;
  __cached_0 = __ins_0[(((fused_0fused_0__itr_0____itr_1_3308____itr_2_3309 / 1024UL) * 1024UL) + (fused_0fused_0__itr_0____itr_1_3308____itr_2_3309 % 1024UL))];
  int8_t __cached_1;
  __cached_1 = (int8_t)sc_max(sc_min(sc_round_and_cast<int32_t>(__cached_0), 127), -128);
  __outs_0[(((fused_0fused_0__itr_0____itr_1_3308____itr_2_3309 / 1024UL) * 1024UL) + (fused_0fused_0__itr_0____itr_1_3308____itr_2_3309 % 1024UL))] = __cached_1;
}

static void cast__1980_closure_274_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept{
  cast__1980_closure_274(i, (float*)(args[0UL].v_ptr), (int8_t*)(args[1UL].v_ptr));
}

static void reorder__4960_closure_275(uint64_t fused_0_fuseiter_9977___fuseiter_9978_3310, int8_t* __restrict__ __ins_0, int8_t* __restrict__ __outs_0) noexcept{
  for (uint64_t _fuseiter_9981 = 0UL; _fuseiter_9981 < 16UL; _fuseiter_9981 += 1UL) {
    for (uint64_t _fuseiter_9982 = 0UL; _fuseiter_9982 < 64UL; _fuseiter_9982 += 1UL) {
      for (uint64_t _fuseiter_9983 = 0UL; _fuseiter_9983 < 4UL; _fuseiter_9983 += 1UL) {
        int8_t __cached_0;
        __cached_0 = __ins_0[(((_fuseiter_9982 + ((fused_0_fuseiter_9977___fuseiter_9978_3310 / 16UL) * 64UL)) * 1024UL) + ((_fuseiter_9983 + (_fuseiter_9981 * 4UL)) + ((fused_0_fuseiter_9977___fuseiter_9978_3310 % 16UL) * 64UL)))];
        int8_t __cached_1;
        __cached_1 = __cached_0;
        __outs_0[(((fused_0_fuseiter_9977___fuseiter_9978_3310 / 16UL) * 65536UL) + (((fused_0_fuseiter_9977___fuseiter_9978_3310 % 16UL) * 4096UL) + ((_fuseiter_9981 * 256UL) + ((_fuseiter_9982 * 4UL) + _fuseiter_9983))))] = __cached_1;
      }
    }
  }
}

static void reorder__4960_closure_275_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept{
  reorder__4960_closure_275(i, (int8_t*)(args[0UL].v_ptr), (int8_t*)(args[1UL].v_ptr));
}

static void mul__2060_closure_276(uint64_t fused_0fused_0__itr_0____itr_1_3311____itr_2_3312, float* __restrict__ __ins_0, float* __restrict__ __ins_1, float* __restrict__ __outs_0) noexcept{
  float __cached_0;
  __cached_0 = __ins_0[(((fused_0fused_0__itr_0____itr_1_3311____itr_2_3312 / 1024UL) * 1024UL) + (fused_0fused_0__itr_0____itr_1_3311____itr_2_3312 % 1024UL))];
  float __cached_1;
  __cached_1 = __ins_1[(fused_0fused_0__itr_0____itr_1_3311____itr_2_3312 / 1024UL)];
  float __cached_2;
  __cached_2 = (__cached_0 * __cached_1);
  __outs_0[(((fused_0fused_0__itr_0____itr_1_3311____itr_2_3312 / 1024UL) * 1024UL) + (fused_0fused_0__itr_0____itr_1_3311____itr_2_3312 % 1024UL))] = __cached_2;
}

static void mul__2060_closure_276_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept{
  mul__2060_closure_276(i, (float*)(args[0UL].v_ptr), (float*)(args[1UL].v_ptr), (float*)(args[2UL].v_ptr));
}

static void cast__2070_closure_277(uint64_t fused_0fused_0__itr_0____itr_1_3313____itr_2_3314, float* __restrict__ __ins_0, int8_t* __restrict__ __outs_0) noexcept{
  float __cached_0;
  __cached_0 = __ins_0[(((fused_0fused_0__itr_0____itr_1_3313____itr_2_3314 / 1024UL) * 1024UL) + (fused_0fused_0__itr_0____itr_1_3313____itr_2_3314 % 1024UL))];
  int8_t __cached_1;
  __cached_1 = (int8_t)sc_max(sc_min(sc_round_and_cast<int32_t>(__cached_0), 127), -128);
  __outs_0[(((fused_0fused_0__itr_0____itr_1_3313____itr_2_3314 / 1024UL) * 1024UL) + (fused_0fused_0__itr_0____itr_1_3313____itr_2_3314 % 1024UL))] = __cached_1;
}

static void cast__2070_closure_277_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept{
  cast__2070_closure_277(i, (float*)(args[0UL].v_ptr), (int8_t*)(args[1UL].v_ptr));
}

static void reorder__5050_closure_278(uint64_t fused_0_fuseiter_9994___fuseiter_9995_3315, int8_t* __restrict__ __ins_0, int8_t* __restrict__ __outs_0) noexcept{
  for (uint64_t _fuseiter_9998 = 0UL; _fuseiter_9998 < 16UL; _fuseiter_9998 += 1UL) {
    for (uint64_t _fuseiter_9999 = 0UL; _fuseiter_9999 < 64UL; _fuseiter_9999 += 1UL) {
      for (uint64_t _fuseiter_10000 = 0UL; _fuseiter_10000 < 4UL; _fuseiter_10000 += 1UL) {
        int8_t __cached_0;
        __cached_0 = __ins_0[(((_fuseiter_9999 + ((fused_0_fuseiter_9994___fuseiter_9995_3315 / 16UL) * 64UL)) * 1024UL) + ((_fuseiter_10000 + (_fuseiter_9998 * 4UL)) + ((fused_0_fuseiter_9994___fuseiter_9995_3315 % 16UL) * 64UL)))];
        int8_t __cached_1;
        __cached_1 = __cached_0;
        __outs_0[(((fused_0_fuseiter_9994___fuseiter_9995_3315 / 16UL) * 65536UL) + (((fused_0_fuseiter_9994___fuseiter_9995_3315 % 16UL) * 4096UL) + ((_fuseiter_9998 * 256UL) + ((_fuseiter_9999 * 4UL) + _fuseiter_10000))))] = __cached_1;
      }
    }
  }
}

static void reorder__5050_closure_278_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept{
  reorder__5050_closure_278(i, (int8_t*)(args[0UL].v_ptr), (int8_t*)(args[1UL].v_ptr));
}

static void mul__2150_closure_279(uint64_t fused_0fused_0__itr_0____itr_1_3316____itr_2_3317, float* __restrict__ __ins_0, float* __restrict__ __ins_1, float* __restrict__ __outs_0) noexcept{
  float __cached_0;
  __cached_0 = __ins_0[(((fused_0fused_0__itr_0____itr_1_3316____itr_2_3317 / 1024UL) * 1024UL) + (fused_0fused_0__itr_0____itr_1_3316____itr_2_3317 % 1024UL))];
  float __cached_1;
  __cached_1 = __ins_1[(fused_0fused_0__itr_0____itr_1_3316____itr_2_3317 / 1024UL)];
  float __cached_2;
  __cached_2 = (__cached_0 * __cached_1);
  __outs_0[(((fused_0fused_0__itr_0____itr_1_3316____itr_2_3317 / 1024UL) * 1024UL) + (fused_0fused_0__itr_0____itr_1_3316____itr_2_3317 % 1024UL))] = __cached_2;
}

static void mul__2150_closure_279_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept{
  mul__2150_closure_279(i, (float*)(args[0UL].v_ptr), (float*)(args[1UL].v_ptr), (float*)(args[2UL].v_ptr));
}

static void cast__2160_closure_280(uint64_t fused_0fused_0__itr_0____itr_1_3318____itr_2_3319, float* __restrict__ __ins_0, int8_t* __restrict__ __outs_0) noexcept{
  float __cached_0;
  __cached_0 = __ins_0[(((fused_0fused_0__itr_0____itr_1_3318____itr_2_3319 / 1024UL) * 1024UL) + (fused_0fused_0__itr_0____itr_1_3318____itr_2_3319 % 1024UL))];
  int8_t __cached_1;
  __cached_1 = (int8_t)sc_max(sc_min(sc_round_and_cast<int32_t>(__cached_0), 127), -128);
  __outs_0[(((fused_0fused_0__itr_0____itr_1_3318____itr_2_3319 / 1024UL) * 1024UL) + (fused_0fused_0__itr_0____itr_1_3318____itr_2_3319 % 1024UL))] = __cached_1;
}

static void cast__2160_closure_280_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept{
  cast__2160_closure_280(i, (float*)(args[0UL].v_ptr), (int8_t*)(args[1UL].v_ptr));
}

static void reorder__5140_closure_281(uint64_t fused_0_fuseiter_10011___fuseiter_10012_3320, int8_t* __restrict__ __ins_0, int8_t* __restrict__ __outs_0) noexcept{
  for (uint64_t _fuseiter_10015 = 0UL; _fuseiter_10015 < 16UL; _fuseiter_10015 += 1UL) {
    for (uint64_t _fuseiter_10016 = 0UL; _fuseiter_10016 < 64UL; _fuseiter_10016 += 1UL) {
      for (uint64_t _fuseiter_10017 = 0UL; _fuseiter_10017 < 4UL; _fuseiter_10017 += 1UL) {
        int8_t __cached_0;
        __cached_0 = __ins_0[(((_fuseiter_10016 + ((fused_0_fuseiter_10011___fuseiter_10012_3320 / 16UL) * 64UL)) * 1024UL) + ((_fuseiter_10017 + (_fuseiter_10015 * 4UL)) + ((fused_0_fuseiter_10011___fuseiter_10012_3320 % 16UL) * 64UL)))];
        int8_t __cached_1;
        __cached_1 = __cached_0;
        __outs_0[(((fused_0_fuseiter_10011___fuseiter_10012_3320 / 16UL) * 65536UL) + (((fused_0_fuseiter_10011___fuseiter_10012_3320 % 16UL) * 4096UL) + ((_fuseiter_10015 * 256UL) + ((_fuseiter_10016 * 4UL) + _fuseiter_10017))))] = __cached_1;
      }
    }
  }
}

static void reorder__5140_closure_281_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept{
  reorder__5140_closure_281(i, (int8_t*)(args[0UL].v_ptr), (int8_t*)(args[1UL].v_ptr));
}

static void mul__2240_closure_282(uint64_t fused_0fused_0__itr_0____itr_1_3321____itr_2_3322, float* __restrict__ __ins_0, float* __restrict__ __ins_1, float* __restrict__ __outs_0) noexcept{
  float __cached_0;
  __cached_0 = __ins_0[(((fused_0fused_0__itr_0____itr_1_3321____itr_2_3322 / 1024UL) * 1024UL) + (fused_0fused_0__itr_0____itr_1_3321____itr_2_3322 % 1024UL))];
  float __cached_1;
  __cached_1 = __ins_1[(fused_0fused_0__itr_0____itr_1_3321____itr_2_3322 / 1024UL)];
  float __cached_2;
  __cached_2 = (__cached_0 * __cached_1);
  __outs_0[(((fused_0fused_0__itr_0____itr_1_3321____itr_2_3322 / 1024UL) * 1024UL) + (fused_0fused_0__itr_0____itr_1_3321____itr_2_3322 % 1024UL))] = __cached_2;
}

static void mul__2240_closure_282_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept{
  mul__2240_closure_282(i, (float*)(args[0UL].v_ptr), (float*)(args[1UL].v_ptr), (float*)(args[2UL].v_ptr));
}

static void cast__2250_closure_283(uint64_t fused_0fused_0__itr_0____itr_1_3323____itr_2_3324, float* __restrict__ __ins_0, int8_t* __restrict__ __outs_0) noexcept{
  float __cached_0;
  __cached_0 = __ins_0[(((fused_0fused_0__itr_0____itr_1_3323____itr_2_3324 / 1024UL) * 1024UL) + (fused_0fused_0__itr_0____itr_1_3323____itr_2_3324 % 1024UL))];
  int8_t __cached_1;
  __cached_1 = (int8_t)sc_max(sc_min(sc_round_and_cast<int32_t>(__cached_0), 127), -128);
  __outs_0[(((fused_0fused_0__itr_0____itr_1_3323____itr_2_3324 / 1024UL) * 1024UL) + (fused_0fused_0__itr_0____itr_1_3323____itr_2_3324 % 1024UL))] = __cached_1;
}

static void cast__2250_closure_283_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept{
  cast__2250_closure_283(i, (float*)(args[0UL].v_ptr), (int8_t*)(args[1UL].v_ptr));
}

static void reorder__5230_closure_284(uint64_t fused_0_fuseiter_10028___fuseiter_10029_3325, int8_t* __restrict__ __ins_0, int8_t* __restrict__ __outs_0) noexcept{
  for (uint64_t _fuseiter_10032 = 0UL; _fuseiter_10032 < 16UL; _fuseiter_10032 += 1UL) {
    for (uint64_t _fuseiter_10033 = 0UL; _fuseiter_10033 < 64UL; _fuseiter_10033 += 1UL) {
      for (uint64_t _fuseiter_10034 = 0UL; _fuseiter_10034 < 4UL; _fuseiter_10034 += 1UL) {
        int8_t __cached_0;
        __cached_0 = __ins_0[(((_fuseiter_10033 + ((fused_0_fuseiter_10028___fuseiter_10029_3325 / 16UL) * 64UL)) * 1024UL) + ((_fuseiter_10034 + (_fuseiter_10032 * 4UL)) + ((fused_0_fuseiter_10028___fuseiter_10029_3325 % 16UL) * 64UL)))];
        int8_t __cached_1;
        __cached_1 = __cached_0;
        __outs_0[(((fused_0_fuseiter_10028___fuseiter_10029_3325 / 16UL) * 65536UL) + (((fused_0_fuseiter_10028___fuseiter_10029_3325 % 16UL) * 4096UL) + ((_fuseiter_10032 * 256UL) + ((_fuseiter_10033 * 4UL) + _fuseiter_10034))))] = __cached_1;
      }
    }
  }
}

static void reorder__5230_closure_284_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept{
  reorder__5230_closure_284(i, (int8_t*)(args[0UL].v_ptr), (int8_t*)(args[1UL].v_ptr));
}

static void mul__1760_closure_285(uint64_t fused_0fused_0__itr_0____itr_1_3326____itr_2_3327, float* __restrict__ __ins_0, float* __restrict__ __ins_1, float* __restrict__ __outs_0) noexcept{
  float __cached_0;
  __cached_0 = __ins_0[(((fused_0fused_0__itr_0____itr_1_3326____itr_2_3327 / 512UL) * 512UL) + (fused_0fused_0__itr_0____itr_1_3326____itr_2_3327 % 512UL))];
  float __cached_1;
  __cached_1 = __ins_1[(fused_0fused_0__itr_0____itr_1_3326____itr_2_3327 / 512UL)];
  float __cached_2;
  __cached_2 = (__cached_0 * __cached_1);
  __outs_0[(((fused_0fused_0__itr_0____itr_1_3326____itr_2_3327 / 512UL) * 512UL) + (fused_0fused_0__itr_0____itr_1_3326____itr_2_3327 % 512UL))] = __cached_2;
}

static void mul__1760_closure_285_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept{
  mul__1760_closure_285(i, (float*)(args[0UL].v_ptr), (float*)(args[1UL].v_ptr), (float*)(args[2UL].v_ptr));
}

static void cast__1770_closure_286(uint64_t fused_0fused_0__itr_0____itr_1_3328____itr_2_3329, float* __restrict__ __ins_0, int8_t* __restrict__ __outs_0) noexcept{
  float __cached_0;
  __cached_0 = __ins_0[(((fused_0fused_0__itr_0____itr_1_3328____itr_2_3329 / 512UL) * 512UL) + (fused_0fused_0__itr_0____itr_1_3328____itr_2_3329 % 512UL))];
  int8_t __cached_1;
  __cached_1 = (int8_t)sc_max(sc_min(sc_round_and_cast<int32_t>(__cached_0), 127), -128);
  __outs_0[(((fused_0fused_0__itr_0____itr_1_3328____itr_2_3329 / 512UL) * 512UL) + (fused_0fused_0__itr_0____itr_1_3328____itr_2_3329 % 512UL))] = __cached_1;
}

static void cast__1770_closure_286_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept{
  cast__1770_closure_286(i, (float*)(args[0UL].v_ptr), (int8_t*)(args[1UL].v_ptr));
}

static void reorder__4750_closure_287(uint64_t fused_0_fuseiter_10045___fuseiter_10046_3330, int8_t* __restrict__ __ins_0, int8_t* __restrict__ __outs_0) noexcept{
  for (uint64_t _fuseiter_10049 = 0UL; _fuseiter_10049 < 16UL; _fuseiter_10049 += 1UL) {
    for (uint64_t _fuseiter_10050 = 0UL; _fuseiter_10050 < 64UL; _fuseiter_10050 += 1UL) {
      for (uint64_t _fuseiter_10051 = 0UL; _fuseiter_10051 < 4UL; _fuseiter_10051 += 1UL) {
        int8_t __cached_0;
        __cached_0 = __ins_0[(((_fuseiter_10050 + ((fused_0_fuseiter_10045___fuseiter_10046_3330 / 8UL) * 64UL)) * 512UL) + ((_fuseiter_10051 + (_fuseiter_10049 * 4UL)) + ((fused_0_fuseiter_10045___fuseiter_10046_3330 % 8UL) * 64UL)))];
        int8_t __cached_1;
        __cached_1 = __cached_0;
        __outs_0[(((fused_0_fuseiter_10045___fuseiter_10046_3330 / 8UL) * 32768UL) + (((fused_0_fuseiter_10045___fuseiter_10046_3330 % 8UL) * 4096UL) + ((_fuseiter_10049 * 256UL) + ((_fuseiter_10050 * 4UL) + _fuseiter_10051))))] = __cached_1;
      }
    }
  }
}

static void reorder__4750_closure_287_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept{
  reorder__4750_closure_287(i, (int8_t*)(args[0UL].v_ptr), (int8_t*)(args[1UL].v_ptr));
}

static void mul__2360_closure_288(uint64_t fused_0fused_0__itr_0____itr_1_3331____itr_2_3332, float* __restrict__ __ins_0, float* __restrict__ __ins_1, float* __restrict__ __outs_0) noexcept{
  float __cached_0;
  __cached_0 = __ins_0[(((fused_0fused_0__itr_0____itr_1_3331____itr_2_3332 / 1024UL) * 1024UL) + (fused_0fused_0__itr_0____itr_1_3331____itr_2_3332 % 1024UL))];
  float __cached_1;
  __cached_1 = __ins_1[(fused_0fused_0__itr_0____itr_1_3331____itr_2_3332 / 1024UL)];
  float __cached_2;
  __cached_2 = (__cached_0 * __cached_1);
  __outs_0[(((fused_0fused_0__itr_0____itr_1_3331____itr_2_3332 / 1024UL) * 1024UL) + (fused_0fused_0__itr_0____itr_1_3331____itr_2_3332 % 1024UL))] = __cached_2;
}

static void mul__2360_closure_288_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept{
  mul__2360_closure_288(i, (float*)(args[0UL].v_ptr), (float*)(args[1UL].v_ptr), (float*)(args[2UL].v_ptr));
}

static void cast__2370_closure_289(uint64_t fused_0fused_0__itr_0____itr_1_3333____itr_2_3334, float* __restrict__ __ins_0, int8_t* __restrict__ __outs_0) noexcept{
  float __cached_0;
  __cached_0 = __ins_0[(((fused_0fused_0__itr_0____itr_1_3333____itr_2_3334 / 1024UL) * 1024UL) + (fused_0fused_0__itr_0____itr_1_3333____itr_2_3334 % 1024UL))];
  int8_t __cached_1;
  __cached_1 = (int8_t)sc_max(sc_min(sc_round_and_cast<int32_t>(__cached_0), 127), -128);
  __outs_0[(((fused_0fused_0__itr_0____itr_1_3333____itr_2_3334 / 1024UL) * 1024UL) + (fused_0fused_0__itr_0____itr_1_3333____itr_2_3334 % 1024UL))] = __cached_1;
}

static void cast__2370_closure_289_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept{
  cast__2370_closure_289(i, (float*)(args[0UL].v_ptr), (int8_t*)(args[1UL].v_ptr));
}

static void reorder__5350_closure_290(uint64_t fused_0fused_0fused_0fused_0_fuseiter_10062___fuseiter_10063_3335___fuseiter_10064_3336___fuseiter_10065_3337___fuseiter_10066_3338, int8_t* __restrict__ __ins_0, int8_t* __restrict__ __outs_0) noexcept{
  for (uint64_t _fuseiter_10067 = 0UL; _fuseiter_10067 < 512UL; _fuseiter_10067 += 1UL) {
    for (uint64_t _fuseiter_10068 = 0UL; _fuseiter_10068 < 4UL; _fuseiter_10068 += 1UL) {
      int8_t __cached_0;
      __cached_0 = __ins_0[(((_fuseiter_10067 + ((fused_0fused_0fused_0fused_0_fuseiter_10062___fuseiter_10063_3335___fuseiter_10064_3336___fuseiter_10065_3337___fuseiter_10066_3338 / 256UL) * 512UL)) * 1024UL) + ((_fuseiter_10068 + ((fused_0fused_0fused_0fused_0_fuseiter_10062___fuseiter_10063_3335___fuseiter_10064_3336___fuseiter_10065_3337___fuseiter_10066_3338 % 16UL) * 4UL)) + (((fused_0fused_0fused_0fused_0_fuseiter_10062___fuseiter_10063_3335___fuseiter_10064_3336___fuseiter_10065_3337___fuseiter_10066_3338 / 16UL) % 16UL) * 64UL)))];
      int8_t __cached_1;
      __cached_1 = __cached_0;
      __outs_0[(((fused_0fused_0fused_0fused_0_fuseiter_10062___fuseiter_10063_3335___fuseiter_10064_3336___fuseiter_10065_3337___fuseiter_10066_3338 / 256UL) * 524288UL) + ((((fused_0fused_0fused_0fused_0_fuseiter_10062___fuseiter_10063_3335___fuseiter_10064_3336___fuseiter_10065_3337___fuseiter_10066_3338 / 16UL) % 16UL) * 32768UL) + (((fused_0fused_0fused_0fused_0_fuseiter_10062___fuseiter_10063_3335___fuseiter_10064_3336___fuseiter_10065_3337___fuseiter_10066_3338 % 16UL) * 2048UL) + ((_fuseiter_10067 * 4UL) + _fuseiter_10068))))] = __cached_1;
    }
  }
}

static void reorder__5350_closure_290_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept{
  reorder__5350_closure_290(i, (int8_t*)(args[0UL].v_ptr), (int8_t*)(args[1UL].v_ptr));
}

static void mul__1820_closure_291(uint64_t fused_0fused_0__itr_0____itr_1_3339____itr_2_3340, float* __restrict__ __ins_0, float* __restrict__ __ins_1, float* __restrict__ __outs_0) noexcept{
  for (uint64_t _fuseiter_10073 = 0UL; _fuseiter_10073 < 3UL; _fuseiter_10073 += 1UL) {
    float __cached_0;
    __cached_0 = __ins_0[((((fused_0fused_0__itr_0____itr_1_3339____itr_2_3340 / 768UL) * 2304UL) + ((((fused_0fused_0__itr_0____itr_1_3339____itr_2_3340 / 3UL) % 256UL) * 9UL) + ((fused_0fused_0__itr_0____itr_1_3339____itr_2_3340 % 3UL) * 3UL))) + _fuseiter_10073)];
    float __cached_1;
    __cached_1 = __ins_1[(fused_0fused_0__itr_0____itr_1_3339____itr_2_3340 / 768UL)];
    float __cached_2;
    __cached_2 = (__cached_0 * __cached_1);
    __outs_0[((((fused_0fused_0__itr_0____itr_1_3339____itr_2_3340 / 768UL) * 2304UL) + ((((fused_0fused_0__itr_0____itr_1_3339____itr_2_3340 / 3UL) % 256UL) * 9UL) + ((fused_0fused_0__itr_0____itr_1_3339____itr_2_3340 % 3UL) * 3UL))) + _fuseiter_10073)] = __cached_2;
  }
}

static void mul__1820_closure_291_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept{
  mul__1820_closure_291(i, (float*)(args[0UL].v_ptr), (float*)(args[1UL].v_ptr), (float*)(args[2UL].v_ptr));
}

static void cast__1830_closure_292(uint64_t fused_0fused_0__itr_0____itr_1_3341____itr_2_3342, float* __restrict__ __ins_0, int8_t* __restrict__ __outs_0) noexcept{
  for (uint64_t _fuseiter10078 = 0UL; _fuseiter10078 < 3UL; _fuseiter10078 += 1UL) {
    float __cached_0;
    __cached_0 = __ins_0[((((fused_0fused_0__itr_0____itr_1_3341____itr_2_3342 / 768UL) * 2304UL) + ((((fused_0fused_0__itr_0____itr_1_3341____itr_2_3342 / 3UL) % 256UL) * 9UL) + ((fused_0fused_0__itr_0____itr_1_3341____itr_2_3342 % 3UL) * 3UL))) + _fuseiter10078)];
    int8_t __cached_1;
    __cached_1 = (int8_t)sc_max(sc_min(sc_round_and_cast<int32_t>(__cached_0), 127), -128);
    __outs_0[((((fused_0fused_0__itr_0____itr_1_3341____itr_2_3342 / 768UL) * 2304UL) + ((((fused_0fused_0__itr_0____itr_1_3341____itr_2_3342 / 3UL) % 256UL) * 9UL) + ((fused_0fused_0__itr_0____itr_1_3341____itr_2_3342 % 3UL) * 3UL))) + _fuseiter10078)] = __cached_1;
  }
}

static void cast__1830_closure_292_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept{
  cast__1830_closure_292(i, (float*)(args[0UL].v_ptr), (int8_t*)(args[1UL].v_ptr));
}

static void reorder__4810_closure_293(uint64_t fused_0fused_0_fuseiter_10079___fuseiter_10080_3343___fuseiter_10081_3344, int8_t* __restrict__ __ins_0, int8_t* __restrict__ __outs_0) noexcept{
  for (uint64_t _fuseiter_10082 = 0UL; _fuseiter_10082 < 3UL; _fuseiter_10082 += 1UL) {
    for (uint64_t _fuseiter_10083 = 0UL; _fuseiter_10083 < 16UL; _fuseiter_10083 += 1UL) {
      for (uint64_t _fuseiter_10084 = 0UL; _fuseiter_10084 < 64UL; _fuseiter_10084 += 1UL) {
        for (uint64_t _fuseiter_10085 = 0UL; _fuseiter_10085 < 4UL; _fuseiter_10085 += 1UL) {
          int8_t __cached_0;
          __cached_0 = __ins_0[(((_fuseiter_10084 + ((fused_0fused_0_fuseiter_10079___fuseiter_10080_3343___fuseiter_10081_3344 / 12UL) * 64UL)) * 2304UL) + ((((_fuseiter_10085 + (_fuseiter_10083 * 4UL)) + (((fused_0fused_0_fuseiter_10079___fuseiter_10080_3343___fuseiter_10081_3344 / 3UL) % 4UL) * 64UL)) * 9UL) + (((fused_0fused_0_fuseiter_10079___fuseiter_10080_3343___fuseiter_10081_3344 % 3UL) * 3UL) + _fuseiter_10082)))];
          int8_t __cached_1;
          __cached_1 = __cached_0;
          __outs_0[(((fused_0fused_0_fuseiter_10079___fuseiter_10080_3343___fuseiter_10081_3344 / 12UL) * 147456UL) + ((((fused_0fused_0_fuseiter_10079___fuseiter_10080_3343___fuseiter_10081_3344 / 3UL) % 4UL) * 36864UL) + (((fused_0fused_0_fuseiter_10079___fuseiter_10080_3343___fuseiter_10081_3344 % 3UL) * 12288UL) + ((_fuseiter_10082 * 4096UL) + ((_fuseiter_10083 * 256UL) + ((_fuseiter_10084 * 4UL) + _fuseiter_10085))))))] = __cached_1;
        }
      }
    }
  }
}

static void reorder__4810_closure_293_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept{
  reorder__4810_closure_293(i, (int8_t*)(args[0UL].v_ptr), (int8_t*)(args[1UL].v_ptr));
}

static void mul__1910_closure_294(uint64_t fused_0fused_0__itr_0____itr_1_3345____itr_2_3346, float* __restrict__ __ins_0, float* __restrict__ __ins_1, float* __restrict__ __outs_0) noexcept{
  for (uint64_t _fuseiter_10090 = 0UL; _fuseiter_10090 < 3UL; _fuseiter_10090 += 1UL) {
    float __cached_0;
    __cached_0 = __ins_0[((((fused_0fused_0__itr_0____itr_1_3345____itr_2_3346 / 768UL) * 2304UL) + ((((fused_0fused_0__itr_0____itr_1_3345____itr_2_3346 / 3UL) % 256UL) * 9UL) + ((fused_0fused_0__itr_0____itr_1_3345____itr_2_3346 % 3UL) * 3UL))) + _fuseiter_10090)];
    float __cached_1;
    __cached_1 = __ins_1[(fused_0fused_0__itr_0____itr_1_3345____itr_2_3346 / 768UL)];
    float __cached_2;
    __cached_2 = (__cached_0 * __cached_1);
    __outs_0[((((fused_0fused_0__itr_0____itr_1_3345____itr_2_3346 / 768UL) * 2304UL) + ((((fused_0fused_0__itr_0____itr_1_3345____itr_2_3346 / 3UL) % 256UL) * 9UL) + ((fused_0fused_0__itr_0____itr_1_3345____itr_2_3346 % 3UL) * 3UL))) + _fuseiter_10090)] = __cached_2;
  }
}

static void mul__1910_closure_294_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept{
  mul__1910_closure_294(i, (float*)(args[0UL].v_ptr), (float*)(args[1UL].v_ptr), (float*)(args[2UL].v_ptr));
}

static void cast__1920_closure_295(uint64_t fused_0fused_0__itr_0____itr_1_3347____itr_2_3348, float* __restrict__ __ins_0, int8_t* __restrict__ __outs_0) noexcept{
  for (uint64_t _fuseiter10095 = 0UL; _fuseiter10095 < 3UL; _fuseiter10095 += 1UL) {
    float __cached_0;
    __cached_0 = __ins_0[((((fused_0fused_0__itr_0____itr_1_3347____itr_2_3348 / 768UL) * 2304UL) + ((((fused_0fused_0__itr_0____itr_1_3347____itr_2_3348 / 3UL) % 256UL) * 9UL) + ((fused_0fused_0__itr_0____itr_1_3347____itr_2_3348 % 3UL) * 3UL))) + _fuseiter10095)];
    int8_t __cached_1;
    __cached_1 = (int8_t)sc_max(sc_min(sc_round_and_cast<int32_t>(__cached_0), 127), -128);
    __outs_0[((((fused_0fused_0__itr_0____itr_1_3347____itr_2_3348 / 768UL) * 2304UL) + ((((fused_0fused_0__itr_0____itr_1_3347____itr_2_3348 / 3UL) % 256UL) * 9UL) + ((fused_0fused_0__itr_0____itr_1_3347____itr_2_3348 % 3UL) * 3UL))) + _fuseiter10095)] = __cached_1;
  }
}

static void cast__1920_closure_295_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept{
  cast__1920_closure_295(i, (float*)(args[0UL].v_ptr), (int8_t*)(args[1UL].v_ptr));
}

static void reorder__4900_closure_296(uint64_t fused_0fused_0_fuseiter_10096___fuseiter_10097_3349___fuseiter_10098_3350, int8_t* __restrict__ __ins_0, int8_t* __restrict__ __outs_0) noexcept{
  for (uint64_t _fuseiter_10099 = 0UL; _fuseiter_10099 < 3UL; _fuseiter_10099 += 1UL) {
    for (uint64_t _fuseiter_10100 = 0UL; _fuseiter_10100 < 16UL; _fuseiter_10100 += 1UL) {
      for (uint64_t _fuseiter_10101 = 0UL; _fuseiter_10101 < 64UL; _fuseiter_10101 += 1UL) {
        for (uint64_t _fuseiter_10102 = 0UL; _fuseiter_10102 < 4UL; _fuseiter_10102 += 1UL) {
          int8_t __cached_0;
          __cached_0 = __ins_0[(((_fuseiter_10101 + ((fused_0fused_0_fuseiter_10096___fuseiter_10097_3349___fuseiter_10098_3350 / 12UL) * 64UL)) * 2304UL) + ((((_fuseiter_10102 + (_fuseiter_10100 * 4UL)) + (((fused_0fused_0_fuseiter_10096___fuseiter_10097_3349___fuseiter_10098_3350 / 3UL) % 4UL) * 64UL)) * 9UL) + (((fused_0fused_0_fuseiter_10096___fuseiter_10097_3349___fuseiter_10098_3350 % 3UL) * 3UL) + _fuseiter_10099)))];
          int8_t __cached_1;
          __cached_1 = __cached_0;
          __outs_0[(((fused_0fused_0_fuseiter_10096___fuseiter_10097_3349___fuseiter_10098_3350 / 12UL) * 147456UL) + ((((fused_0fused_0_fuseiter_10096___fuseiter_10097_3349___fuseiter_10098_3350 / 3UL) % 4UL) * 36864UL) + (((fused_0fused_0_fuseiter_10096___fuseiter_10097_3349___fuseiter_10098_3350 % 3UL) * 12288UL) + ((_fuseiter_10099 * 4096UL) + ((_fuseiter_10100 * 256UL) + ((_fuseiter_10101 * 4UL) + _fuseiter_10102))))))] = __cached_1;
        }
      }
    }
  }
}

static void reorder__4900_closure_296_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept{
  reorder__4900_closure_296(i, (int8_t*)(args[0UL].v_ptr), (int8_t*)(args[1UL].v_ptr));
}

static void mul__2000_closure_297(uint64_t fused_0fused_0__itr_0____itr_1_3351____itr_2_3352, float* __restrict__ __ins_0, float* __restrict__ __ins_1, float* __restrict__ __outs_0) noexcept{
  for (uint64_t _fuseiter_10107 = 0UL; _fuseiter_10107 < 3UL; _fuseiter_10107 += 1UL) {
    float __cached_0;
    __cached_0 = __ins_0[((((fused_0fused_0__itr_0____itr_1_3351____itr_2_3352 / 768UL) * 2304UL) + ((((fused_0fused_0__itr_0____itr_1_3351____itr_2_3352 / 3UL) % 256UL) * 9UL) + ((fused_0fused_0__itr_0____itr_1_3351____itr_2_3352 % 3UL) * 3UL))) + _fuseiter_10107)];
    float __cached_1;
    __cached_1 = __ins_1[(fused_0fused_0__itr_0____itr_1_3351____itr_2_3352 / 768UL)];
    float __cached_2;
    __cached_2 = (__cached_0 * __cached_1);
    __outs_0[((((fused_0fused_0__itr_0____itr_1_3351____itr_2_3352 / 768UL) * 2304UL) + ((((fused_0fused_0__itr_0____itr_1_3351____itr_2_3352 / 3UL) % 256UL) * 9UL) + ((fused_0fused_0__itr_0____itr_1_3351____itr_2_3352 % 3UL) * 3UL))) + _fuseiter_10107)] = __cached_2;
  }
}

static void mul__2000_closure_297_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept{
  mul__2000_closure_297(i, (float*)(args[0UL].v_ptr), (float*)(args[1UL].v_ptr), (float*)(args[2UL].v_ptr));
}

static void cast__2010_closure_298(uint64_t fused_0fused_0__itr_0____itr_1_3353____itr_2_3354, float* __restrict__ __ins_0, int8_t* __restrict__ __outs_0) noexcept{
  for (uint64_t _fuseiter10112 = 0UL; _fuseiter10112 < 3UL; _fuseiter10112 += 1UL) {
    float __cached_0;
    __cached_0 = __ins_0[((((fused_0fused_0__itr_0____itr_1_3353____itr_2_3354 / 768UL) * 2304UL) + ((((fused_0fused_0__itr_0____itr_1_3353____itr_2_3354 / 3UL) % 256UL) * 9UL) + ((fused_0fused_0__itr_0____itr_1_3353____itr_2_3354 % 3UL) * 3UL))) + _fuseiter10112)];
    int8_t __cached_1;
    __cached_1 = (int8_t)sc_max(sc_min(sc_round_and_cast<int32_t>(__cached_0), 127), -128);
    __outs_0[((((fused_0fused_0__itr_0____itr_1_3353____itr_2_3354 / 768UL) * 2304UL) + ((((fused_0fused_0__itr_0____itr_1_3353____itr_2_3354 / 3UL) % 256UL) * 9UL) + ((fused_0fused_0__itr_0____itr_1_3353____itr_2_3354 % 3UL) * 3UL))) + _fuseiter10112)] = __cached_1;
  }
}

static void cast__2010_closure_298_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept{
  cast__2010_closure_298(i, (float*)(args[0UL].v_ptr), (int8_t*)(args[1UL].v_ptr));
}

static void reorder__4990_closure_299(uint64_t fused_0fused_0_fuseiter_10113___fuseiter_10114_3355___fuseiter_10115_3356, int8_t* __restrict__ __ins_0, int8_t* __restrict__ __outs_0) noexcept{
  for (uint64_t _fuseiter_10116 = 0UL; _fuseiter_10116 < 3UL; _fuseiter_10116 += 1UL) {
    for (uint64_t _fuseiter_10117 = 0UL; _fuseiter_10117 < 16UL; _fuseiter_10117 += 1UL) {
      for (uint64_t _fuseiter_10118 = 0UL; _fuseiter_10118 < 64UL; _fuseiter_10118 += 1UL) {
        for (uint64_t _fuseiter_10119 = 0UL; _fuseiter_10119 < 4UL; _fuseiter_10119 += 1UL) {
          int8_t __cached_0;
          __cached_0 = __ins_0[(((_fuseiter_10118 + ((fused_0fused_0_fuseiter_10113___fuseiter_10114_3355___fuseiter_10115_3356 / 12UL) * 64UL)) * 2304UL) + ((((_fuseiter_10119 + (_fuseiter_10117 * 4UL)) + (((fused_0fused_0_fuseiter_10113___fuseiter_10114_3355___fuseiter_10115_3356 / 3UL) % 4UL) * 64UL)) * 9UL) + (((fused_0fused_0_fuseiter_10113___fuseiter_10114_3355___fuseiter_10115_3356 % 3UL) * 3UL) + _fuseiter_10116)))];
          int8_t __cached_1;
          __cached_1 = __cached_0;
          __outs_0[(((fused_0fused_0_fuseiter_10113___fuseiter_10114_3355___fuseiter_10115_3356 / 12UL) * 147456UL) + ((((fused_0fused_0_fuseiter_10113___fuseiter_10114_3355___fuseiter_10115_3356 / 3UL) % 4UL) * 36864UL) + (((fused_0fused_0_fuseiter_10113___fuseiter_10114_3355___fuseiter_10115_3356 % 3UL) * 12288UL) + ((_fuseiter_10116 * 4096UL) + ((_fuseiter_10117 * 256UL) + ((_fuseiter_10118 * 4UL) + _fuseiter_10119))))))] = __cached_1;
        }
      }
    }
  }
}

static void reorder__4990_closure_299_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept{
  reorder__4990_closure_299(i, (int8_t*)(args[0UL].v_ptr), (int8_t*)(args[1UL].v_ptr));
}

static void mul__2090_closure_300(uint64_t fused_0fused_0__itr_0____itr_1_3357____itr_2_3358, float* __restrict__ __ins_0, float* __restrict__ __ins_1, float* __restrict__ __outs_0) noexcept{
  for (uint64_t _fuseiter_10124 = 0UL; _fuseiter_10124 < 3UL; _fuseiter_10124 += 1UL) {
    float __cached_0;
    __cached_0 = __ins_0[((((fused_0fused_0__itr_0____itr_1_3357____itr_2_3358 / 768UL) * 2304UL) + ((((fused_0fused_0__itr_0____itr_1_3357____itr_2_3358 / 3UL) % 256UL) * 9UL) + ((fused_0fused_0__itr_0____itr_1_3357____itr_2_3358 % 3UL) * 3UL))) + _fuseiter_10124)];
    float __cached_1;
    __cached_1 = __ins_1[(fused_0fused_0__itr_0____itr_1_3357____itr_2_3358 / 768UL)];
    float __cached_2;
    __cached_2 = (__cached_0 * __cached_1);
    __outs_0[((((fused_0fused_0__itr_0____itr_1_3357____itr_2_3358 / 768UL) * 2304UL) + ((((fused_0fused_0__itr_0____itr_1_3357____itr_2_3358 / 3UL) % 256UL) * 9UL) + ((fused_0fused_0__itr_0____itr_1_3357____itr_2_3358 % 3UL) * 3UL))) + _fuseiter_10124)] = __cached_2;
  }
}

static void mul__2090_closure_300_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept{
  mul__2090_closure_300(i, (float*)(args[0UL].v_ptr), (float*)(args[1UL].v_ptr), (float*)(args[2UL].v_ptr));
}

static void cast__2100_closure_301(uint64_t fused_0fused_0__itr_0____itr_1_3359____itr_2_3360, float* __restrict__ __ins_0, int8_t* __restrict__ __outs_0) noexcept{
  for (uint64_t _fuseiter10129 = 0UL; _fuseiter10129 < 3UL; _fuseiter10129 += 1UL) {
    float __cached_0;
    __cached_0 = __ins_0[((((fused_0fused_0__itr_0____itr_1_3359____itr_2_3360 / 768UL) * 2304UL) + ((((fused_0fused_0__itr_0____itr_1_3359____itr_2_3360 / 3UL) % 256UL) * 9UL) + ((fused_0fused_0__itr_0____itr_1_3359____itr_2_3360 % 3UL) * 3UL))) + _fuseiter10129)];
    int8_t __cached_1;
    __cached_1 = (int8_t)sc_max(sc_min(sc_round_and_cast<int32_t>(__cached_0), 127), -128);
    __outs_0[((((fused_0fused_0__itr_0____itr_1_3359____itr_2_3360 / 768UL) * 2304UL) + ((((fused_0fused_0__itr_0____itr_1_3359____itr_2_3360 / 3UL) % 256UL) * 9UL) + ((fused_0fused_0__itr_0____itr_1_3359____itr_2_3360 % 3UL) * 3UL))) + _fuseiter10129)] = __cached_1;
  }
}

static void cast__2100_closure_301_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept{
  cast__2100_closure_301(i, (float*)(args[0UL].v_ptr), (int8_t*)(args[1UL].v_ptr));
}

static void reorder__5080_closure_302(uint64_t fused_0fused_0_fuseiter_10130___fuseiter_10131_3361___fuseiter_10132_3362, int8_t* __restrict__ __ins_0, int8_t* __restrict__ __outs_0) noexcept{
  for (uint64_t _fuseiter_10133 = 0UL; _fuseiter_10133 < 3UL; _fuseiter_10133 += 1UL) {
    for (uint64_t _fuseiter_10134 = 0UL; _fuseiter_10134 < 16UL; _fuseiter_10134 += 1UL) {
      for (uint64_t _fuseiter_10135 = 0UL; _fuseiter_10135 < 64UL; _fuseiter_10135 += 1UL) {
        for (uint64_t _fuseiter_10136 = 0UL; _fuseiter_10136 < 4UL; _fuseiter_10136 += 1UL) {
          int8_t __cached_0;
          __cached_0 = __ins_0[(((_fuseiter_10135 + ((fused_0fused_0_fuseiter_10130___fuseiter_10131_3361___fuseiter_10132_3362 / 12UL) * 64UL)) * 2304UL) + ((((_fuseiter_10136 + (_fuseiter_10134 * 4UL)) + (((fused_0fused_0_fuseiter_10130___fuseiter_10131_3361___fuseiter_10132_3362 / 3UL) % 4UL) * 64UL)) * 9UL) + (((fused_0fused_0_fuseiter_10130___fuseiter_10131_3361___fuseiter_10132_3362 % 3UL) * 3UL) + _fuseiter_10133)))];
          int8_t __cached_1;
          __cached_1 = __cached_0;
          __outs_0[(((fused_0fused_0_fuseiter_10130___fuseiter_10131_3361___fuseiter_10132_3362 / 12UL) * 147456UL) + ((((fused_0fused_0_fuseiter_10130___fuseiter_10131_3361___fuseiter_10132_3362 / 3UL) % 4UL) * 36864UL) + (((fused_0fused_0_fuseiter_10130___fuseiter_10131_3361___fuseiter_10132_3362 % 3UL) * 12288UL) + ((_fuseiter_10133 * 4096UL) + ((_fuseiter_10134 * 256UL) + ((_fuseiter_10135 * 4UL) + _fuseiter_10136))))))] = __cached_1;
        }
      }
    }
  }
}

static void reorder__5080_closure_302_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept{
  reorder__5080_closure_302(i, (int8_t*)(args[0UL].v_ptr), (int8_t*)(args[1UL].v_ptr));
}

static void mul__2180_closure_303(uint64_t fused_0fused_0__itr_0____itr_1_3363____itr_2_3364, float* __restrict__ __ins_0, float* __restrict__ __ins_1, float* __restrict__ __outs_0) noexcept{
  for (uint64_t _fuseiter_10141 = 0UL; _fuseiter_10141 < 3UL; _fuseiter_10141 += 1UL) {
    float __cached_0;
    __cached_0 = __ins_0[((((fused_0fused_0__itr_0____itr_1_3363____itr_2_3364 / 768UL) * 2304UL) + ((((fused_0fused_0__itr_0____itr_1_3363____itr_2_3364 / 3UL) % 256UL) * 9UL) + ((fused_0fused_0__itr_0____itr_1_3363____itr_2_3364 % 3UL) * 3UL))) + _fuseiter_10141)];
    float __cached_1;
    __cached_1 = __ins_1[(fused_0fused_0__itr_0____itr_1_3363____itr_2_3364 / 768UL)];
    float __cached_2;
    __cached_2 = (__cached_0 * __cached_1);
    __outs_0[((((fused_0fused_0__itr_0____itr_1_3363____itr_2_3364 / 768UL) * 2304UL) + ((((fused_0fused_0__itr_0____itr_1_3363____itr_2_3364 / 3UL) % 256UL) * 9UL) + ((fused_0fused_0__itr_0____itr_1_3363____itr_2_3364 % 3UL) * 3UL))) + _fuseiter_10141)] = __cached_2;
  }
}

static void mul__2180_closure_303_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept{
  mul__2180_closure_303(i, (float*)(args[0UL].v_ptr), (float*)(args[1UL].v_ptr), (float*)(args[2UL].v_ptr));
}

static void cast__2190_closure_304(uint64_t fused_0fused_0__itr_0____itr_1_3365____itr_2_3366, float* __restrict__ __ins_0, int8_t* __restrict__ __outs_0) noexcept{
  for (uint64_t _fuseiter10146 = 0UL; _fuseiter10146 < 3UL; _fuseiter10146 += 1UL) {
    float __cached_0;
    __cached_0 = __ins_0[((((fused_0fused_0__itr_0____itr_1_3365____itr_2_3366 / 768UL) * 2304UL) + ((((fused_0fused_0__itr_0____itr_1_3365____itr_2_3366 / 3UL) % 256UL) * 9UL) + ((fused_0fused_0__itr_0____itr_1_3365____itr_2_3366 % 3UL) * 3UL))) + _fuseiter10146)];
    int8_t __cached_1;
    __cached_1 = (int8_t)sc_max(sc_min(sc_round_and_cast<int32_t>(__cached_0), 127), -128);
    __outs_0[((((fused_0fused_0__itr_0____itr_1_3365____itr_2_3366 / 768UL) * 2304UL) + ((((fused_0fused_0__itr_0____itr_1_3365____itr_2_3366 / 3UL) % 256UL) * 9UL) + ((fused_0fused_0__itr_0____itr_1_3365____itr_2_3366 % 3UL) * 3UL))) + _fuseiter10146)] = __cached_1;
  }
}

static void cast__2190_closure_304_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept{
  cast__2190_closure_304(i, (float*)(args[0UL].v_ptr), (int8_t*)(args[1UL].v_ptr));
}

static void reorder__5170_closure_305(uint64_t fused_0fused_0_fuseiter_10147___fuseiter_10148_3367___fuseiter_10149_3368, int8_t* __restrict__ __ins_0, int8_t* __restrict__ __outs_0) noexcept{
  for (uint64_t _fuseiter_10150 = 0UL; _fuseiter_10150 < 3UL; _fuseiter_10150 += 1UL) {
    for (uint64_t _fuseiter_10151 = 0UL; _fuseiter_10151 < 16UL; _fuseiter_10151 += 1UL) {
      for (uint64_t _fuseiter_10152 = 0UL; _fuseiter_10152 < 64UL; _fuseiter_10152 += 1UL) {
        for (uint64_t _fuseiter_10153 = 0UL; _fuseiter_10153 < 4UL; _fuseiter_10153 += 1UL) {
          int8_t __cached_0;
          __cached_0 = __ins_0[(((_fuseiter_10152 + ((fused_0fused_0_fuseiter_10147___fuseiter_10148_3367___fuseiter_10149_3368 / 12UL) * 64UL)) * 2304UL) + ((((_fuseiter_10153 + (_fuseiter_10151 * 4UL)) + (((fused_0fused_0_fuseiter_10147___fuseiter_10148_3367___fuseiter_10149_3368 / 3UL) % 4UL) * 64UL)) * 9UL) + (((fused_0fused_0_fuseiter_10147___fuseiter_10148_3367___fuseiter_10149_3368 % 3UL) * 3UL) + _fuseiter_10150)))];
          int8_t __cached_1;
          __cached_1 = __cached_0;
          __outs_0[(((fused_0fused_0_fuseiter_10147___fuseiter_10148_3367___fuseiter_10149_3368 / 12UL) * 147456UL) + ((((fused_0fused_0_fuseiter_10147___fuseiter_10148_3367___fuseiter_10149_3368 / 3UL) % 4UL) * 36864UL) + (((fused_0fused_0_fuseiter_10147___fuseiter_10148_3367___fuseiter_10149_3368 % 3UL) * 12288UL) + ((_fuseiter_10150 * 4096UL) + ((_fuseiter_10151 * 256UL) + ((_fuseiter_10152 * 4UL) + _fuseiter_10153))))))] = __cached_1;
        }
      }
    }
  }
}

static void reorder__5170_closure_305_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept{
  reorder__5170_closure_305(i, (int8_t*)(args[0UL].v_ptr), (int8_t*)(args[1UL].v_ptr));
}

static void mul__2270_closure_306(uint64_t fused_0fused_0__itr_0____itr_1_3369____itr_2_3370, float* __restrict__ __ins_0, float* __restrict__ __ins_1, float* __restrict__ __outs_0) noexcept{
  for (uint64_t _fuseiter_10158 = 0UL; _fuseiter_10158 < 3UL; _fuseiter_10158 += 1UL) {
    float __cached_0;
    __cached_0 = __ins_0[((((fused_0fused_0__itr_0____itr_1_3369____itr_2_3370 / 768UL) * 2304UL) + ((((fused_0fused_0__itr_0____itr_1_3369____itr_2_3370 / 3UL) % 256UL) * 9UL) + ((fused_0fused_0__itr_0____itr_1_3369____itr_2_3370 % 3UL) * 3UL))) + _fuseiter_10158)];
    float __cached_1;
    __cached_1 = __ins_1[(fused_0fused_0__itr_0____itr_1_3369____itr_2_3370 / 768UL)];
    float __cached_2;
    __cached_2 = (__cached_0 * __cached_1);
    __outs_0[((((fused_0fused_0__itr_0____itr_1_3369____itr_2_3370 / 768UL) * 2304UL) + ((((fused_0fused_0__itr_0____itr_1_3369____itr_2_3370 / 3UL) % 256UL) * 9UL) + ((fused_0fused_0__itr_0____itr_1_3369____itr_2_3370 % 3UL) * 3UL))) + _fuseiter_10158)] = __cached_2;
  }
}

static void mul__2270_closure_306_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept{
  mul__2270_closure_306(i, (float*)(args[0UL].v_ptr), (float*)(args[1UL].v_ptr), (float*)(args[2UL].v_ptr));
}

static void cast__2280_closure_307(uint64_t fused_0fused_0__itr_0____itr_1_3371____itr_2_3372, float* __restrict__ __ins_0, int8_t* __restrict__ __outs_0) noexcept{
  for (uint64_t _fuseiter10163 = 0UL; _fuseiter10163 < 3UL; _fuseiter10163 += 1UL) {
    float __cached_0;
    __cached_0 = __ins_0[((((fused_0fused_0__itr_0____itr_1_3371____itr_2_3372 / 768UL) * 2304UL) + ((((fused_0fused_0__itr_0____itr_1_3371____itr_2_3372 / 3UL) % 256UL) * 9UL) + ((fused_0fused_0__itr_0____itr_1_3371____itr_2_3372 % 3UL) * 3UL))) + _fuseiter10163)];
    int8_t __cached_1;
    __cached_1 = (int8_t)sc_max(sc_min(sc_round_and_cast<int32_t>(__cached_0), 127), -128);
    __outs_0[((((fused_0fused_0__itr_0____itr_1_3371____itr_2_3372 / 768UL) * 2304UL) + ((((fused_0fused_0__itr_0____itr_1_3371____itr_2_3372 / 3UL) % 256UL) * 9UL) + ((fused_0fused_0__itr_0____itr_1_3371____itr_2_3372 % 3UL) * 3UL))) + _fuseiter10163)] = __cached_1;
  }
}

static void cast__2280_closure_307_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept{
  cast__2280_closure_307(i, (float*)(args[0UL].v_ptr), (int8_t*)(args[1UL].v_ptr));
}

static void reorder__5260_closure_308(uint64_t fused_0fused_0_fuseiter_10164___fuseiter_10165_3373___fuseiter_10166_3374, int8_t* __restrict__ __ins_0, int8_t* __restrict__ __outs_0) noexcept{
  for (uint64_t _fuseiter_10167 = 0UL; _fuseiter_10167 < 3UL; _fuseiter_10167 += 1UL) {
    for (uint64_t _fuseiter_10168 = 0UL; _fuseiter_10168 < 16UL; _fuseiter_10168 += 1UL) {
      for (uint64_t _fuseiter_10169 = 0UL; _fuseiter_10169 < 64UL; _fuseiter_10169 += 1UL) {
        for (uint64_t _fuseiter_10170 = 0UL; _fuseiter_10170 < 4UL; _fuseiter_10170 += 1UL) {
          int8_t __cached_0;
          __cached_0 = __ins_0[(((_fuseiter_10169 + ((fused_0fused_0_fuseiter_10164___fuseiter_10165_3373___fuseiter_10166_3374 / 12UL) * 64UL)) * 2304UL) + ((((_fuseiter_10170 + (_fuseiter_10168 * 4UL)) + (((fused_0fused_0_fuseiter_10164___fuseiter_10165_3373___fuseiter_10166_3374 / 3UL) % 4UL) * 64UL)) * 9UL) + (((fused_0fused_0_fuseiter_10164___fuseiter_10165_3373___fuseiter_10166_3374 % 3UL) * 3UL) + _fuseiter_10167)))];
          int8_t __cached_1;
          __cached_1 = __cached_0;
          __outs_0[(((fused_0fused_0_fuseiter_10164___fuseiter_10165_3373___fuseiter_10166_3374 / 12UL) * 147456UL) + ((((fused_0fused_0_fuseiter_10164___fuseiter_10165_3373___fuseiter_10166_3374 / 3UL) % 4UL) * 36864UL) + (((fused_0fused_0_fuseiter_10164___fuseiter_10165_3373___fuseiter_10166_3374 % 3UL) * 12288UL) + ((_fuseiter_10167 * 4096UL) + ((_fuseiter_10168 * 256UL) + ((_fuseiter_10169 * 4UL) + _fuseiter_10170))))))] = __cached_1;
        }
      }
    }
  }
}

static void reorder__5260_closure_308_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept{
  reorder__5260_closure_308(i, (int8_t*)(args[0UL].v_ptr), (int8_t*)(args[1UL].v_ptr));
}

static void mul__2420_closure_309(uint64_t fused_0fused_0__itr_0____itr_1_3375____itr_2_3376, float* __restrict__ __ins_0, float* __restrict__ __ins_1, float* __restrict__ __outs_0) noexcept{
  float __cached_0;
  __cached_0 = __ins_0[(((fused_0fused_0__itr_0____itr_1_3375____itr_2_3376 / 512UL) * 512UL) + (fused_0fused_0__itr_0____itr_1_3375____itr_2_3376 % 512UL))];
  float __cached_1;
  __cached_1 = __ins_1[(fused_0fused_0__itr_0____itr_1_3375____itr_2_3376 / 512UL)];
  float __cached_2;
  __cached_2 = (__cached_0 * __cached_1);
  __outs_0[(((fused_0fused_0__itr_0____itr_1_3375____itr_2_3376 / 512UL) * 512UL) + (fused_0fused_0__itr_0____itr_1_3375____itr_2_3376 % 512UL))] = __cached_2;
}

static void mul__2420_closure_309_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept{
  mul__2420_closure_309(i, (float*)(args[0UL].v_ptr), (float*)(args[1UL].v_ptr), (float*)(args[2UL].v_ptr));
}

static void cast__2430_closure_310(uint64_t fused_0fused_0__itr_0____itr_1_3377____itr_2_3378, float* __restrict__ __ins_0, int8_t* __restrict__ __outs_0) noexcept{
  float __cached_0;
  __cached_0 = __ins_0[(((fused_0fused_0__itr_0____itr_1_3377____itr_2_3378 / 512UL) * 512UL) + (fused_0fused_0__itr_0____itr_1_3377____itr_2_3378 % 512UL))];
  int8_t __cached_1;
  __cached_1 = (int8_t)sc_max(sc_min(sc_round_and_cast<int32_t>(__cached_0), 127), -128);
  __outs_0[(((fused_0fused_0__itr_0____itr_1_3377____itr_2_3378 / 512UL) * 512UL) + (fused_0fused_0__itr_0____itr_1_3377____itr_2_3378 % 512UL))] = __cached_1;
}

static void cast__2430_closure_310_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept{
  cast__2430_closure_310(i, (float*)(args[0UL].v_ptr), (int8_t*)(args[1UL].v_ptr));
}

static void reorder__5390_closure_311(uint64_t fused_0fused_0fused_0fused_0_fuseiter_10181___fuseiter_10182_3379___fuseiter_10183_3380___fuseiter_10184_3381___fuseiter_10185_3382, int8_t* __restrict__ __ins_0, int8_t* __restrict__ __outs_0) noexcept{
  for (uint64_t _fuseiter_10186 = 0UL; _fuseiter_10186 < 512UL; _fuseiter_10186 += 1UL) {
    for (uint64_t _fuseiter_10187 = 0UL; _fuseiter_10187 < 4UL; _fuseiter_10187 += 1UL) {
      int8_t __cached_0;
      __cached_0 = __ins_0[(((_fuseiter_10186 + ((fused_0fused_0fused_0fused_0_fuseiter_10181___fuseiter_10182_3379___fuseiter_10183_3380___fuseiter_10184_3381___fuseiter_10185_3382 / 128UL) * 512UL)) * 512UL) + (_fuseiter_10187 + ((fused_0fused_0fused_0fused_0_fuseiter_10181___fuseiter_10182_3379___fuseiter_10183_3380___fuseiter_10184_3381___fuseiter_10185_3382 % 128UL) * 4UL)))];
      int8_t __cached_1;
      __cached_1 = __cached_0;
      __outs_0[(((fused_0fused_0fused_0fused_0_fuseiter_10181___fuseiter_10182_3379___fuseiter_10183_3380___fuseiter_10184_3381___fuseiter_10185_3382 / 128UL) * 262144UL) + (((fused_0fused_0fused_0fused_0_fuseiter_10181___fuseiter_10182_3379___fuseiter_10183_3380___fuseiter_10184_3381___fuseiter_10185_3382 % 128UL) * 2048UL) + ((_fuseiter_10186 * 4UL) + _fuseiter_10187)))] = __cached_1;
    }
  }
}

static void reorder__5390_closure_311_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept{
  reorder__5390_closure_311(i, (int8_t*)(args[0UL].v_ptr), (int8_t*)(args[1UL].v_ptr));
}

static void mul__2510_closure_312(uint64_t fused_0fused_0__itr_0____itr_1_3383____itr_2_3384, float* __restrict__ __ins_0, float* __restrict__ __ins_1, float* __restrict__ __outs_0) noexcept{
  float __cached_0;
  __cached_0 = __ins_0[(((fused_0fused_0__itr_0____itr_1_3383____itr_2_3384 / 512UL) * 512UL) + (fused_0fused_0__itr_0____itr_1_3383____itr_2_3384 % 512UL))];
  float __cached_1;
  __cached_1 = __ins_1[(fused_0fused_0__itr_0____itr_1_3383____itr_2_3384 / 512UL)];
  float __cached_2;
  __cached_2 = (__cached_0 * __cached_1);
  __outs_0[(((fused_0fused_0__itr_0____itr_1_3383____itr_2_3384 / 512UL) * 512UL) + (fused_0fused_0__itr_0____itr_1_3383____itr_2_3384 % 512UL))] = __cached_2;
}

static void mul__2510_closure_312_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept{
  mul__2510_closure_312(i, (float*)(args[0UL].v_ptr), (float*)(args[1UL].v_ptr), (float*)(args[2UL].v_ptr));
}

static void cast__2520_closure_313(uint64_t fused_0fused_0__itr_0____itr_1_3385____itr_2_3386, float* __restrict__ __ins_0, int8_t* __restrict__ __outs_0) noexcept{
  float __cached_0;
  __cached_0 = __ins_0[(((fused_0fused_0__itr_0____itr_1_3385____itr_2_3386 / 512UL) * 512UL) + (fused_0fused_0__itr_0____itr_1_3385____itr_2_3386 % 512UL))];
  int8_t __cached_1;
  __cached_1 = (int8_t)sc_max(sc_min(sc_round_and_cast<int32_t>(__cached_0), 127), -128);
  __outs_0[(((fused_0fused_0__itr_0____itr_1_3385____itr_2_3386 / 512UL) * 512UL) + (fused_0fused_0__itr_0____itr_1_3385____itr_2_3386 % 512UL))] = __cached_1;
}

static void cast__2520_closure_313_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept{
  cast__2520_closure_313(i, (float*)(args[0UL].v_ptr), (int8_t*)(args[1UL].v_ptr));
}

static void reorder__5480_closure_314(uint64_t fused_0fused_0fused_0fused_0_fuseiter_10198___fuseiter_10199_3387___fuseiter_10200_3388___fuseiter_10201_3389___fuseiter_10202_3390, int8_t* __restrict__ __ins_0, int8_t* __restrict__ __outs_0) noexcept{
  for (uint64_t _fuseiter_10203 = 0UL; _fuseiter_10203 < 512UL; _fuseiter_10203 += 1UL) {
    for (uint64_t _fuseiter_10204 = 0UL; _fuseiter_10204 < 4UL; _fuseiter_10204 += 1UL) {
      int8_t __cached_0;
      __cached_0 = __ins_0[(((_fuseiter_10203 + ((fused_0fused_0fused_0fused_0_fuseiter_10198___fuseiter_10199_3387___fuseiter_10200_3388___fuseiter_10201_3389___fuseiter_10202_3390 / 128UL) * 512UL)) * 512UL) + (_fuseiter_10204 + ((fused_0fused_0fused_0fused_0_fuseiter_10198___fuseiter_10199_3387___fuseiter_10200_3388___fuseiter_10201_3389___fuseiter_10202_3390 % 128UL) * 4UL)))];
      int8_t __cached_1;
      __cached_1 = __cached_0;
      __outs_0[(((fused_0fused_0fused_0fused_0_fuseiter_10198___fuseiter_10199_3387___fuseiter_10200_3388___fuseiter_10201_3389___fuseiter_10202_3390 / 128UL) * 262144UL) + (((fused_0fused_0fused_0fused_0_fuseiter_10198___fuseiter_10199_3387___fuseiter_10200_3388___fuseiter_10201_3389___fuseiter_10202_3390 % 128UL) * 2048UL) + ((_fuseiter_10203 * 4UL) + _fuseiter_10204)))] = __cached_1;
    }
  }
}

static void reorder__5480_closure_314_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept{
  reorder__5480_closure_314(i, (int8_t*)(args[0UL].v_ptr), (int8_t*)(args[1UL].v_ptr));
}

static void mul__2600_closure_315(uint64_t fused_0fused_0__itr_0____itr_1_3391____itr_2_3392, float* __restrict__ __ins_0, float* __restrict__ __ins_1, float* __restrict__ __outs_0) noexcept{
  float __cached_0;
  __cached_0 = __ins_0[(((fused_0fused_0__itr_0____itr_1_3391____itr_2_3392 / 512UL) * 512UL) + (fused_0fused_0__itr_0____itr_1_3391____itr_2_3392 % 512UL))];
  float __cached_1;
  __cached_1 = __ins_1[(fused_0fused_0__itr_0____itr_1_3391____itr_2_3392 / 512UL)];
  float __cached_2;
  __cached_2 = (__cached_0 * __cached_1);
  __outs_0[(((fused_0fused_0__itr_0____itr_1_3391____itr_2_3392 / 512UL) * 512UL) + (fused_0fused_0__itr_0____itr_1_3391____itr_2_3392 % 512UL))] = __cached_2;
}

static void mul__2600_closure_315_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept{
  mul__2600_closure_315(i, (float*)(args[0UL].v_ptr), (float*)(args[1UL].v_ptr), (float*)(args[2UL].v_ptr));
}

static void cast__2610_closure_316(uint64_t fused_0fused_0__itr_0____itr_1_3393____itr_2_3394, float* __restrict__ __ins_0, int8_t* __restrict__ __outs_0) noexcept{
  float __cached_0;
  __cached_0 = __ins_0[(((fused_0fused_0__itr_0____itr_1_3393____itr_2_3394 / 512UL) * 512UL) + (fused_0fused_0__itr_0____itr_1_3393____itr_2_3394 % 512UL))];
  int8_t __cached_1;
  __cached_1 = (int8_t)sc_max(sc_min(sc_round_and_cast<int32_t>(__cached_0), 127), -128);
  __outs_0[(((fused_0fused_0__itr_0____itr_1_3393____itr_2_3394 / 512UL) * 512UL) + (fused_0fused_0__itr_0____itr_1_3393____itr_2_3394 % 512UL))] = __cached_1;
}

static void cast__2610_closure_316_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept{
  cast__2610_closure_316(i, (float*)(args[0UL].v_ptr), (int8_t*)(args[1UL].v_ptr));
}

static void reorder__5570_closure_317(uint64_t fused_0_fuseiter_10215___fuseiter_10216_3395, int8_t* __restrict__ __ins_0, int8_t* __restrict__ __outs_0) noexcept{
  for (uint64_t _fuseiter_10219 = 0UL; _fuseiter_10219 < 16UL; _fuseiter_10219 += 1UL) {
    for (uint64_t _fuseiter_10220 = 0UL; _fuseiter_10220 < 512UL; _fuseiter_10220 += 1UL) {
      for (uint64_t _fuseiter_10221 = 0UL; _fuseiter_10221 < 4UL; _fuseiter_10221 += 1UL) {
        int8_t __cached_0;
        __cached_0 = __ins_0[(((_fuseiter_10220 + ((fused_0_fuseiter_10215___fuseiter_10216_3395 / 8UL) * 512UL)) * 512UL) + ((_fuseiter_10221 + (_fuseiter_10219 * 4UL)) + ((fused_0_fuseiter_10215___fuseiter_10216_3395 % 8UL) * 64UL)))];
        int8_t __cached_1;
        __cached_1 = __cached_0;
        __outs_0[(((fused_0_fuseiter_10215___fuseiter_10216_3395 / 8UL) * 262144UL) + (((fused_0_fuseiter_10215___fuseiter_10216_3395 % 8UL) * 32768UL) + ((_fuseiter_10219 * 2048UL) + ((_fuseiter_10220 * 4UL) + _fuseiter_10221))))] = __cached_1;
      }
    }
  }
}

static void reorder__5570_closure_317_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept{
  reorder__5570_closure_317(i, (int8_t*)(args[0UL].v_ptr), (int8_t*)(args[1UL].v_ptr));
}

static void mul__2450_closure_318(uint64_t fused_0fused_0__itr_0____itr_1_3396____itr_2_3397, float* __restrict__ __ins_0, float* __restrict__ __ins_1, float* __restrict__ __outs_0) noexcept{
  float __cached_0;
  __cached_0 = __ins_0[(((fused_0fused_0__itr_0____itr_1_3396____itr_2_3397 / 2048UL) * 2048UL) + (fused_0fused_0__itr_0____itr_1_3396____itr_2_3397 % 2048UL))];
  float __cached_1;
  __cached_1 = __ins_1[(fused_0fused_0__itr_0____itr_1_3396____itr_2_3397 / 2048UL)];
  float __cached_2;
  __cached_2 = (__cached_0 * __cached_1);
  __outs_0[(((fused_0fused_0__itr_0____itr_1_3396____itr_2_3397 / 2048UL) * 2048UL) + (fused_0fused_0__itr_0____itr_1_3396____itr_2_3397 % 2048UL))] = __cached_2;
}

static void mul__2450_closure_318_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept{
  mul__2450_closure_318(i, (float*)(args[0UL].v_ptr), (float*)(args[1UL].v_ptr), (float*)(args[2UL].v_ptr));
}

static void cast__2460_closure_319(uint64_t fused_0fused_0__itr_0____itr_1_3398____itr_2_3399, float* __restrict__ __ins_0, int8_t* __restrict__ __outs_0) noexcept{
  float __cached_0;
  __cached_0 = __ins_0[(((fused_0fused_0__itr_0____itr_1_3398____itr_2_3399 / 2048UL) * 2048UL) + (fused_0fused_0__itr_0____itr_1_3398____itr_2_3399 % 2048UL))];
  int8_t __cached_1;
  __cached_1 = (int8_t)sc_max(sc_min(sc_round_and_cast<int32_t>(__cached_0), 127), -128);
  __outs_0[(((fused_0fused_0__itr_0____itr_1_3398____itr_2_3399 / 2048UL) * 2048UL) + (fused_0fused_0__itr_0____itr_1_3398____itr_2_3399 % 2048UL))] = __cached_1;
}

static void cast__2460_closure_319_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept{
  cast__2460_closure_319(i, (float*)(args[0UL].v_ptr), (int8_t*)(args[1UL].v_ptr));
}

static void reorder__5420_closure_320(uint64_t fused_0_fuseiter_10232___fuseiter_10233_3400, int8_t* __restrict__ __ins_0, int8_t* __restrict__ __outs_0) noexcept{
  for (uint64_t _fuseiter_10236 = 0UL; _fuseiter_10236 < 128UL; _fuseiter_10236 += 1UL) {
    for (uint64_t _fuseiter_10237 = 0UL; _fuseiter_10237 < 64UL; _fuseiter_10237 += 1UL) {
      for (uint64_t _fuseiter_10238 = 0UL; _fuseiter_10238 < 4UL; _fuseiter_10238 += 1UL) {
        int8_t __cached_0;
        __cached_0 = __ins_0[(((_fuseiter_10237 + ((fused_0_fuseiter_10232___fuseiter_10233_3400 / 4UL) * 64UL)) * 2048UL) + ((_fuseiter_10238 + (_fuseiter_10236 * 4UL)) + ((fused_0_fuseiter_10232___fuseiter_10233_3400 % 4UL) * 512UL)))];
        int8_t __cached_1;
        __cached_1 = __cached_0;
        __outs_0[(((fused_0_fuseiter_10232___fuseiter_10233_3400 / 4UL) * 131072UL) + (((fused_0_fuseiter_10232___fuseiter_10233_3400 % 4UL) * 32768UL) + ((_fuseiter_10236 * 256UL) + ((_fuseiter_10237 * 4UL) + _fuseiter_10238))))] = __cached_1;
      }
    }
  }
}

static void reorder__5420_closure_320_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept{
  reorder__5420_closure_320(i, (int8_t*)(args[0UL].v_ptr), (int8_t*)(args[1UL].v_ptr));
}

static void mul__2540_closure_321(uint64_t fused_0fused_0__itr_0____itr_1_3401____itr_2_3402, float* __restrict__ __ins_0, float* __restrict__ __ins_1, float* __restrict__ __outs_0) noexcept{
  float __cached_0;
  __cached_0 = __ins_0[(((fused_0fused_0__itr_0____itr_1_3401____itr_2_3402 / 2048UL) * 2048UL) + (fused_0fused_0__itr_0____itr_1_3401____itr_2_3402 % 2048UL))];
  float __cached_1;
  __cached_1 = __ins_1[(fused_0fused_0__itr_0____itr_1_3401____itr_2_3402 / 2048UL)];
  float __cached_2;
  __cached_2 = (__cached_0 * __cached_1);
  __outs_0[(((fused_0fused_0__itr_0____itr_1_3401____itr_2_3402 / 2048UL) * 2048UL) + (fused_0fused_0__itr_0____itr_1_3401____itr_2_3402 % 2048UL))] = __cached_2;
}

static void mul__2540_closure_321_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept{
  mul__2540_closure_321(i, (float*)(args[0UL].v_ptr), (float*)(args[1UL].v_ptr), (float*)(args[2UL].v_ptr));
}

static void cast__2550_closure_322(uint64_t fused_0fused_0__itr_0____itr_1_3403____itr_2_3404, float* __restrict__ __ins_0, int8_t* __restrict__ __outs_0) noexcept{
  float __cached_0;
  __cached_0 = __ins_0[(((fused_0fused_0__itr_0____itr_1_3403____itr_2_3404 / 2048UL) * 2048UL) + (fused_0fused_0__itr_0____itr_1_3403____itr_2_3404 % 2048UL))];
  int8_t __cached_1;
  __cached_1 = (int8_t)sc_max(sc_min(sc_round_and_cast<int32_t>(__cached_0), 127), -128);
  __outs_0[(((fused_0fused_0__itr_0____itr_1_3403____itr_2_3404 / 2048UL) * 2048UL) + (fused_0fused_0__itr_0____itr_1_3403____itr_2_3404 % 2048UL))] = __cached_1;
}

static void cast__2550_closure_322_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept{
  cast__2550_closure_322(i, (float*)(args[0UL].v_ptr), (int8_t*)(args[1UL].v_ptr));
}

static void reorder__5510_closure_323(uint64_t fused_0fused_0fused_0fused_0_fuseiter_10249___fuseiter_10250_3405___fuseiter_10251_3406___fuseiter_10252_3407___fuseiter_10253_3408, int8_t* __restrict__ __ins_0, int8_t* __restrict__ __outs_0) noexcept{
  for (uint64_t _fuseiter_10254 = 0UL; _fuseiter_10254 < 256UL; _fuseiter_10254 += 1UL) {
    for (uint64_t _fuseiter_10255 = 0UL; _fuseiter_10255 < 4UL; _fuseiter_10255 += 1UL) {
      int8_t __cached_0;
      __cached_0 = __ins_0[(((_fuseiter_10254 + ((fused_0fused_0fused_0fused_0_fuseiter_10249___fuseiter_10250_3405___fuseiter_10251_3406___fuseiter_10252_3407___fuseiter_10253_3408 / 512UL) * 256UL)) * 2048UL) + ((_fuseiter_10255 + ((fused_0fused_0fused_0fused_0_fuseiter_10249___fuseiter_10250_3405___fuseiter_10251_3406___fuseiter_10252_3407___fuseiter_10253_3408 % 128UL) * 4UL)) + (((fused_0fused_0fused_0fused_0_fuseiter_10249___fuseiter_10250_3405___fuseiter_10251_3406___fuseiter_10252_3407___fuseiter_10253_3408 / 128UL) % 4UL) * 512UL)))];
      int8_t __cached_1;
      __cached_1 = __cached_0;
      __outs_0[(((fused_0fused_0fused_0fused_0_fuseiter_10249___fuseiter_10250_3405___fuseiter_10251_3406___fuseiter_10252_3407___fuseiter_10253_3408 / 512UL) * 524288UL) + ((((fused_0fused_0fused_0fused_0_fuseiter_10249___fuseiter_10250_3405___fuseiter_10251_3406___fuseiter_10252_3407___fuseiter_10253_3408 / 128UL) % 4UL) * 131072UL) + (((fused_0fused_0fused_0fused_0_fuseiter_10249___fuseiter_10250_3405___fuseiter_10251_3406___fuseiter_10252_3407___fuseiter_10253_3408 % 128UL) * 1024UL) + ((_fuseiter_10254 * 4UL) + _fuseiter_10255))))] = __cached_1;
    }
  }
}

static void reorder__5510_closure_323_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept{
  reorder__5510_closure_323(i, (int8_t*)(args[0UL].v_ptr), (int8_t*)(args[1UL].v_ptr));
}

static void mul__2330_closure_324(uint64_t fused_0fused_0__itr_0____itr_1_3409____itr_2_3410, float* __restrict__ __ins_0, float* __restrict__ __ins_1, float* __restrict__ __outs_0) noexcept{
  float __cached_0;
  __cached_0 = __ins_0[(((fused_0fused_0__itr_0____itr_1_3409____itr_2_3410 / 1024UL) * 1024UL) + (fused_0fused_0__itr_0____itr_1_3409____itr_2_3410 % 1024UL))];
  float __cached_1;
  __cached_1 = __ins_1[(fused_0fused_0__itr_0____itr_1_3409____itr_2_3410 / 1024UL)];
  float __cached_2;
  __cached_2 = (__cached_0 * __cached_1);
  __outs_0[(((fused_0fused_0__itr_0____itr_1_3409____itr_2_3410 / 1024UL) * 1024UL) + (fused_0fused_0__itr_0____itr_1_3409____itr_2_3410 % 1024UL))] = __cached_2;
}

static void mul__2330_closure_324_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept{
  mul__2330_closure_324(i, (float*)(args[0UL].v_ptr), (float*)(args[1UL].v_ptr), (float*)(args[2UL].v_ptr));
}

static void cast__2340_closure_325(uint64_t fused_0fused_0__itr_0____itr_1_3411____itr_2_3412, float* __restrict__ __ins_0, int8_t* __restrict__ __outs_0) noexcept{
  float __cached_0;
  __cached_0 = __ins_0[(((fused_0fused_0__itr_0____itr_1_3411____itr_2_3412 / 1024UL) * 1024UL) + (fused_0fused_0__itr_0____itr_1_3411____itr_2_3412 % 1024UL))];
  int8_t __cached_1;
  __cached_1 = (int8_t)sc_max(sc_min(sc_round_and_cast<int32_t>(__cached_0), 127), -128);
  __outs_0[(((fused_0fused_0__itr_0____itr_1_3411____itr_2_3412 / 1024UL) * 1024UL) + (fused_0fused_0__itr_0____itr_1_3411____itr_2_3412 % 1024UL))] = __cached_1;
}

static void cast__2340_closure_325_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept{
  cast__2340_closure_325(i, (float*)(args[0UL].v_ptr), (int8_t*)(args[1UL].v_ptr));
}

static void reorder__5320_closure_326(uint64_t fused_0_fuseiter_10266___fuseiter_10267_3413, int8_t* __restrict__ __ins_0, int8_t* __restrict__ __outs_0) noexcept{
  for (uint64_t _fuseiter_10270 = 0UL; _fuseiter_10270 < 16UL; _fuseiter_10270 += 1UL) {
    for (uint64_t _fuseiter_10271 = 0UL; _fuseiter_10271 < 512UL; _fuseiter_10271 += 1UL) {
      for (uint64_t _fuseiter_10272 = 0UL; _fuseiter_10272 < 4UL; _fuseiter_10272 += 1UL) {
        int8_t __cached_0;
        __cached_0 = __ins_0[(((_fuseiter_10271 + ((fused_0_fuseiter_10266___fuseiter_10267_3413 / 16UL) * 512UL)) * 1024UL) + ((_fuseiter_10272 + (_fuseiter_10270 * 4UL)) + ((fused_0_fuseiter_10266___fuseiter_10267_3413 % 16UL) * 64UL)))];
        int8_t __cached_1;
        __cached_1 = __cached_0;
        __outs_0[(((fused_0_fuseiter_10266___fuseiter_10267_3413 / 16UL) * 524288UL) + (((fused_0_fuseiter_10266___fuseiter_10267_3413 % 16UL) * 32768UL) + ((_fuseiter_10270 * 2048UL) + ((_fuseiter_10271 * 4UL) + _fuseiter_10272))))] = __cached_1;
      }
    }
  }
}

static void reorder__5320_closure_326_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept{
  reorder__5320_closure_326(i, (int8_t*)(args[0UL].v_ptr), (int8_t*)(args[1UL].v_ptr));
}

static void mul__2390_closure_327(uint64_t fused_0fused_0__itr_0____itr_1_3414____itr_2_3415, float* __restrict__ __ins_0, float* __restrict__ __ins_1, float* __restrict__ __outs_0) noexcept{
  for (uint64_t _fuseiter_10277 = 0UL; _fuseiter_10277 < 3UL; _fuseiter_10277 += 1UL) {
    float __cached_0;
    __cached_0 = __ins_0[((((fused_0fused_0__itr_0____itr_1_3414____itr_2_3415 / 1536UL) * 4608UL) + ((((fused_0fused_0__itr_0____itr_1_3414____itr_2_3415 / 3UL) % 512UL) * 9UL) + ((fused_0fused_0__itr_0____itr_1_3414____itr_2_3415 % 3UL) * 3UL))) + _fuseiter_10277)];
    float __cached_1;
    __cached_1 = __ins_1[(fused_0fused_0__itr_0____itr_1_3414____itr_2_3415 / 1536UL)];
    float __cached_2;
    __cached_2 = (__cached_0 * __cached_1);
    __outs_0[((((fused_0fused_0__itr_0____itr_1_3414____itr_2_3415 / 1536UL) * 4608UL) + ((((fused_0fused_0__itr_0____itr_1_3414____itr_2_3415 / 3UL) % 512UL) * 9UL) + ((fused_0fused_0__itr_0____itr_1_3414____itr_2_3415 % 3UL) * 3UL))) + _fuseiter_10277)] = __cached_2;
  }
}

static void mul__2390_closure_327_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept{
  mul__2390_closure_327(i, (float*)(args[0UL].v_ptr), (float*)(args[1UL].v_ptr), (float*)(args[2UL].v_ptr));
}

static void cast__2400_closure_328(uint64_t fused_0fused_0__itr_0____itr_1_3416____itr_2_3417, float* __restrict__ __ins_0, int8_t* __restrict__ __outs_0) noexcept{
  for (uint64_t _fuseiter10282 = 0UL; _fuseiter10282 < 3UL; _fuseiter10282 += 1UL) {
    float __cached_0;
    __cached_0 = __ins_0[((((fused_0fused_0__itr_0____itr_1_3416____itr_2_3417 / 1536UL) * 4608UL) + ((((fused_0fused_0__itr_0____itr_1_3416____itr_2_3417 / 3UL) % 512UL) * 9UL) + ((fused_0fused_0__itr_0____itr_1_3416____itr_2_3417 % 3UL) * 3UL))) + _fuseiter10282)];
    int8_t __cached_1;
    __cached_1 = (int8_t)sc_max(sc_min(sc_round_and_cast<int32_t>(__cached_0), 127), -128);
    __outs_0[((((fused_0fused_0__itr_0____itr_1_3416____itr_2_3417 / 1536UL) * 4608UL) + ((((fused_0fused_0__itr_0____itr_1_3416____itr_2_3417 / 3UL) % 512UL) * 9UL) + ((fused_0fused_0__itr_0____itr_1_3416____itr_2_3417 % 3UL) * 3UL))) + _fuseiter10282)] = __cached_1;
  }
}

static void cast__2400_closure_328_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept{
  cast__2400_closure_328(i, (float*)(args[0UL].v_ptr), (int8_t*)(args[1UL].v_ptr));
}

static void reorder__5360_closure_329(uint64_t fused_0fused_0_fuseiter_10283___fuseiter_10284_3418___fuseiter_10285_3419, int8_t* __restrict__ __ins_0, int8_t* __restrict__ __outs_0) noexcept{
  for (uint64_t _fuseiter_10286 = 0UL; _fuseiter_10286 < 3UL; _fuseiter_10286 += 1UL) {
    for (uint64_t _fuseiter_10287 = 0UL; _fuseiter_10287 < 16UL; _fuseiter_10287 += 1UL) {
      for (uint64_t _fuseiter_10288 = 0UL; _fuseiter_10288 < 256UL; _fuseiter_10288 += 1UL) {
        for (uint64_t _fuseiter_10289 = 0UL; _fuseiter_10289 < 4UL; _fuseiter_10289 += 1UL) {
          int8_t __cached_0;
          __cached_0 = __ins_0[(((_fuseiter_10288 + ((fused_0fused_0_fuseiter_10283___fuseiter_10284_3418___fuseiter_10285_3419 / 24UL) * 256UL)) * 4608UL) + ((((_fuseiter_10289 + (_fuseiter_10287 * 4UL)) + (((fused_0fused_0_fuseiter_10283___fuseiter_10284_3418___fuseiter_10285_3419 / 3UL) % 8UL) * 64UL)) * 9UL) + (((fused_0fused_0_fuseiter_10283___fuseiter_10284_3418___fuseiter_10285_3419 % 3UL) * 3UL) + _fuseiter_10286)))];
          int8_t __cached_1;
          __cached_1 = __cached_0;
          __outs_0[(((fused_0fused_0_fuseiter_10283___fuseiter_10284_3418___fuseiter_10285_3419 / 24UL) * 1179648UL) + ((((fused_0fused_0_fuseiter_10283___fuseiter_10284_3418___fuseiter_10285_3419 / 3UL) % 8UL) * 147456UL) + (((fused_0fused_0_fuseiter_10283___fuseiter_10284_3418___fuseiter_10285_3419 % 3UL) * 49152UL) + ((_fuseiter_10286 * 16384UL) + ((_fuseiter_10287 * 1024UL) + ((_fuseiter_10288 * 4UL) + _fuseiter_10289))))))] = __cached_1;
        }
      }
    }
  }
}

static void reorder__5360_closure_329_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept{
  reorder__5360_closure_329(i, (int8_t*)(args[0UL].v_ptr), (int8_t*)(args[1UL].v_ptr));
}

static void mul__2480_closure_330(uint64_t fused_0fused_0__itr_0____itr_1_3420____itr_2_3421, float* __restrict__ __ins_0, float* __restrict__ __ins_1, float* __restrict__ __outs_0) noexcept{
  for (uint64_t _fuseiter_10294 = 0UL; _fuseiter_10294 < 3UL; _fuseiter_10294 += 1UL) {
    float __cached_0;
    __cached_0 = __ins_0[((((fused_0fused_0__itr_0____itr_1_3420____itr_2_3421 / 1536UL) * 4608UL) + ((((fused_0fused_0__itr_0____itr_1_3420____itr_2_3421 / 3UL) % 512UL) * 9UL) + ((fused_0fused_0__itr_0____itr_1_3420____itr_2_3421 % 3UL) * 3UL))) + _fuseiter_10294)];
    float __cached_1;
    __cached_1 = __ins_1[(fused_0fused_0__itr_0____itr_1_3420____itr_2_3421 / 1536UL)];
    float __cached_2;
    __cached_2 = (__cached_0 * __cached_1);
    __outs_0[((((fused_0fused_0__itr_0____itr_1_3420____itr_2_3421 / 1536UL) * 4608UL) + ((((fused_0fused_0__itr_0____itr_1_3420____itr_2_3421 / 3UL) % 512UL) * 9UL) + ((fused_0fused_0__itr_0____itr_1_3420____itr_2_3421 % 3UL) * 3UL))) + _fuseiter_10294)] = __cached_2;
  }
}

static void mul__2480_closure_330_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept{
  mul__2480_closure_330(i, (float*)(args[0UL].v_ptr), (float*)(args[1UL].v_ptr), (float*)(args[2UL].v_ptr));
}

static void cast__2490_closure_331(uint64_t fused_0fused_0__itr_0____itr_1_3422____itr_2_3423, float* __restrict__ __ins_0, int8_t* __restrict__ __outs_0) noexcept{
  for (uint64_t _fuseiter10299 = 0UL; _fuseiter10299 < 3UL; _fuseiter10299 += 1UL) {
    float __cached_0;
    __cached_0 = __ins_0[((((fused_0fused_0__itr_0____itr_1_3422____itr_2_3423 / 1536UL) * 4608UL) + ((((fused_0fused_0__itr_0____itr_1_3422____itr_2_3423 / 3UL) % 512UL) * 9UL) + ((fused_0fused_0__itr_0____itr_1_3422____itr_2_3423 % 3UL) * 3UL))) + _fuseiter10299)];
    int8_t __cached_1;
    __cached_1 = (int8_t)sc_max(sc_min(sc_round_and_cast<int32_t>(__cached_0), 127), -128);
    __outs_0[((((fused_0fused_0__itr_0____itr_1_3422____itr_2_3423 / 1536UL) * 4608UL) + ((((fused_0fused_0__itr_0____itr_1_3422____itr_2_3423 / 3UL) % 512UL) * 9UL) + ((fused_0fused_0__itr_0____itr_1_3422____itr_2_3423 % 3UL) * 3UL))) + _fuseiter10299)] = __cached_1;
  }
}

static void cast__2490_closure_331_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept{
  cast__2490_closure_331(i, (float*)(args[0UL].v_ptr), (int8_t*)(args[1UL].v_ptr));
}

static void reorder__5450_closure_332(uint64_t fused_0_fuseiter_10300___fuseiter_10301_3424, int8_t* __restrict__ __ins_0, int8_t* __restrict__ __outs_0) noexcept{
  for (uint64_t _fuseiter_10302 = 0UL; _fuseiter_10302 < 3UL; _fuseiter_10302 += 1UL) {
    for (uint64_t _fuseiter_10303 = 0UL; _fuseiter_10303 < 3UL; _fuseiter_10303 += 1UL) {
      for (uint64_t _fuseiter_10304 = 0UL; _fuseiter_10304 < 16UL; _fuseiter_10304 += 1UL) {
        for (uint64_t _fuseiter_10305 = 0UL; _fuseiter_10305 < 128UL; _fuseiter_10305 += 1UL) {
          for (uint64_t _fuseiter_10306 = 0UL; _fuseiter_10306 < 4UL; _fuseiter_10306 += 1UL) {
            int8_t __cached_0;
            __cached_0 = __ins_0[(((_fuseiter_10305 + ((fused_0_fuseiter_10300___fuseiter_10301_3424 / 8UL) * 128UL)) * 4608UL) + ((((_fuseiter_10306 + (_fuseiter_10304 * 4UL)) + ((fused_0_fuseiter_10300___fuseiter_10301_3424 % 8UL) * 64UL)) * 9UL) + ((_fuseiter_10302 * 3UL) + _fuseiter_10303)))];
            int8_t __cached_1;
            __cached_1 = __cached_0;
            __outs_0[(((fused_0_fuseiter_10300___fuseiter_10301_3424 / 8UL) * 589824UL) + (((fused_0_fuseiter_10300___fuseiter_10301_3424 % 8UL) * 73728UL) + ((_fuseiter_10302 * 24576UL) + ((_fuseiter_10303 * 8192UL) + ((_fuseiter_10304 * 512UL) + ((_fuseiter_10305 * 4UL) + _fuseiter_10306))))))] = __cached_1;
          }
        }
      }
    }
  }
}

static void reorder__5450_closure_332_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept{
  reorder__5450_closure_332(i, (int8_t*)(args[0UL].v_ptr), (int8_t*)(args[1UL].v_ptr));
}

static void mul__2570_closure_333(uint64_t fused_0fused_0__itr_0____itr_1_3425____itr_2_3426, float* __restrict__ __ins_0, float* __restrict__ __ins_1, float* __restrict__ __outs_0) noexcept{
  for (uint64_t _fuseiter_10311 = 0UL; _fuseiter_10311 < 3UL; _fuseiter_10311 += 1UL) {
    float __cached_0;
    __cached_0 = __ins_0[((((fused_0fused_0__itr_0____itr_1_3425____itr_2_3426 / 1536UL) * 4608UL) + ((((fused_0fused_0__itr_0____itr_1_3425____itr_2_3426 / 3UL) % 512UL) * 9UL) + ((fused_0fused_0__itr_0____itr_1_3425____itr_2_3426 % 3UL) * 3UL))) + _fuseiter_10311)];
    float __cached_1;
    __cached_1 = __ins_1[(fused_0fused_0__itr_0____itr_1_3425____itr_2_3426 / 1536UL)];
    float __cached_2;
    __cached_2 = (__cached_0 * __cached_1);
    __outs_0[((((fused_0fused_0__itr_0____itr_1_3425____itr_2_3426 / 1536UL) * 4608UL) + ((((fused_0fused_0__itr_0____itr_1_3425____itr_2_3426 / 3UL) % 512UL) * 9UL) + ((fused_0fused_0__itr_0____itr_1_3425____itr_2_3426 % 3UL) * 3UL))) + _fuseiter_10311)] = __cached_2;
  }
}

static void mul__2570_closure_333_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept{
  mul__2570_closure_333(i, (float*)(args[0UL].v_ptr), (float*)(args[1UL].v_ptr), (float*)(args[2UL].v_ptr));
}

static void cast__2580_closure_334(uint64_t fused_0fused_0__itr_0____itr_1_3427____itr_2_3428, float* __restrict__ __ins_0, int8_t* __restrict__ __outs_0) noexcept{
  for (uint64_t _fuseiter10316 = 0UL; _fuseiter10316 < 3UL; _fuseiter10316 += 1UL) {
    float __cached_0;
    __cached_0 = __ins_0[((((fused_0fused_0__itr_0____itr_1_3427____itr_2_3428 / 1536UL) * 4608UL) + ((((fused_0fused_0__itr_0____itr_1_3427____itr_2_3428 / 3UL) % 512UL) * 9UL) + ((fused_0fused_0__itr_0____itr_1_3427____itr_2_3428 % 3UL) * 3UL))) + _fuseiter10316)];
    int8_t __cached_1;
    __cached_1 = (int8_t)sc_max(sc_min(sc_round_and_cast<int32_t>(__cached_0), 127), -128);
    __outs_0[((((fused_0fused_0__itr_0____itr_1_3427____itr_2_3428 / 1536UL) * 4608UL) + ((((fused_0fused_0__itr_0____itr_1_3427____itr_2_3428 / 3UL) % 512UL) * 9UL) + ((fused_0fused_0__itr_0____itr_1_3427____itr_2_3428 % 3UL) * 3UL))) + _fuseiter10316)] = __cached_1;
  }
}

static void cast__2580_closure_334_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept{
  cast__2580_closure_334(i, (float*)(args[0UL].v_ptr), (int8_t*)(args[1UL].v_ptr));
}

static void reorder__5540_closure_335(uint64_t fused_0fused_0_fuseiter_10317___fuseiter_10318_3429___fuseiter_10319_3430, int8_t* __restrict__ __ins_0, int8_t* __restrict__ __outs_0) noexcept{
  for (uint64_t _fuseiter_10320 = 0UL; _fuseiter_10320 < 3UL; _fuseiter_10320 += 1UL) {
    for (uint64_t _fuseiter_10321 = 0UL; _fuseiter_10321 < 128UL; _fuseiter_10321 += 1UL) {
      for (uint64_t _fuseiter_10322 = 0UL; _fuseiter_10322 < 64UL; _fuseiter_10322 += 1UL) {
        for (uint64_t _fuseiter_10323 = 0UL; _fuseiter_10323 < 4UL; _fuseiter_10323 += 1UL) {
          int8_t __cached_0;
          __cached_0 = __ins_0[(((_fuseiter_10322 + ((fused_0fused_0_fuseiter_10317___fuseiter_10318_3429___fuseiter_10319_3430 / 3UL) * 64UL)) * 4608UL) + (((_fuseiter_10323 + (_fuseiter_10321 * 4UL)) * 9UL) + (((fused_0fused_0_fuseiter_10317___fuseiter_10318_3429___fuseiter_10319_3430 % 3UL) * 3UL) + _fuseiter_10320)))];
          int8_t __cached_1;
          __cached_1 = __cached_0;
          __outs_0[(((fused_0fused_0_fuseiter_10317___fuseiter_10318_3429___fuseiter_10319_3430 / 3UL) * 294912UL) + (((fused_0fused_0_fuseiter_10317___fuseiter_10318_3429___fuseiter_10319_3430 % 3UL) * 98304UL) + ((_fuseiter_10320 * 32768UL) + ((_fuseiter_10321 * 256UL) + ((_fuseiter_10322 * 4UL) + _fuseiter_10323)))))] = __cached_1;
        }
      }
    }
  }
}

static void reorder__5540_closure_335_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept{
  reorder__5540_closure_335(i, (int8_t*)(args[0UL].v_ptr), (int8_t*)(args[1UL].v_ptr));
}

static void batchwise_4_fused_res2a_conv_b_cast_mul_add_cast_res2a_conv_0_cast_mul_add_cast_relu_res2a_conv_1_cast_mul_add_cast_relu_res2a_conv_2_cast_mul_add_cast_add_relu_res2b_conv_0_cast_mul_add_cast_relu_res2b_conv_1_cast_mul_add_cast_relu_res2b_conv_2_cast_mul_add_cast_add_relu_res2c_conv_0_cast_mul_add_cast_relu_res2c_conv_1_cast_mul_add_cast_relu_res2c_conv_2_cast_mul_add_cast_add_relu_res3a_conv_b_cast_mul_add_cast_res3a_conv_0_cast_mul_add_cast_relu_res3a_conv_1_cast_mul_add_cast_relu_res3a_conv_2_cast_mul_add_cast_add_relu_res3b_conv_0_cast_mul_add_cast_relu_res3b_conv_1_cast_mul_add_cast_relu_res3b_conv_2_cast_mul_add_cast_add_relu_res3c_conv_0_cast_mul_add_cast_relu_res3c_conv_1_cast_mul_add_cast_relu_res3c_conv_2_cast_mul_add_cast_add_relu_res3d_conv_0_cast_mul_add_cast_relu_res3d_conv_1_cast_mul_add_cast_relu_res3d_conv_2_cast_mul_add_cast_add_relu__6840_closure_336(uint64_t __batchwise_iter_0, int64_t* __restrict__ input_pointers, int8_t* __restrict__ __ins_1, float* __restrict__ __ins_2, float* __restrict__ __ins_3, int8_t* __restrict__ __ins_4, float* __restrict__ __ins_5, float* __restrict__ __ins_6, int8_t* __restrict__ __ins_7, float* __restrict__ __ins_8, float* __restrict__ __ins_9, int8_t* __restrict__ __ins_10, float* __restrict__ __ins_11, float* __restrict__ __ins_12, int8_t* __restrict__ __ins_13, float* __restrict__ __ins_14, float* __restrict__ __ins_15, int8_t* __restrict__ __ins_16, float* __restrict__ __ins_17, float* __restrict__ __ins_18, int8_t* __restrict__ __ins_19, float* __restrict__ __ins_20, float* __restrict__ __ins_21, int8_t* __restrict__ __ins_22, float* __restrict__ __ins_23, float* __restrict__ __ins_24, int8_t* __restrict__ __ins_25, float* __restrict__ __ins_26, float* __restrict__ __ins_27, int8_t* __restrict__ __ins_28, float* __restrict__ __ins_29, float* __restrict__ __ins_30, int8_t* __restrict__ __ins_31, float* __restrict__ __ins_32, float* __restrict__ __ins_33, int8_t* __restrict__ __ins_34, float* __restrict__ __ins_35, float* __restrict__ __ins_36, int8_t* __restrict__ __ins_37, float* __restrict__ __ins_38, float* __restrict__ __ins_39, int8_t* __restrict__ __ins_40, float* __restrict__ __ins_41, float* __restrict__ __ins_42, int8_t* __restrict__ __ins_43, float* __restrict__ __ins_44, float* __restrict__ __ins_45, int8_t* __restrict__ __ins_46, float* __restrict__ __ins_47, float* __restrict__ __ins_48, int8_t* __restrict__ __ins_49, float* __restrict__ __ins_50, float* __restrict__ __ins_51, int8_t* __restrict__ __ins_52, float* __restrict__ __ins_53, float* __restrict__ __ins_54, int8_t* __restrict__ __ins_55, float* __restrict__ __ins_56, float* __restrict__ __ins_57, int8_t* __restrict__ __ins_58, float* __restrict__ __ins_59, float* __restrict__ __ins_60, int8_t* __restrict__ __ins_61, float* __restrict__ __ins_62, float* __restrict__ __ins_63, int8_t* __restrict__ __ins_64, float* __restrict__ __ins_65, float* __restrict__ __ins_66, int8_t* __restrict__ __outs_0, int8_t* __restrict__ __ins_67, float* __restrict__ __ins_68, float* __restrict__ __ins_69) noexcept{
  int8_t* __rescheduled_1 = (int8_t*)sc_thread_aligned_malloc(__stream, 1634816UL);
  int8_t* conv_out_pointer = (int8_t*)&__rescheduled_1[0UL];
  int8_t* pool_out_pointer = (int8_t*)&__rescheduled_1[1218816UL];
  void* scratchpad_pointer = (void*)&__rescheduled_1[802816UL];

  runStart_Server(__batchwise_iter_0, reinterpret_cast<int8_t*>(input_pointers[__batchwise_iter_0]), conv_out_pointer,
                                                         pool_out_pointer, scratchpad_pointer);
 
   // [s8 [1, 1, 1, 58, 58, 64] @ A1aBCD64b]
  int8_t* buffer_71 = (int8_t*)&__rescheduled_1[802816UL];
  res2a_conv_0_cast_mul_add_cast_relu__8(buffer_71, pool_out_pointer, &__ins_4[0UL], &__ins_5[0UL], &__ins_6[0UL]);
 
  // [s8 [1, 1, 4, 56, 56, 64] @ A1aBCD64b]
  int8_t* buffer_70 = (int8_t*)&__rescheduled_1[0UL];
  res2a_conv_b_cast_mul_add_cast__4(buffer_70, pool_out_pointer, &__ins_1[0UL], &__ins_2[0UL], &__ins_3[0UL]);
 
  // [s8 [1, 1, 1, 56, 56, 64] @ A1aBCD64b]
  int8_t* buffer_72 = (int8_t*)&__rescheduled_1[1233408UL];
  res2a_conv_1_cast_mul_add_cast_relu__12(buffer_72, buffer_71, &__ins_7[0UL], &__ins_8[0UL], &__ins_9[0UL]);
  res2a_conv_2_cast_mul_add_cast_add_relu__16(buffer_70, buffer_72, &__ins_10[0UL], &__ins_11[0UL], &__ins_12[0UL], buffer_70);
  res2b_conv_0_cast_mul_add_cast_relu__20(buffer_72, buffer_70, &__ins_13[0UL], &__ins_14[0UL], &__ins_15[0UL]);
  res2b_conv_1_cast_mul_add_cast_relu__24(buffer_71, buffer_72, &__ins_16[0UL], &__ins_17[0UL], &__ins_18[0UL]);
  res2b_conv_2_cast_mul_add_cast_add_relu__28(buffer_70, buffer_71, &__ins_19[0UL], &__ins_20[0UL], &__ins_21[0UL], buffer_70);
  res2c_conv_0_cast_mul_add_cast_relu__32(buffer_72, buffer_70, &__ins_22[0UL], &__ins_23[0UL], &__ins_24[0UL]);
  res2c_conv_1_cast_mul_add_cast_relu__36(buffer_71, buffer_72, &__ins_25[0UL], &__ins_26[0UL], &__ins_27[0UL]);
  res2c_conv_2_cast_mul_add_cast_add_relu__40(buffer_70, buffer_71, &__ins_28[0UL], &__ins_29[0UL], &__ins_30[0UL], buffer_70);
  res3a_conv_b_cast_mul_add_cast__44(buffer_72, buffer_70, &__ins_31[0UL], &__ins_32[0UL], &__ins_33[0UL]);
  res3a_conv_0_cast_mul_add_cast_relu__48(buffer_71, buffer_70, &__ins_34[0UL], &__ins_35[0UL], &__ins_36[0UL]);
  res3a_conv_1_cast_mul_add_cast_relu__52(buffer_70, buffer_71, &__ins_37[0UL], &__ins_38[0UL], &__ins_39[0UL]);
  res3a_conv_2_cast_mul_add_cast_add_relu__56(buffer_72, buffer_70, &__ins_40[0UL], &__ins_41[0UL], &__ins_42[0UL], buffer_72);
  res3b_conv_0_cast_mul_add_cast_relu__60(buffer_70, buffer_72, &__ins_43[0UL], &__ins_44[0UL], &__ins_45[0UL]);
  res3b_conv_1_cast_mul_add_cast_relu__64(buffer_71, buffer_70, &__ins_46[0UL], &__ins_47[0UL], &__ins_48[0UL]);
  res3b_conv_2_cast_mul_add_cast_add_relu__68(buffer_72, buffer_71, &__ins_49[0UL], &__ins_50[0UL], &__ins_51[0UL], buffer_72);
  res3c_conv_0_cast_mul_add_cast_relu__72(buffer_70, buffer_72, &__ins_52[0UL], &__ins_53[0UL], &__ins_54[0UL]);
  res3c_conv_1_cast_mul_add_cast_relu__76(buffer_71, buffer_70, &__ins_55[0UL], &__ins_56[0UL], &__ins_57[0UL]);
  res3c_conv_2_cast_mul_add_cast_add_relu__80(buffer_72, buffer_71, &__ins_58[0UL], &__ins_59[0UL], &__ins_60[0UL], buffer_72);
  res3d_conv_0_cast_mul_add_cast_relu__84(buffer_70, buffer_72, &__ins_61[0UL], &__ins_62[0UL], &__ins_63[0UL]);
  res3d_conv_1_cast_mul_add_cast_relu__88(buffer_71, buffer_70, &__ins_64[0UL], &__ins_65[0UL], &__ins_66[0UL]);
  res3d_conv_2_cast_mul_add_cast_add_relu__93(&__outs_0[(__batchwise_iter_0 * 401408UL)], buffer_71, &__ins_67[0UL], &__ins_68[0UL], &__ins_69[0UL], buffer_72);
  sc_thread_aligned_free(__stream, __rescheduled_1);
}

static void batchwise_4_fused_res2a_conv_b_cast_mul_add_cast_res2a_conv_0_cast_mul_add_cast_relu_res2a_conv_1_cast_mul_add_cast_relu_res2a_conv_2_cast_mul_add_cast_add_relu_res2b_conv_0_cast_mul_add_cast_relu_res2b_conv_1_cast_mul_add_cast_relu_res2b_conv_2_cast_mul_add_cast_add_relu_res2c_conv_0_cast_mul_add_cast_relu_res2c_conv_1_cast_mul_add_cast_relu_res2c_conv_2_cast_mul_add_cast_add_relu_res3a_conv_b_cast_mul_add_cast_res3a_conv_0_cast_mul_add_cast_relu_res3a_conv_1_cast_mul_add_cast_relu_res3a_conv_2_cast_mul_add_cast_add_relu_res3b_conv_0_cast_mul_add_cast_relu_res3b_conv_1_cast_mul_add_cast_relu_res3b_conv_2_cast_mul_add_cast_add_relu_res3c_conv_0_cast_mul_add_cast_relu_res3c_conv_1_cast_mul_add_cast_relu_res3c_conv_2_cast_mul_add_cast_add_relu_res3d_conv_0_cast_mul_add_cast_relu_res3d_conv_1_cast_mul_add_cast_relu_res3d_conv_2_cast_mul_add_cast_add_relu__6840_closure_336_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept{
  batchwise_4_fused_res2a_conv_b_cast_mul_add_cast_res2a_conv_0_cast_mul_add_cast_relu_res2a_conv_1_cast_mul_add_cast_relu_res2a_conv_2_cast_mul_add_cast_add_relu_res2b_conv_0_cast_mul_add_cast_relu_res2b_conv_1_cast_mul_add_cast_relu_res2b_conv_2_cast_mul_add_cast_add_relu_res2c_conv_0_cast_mul_add_cast_relu_res2c_conv_1_cast_mul_add_cast_relu_res2c_conv_2_cast_mul_add_cast_add_relu_res3a_conv_b_cast_mul_add_cast_res3a_conv_0_cast_mul_add_cast_relu_res3a_conv_1_cast_mul_add_cast_relu_res3a_conv_2_cast_mul_add_cast_add_relu_res3b_conv_0_cast_mul_add_cast_relu_res3b_conv_1_cast_mul_add_cast_relu_res3b_conv_2_cast_mul_add_cast_add_relu_res3c_conv_0_cast_mul_add_cast_relu_res3c_conv_1_cast_mul_add_cast_relu_res3c_conv_2_cast_mul_add_cast_add_relu_res3d_conv_0_cast_mul_add_cast_relu_res3d_conv_1_cast_mul_add_cast_relu_res3d_conv_2_cast_mul_add_cast_add_relu__6840_closure_336(i, (int64_t*)(args[0UL].v_ptr), (int8_t*)(args[1UL].v_ptr), (float*)(args[2UL].v_ptr), (float*)(args[3UL].v_ptr), (int8_t*)(args[4UL].v_ptr), (float*)(args[5UL].v_ptr), (float*)(args[6UL].v_ptr), (int8_t*)(args[7UL].v_ptr), (float*)(args[8UL].v_ptr), (float*)(args[9UL].v_ptr), (int8_t*)(args[10UL].v_ptr), (float*)(args[11UL].v_ptr), (float*)(args[12UL].v_ptr), (int8_t*)(args[13UL].v_ptr), (float*)(args[14UL].v_ptr), (float*)(args[15UL].v_ptr), (int8_t*)(args[16UL].v_ptr), (float*)(args[17UL].v_ptr), (float*)(args[18UL].v_ptr), (int8_t*)(args[19UL].v_ptr), (float*)(args[20UL].v_ptr), (float*)(args[21UL].v_ptr), (int8_t*)(args[22UL].v_ptr), (float*)(args[23UL].v_ptr), (float*)(args[24UL].v_ptr), (int8_t*)(args[25UL].v_ptr), (float*)(args[26UL].v_ptr), (float*)(args[27UL].v_ptr), (int8_t*)(args[28UL].v_ptr), (float*)(args[29UL].v_ptr), (float*)(args[30UL].v_ptr), (int8_t*)(args[31UL].v_ptr), (float*)(args[32UL].v_ptr), (float*)(args[33UL].v_ptr), (int8_t*)(args[34UL].v_ptr), (float*)(args[35UL].v_ptr), (float*)(args[36UL].v_ptr), (int8_t*)(args[37UL].v_ptr), (float*)(args[38UL].v_ptr), (float*)(args[39UL].v_ptr), (int8_t*)(args[40UL].v_ptr), (float*)(args[41UL].v_ptr), (float*)(args[42UL].v_ptr), (int8_t*)(args[43UL].v_ptr), (float*)(args[44UL].v_ptr), (float*)(args[45UL].v_ptr), (int8_t*)(args[46UL].v_ptr), (float*)(args[47UL].v_ptr), (float*)(args[48UL].v_ptr), (int8_t*)(args[49UL].v_ptr), (float*)(args[50UL].v_ptr), (float*)(args[51UL].v_ptr), (int8_t*)(args[52UL].v_ptr), (float*)(args[53UL].v_ptr), (float*)(args[54UL].v_ptr), (int8_t*)(args[55UL].v_ptr), (float*)(args[56UL].v_ptr), (float*)(args[57UL].v_ptr), (int8_t*)(args[58UL].v_ptr), (float*)(args[59UL].v_ptr), (float*)(args[60UL].v_ptr), (int8_t*)(args[61UL].v_ptr), (float*)(args[62UL].v_ptr), (float*)(args[63UL].v_ptr), (int8_t*)(args[64UL].v_ptr), (float*)(args[65UL].v_ptr), (float*)(args[66UL].v_ptr), (int8_t*)(args[67UL].v_ptr), (int8_t*)(args[68UL].v_ptr), (float*)(args[69UL].v_ptr), (float*)(args[70UL].v_ptr));
}

static void batchwise_2_fused_res4a_conv_b_cast_mul_add_cast_res4a_conv_0_cast_mul_add_cast_relu_res4a_conv_1_cast_mul_add_cast_relu_res4a_conv_2_cast_mul_add_cast_add_relu_res4b_conv_0_cast_mul_add_cast_relu_res4b_conv_1_cast_mul_add_cast_relu_res4b_conv_2_cast_mul_add_cast_add_relu_res4c_conv_0_cast_mul_add_cast_relu_res4c_conv_1_cast_mul_add_cast_relu_res4c_conv_2_cast_mul_add_cast_add_relu_res4d_conv_0_cast_mul_add_cast_relu_res4d_conv_1_cast_mul_add_cast_relu_res4d_conv_2_cast_mul_add_cast_add_relu_res4e_conv_0_cast_mul_add_cast_relu_res4e_conv_1_cast_mul_add_cast_relu_res4e_conv_2_cast_mul_add_cast_add_relu_res4f_conv_0_cast_mul_add_cast_relu_res4f_conv_1_cast_mul_add_cast_relu_res4f_conv_2_cast_mul_add_cast_add_relu__6850_closure_337(uint64_t __batchwise_iter_0, int8_t* __restrict__ __ins_0, int8_t* __restrict__ __ins_1, float* __restrict__ __ins_2, float* __restrict__ __ins_3, int8_t* __restrict__ __ins_4, float* __restrict__ __ins_5, float* __restrict__ __ins_6, int8_t* __restrict__ __ins_7, float* __restrict__ __ins_8, float* __restrict__ __ins_9, int8_t* __restrict__ __ins_10, float* __restrict__ __ins_11, float* __restrict__ __ins_12, int8_t* __restrict__ __ins_13, float* __restrict__ __ins_14, float* __restrict__ __ins_15, int8_t* __restrict__ __ins_16, float* __restrict__ __ins_17, float* __restrict__ __ins_18, int8_t* __restrict__ __ins_19, float* __restrict__ __ins_20, float* __restrict__ __ins_21, int8_t* __restrict__ __ins_22, float* __restrict__ __ins_23, float* __restrict__ __ins_24, int8_t* __restrict__ __ins_25, float* __restrict__ __ins_26, float* __restrict__ __ins_27, int8_t* __restrict__ __ins_28, float* __restrict__ __ins_29, float* __restrict__ __ins_30, int8_t* __restrict__ __ins_31, float* __restrict__ __ins_32, float* __restrict__ __ins_33, int8_t* __restrict__ __ins_34, float* __restrict__ __ins_35, float* __restrict__ __ins_36, int8_t* __restrict__ __ins_37, float* __restrict__ __ins_38, float* __restrict__ __ins_39, int8_t* __restrict__ __ins_40, float* __restrict__ __ins_41, float* __restrict__ __ins_42, int8_t* __restrict__ __ins_43, float* __restrict__ __ins_44, float* __restrict__ __ins_45, int8_t* __restrict__ __ins_46, float* __restrict__ __ins_47, float* __restrict__ __ins_48, int8_t* __restrict__ __ins_49, float* __restrict__ __ins_50, float* __restrict__ __ins_51, int8_t* __restrict__ __ins_52, float* __restrict__ __ins_53, float* __restrict__ __ins_54, int8_t* __restrict__ __outs_0, int8_t* __restrict__ __ins_55, float* __restrict__ __ins_56, float* __restrict__ __ins_57) noexcept{
  int8_t* __rescheduled_1 = (int8_t*)sc_thread_aligned_malloc(__stream, 993280UL);
  // [s8 [1, 2, 16, 14, 14, 64] @ A2aBCD64b]
  int8_t* buffer_58 = (int8_t*)&__rescheduled_1[0UL];
  res4a_conv_b_cast_mul_add_cast__4(buffer_58, &__ins_0[(__batchwise_iter_0 * 802816UL)], &__ins_1[0UL], &__ins_2[0UL], &__ins_3[0UL]);
  // [s8 [1, 2, 4, 30, 30, 64] @ A2aBCD64b]
  int8_t* buffer_59 = (int8_t*)&__rescheduled_1[401408UL];
  res4a_conv_0_cast_mul_add_cast_relu__8(buffer_59, &__ins_0[(__batchwise_iter_0 * 802816UL)], &__ins_4[0UL], &__ins_5[0UL], &__ins_6[0UL]);
  // [s8 [1, 2, 4, 14, 14, 64] @ A2aBCD64b]
  int8_t* buffer_60 = (int8_t*)&__rescheduled_1[862208UL];
  res4a_conv_1_cast_mul_add_cast_relu__12(buffer_60, buffer_59, &__ins_7[0UL], &__ins_8[0UL], &__ins_9[0UL]);
  res4a_conv_2_cast_mul_add_cast_add_relu__16(buffer_58, buffer_60, &__ins_10[0UL], &__ins_11[0UL], &__ins_12[0UL], buffer_58);
  res4b_conv_0_cast_mul_add_cast_relu__20(buffer_60, buffer_58, &__ins_13[0UL], &__ins_14[0UL], &__ins_15[0UL]);
  res4b_conv_1_cast_mul_add_cast_relu__24(buffer_59, buffer_60, &__ins_16[0UL], &__ins_17[0UL], &__ins_18[0UL]);
  res4b_conv_2_cast_mul_add_cast_add_relu__28(buffer_58, buffer_59, &__ins_19[0UL], &__ins_20[0UL], &__ins_21[0UL], buffer_58);
  res4c_conv_0_cast_mul_add_cast_relu__32(buffer_60, buffer_58, &__ins_22[0UL], &__ins_23[0UL], &__ins_24[0UL]);
  res4c_conv_1_cast_mul_add_cast_relu__36(buffer_59, buffer_60, &__ins_25[0UL], &__ins_26[0UL], &__ins_27[0UL]);
  res4c_conv_2_cast_mul_add_cast_add_relu__40(buffer_58, buffer_59, &__ins_28[0UL], &__ins_29[0UL], &__ins_30[0UL], buffer_58);
  res4d_conv_0_cast_mul_add_cast_relu__44(buffer_60, buffer_58, &__ins_31[0UL], &__ins_32[0UL], &__ins_33[0UL]);
  res4d_conv_1_cast_mul_add_cast_relu__48(buffer_59, buffer_60, &__ins_34[0UL], &__ins_35[0UL], &__ins_36[0UL]);
  res4d_conv_2_cast_mul_add_cast_add_relu__52(buffer_58, buffer_59, &__ins_37[0UL], &__ins_38[0UL], &__ins_39[0UL], buffer_58);
  res4e_conv_0_cast_mul_add_cast_relu__56(buffer_60, buffer_58, &__ins_40[0UL], &__ins_41[0UL], &__ins_42[0UL]);
  res4e_conv_1_cast_mul_add_cast_relu__60(buffer_59, buffer_60, &__ins_43[0UL], &__ins_44[0UL], &__ins_45[0UL]);
  res4e_conv_2_cast_mul_add_cast_add_relu__64(buffer_58, buffer_59, &__ins_46[0UL], &__ins_47[0UL], &__ins_48[0UL], buffer_58);
  res4f_conv_0_cast_mul_add_cast_relu__68(buffer_60, buffer_58, &__ins_49[0UL], &__ins_50[0UL], &__ins_51[0UL]);
  res4f_conv_1_cast_mul_add_cast_relu__72(buffer_59, buffer_60, &__ins_52[0UL], &__ins_53[0UL], &__ins_54[0UL]);
  res4f_conv_2_cast_mul_add_cast_add_relu__77(&__outs_0[(__batchwise_iter_0 * 401408UL)], buffer_59, &__ins_55[0UL], &__ins_56[0UL], &__ins_57[0UL], buffer_58);
  sc_thread_aligned_free(__stream, __rescheduled_1);
}

static void batchwise_2_fused_res4a_conv_b_cast_mul_add_cast_res4a_conv_0_cast_mul_add_cast_relu_res4a_conv_1_cast_mul_add_cast_relu_res4a_conv_2_cast_mul_add_cast_add_relu_res4b_conv_0_cast_mul_add_cast_relu_res4b_conv_1_cast_mul_add_cast_relu_res4b_conv_2_cast_mul_add_cast_add_relu_res4c_conv_0_cast_mul_add_cast_relu_res4c_conv_1_cast_mul_add_cast_relu_res4c_conv_2_cast_mul_add_cast_add_relu_res4d_conv_0_cast_mul_add_cast_relu_res4d_conv_1_cast_mul_add_cast_relu_res4d_conv_2_cast_mul_add_cast_add_relu_res4e_conv_0_cast_mul_add_cast_relu_res4e_conv_1_cast_mul_add_cast_relu_res4e_conv_2_cast_mul_add_cast_add_relu_res4f_conv_0_cast_mul_add_cast_relu_res4f_conv_1_cast_mul_add_cast_relu_res4f_conv_2_cast_mul_add_cast_add_relu__6850_closure_337_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept{
  batchwise_2_fused_res4a_conv_b_cast_mul_add_cast_res4a_conv_0_cast_mul_add_cast_relu_res4a_conv_1_cast_mul_add_cast_relu_res4a_conv_2_cast_mul_add_cast_add_relu_res4b_conv_0_cast_mul_add_cast_relu_res4b_conv_1_cast_mul_add_cast_relu_res4b_conv_2_cast_mul_add_cast_add_relu_res4c_conv_0_cast_mul_add_cast_relu_res4c_conv_1_cast_mul_add_cast_relu_res4c_conv_2_cast_mul_add_cast_add_relu_res4d_conv_0_cast_mul_add_cast_relu_res4d_conv_1_cast_mul_add_cast_relu_res4d_conv_2_cast_mul_add_cast_add_relu_res4e_conv_0_cast_mul_add_cast_relu_res4e_conv_1_cast_mul_add_cast_relu_res4e_conv_2_cast_mul_add_cast_add_relu_res4f_conv_0_cast_mul_add_cast_relu_res4f_conv_1_cast_mul_add_cast_relu_res4f_conv_2_cast_mul_add_cast_add_relu__6850_closure_337(i, (int8_t*)(args[0UL].v_ptr), (int8_t*)(args[1UL].v_ptr), (float*)(args[2UL].v_ptr), (float*)(args[3UL].v_ptr), (int8_t*)(args[4UL].v_ptr), (float*)(args[5UL].v_ptr), (float*)(args[6UL].v_ptr), (int8_t*)(args[7UL].v_ptr), (float*)(args[8UL].v_ptr), (float*)(args[9UL].v_ptr), (int8_t*)(args[10UL].v_ptr), (float*)(args[11UL].v_ptr), (float*)(args[12UL].v_ptr), (int8_t*)(args[13UL].v_ptr), (float*)(args[14UL].v_ptr), (float*)(args[15UL].v_ptr), (int8_t*)(args[16UL].v_ptr), (float*)(args[17UL].v_ptr), (float*)(args[18UL].v_ptr), (int8_t*)(args[19UL].v_ptr), (float*)(args[20UL].v_ptr), (float*)(args[21UL].v_ptr), (int8_t*)(args[22UL].v_ptr), (float*)(args[23UL].v_ptr), (float*)(args[24UL].v_ptr), (int8_t*)(args[25UL].v_ptr), (float*)(args[26UL].v_ptr), (float*)(args[27UL].v_ptr), (int8_t*)(args[28UL].v_ptr), (float*)(args[29UL].v_ptr), (float*)(args[30UL].v_ptr), (int8_t*)(args[31UL].v_ptr), (float*)(args[32UL].v_ptr), (float*)(args[33UL].v_ptr), (int8_t*)(args[34UL].v_ptr), (float*)(args[35UL].v_ptr), (float*)(args[36UL].v_ptr), (int8_t*)(args[37UL].v_ptr), (float*)(args[38UL].v_ptr), (float*)(args[39UL].v_ptr), (int8_t*)(args[40UL].v_ptr), (float*)(args[41UL].v_ptr), (float*)(args[42UL].v_ptr), (int8_t*)(args[43UL].v_ptr), (float*)(args[44UL].v_ptr), (float*)(args[45UL].v_ptr), (int8_t*)(args[46UL].v_ptr), (float*)(args[47UL].v_ptr), (float*)(args[48UL].v_ptr), (int8_t*)(args[49UL].v_ptr), (float*)(args[50UL].v_ptr), (float*)(args[51UL].v_ptr), (int8_t*)(args[52UL].v_ptr), (float*)(args[53UL].v_ptr), (float*)(args[54UL].v_ptr), (int8_t*)(args[55UL].v_ptr), (int8_t*)(args[56UL].v_ptr), (float*)(args[57UL].v_ptr), (float*)(args[58UL].v_ptr));
}

static void res5a_conv_b_cast_mul_add_cast__6830_closure_338(uint64_t n, int8_t* __restrict__ __ins_0, int8_t* __restrict__ input_tmp) noexcept{
  for (uint64_t c_o = 0UL; c_o < 16UL; c_o += 1UL) {
    for (uint64_t p = 0UL; p < 7UL; p += 1UL) {
      for (uint64_t q = 0UL; q < 7UL; q += 1UL) {
        vec_s8x64 __cached_0;
        __cached_0 = vec_s8x64::load(&__ins_0[((n * 200704UL) + ((c_o * 12544UL) + ((p * 1792UL) + (q * 128UL))))]);
        vec_s8x64 __cached_1;
        __cached_1 = __cached_0;
        vec_s8x64::store(__cached_1, &input_tmp[((n * 50176UL) + ((c_o * 3136UL) + ((p * 448UL) + (q * 64UL))))]);
      }
    }
  }
}

static void res5a_conv_b_cast_mul_add_cast__6830_closure_338_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept{
  res5a_conv_b_cast_mul_add_cast__6830_closure_338(i, (int8_t*)(args[0UL].v_ptr), (int8_t*)(args[1UL].v_ptr));
}

static void res5a_conv_b_cast_mul_add_cast__6830_closure_339(uint64_t fused_0fused_0fused_0oc_i__k_3515__n_3516__n_i_3517, int8_t* __restrict__ input_tmp, int8_t* __restrict__ __ins_1, float* __restrict__ __ins_2, float* __restrict__ __ins_3, int8_t* __restrict__ __outs_0) noexcept{
  void*& __sc_kernel_cache_138 = *(void**)(__module_data + 120);
  int8_t* __rescheduled_2 = (int8_t*)sc_thread_aligned_malloc(__stream, 256UL);
  int32_t* __origouts_3020_shr = (int32_t*)sc_thread_aligned_malloc(__stream, 100352UL);
  void** A_list = (void**)&__rescheduled_2[0UL];
  void** B_list = (void**)&__rescheduled_2[128UL];
  for (uint64_t c = 0UL; c < 16UL; c += 1UL) {
    void* __cached_2;
    __cached_2 = &input_tmp[(((fused_0fused_0fused_0oc_i__k_3515__n_3516__n_i_3517 % 4UL) * 50176UL) + (c * 3136UL))];
    A_list[c] = __cached_2;
    void* __cached_3;
    __cached_3 = &__ins_1[(((((fused_0fused_0fused_0oc_i__k_3515__n_3516__n_i_3517 / 4UL) % 2UL) + ((fused_0fused_0fused_0oc_i__k_3515__n_3516__n_i_3517 / 8UL) * 2UL)) * 524288UL) + (c * 32768UL))];
    B_list[c] = __cached_3;
  }
  void* _arg_cache_42 = &__origouts_3020_shr[0UL];
  dnnl_brgemm_list_call(__sc_kernel_cache_138, A_list, B_list, &__origouts_3020_shr[0UL], 1, 1, 1, 16, 7, 7, __stream);
  for (uint64_t _fuseiter11867 = 0UL; _fuseiter11867 < 7UL; _fuseiter11867 += 1UL) {
    for (uint64_t _fuseiter11868 = 0UL; _fuseiter11868 < 7UL; _fuseiter11868 += 1UL) {
      for (uint64_t _fuseiter11869 = 0UL; _fuseiter11869 < 512UL; _fuseiter11869 += 16UL) {
        vec_s32x16 __cached_4;
        __cached_4 = vec_s32x16::load(&__origouts_3020_shr[((_fuseiter11867 * 3584UL) + ((_fuseiter11868 * 512UL) + _fuseiter11869))]);
        vec_f32x16 __cached_5;
        __cached_5 = (vec_f32x16)(__cached_4);
        vec_f32x16 __cached_6;
        __cached_6 = vec_f32x16::load(&__ins_2[(((((fused_0fused_0fused_0oc_i__k_3515__n_3516__n_i_3517 / 4UL) % 2UL) + ((fused_0fused_0fused_0oc_i__k_3515__n_3516__n_i_3517 / 8UL) * 2UL)) * 512UL) + _fuseiter11869)]);
        __cached_5 = (__cached_5 * __cached_6);
        vec_f32x16 __cached_7;
        __cached_7 = vec_f32x16::load(&__ins_3[(((((fused_0fused_0fused_0oc_i__k_3515__n_3516__n_i_3517 / 4UL) % 2UL) + ((fused_0fused_0fused_0oc_i__k_3515__n_3516__n_i_3517 / 8UL) * 2UL)) * 512UL) + _fuseiter11869)]);
        __cached_5 = (__cached_5 + __cached_7);
        vec_s8x16 __cached_8;
        __cached_8 = sc_saturated_cast<vec_s8x16>(sc_round_and_cast<vec_s32x16>(__cached_5));
        vec_s8x16::store(__cached_8, &__outs_0[((((fused_0fused_0fused_0oc_i__k_3515__n_3516__n_i_3517 % 4UL) * 100352UL) + ((((fused_0fused_0fused_0oc_i__k_3515__n_3516__n_i_3517 / 4UL) % 2UL) + ((fused_0fused_0fused_0oc_i__k_3515__n_3516__n_i_3517 / 8UL) * 2UL)) * 25088UL)) + ((_fuseiter11867 * 3584UL) + ((_fuseiter11868 * 512UL) + _fuseiter11869)))]);
      }
    }
  }
  sc_thread_aligned_free(__stream, __origouts_3020_shr);
  sc_thread_aligned_free(__stream, __rescheduled_2);
}

static void res5a_conv_b_cast_mul_add_cast__6830_closure_339_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept{
  res5a_conv_b_cast_mul_add_cast__6830_closure_339(i, (int8_t*)(args[0UL].v_ptr), (int8_t*)(args[1UL].v_ptr), (float*)(args[2UL].v_ptr), (float*)(args[3UL].v_ptr), (int8_t*)(args[4UL].v_ptr));
}

static void res5a_conv_0_cast_mul_add_cast_relu_reorder__6820_closure_340(uint64_t n, int8_t* __restrict__ __outs_0) noexcept{
  for (uint64_t k = 0UL; k < 8UL; k += 1UL) {
    memset(&__outs_0[((n * 131072UL) + (k * 16384UL))], 0, 1024UL);
    for (uint64_t p1 = 0UL; p1 < 14UL; p1 += 1UL) {
      memset(&__outs_0[((n * 131072UL) + ((k * 16384UL) + ((p1 + 1UL) * 1024UL)))], 0, 64UL);
      memset(&__outs_0[(((n * 131072UL) + ((k * 16384UL) + ((p1 + 1UL) * 1024UL))) + 960UL)], 0, 64UL);
    }
    memset(&__outs_0[(((n * 131072UL) + (k * 16384UL)) + 15360UL)], 0, 1024UL);
  }
}

static void res5a_conv_0_cast_mul_add_cast_relu_reorder__6820_closure_340_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept{
  res5a_conv_0_cast_mul_add_cast_relu_reorder__6820_closure_340(i, (int8_t*)(args[0UL].v_ptr));
}

static void res5a_conv_0_cast_mul_add_cast_relu_reorder__6820_closure_341(uint64_t fused_0fused_0k__n_3518__n_i_3519, int8_t* __restrict__ __ins_0, int8_t* __restrict__ __ins_1, float* __restrict__ __ins_2, float* __restrict__ __ins_3, int8_t* __restrict__ __outs_0) noexcept{
  void*& __sc_kernel_cache_140 = *(void**)(__module_data + 128);
  int8_t* __rescheduled_2 = (int8_t*)sc_thread_aligned_malloc(__stream, 256UL);
  for (uint64_t p_o = 0UL; p_o < 7UL; p_o += 1UL) {
    int32_t* __origouts_3030_shr = (int32_t*)sc_thread_aligned_malloc(__stream, 57344UL);
    void** A_list = (void**)&__rescheduled_2[0UL];
    void** B_list = (void**)&__rescheduled_2[128UL];
    for (uint64_t c = 0UL; c < 16UL; c += 1UL) {
      void* __cached_0;
      __cached_0 = &__ins_0[(((fused_0fused_0k__n_3518__n_i_3519 % 4UL) * 200704UL) + ((c * 12544UL) + (p_o * 1792UL)))];
      A_list[c] = __cached_0;
      void* __cached_1;
      __cached_1 = &__ins_1[(((fused_0fused_0k__n_3518__n_i_3519 / 4UL) * 524288UL) + (c * 32768UL))];
      B_list[c] = __cached_1;
    }
    void* _arg_cache_43 = &__origouts_3030_shr[0UL];
    dnnl_brgemm_list_call(__sc_kernel_cache_140, A_list, B_list, &__origouts_3030_shr[0UL], 1, 1, 1, 16, 7, 7, __stream);
    for (uint64_t _fuseiter11895 = 0UL; _fuseiter11895 < 2UL; _fuseiter11895 += 1UL) {
      for (uint64_t _fuseiter11896 = 0UL; _fuseiter11896 < 14UL; _fuseiter11896 += 1UL) {
        for (uint64_t _fuseiter11897 = 0UL; _fuseiter11897 < 512UL; _fuseiter11897 += 16UL) {
          vec_s32x16 __cached_2;
          __cached_2 = vec_s32x16::load(&__origouts_3030_shr[((_fuseiter11895 * 7168UL) + ((_fuseiter11896 * 512UL) + _fuseiter11897))]);
          vec_f32x16 __cached_3;
          __cached_3 = (vec_f32x16)(__cached_2);
          vec_f32x16 __cached_4;
          __cached_4 = vec_f32x16::load(&__ins_2[(((fused_0fused_0k__n_3518__n_i_3519 / 4UL) * 512UL) + _fuseiter11897)]);
          __cached_3 = (__cached_3 * __cached_4);
          vec_f32x16 __cached_5;
          __cached_5 = vec_f32x16::load(&__ins_3[(((fused_0fused_0k__n_3518__n_i_3519 / 4UL) * 512UL) + _fuseiter11897)]);
          __cached_3 = (__cached_3 + __cached_5);
          vec_s8x16 __cached_6;
          __cached_6 = sc_saturated_cast<vec_s8x16>(sc_round_and_cast<vec_s32x16>(__cached_3));
          __cached_6 = sc_max(__cached_6, vec_s8x16(0));
          vec_s8x16 __cached_7;
          __cached_7 = __cached_6;
          vec_s8x16::store(__cached_7, &__outs_0[(((fused_0fused_0k__n_3518__n_i_3519 % 4UL) * 131072UL) + ((((_fuseiter11897 + ((fused_0fused_0k__n_3518__n_i_3519 / 4UL) * 512UL)) / 64UL) * 16384UL) + ((((_fuseiter11895 + (p_o * 2UL)) + 1UL) * 1024UL) + (((_fuseiter11896 + 1UL) * 64UL) + ((_fuseiter11897 + ((fused_0fused_0k__n_3518__n_i_3519 / 4UL) * 512UL)) % 64UL)))))]);
        }
      }
    }
    sc_thread_aligned_free(__stream, __origouts_3030_shr);
  }
  sc_thread_aligned_free(__stream, __rescheduled_2);
}

static void res5a_conv_0_cast_mul_add_cast_relu_reorder__6820_closure_341_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept{
  res5a_conv_0_cast_mul_add_cast_relu_reorder__6820_closure_341(i, (int8_t*)(args[0UL].v_ptr), (int8_t*)(args[1UL].v_ptr), (float*)(args[2UL].v_ptr), (float*)(args[3UL].v_ptr), (int8_t*)(args[4UL].v_ptr));
}

static void res5a_conv_1_cast_mul_add_cast_relu_reorder__6810_closure_342(uint64_t fused_0fused_0fused_0oc_i__n_3520__n_i_3521__k_o_3522, int8_t* __restrict__ __ins_0, int8_t* __restrict__ __ins_1, float* __restrict__ __ins_2, float* __restrict__ __ins_3, int8_t* __restrict__ __outs_0) noexcept{
  void*& __sc_kernel_cache_142 = *(void**)(__module_data + 136);
  int8_t* __rescheduled_1 = (int8_t*)sc_thread_aligned_malloc(__stream, 1152UL);
  void** A_list = (void**)&__rescheduled_1[0UL];
  void** B_list = (void**)&__rescheduled_1[576UL];
  for (uint64_t p_i = 0UL; p_i < 7UL; p_i += 1UL) {
    int32_t* __origouts_3040_shr = (int32_t*)sc_thread_aligned_malloc(__stream, 7168UL);
    for (uint64_t c_o = 0UL; c_o < 8UL; c_o += 1UL) {
      for (uint64_t r = 0UL; r < 3UL; r += 1UL) {
        for (uint64_t s = 0UL; s < 3UL; s += 1UL) {
          void* __cached_0;
          __cached_0 = &__ins_0[(((fused_0fused_0fused_0oc_i__n_3520__n_i_3521__k_o_3522 % 4UL) * 131072UL) + ((c_o * 16384UL) + ((((p_i * 2UL) + r) * 1024UL) + (s * 64UL))))];
          A_list[(((c_o * 9UL) + (r * 3UL)) + s)] = __cached_0;
          void* __cached_1;
          __cached_1 = &__ins_1[(((fused_0fused_0fused_0oc_i__n_3520__n_i_3521__k_o_3522 / 4UL) * 1179648UL) + ((c_o * 147456UL) + ((r * 49152UL) + (s * 16384UL))))];
          B_list[(((c_o * 9UL) + (r * 3UL)) + s)] = __cached_1;
        }
      }
    }
    void* _arg_cache_44 = &__origouts_3040_shr[0UL];
    dnnl_brgemm_list_call(__sc_kernel_cache_142, A_list, B_list, &__origouts_3040_shr[0UL], 1, 64, 16384, 72, 7, 7, __stream);
    for (uint64_t _fuseiter11937 = 0UL; _fuseiter11937 < 7UL; _fuseiter11937 += 1UL) {
      for (uint64_t _fuseiter11938 = 0UL; _fuseiter11938 < 256UL; _fuseiter11938 += 16UL) {
        vec_s32x16 __cached_2;
        __cached_2 = vec_s32x16::load(&__origouts_3040_shr[((_fuseiter11937 * 256UL) + _fuseiter11938)]);
        vec_f32x16 __cached_3;
        __cached_3 = (vec_f32x16)(__cached_2);
        vec_f32x16 __cached_4;
        __cached_4 = vec_f32x16::load(&__ins_2[(((fused_0fused_0fused_0oc_i__n_3520__n_i_3521__k_o_3522 / 4UL) * 256UL) + _fuseiter11938)]);
        __cached_3 = (__cached_3 * __cached_4);
        vec_f32x16 __cached_5;
        __cached_5 = vec_f32x16::load(&__ins_3[(((fused_0fused_0fused_0oc_i__n_3520__n_i_3521__k_o_3522 / 4UL) * 256UL) + _fuseiter11938)]);
        __cached_3 = (__cached_3 + __cached_5);
        vec_s8x16 __cached_6;
        __cached_6 = sc_saturated_cast<vec_s8x16>(sc_round_and_cast<vec_s32x16>(__cached_3));
        __cached_6 = sc_max(__cached_6, vec_s8x16(0));
        vec_s8x16 __cached_7;
        __cached_7 = __cached_6;
        vec_s8x16::store(__cached_7, &__outs_0[(((fused_0fused_0fused_0oc_i__n_3520__n_i_3521__k_o_3522 % 4UL) * 25088UL) + ((((_fuseiter11938 + ((fused_0fused_0fused_0oc_i__n_3520__n_i_3521__k_o_3522 / 4UL) * 256UL)) / 512UL) * 25088UL) + ((p_i * 3584UL) + ((_fuseiter11937 * 512UL) + ((_fuseiter11938 + ((fused_0fused_0fused_0oc_i__n_3520__n_i_3521__k_o_3522 / 4UL) * 256UL)) % 512UL)))))]);
      }
    }
    sc_thread_aligned_free(__stream, __origouts_3040_shr);
  }
  sc_thread_aligned_free(__stream, __rescheduled_1);
}

static void res5a_conv_1_cast_mul_add_cast_relu_reorder__6810_closure_342_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept{
  res5a_conv_1_cast_mul_add_cast_relu_reorder__6810_closure_342(i, (int8_t*)(args[0UL].v_ptr), (int8_t*)(args[1UL].v_ptr), (float*)(args[2UL].v_ptr), (float*)(args[3UL].v_ptr), (int8_t*)(args[4UL].v_ptr));
}

static void res5a_conv_2_cast_mul_add_cast_add_relu__6800_closure_343(uint64_t fused_0fused_0n__n_i_3523__k_3524, int8_t* __restrict__ __ins_0, int8_t* __restrict__ __ins_1, float* __restrict__ __ins_2, float* __restrict__ __ins_3, int8_t* __restrict__ __ins_4, int8_t* __restrict__ __outs_0) noexcept{
  void*& __sc_kernel_cache_144 = *(void**)(__module_data + 144);
  alignas(64) int8_t __rescheduled_1[128UL];
  int32_t* __origouts_3050_shr = (int32_t*)sc_thread_aligned_malloc(__stream, 100352UL);
  void** A_list = (void**)&__rescheduled_1[0UL];
  void** B_list = (void**)&__rescheduled_1[64UL];
  void* __cached_0;
  __cached_0 = &__ins_0[((fused_0fused_0n__n_i_3523__k_3524 / 4UL) * 25088UL)];
  A_list[0UL] = __cached_0;
  void* __cached_1;
  __cached_1 = &__ins_1[((fused_0fused_0n__n_i_3523__k_3524 % 4UL) * 262144UL)];
  B_list[0UL] = __cached_1;
  void* _arg_cache_45 = &__origouts_3050_shr[0UL];
  dnnl_brgemm_list_call(__sc_kernel_cache_144, A_list, B_list, &__origouts_3050_shr[0UL], 1, 1, 1, 1, 7, 7, __stream);
  for (uint64_t _fuseiter11977 = 0UL; _fuseiter11977 < 7UL; _fuseiter11977 += 1UL) {
    for (uint64_t _fuseiter11978 = 0UL; _fuseiter11978 < 7UL; _fuseiter11978 += 1UL) {
      for (uint64_t _fuseiter11979 = 0UL; _fuseiter11979 < 512UL; _fuseiter11979 += 16UL) {
        vec_s32x16 __cached_2;
        __cached_2 = vec_s32x16::load(&__origouts_3050_shr[((_fuseiter11977 * 3584UL) + ((_fuseiter11978 * 512UL) + _fuseiter11979))]);
        vec_f32x16 __cached_3;
        __cached_3 = (vec_f32x16)(__cached_2);
        vec_f32x16 __cached_4;
        __cached_4 = vec_f32x16::load(&__ins_2[(((fused_0fused_0n__n_i_3523__k_3524 % 4UL) * 512UL) + _fuseiter11979)]);
        __cached_3 = (__cached_3 * __cached_4);
        vec_f32x16 __cached_5;
        __cached_5 = vec_f32x16::load(&__ins_3[(((fused_0fused_0n__n_i_3523__k_3524 % 4UL) * 512UL) + _fuseiter11979)]);
        __cached_3 = (__cached_3 + __cached_5);
        vec_s8x16 __cached_6;
        __cached_6 = sc_saturated_cast<vec_s8x16>(sc_round_and_cast<vec_s32x16>(__cached_3));
        vec_s8x16 __cached_7;
        __cached_7 = vec_s8x16::load(&__ins_4[((((fused_0fused_0n__n_i_3523__k_3524 / 4UL) * 100352UL) + ((fused_0fused_0n__n_i_3523__k_3524 % 4UL) * 25088UL)) + ((_fuseiter11977 * 3584UL) + ((_fuseiter11978 * 512UL) + _fuseiter11979)))]);
        __cached_6 = (__cached_6 + __cached_7);
        vec_s8x16 __cached_8;
        __cached_8 = sc_max(__cached_6, vec_s8x16(0));
        vec_s8x16::store(__cached_8, &__outs_0[((((fused_0fused_0n__n_i_3523__k_3524 / 4UL) * 100352UL) + ((fused_0fused_0n__n_i_3523__k_3524 % 4UL) * 25088UL)) + ((_fuseiter11977 * 3584UL) + ((_fuseiter11978 * 512UL) + _fuseiter11979)))]);
      }
    }
  }
  sc_thread_aligned_free(__stream, __origouts_3050_shr);
}

static void res5a_conv_2_cast_mul_add_cast_add_relu__6800_closure_343_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept{
  res5a_conv_2_cast_mul_add_cast_add_relu__6800_closure_343(i, (int8_t*)(args[0UL].v_ptr), (int8_t*)(args[1UL].v_ptr), (float*)(args[2UL].v_ptr), (float*)(args[3UL].v_ptr), (int8_t*)(args[4UL].v_ptr), (int8_t*)(args[5UL].v_ptr));
}

static void res5b_conv_0_cast_mul_add_cast_relu__6790_closure_344(uint64_t n, int8_t* __restrict__ __outs_0) noexcept{
  for (uint64_t k = 0UL; k < 8UL; k += 1UL) {
    memset(&__outs_0[((n * 41472UL) + (k * 5184UL))], 0, 576UL);
    for (uint64_t p1 = 0UL; p1 < 7UL; p1 += 1UL) {
      memset(&__outs_0[((n * 41472UL) + ((k * 5184UL) + ((p1 + 1UL) * 576UL)))], 0, 64UL);
      memset(&__outs_0[(((n * 41472UL) + ((k * 5184UL) + ((p1 + 1UL) * 576UL))) + 512UL)], 0, 64UL);
    }
    memset(&__outs_0[(((n * 41472UL) + (k * 5184UL)) + 4608UL)], 0, 576UL);
  }
}

static void res5b_conv_0_cast_mul_add_cast_relu__6790_closure_344_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept{
  res5b_conv_0_cast_mul_add_cast_relu__6790_closure_344(i, (int8_t*)(args[0UL].v_ptr));
}

static void res5b_conv_0_cast_mul_add_cast_relu__6790_closure_345(uint64_t fused_0fused_0n__n_i_3525__k_3526, int8_t* __restrict__ __ins_0, int8_t* __restrict__ __ins_1, float* __restrict__ __ins_2, float* __restrict__ __ins_3, int8_t* __restrict__ __outs_0) noexcept{
  void*& __sc_kernel_cache_146 = *(void**)(__module_data + 152);
  alignas(64) int8_t __rescheduled_2[128UL];
  int32_t* __origouts_3060_shr = (int32_t*)sc_thread_aligned_malloc(__stream, 12544UL);
  void** A_list = (void**)&__rescheduled_2[0UL];
  void** B_list = (void**)&__rescheduled_2[64UL];
  for (uint64_t c = 0UL; c < 4UL; c += 1UL) {
    void* __cached_0;
    __cached_0 = &__ins_0[(((fused_0fused_0n__n_i_3525__k_3526 / 8UL) * 100352UL) + (c * 25088UL))];
    A_list[c] = __cached_0;
    void* __cached_1;
    __cached_1 = &__ins_1[(((fused_0fused_0n__n_i_3525__k_3526 % 8UL) * 131072UL) + (c * 32768UL))];
    B_list[c] = __cached_1;
  }
  void* _arg_cache_46 = &__origouts_3060_shr[0UL];
  dnnl_brgemm_list_call(__sc_kernel_cache_146, A_list, B_list, &__origouts_3060_shr[0UL], 1, 1, 1, 4, 7, 7, __stream);
  for (uint64_t _fuseiter12019 = 0UL; _fuseiter12019 < 7UL; _fuseiter12019 += 1UL) {
    for (uint64_t _fuseiter12020 = 0UL; _fuseiter12020 < 7UL; _fuseiter12020 += 1UL) {
      for (uint64_t _fuseiter12021 = 0UL; _fuseiter12021 < 64UL; _fuseiter12021 += 16UL) {
        vec_s32x16 __cached_2;
        __cached_2 = vec_s32x16::load(&__origouts_3060_shr[((_fuseiter12019 * 448UL) + ((_fuseiter12020 * 64UL) + _fuseiter12021))]);
        vec_f32x16 __cached_3;
        __cached_3 = (vec_f32x16)(__cached_2);
        vec_f32x16 __cached_4;
        __cached_4 = vec_f32x16::load(&__ins_2[(((fused_0fused_0n__n_i_3525__k_3526 % 8UL) * 64UL) + _fuseiter12021)]);
        __cached_3 = (__cached_3 * __cached_4);
        vec_f32x16 __cached_5;
        __cached_5 = vec_f32x16::load(&__ins_3[(((fused_0fused_0n__n_i_3525__k_3526 % 8UL) * 64UL) + _fuseiter12021)]);
        __cached_3 = (__cached_3 + __cached_5);
        vec_s8x16 __cached_6;
        __cached_6 = sc_saturated_cast<vec_s8x16>(sc_round_and_cast<vec_s32x16>(__cached_3));
        vec_s8x16 __cached_7;
        __cached_7 = sc_max(__cached_6, vec_s8x16(0));
        vec_s8x16::store(__cached_7, &__outs_0[(((((fused_0fused_0n__n_i_3525__k_3526 / 8UL) * 41472UL) + ((fused_0fused_0n__n_i_3525__k_3526 % 8UL) * 5184UL)) + 640UL) + ((_fuseiter12019 * 576UL) + ((_fuseiter12020 * 64UL) + _fuseiter12021)))]);
      }
    }
  }
  sc_thread_aligned_free(__stream, __origouts_3060_shr);
}

static void res5b_conv_0_cast_mul_add_cast_relu__6790_closure_345_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept{
  res5b_conv_0_cast_mul_add_cast_relu__6790_closure_345(i, (int8_t*)(args[0UL].v_ptr), (int8_t*)(args[1UL].v_ptr), (float*)(args[2UL].v_ptr), (float*)(args[3UL].v_ptr), (int8_t*)(args[4UL].v_ptr));
}

static void res5b_conv_1_cast_mul_add_cast_relu_reorder__6780_closure_346(uint64_t fused_0fused_0fused_0oc_i__n_3527__n_i_3528__k_o_3529, int8_t* __restrict__ __ins_0, int8_t* __restrict__ __ins_1, float* __restrict__ __ins_2, float* __restrict__ __ins_3, int8_t* __restrict__ __outs_0) noexcept{
  void** __sc_kernel_cache_arr_150 = (void**)&__uninitialized_data[23657528UL];
  int8_t* __rescheduled_1 = (int8_t*)sc_thread_aligned_malloc(__stream, 1152UL);
  int32_t* __origouts_3070_shr = (int32_t*)sc_thread_aligned_malloc(__stream, 25088UL);
  void** A_list = (void**)&__rescheduled_1[0UL];
  void** B_list = (void**)&__rescheduled_1[576UL];
  for (uint64_t c_o = 0UL; c_o < 8UL; c_o += 1UL) {
    for (uint64_t r = 0UL; r < 3UL; r += 1UL) {
      for (uint64_t s = 0UL; s < 3UL; s += 1UL) {
        void* __cached_1;
        __cached_1 = &__ins_0[((((fused_0fused_0fused_0oc_i__n_3527__n_i_3528__k_o_3529 / 2UL) % 4UL) * 41472UL) + ((c_o * 5184UL) + ((r * 576UL) + (s * 64UL))))];
        A_list[(((c_o * 9UL) + (r * 3UL)) + s)] = __cached_1;
        void* __cached_2;
        __cached_2 = &__ins_1[((((fused_0fused_0fused_0oc_i__n_3527__n_i_3528__k_o_3529 % 2UL) + ((fused_0fused_0fused_0oc_i__n_3527__n_i_3528__k_o_3529 / 8UL) * 2UL)) * 589824UL) + ((c_o * 73728UL) + ((r * 24576UL) + (s * 8192UL))))];
        B_list[(((c_o * 9UL) + (r * 3UL)) + s)] = __cached_2;
      }
    }
  }
  void* _arg_cache_47 = &__origouts_3070_shr[0UL];
  dnnl_brgemm_list_call(__sc_kernel_cache_arr_150[0UL], A_list, B_list, &__origouts_3070_shr[0UL], 1, 64, 8192, 72, 7, 7, __stream);
  for (uint64_t _fuseiter12054 = 0UL; _fuseiter12054 < 7UL; _fuseiter12054 += 1UL) {
    for (uint64_t _fuseiter12055 = 0UL; _fuseiter12055 < 7UL; _fuseiter12055 += 1UL) {
      for (uint64_t _fuseiter12056 = 0UL; _fuseiter12056 < 128UL; _fuseiter12056 += 16UL) {
        vec_s32x16 __cached_3;
        __cached_3 = vec_s32x16::load(&__origouts_3070_shr[((_fuseiter12054 * 896UL) + ((_fuseiter12055 * 128UL) + _fuseiter12056))]);
        vec_f32x16 __cached_4;
        __cached_4 = (vec_f32x16)(__cached_3);
        vec_f32x16 __cached_5;
        __cached_5 = vec_f32x16::load(&__ins_2[((((fused_0fused_0fused_0oc_i__n_3527__n_i_3528__k_o_3529 % 2UL) + ((fused_0fused_0fused_0oc_i__n_3527__n_i_3528__k_o_3529 / 8UL) * 2UL)) * 128UL) + _fuseiter12056)]);
        __cached_4 = (__cached_4 * __cached_5);
        vec_f32x16 __cached_6;
        __cached_6 = vec_f32x16::load(&__ins_3[((((fused_0fused_0fused_0oc_i__n_3527__n_i_3528__k_o_3529 % 2UL) + ((fused_0fused_0fused_0oc_i__n_3527__n_i_3528__k_o_3529 / 8UL) * 2UL)) * 128UL) + _fuseiter12056)]);
        __cached_4 = (__cached_4 + __cached_6);
        vec_s8x16 __cached_7;
        __cached_7 = sc_saturated_cast<vec_s8x16>(sc_round_and_cast<vec_s32x16>(__cached_4));
        __cached_7 = sc_max(__cached_7, vec_s8x16(0));
        vec_s8x16 __cached_8;
        __cached_8 = __cached_7;
        vec_s8x16::store(__cached_8, &__outs_0[((((fused_0fused_0fused_0oc_i__n_3527__n_i_3528__k_o_3529 / 2UL) % 4UL) * 25088UL) + ((((_fuseiter12056 + (((fused_0fused_0fused_0oc_i__n_3527__n_i_3528__k_o_3529 % 2UL) + ((fused_0fused_0fused_0oc_i__n_3527__n_i_3528__k_o_3529 / 8UL) * 2UL)) * 128UL)) / 512UL) * 25088UL) + ((_fuseiter12054 * 3584UL) + ((_fuseiter12055 * 512UL) + ((_fuseiter12056 + (((fused_0fused_0fused_0oc_i__n_3527__n_i_3528__k_o_3529 % 2UL) + ((fused_0fused_0fused_0oc_i__n_3527__n_i_3528__k_o_3529 / 8UL) * 2UL)) * 128UL)) % 512UL)))))]);
      }
    }
  }
  sc_thread_aligned_free(__stream, __origouts_3070_shr);
  sc_thread_aligned_free(__stream, __rescheduled_1);
}

static void res5b_conv_1_cast_mul_add_cast_relu_reorder__6780_closure_346_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept{
  res5b_conv_1_cast_mul_add_cast_relu_reorder__6780_closure_346(i, (int8_t*)(args[0UL].v_ptr), (int8_t*)(args[1UL].v_ptr), (float*)(args[2UL].v_ptr), (float*)(args[3UL].v_ptr), (int8_t*)(args[4UL].v_ptr));
}

static void res5b_conv_2_cast_mul_add_cast_add_relu__6770_closure_347(uint64_t fused_0fused_0k__n_3530__n_i_3531, int8_t* __restrict__ __ins_0, int8_t* __restrict__ __ins_1, float* __restrict__ __ins_2, float* __restrict__ __ins_3, int8_t* __restrict__ __ins_4, int8_t* __restrict__ __outs_0) noexcept{
  void*& __sc_kernel_cache_144 = *(void**)(__module_data + 144);
  alignas(64) int8_t __rescheduled_1[128UL];
  int32_t* __origouts_3080_shr = (int32_t*)sc_thread_aligned_malloc(__stream, 100352UL);
  void** A_list = (void**)&__rescheduled_1[0UL];
  void** B_list = (void**)&__rescheduled_1[64UL];
  void* __cached_0;
  __cached_0 = &__ins_0[((fused_0fused_0k__n_3530__n_i_3531 % 4UL) * 25088UL)];
  A_list[0UL] = __cached_0;
  void* __cached_1;
  __cached_1 = &__ins_1[((fused_0fused_0k__n_3530__n_i_3531 / 4UL) * 262144UL)];
  B_list[0UL] = __cached_1;
  void* _arg_cache_48 = &__origouts_3080_shr[0UL];
  dnnl_brgemm_list_call(__sc_kernel_cache_144, A_list, B_list, &__origouts_3080_shr[0UL], 1, 1, 1, 1, 7, 7, __stream);
  for (uint64_t _fuseiter12095 = 0UL; _fuseiter12095 < 7UL; _fuseiter12095 += 1UL) {
    for (uint64_t _fuseiter12096 = 0UL; _fuseiter12096 < 7UL; _fuseiter12096 += 1UL) {
      for (uint64_t _fuseiter12097 = 0UL; _fuseiter12097 < 512UL; _fuseiter12097 += 16UL) {
        vec_s32x16 __cached_2;
        __cached_2 = vec_s32x16::load(&__origouts_3080_shr[((_fuseiter12095 * 3584UL) + ((_fuseiter12096 * 512UL) + _fuseiter12097))]);
        vec_f32x16 __cached_3;
        __cached_3 = (vec_f32x16)(__cached_2);
        vec_f32x16 __cached_4;
        __cached_4 = vec_f32x16::load(&__ins_2[(((fused_0fused_0k__n_3530__n_i_3531 / 4UL) * 512UL) + _fuseiter12097)]);
        __cached_3 = (__cached_3 * __cached_4);
        vec_f32x16 __cached_5;
        __cached_5 = vec_f32x16::load(&__ins_3[(((fused_0fused_0k__n_3530__n_i_3531 / 4UL) * 512UL) + _fuseiter12097)]);
        __cached_3 = (__cached_3 + __cached_5);
        vec_s8x16 __cached_6;
        __cached_6 = sc_saturated_cast<vec_s8x16>(sc_round_and_cast<vec_s32x16>(__cached_3));
        vec_s8x16 __cached_7;
        __cached_7 = vec_s8x16::load(&__ins_4[((((fused_0fused_0k__n_3530__n_i_3531 % 4UL) * 100352UL) + ((fused_0fused_0k__n_3530__n_i_3531 / 4UL) * 25088UL)) + ((_fuseiter12095 * 3584UL) + ((_fuseiter12096 * 512UL) + _fuseiter12097)))]);
        __cached_6 = (__cached_6 + __cached_7);
        vec_s8x16 __cached_8;
        __cached_8 = sc_max(__cached_6, vec_s8x16(0));
        vec_s8x16::store(__cached_8, &__outs_0[((((fused_0fused_0k__n_3530__n_i_3531 % 4UL) * 100352UL) + ((fused_0fused_0k__n_3530__n_i_3531 / 4UL) * 25088UL)) + ((_fuseiter12095 * 3584UL) + ((_fuseiter12096 * 512UL) + _fuseiter12097)))]);
      }
    }
  }
  sc_thread_aligned_free(__stream, __origouts_3080_shr);
}

static void res5b_conv_2_cast_mul_add_cast_add_relu__6770_closure_347_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept{
  res5b_conv_2_cast_mul_add_cast_add_relu__6770_closure_347(i, (int8_t*)(args[0UL].v_ptr), (int8_t*)(args[1UL].v_ptr), (float*)(args[2UL].v_ptr), (float*)(args[3UL].v_ptr), (int8_t*)(args[4UL].v_ptr), (int8_t*)(args[5UL].v_ptr));
}

static void res5c_conv_0_cast_mul_add_cast_relu_reorder__6760_closure_348(uint64_t n, int8_t* __restrict__ __outs_0) noexcept{
  memset(&__outs_0[(n * 41472UL)], 0, 4608UL);
  for (uint64_t p1 = 0UL; p1 < 7UL; p1 += 1UL) {
    memset(&__outs_0[((n * 41472UL) + ((p1 + 1UL) * 4608UL))], 0, 512UL);
    memset(&__outs_0[(((n * 41472UL) + ((p1 + 1UL) * 4608UL)) + 4096UL)], 0, 512UL);
  }
  memset(&__outs_0[((n * 41472UL) + 36864UL)], 0, 4608UL);
}

static void res5c_conv_0_cast_mul_add_cast_relu_reorder__6760_closure_348_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept{
  res5c_conv_0_cast_mul_add_cast_relu_reorder__6760_closure_348(i, (int8_t*)(args[0UL].v_ptr));
}

static void res5c_conv_0_cast_mul_add_cast_relu_reorder__6760_closure_349(uint64_t fused_0fused_0n__n_i_3532__k_3533, int8_t* __restrict__ __ins_0, int8_t* __restrict__ __ins_1, float* __restrict__ __ins_2, float* __restrict__ __ins_3, int8_t* __restrict__ __outs_0) noexcept{
  void*& __sc_kernel_cache_152 = *(void**)(__module_data + 160);
  alignas(64) int8_t __rescheduled_2[128UL];
  int32_t* __origouts_3090_shr = (int32_t*)sc_thread_aligned_malloc(__stream, 50176UL);
  void** A_list = (void**)&__rescheduled_2[0UL];
  void** B_list = (void**)&__rescheduled_2[64UL];
  for (uint64_t c = 0UL; c < 4UL; c += 1UL) {
    void* __cached_0;
    __cached_0 = &__ins_0[(((fused_0fused_0n__n_i_3532__k_3533 / 2UL) * 100352UL) + (c * 25088UL))];
    A_list[c] = __cached_0;
    void* __cached_1;
    __cached_1 = &__ins_1[(((fused_0fused_0n__n_i_3532__k_3533 % 2UL) * 524288UL) + (c * 131072UL))];
    B_list[c] = __cached_1;
  }
  void* _arg_cache_49 = &__origouts_3090_shr[0UL];
  dnnl_brgemm_list_call(__sc_kernel_cache_152, A_list, B_list, &__origouts_3090_shr[0UL], 1, 1, 1, 4, 7, 7, __stream);
  for (uint64_t _fuseiter12137 = 0UL; _fuseiter12137 < 7UL; _fuseiter12137 += 1UL) {
    for (uint64_t _fuseiter12138 = 0UL; _fuseiter12138 < 7UL; _fuseiter12138 += 1UL) {
      for (uint64_t _fuseiter12139 = 0UL; _fuseiter12139 < 256UL; _fuseiter12139 += 16UL) {
        vec_s32x16 __cached_2;
        __cached_2 = vec_s32x16::load(&__origouts_3090_shr[((_fuseiter12137 * 1792UL) + ((_fuseiter12138 * 256UL) + _fuseiter12139))]);
        vec_f32x16 __cached_3;
        __cached_3 = (vec_f32x16)(__cached_2);
        vec_f32x16 __cached_4;
        __cached_4 = vec_f32x16::load(&__ins_2[(((fused_0fused_0n__n_i_3532__k_3533 % 2UL) * 256UL) + _fuseiter12139)]);
        __cached_3 = (__cached_3 * __cached_4);
        vec_f32x16 __cached_5;
        __cached_5 = vec_f32x16::load(&__ins_3[(((fused_0fused_0n__n_i_3532__k_3533 % 2UL) * 256UL) + _fuseiter12139)]);
        __cached_3 = (__cached_3 + __cached_5);
        vec_s8x16 __cached_6;
        __cached_6 = sc_saturated_cast<vec_s8x16>(sc_round_and_cast<vec_s32x16>(__cached_3));
        __cached_6 = sc_max(__cached_6, vec_s8x16(0));
        vec_s8x16 __cached_7;
        __cached_7 = __cached_6;
        vec_s8x16::store(__cached_7, &__outs_0[(((fused_0fused_0n__n_i_3532__k_3533 / 2UL) * 41472UL) + ((((_fuseiter12139 + ((fused_0fused_0n__n_i_3532__k_3533 % 2UL) * 256UL)) / 512UL) * 41472UL) + (((_fuseiter12137 + 1UL) * 4608UL) + (((_fuseiter12138 + 1UL) * 512UL) + ((_fuseiter12139 + ((fused_0fused_0n__n_i_3532__k_3533 % 2UL) * 256UL)) % 512UL)))))]);
      }
    }
  }
  sc_thread_aligned_free(__stream, __origouts_3090_shr);
}

static void res5c_conv_0_cast_mul_add_cast_relu_reorder__6760_closure_349_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept{
  res5c_conv_0_cast_mul_add_cast_relu_reorder__6760_closure_349(i, (int8_t*)(args[0UL].v_ptr), (int8_t*)(args[1UL].v_ptr), (float*)(args[2UL].v_ptr), (float*)(args[3UL].v_ptr), (int8_t*)(args[4UL].v_ptr));
}

static void res5c_conv_1_cast_mul_add_cast_relu__6750_closure_350(uint64_t fused_0fused_0fused_0oc_i__n_3534__n_i_3535__k_o_3536, int8_t* __restrict__ __ins_0, int8_t* __restrict__ __ins_1, float* __restrict__ __ins_2, float* __restrict__ __ins_3, int8_t* __restrict__ __outs_0) noexcept{
  void** __sc_kernel_cache_arr_154 = (void**)&__uninitialized_data[23657536UL];
  int8_t* __rescheduled_1 = (int8_t*)sc_thread_aligned_malloc(__stream, 256UL);
  int32_t* __origouts_3100_shr = (int32_t*)sc_thread_aligned_malloc(__stream, 12544UL);
  void** A_list = (void**)&__rescheduled_1[0UL];
  void** B_list = (void**)&__rescheduled_1[128UL];
  for (uint64_t r = 0UL; r < 3UL; r += 1UL) {
    for (uint64_t s = 0UL; s < 3UL; s += 1UL) {
      void* __cached_1;
      __cached_1 = &__ins_0[((((fused_0fused_0fused_0oc_i__n_3534__n_i_3535__k_o_3536 / 4UL) % 4UL) * 41472UL) + ((r * 4608UL) + (s * 512UL)))];
      A_list[((r * 3UL) + s)] = __cached_1;
      void* __cached_2;
      __cached_2 = &__ins_1[((((fused_0fused_0fused_0oc_i__n_3534__n_i_3535__k_o_3536 % 4UL) + ((fused_0fused_0fused_0oc_i__n_3534__n_i_3535__k_o_3536 / 16UL) * 4UL)) * 294912UL) + ((r * 98304UL) + (s * 32768UL)))];
      B_list[((r * 3UL) + s)] = __cached_2;
    }
  }
  void* _arg_cache_50 = &__origouts_3100_shr[0UL];
  dnnl_brgemm_list_call(__sc_kernel_cache_arr_154[0UL], A_list, B_list, &__origouts_3100_shr[0UL], 1, 512, 32768, 9, 7, 7, __stream);
  for (uint64_t _fuseiter12178 = 0UL; _fuseiter12178 < 7UL; _fuseiter12178 += 1UL) {
    for (uint64_t _fuseiter12179 = 0UL; _fuseiter12179 < 7UL; _fuseiter12179 += 1UL) {
      for (uint64_t _fuseiter12180 = 0UL; _fuseiter12180 < 64UL; _fuseiter12180 += 16UL) {
        vec_s32x16 __cached_3;
        __cached_3 = vec_s32x16::load(&__origouts_3100_shr[((_fuseiter12178 * 448UL) + ((_fuseiter12179 * 64UL) + _fuseiter12180))]);
        vec_f32x16 __cached_4;
        __cached_4 = (vec_f32x16)(__cached_3);
        vec_f32x16 __cached_5;
        __cached_5 = vec_f32x16::load(&__ins_2[((((fused_0fused_0fused_0oc_i__n_3534__n_i_3535__k_o_3536 % 4UL) + ((fused_0fused_0fused_0oc_i__n_3534__n_i_3535__k_o_3536 / 16UL) * 4UL)) * 64UL) + _fuseiter12180)]);
        __cached_4 = (__cached_4 * __cached_5);
        vec_f32x16 __cached_6;
        __cached_6 = vec_f32x16::load(&__ins_3[((((fused_0fused_0fused_0oc_i__n_3534__n_i_3535__k_o_3536 % 4UL) + ((fused_0fused_0fused_0oc_i__n_3534__n_i_3535__k_o_3536 / 16UL) * 4UL)) * 64UL) + _fuseiter12180)]);
        __cached_4 = (__cached_4 + __cached_6);
        vec_s8x16 __cached_7;
        __cached_7 = sc_saturated_cast<vec_s8x16>(sc_round_and_cast<vec_s32x16>(__cached_4));
        vec_s8x16 __cached_8;
        __cached_8 = sc_max(__cached_7, vec_s8x16(0));
        vec_s8x16::store(__cached_8, &__outs_0[((((fused_0fused_0fused_0oc_i__n_3534__n_i_3535__k_o_3536 / 4UL) % 4UL) * 25088UL) + ((((fused_0fused_0fused_0oc_i__n_3534__n_i_3535__k_o_3536 % 4UL) + ((fused_0fused_0fused_0oc_i__n_3534__n_i_3535__k_o_3536 / 16UL) * 4UL)) * 3136UL) + ((_fuseiter12178 * 448UL) + ((_fuseiter12179 * 64UL) + _fuseiter12180))))]);
      }
    }
  }
  sc_thread_aligned_free(__stream, __origouts_3100_shr);
  sc_thread_aligned_free(__stream, __rescheduled_1);
}

static void res5c_conv_1_cast_mul_add_cast_relu__6750_closure_350_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept{
  res5c_conv_1_cast_mul_add_cast_relu__6750_closure_350(i, (int8_t*)(args[0UL].v_ptr), (int8_t*)(args[1UL].v_ptr), (float*)(args[2UL].v_ptr), (float*)(args[3UL].v_ptr), (int8_t*)(args[4UL].v_ptr));
}

static void res5c_conv_2_cast_mul_add_cast_add_relu_reorder__6740_closure_351(uint64_t fused_0fused_0n__n_i_3537__k_3538, int8_t* __restrict__ __ins_0, int8_t* __restrict__ __ins_1, float* __restrict__ __ins_2, float* __restrict__ __ins_3, int8_t* __restrict__ __ins_4, int8_t* __restrict__ __outs_0) noexcept{
  void*& __sc_kernel_cache_156 = *(void**)(__module_data + 168);
  alignas(64) int8_t __rescheduled_1[128UL];
  int32_t* __origouts_3110_shr = (int32_t*)sc_thread_aligned_malloc(__stream, 100352UL);
  void** A_list = (void**)&__rescheduled_1[0UL];
  void** B_list = (void**)&__rescheduled_1[64UL];
  for (uint64_t c = 0UL; c < 8UL; c += 1UL) {
    void* __cached_0;
    __cached_0 = &__ins_0[(((fused_0fused_0n__n_i_3537__k_3538 / 4UL) * 25088UL) + (c * 3136UL))];
    A_list[c] = __cached_0;
    void* __cached_1;
    __cached_1 = &__ins_1[(((fused_0fused_0n__n_i_3537__k_3538 % 4UL) * 262144UL) + (c * 32768UL))];
    B_list[c] = __cached_1;
  }
  void* _arg_cache_51 = &__origouts_3110_shr[0UL];
  dnnl_brgemm_list_call(__sc_kernel_cache_156, A_list, B_list, &__origouts_3110_shr[0UL], 1, 1, 1, 8, 7, 7, __stream);
  for (uint64_t _fuseiter12213 = 0UL; _fuseiter12213 < 7UL; _fuseiter12213 += 1UL) {
    for (uint64_t _fuseiter12214 = 0UL; _fuseiter12214 < 7UL; _fuseiter12214 += 1UL) {
      for (uint64_t _fuseiter12215 = 0UL; _fuseiter12215 < 512UL; _fuseiter12215 += 16UL) {
        vec_s32x16 __cached_2;
        __cached_2 = vec_s32x16::load(&__origouts_3110_shr[((_fuseiter12213 * 3584UL) + ((_fuseiter12214 * 512UL) + _fuseiter12215))]);
        vec_f32x16 __cached_3;
        __cached_3 = (vec_f32x16)(__cached_2);
        vec_f32x16 __cached_4;
        __cached_4 = vec_f32x16::load(&__ins_2[(((fused_0fused_0n__n_i_3537__k_3538 % 4UL) * 512UL) + _fuseiter12215)]);
        __cached_3 = (__cached_3 * __cached_4);
        vec_f32x16 __cached_5;
        __cached_5 = vec_f32x16::load(&__ins_3[(((fused_0fused_0n__n_i_3537__k_3538 % 4UL) * 512UL) + _fuseiter12215)]);
        __cached_3 = (__cached_3 + __cached_5);
        vec_s8x16 __cached_6;
        __cached_6 = sc_saturated_cast<vec_s8x16>(sc_round_and_cast<vec_s32x16>(__cached_3));
        vec_s8x16 __cached_7;
        __cached_7 = vec_s8x16::load(&__ins_4[((((fused_0fused_0n__n_i_3537__k_3538 / 4UL) * 100352UL) + ((fused_0fused_0n__n_i_3537__k_3538 % 4UL) * 25088UL)) + ((_fuseiter12213 * 3584UL) + ((_fuseiter12214 * 512UL) + _fuseiter12215)))]);
        __cached_6 = (__cached_6 + __cached_7);
        __cached_6 = sc_max(__cached_6, vec_s8x16(0));
        vec_s8x16 __cached_8;
        __cached_8 = __cached_6;
        vec_s8x16::store(__cached_8, &__outs_0[(((fused_0fused_0n__n_i_3537__k_3538 / 4UL) * 100352UL) + ((_fuseiter12213 * 14336UL) + ((_fuseiter12214 * 2048UL) + (_fuseiter12215 + ((fused_0fused_0n__n_i_3537__k_3538 % 4UL) * 512UL)))))]);
      }
    }
  }
  sc_thread_aligned_free(__stream, __origouts_3110_shr);
}

static void res5c_conv_2_cast_mul_add_cast_add_relu_reorder__6740_closure_351_0wrapper(void* __stream, int8_t* __restrict__ __module_data, uint64_t i, generic_val* __restrict__ args) noexcept{
  res5c_conv_2_cast_mul_add_cast_add_relu_reorder__6740_closure_351(i, (int8_t*)(args[0UL].v_ptr), (int8_t*)(args[1UL].v_ptr), (float*)(args[2UL].v_ptr), (float*)(args[3UL].v_ptr), (int8_t*)(args[4UL].v_ptr), (int8_t*)(args[5UL].v_ptr));
}
