import json
import argparse
import struct


def parse_args():
    parser = argparse.ArgumentParser()
    parser.add_argument(
        "--infile", type=str, default="int8-scales-fused.json",
        help="The calibration json file")
    parser.add_argument(
        "--outfile",
        type=str,
        default="qinfos.cpp",
        help="The converted files")
    parser.add_argument(
        "--batchsize",
        type=int,
        choices=[4,8,256],
        default=256,
        help="Batch size for module data")
    args = parser.parse_args()
    return args


def get_qinfos(path):
    print("read qinfos from file", path)
    qinfos = [() for _ in range(100)]

    with open(path, "r") as f:
        data = json.load(f)[" "]["q_op_infos"]
        cnt = 0
        layer_start = [3, 25, 54, 97, 119]
        layer_index = 0
        index = 0
        old_index = 0
        conv_index = 0
        for i in range(122):
            item = data[str(i)]

            if i < 3 or i > 118:
                continue

            if i >= layer_start[layer_index]:
                old_index = index
                layer_index += 1
                index += 1
                conv_index = 0

            if item["op_type"] == "<class 'torch.nn.modules.conv.Conv2d'>":
                conv_index += 1
                input_tensor_infos = item["input_tensor_infos"][0]
                q1 = input_tensor_infos["scale"]

                weight_tensor_infos = item["weight_tensor_infos"][0]
                q2 = weight_tensor_infos["scale"]
                cnt += 1
                if conv_index == 4:
                    qinfos[old_index] = (q1, q2)
                else:
                    qinfos[index] = (q1, q2)
                    index += 1

            elif item[
                    "op_type"] == "<method 'add' of 'torch._C._TensorBase' objects>":
                residual_input = item["input_tensor_infos"][1]
                main_branch_input = item["input_tensor_infos"][0]

                q1 = residual_input["scale"]
                q2 = main_branch_input["scale"]

                # conv block add
                if i in (9, 31, 60, 103):
                    q1 = residual_input["scale"]

                next_input = data[str(i + 2)]["input_tensor_infos"][0]
                q3 = next_input["scale"]

                qinfos[index] = (q1, q1)
                index += 1
                qinfos[index] = (q2, q2)
                index += 1
                qinfos[index] = (q3, q3)
                index += 1
    return qinfos


def main():
    args = parse_args()
    infile = args.infile
    outfile = args.outfile
    batchsize = args.batchsize
    # pair of [activation_scale, weight_scales]
    qinfos = get_qinfos(infile)

    # used in dequantization calculation
    in_scales_idx = [0,1,2,3,7,8,9,13,14,15,19,20,21,22,26,27,28,32,33,34,38,39,40,44,45,46,47,51,52,53,57,58,59,63,64,65,69,70,71,75,76,77,81,82,83,84,88,89,90,94,95,96]
    # used in cached quantize_activation
    out_scales_idx = [4,2,3,5,8,9,11,14,15,17,23,21,22,24,27,28,30,33,34,36,39,40,42,48,46,47,49,52,53,55,58,59,61,64,65,67,70,71,73,76,77,79,85,83,84,86,89,90,92,95,96,98]
    ## rearrange dequantize_scales and activation_scales
    desired_idx_list = [51,102,50,101,49,48,99,47,98,46,45,96,44,95,43,42,41,92,40,91,39,38,89,37,88,36,35,86,34,85,33,32,83,31,82,30,29,80,28,79,27,26,77,25,76,24,23,22,73,21,72,20,19,70,18,69,17,16,67,15,66,14,13,64,12,63,11,10,9,60,8,59,7,6,57,5,56,4,3,54,2,53,103,100,97,94,93,90,87,84,81,78,75,74,71,68,65,62,61,58,55,52,1,0]

    in_scales = []
    in_scales_rcp = []
    wei_scales = []
    wei_scales_rcp = []
    for idx in in_scales_idx:
        in_scales.append(qinfos[idx][0])
        in_scales_rcp.append([1.0/(float)(s) for s in qinfos[idx][0]])
        wei_scales.append(qinfos[idx][1])
        wei_scales_rcp.append([1.0/(float)(s) for s in qinfos[idx][1]])

    out_scales = []
    out_scales_rcp = []
    for idx in out_scales_idx:
        out_scales.append(qinfos[idx][0])
        out_scales_rcp.append([1.0/(float)(s) for s in qinfos[idx][0]])

    dequantize_scales = []
    for idx in range(len(in_scales)):
        scales = []
        for cidx in range(len(wei_scales[idx])):
            scales.append(in_scales[idx][0] * wei_scales[idx][cidx])
        dequantize_scales.append(scales)

    dequantize_scales = dequantize_scales
    dequantize_scales.extend(out_scales_rcp)

    ret = bytes()
    act_scale_idx = 0
    pad_bytes = 0
    for idx in desired_idx_list:
        scales = dequantize_scales[idx]

        if len(scales) == 1:
            act_scale_idx += 1
            if act_scale_idx <=31:
                pad_bytes = 60
            elif act_scale_idx == 52:
                pad_bytes = 44
            else:
                pad_bytes = 0

        for s in scales:
            ret += struct.pack("f", s)
        if pad_bytes > 0:
            ret += bytearray(pad_bytes)
            pad_bytes = 0

    ## weight_scale
    wei_scales_rcp.reverse()
    wei_scale_rcp_flatten = [s for ws in wei_scales_rcp for s in ws]
    for s in wei_scale_rcp_flatten:
        ret += struct.pack("f", s)

    print ("total num of qinfos is:{}, num of packed elements is:{} for bs={} kernel".format(len(ret), len(ret) / 8, batchsize))

    header = "0x0,0x0,0x0,0x0,0x0,0x0,0x0,0x0,0x0,0x0,0x0,0x0,0x0,0x0,0x0,0x0,0x0,0x0,0x0,0x0,0x0,0x0,0x0,0x0,0x6,0x0,0x1,0x3,0xe00,0x4,0x1000,0x5,0xe00,0xc,0x1,0xd,0x1,0x0,0x0,0x0,0x6,0x0,0x1,0x3,0x1c00,0x4,0x1000,0x5,0x1c00,0xc,0x1,0xd,0x1,0x0,0x0,0x0,0x7,0x0,0x9,0x3,0x7e00,0x4,0x9000,0x5,0xe00,0xb,0x0,0xc,0x1,0xd,0x1,0x0,0x6,0x0,0x4,0x3,0x3800,0x4,0x4000,0x5,0xe00,0xc,0x1,0xd,0x1,0x0,0x0,0x0,0x6,0x0,0x4,0x3,0x1c00,0x4,0x4000,0x5,0x700,0xc,0x1,0xd,0x1,0x0,0x0,0x0,0x7,0x0,0x12,0x3,0x7e00,0x4,0x9000,0x5,0x700,0xb,0x0,0xc,0x1,0xd,0x1,0x0,0x6,0x0,0x2,0x3,0x1c00,0x4,0x2000,0x5,0xe00,0xc,0x1,0xd,0x1,0x0,0x0,0x0,0x6,0x0,0x8,0x3,0x3800,0x4,0x8000,0x5,0x700,0xc,0x1,0xd,0x1,0x0,0x0,0x0,0x7,0x0,0x12,0x3,0x75d80,0x4,0x9000,0x5,0x68c0,0xb,0x2,0xc,0x1,0xd,0x1,0x0,0x101010101010101,0x101010101010101,0x101010101010101,0x101000001010101,0x101010101010101,0x101010101010101,0x101010101010101,0x101010100000101,0x101010101010101,0x101010101010101,0x101010101010101,0x101010101010000,0x101010101010101,0x101010101010101,0x10101010101,0x101010101010101,0x101010101010101,0x101010101010101,0x101000001010101,0x101010101010101,0x101010101010101,0x101010101010101,0x101010100000101,0x101010101010101,0x101010101010101,0x101010101010101,0x101010101010000,0x101010101010101,0x101010101010101,0x10101010101,0x101010101010101,0x101010101010101,0x101010101010101,0x101000001010101,0x101010101010101,0x101010101010101,0x101010101010101,0x101010100000101,0x101010101010101,0x101010101010101,0x101010101010101,0x101010101010000,0x101010101010101,0x101010101010101,0x10101010101,0x101010101010101,0x101010101010101,0x101010101010101,0x101000001010101,0x101010101010101,0x101010101010101,0x101010101010101,0x101010100000101,0x101010101010101,0x101010101010101,0x101010101010101,0x101010101010000,0x101010101010101,0x101010101010101,0x10101010101,0x101010101010101,0x101010101010101,0x101010101010101,0x101000001010101,0x101010101010101,0x101010101010101,0x101010101010101,0x101010100000101,0x101010101010101,0x101010101010101,0x101010101010101,0x101010101010000,0x101010101010101,0x101010101010101,0x10101010101,0x101010101010101,0x101010101010101,0x101010101010101,0x101000001010101,0x101010101010101,0x101010101010101,0x101010101010101,0x101010100000101,0x101010101010101,0x101010101010101,0x101010101010101,0x101010101010000,0x101010101010101,0x101010101010101,0x10101010101,0x101010101010101,0x101010101010101,0x101010101010101,0x101000001010101,0x101010101010101,0x101010101010101,0x101010101010101,0x101010100000101,0x101010101010101,0x101010101010101,0x101010101010101,0x101010101010000,0x101010101010101,0x101010101010101,0x10101010101,0x0,0x0,0x0,0x0,0x0,0x0,0x0,0x6,0x0,0x2,0x3,0xe00,0x4,0x2000,0x5,0x700,0xc,0x1,0xd,0x1,0x0,0x0,0x0,0x6,0x0,0x8,0x3,0x31000,0x4,0x8000,0x5,0x6200,0xc,0x1,0xd,0x1,0x0,0x0,0x0,0x6,0x0,0x2,0x3,0x3800,0x4,0x2000,0x5,0x1c00,0xc,0x1,0xd,0x1,0x0,0x0,0x0,0x6,0x0,0x8,0x3,0x7000,0x4,0x8000,0x5,0xe00,0xc,0x1,0xd,0x1,0x0,0x0,0x0,0x7,0x0,0x24,0x3,0x7e00,0x4,0x9000,0x5,0x380,0xb,0x0,0xc,0x1,0xd,0x1,0x0,0x6,0x0,0x10,0x3,0x7000,0x4,0x10000,0x5,0x700,0xc,0x1,0xd,0x1,0x0,0x0,0x0,0x7,0x0,0x24,0x3,0x7ce00,0x4,0x9000,0x5,0x3780,0xb,0x2,0xc,0x1,0xd,0x1,0x0,0x101010101010101,0x10101010101,0x101010101010101,0x10101010101,0x101010101010101,0x10101010101,0x101010101010101,0x10101010101,0x101010101010101,0x10101010101,0x101010101010101,0x10101010101,0x101010101010101,0x10101010101,0x101010101010101,0x10101010101,0x101010101010101,0x10101010101,0x101010101010101,0x10101010101,0x101010101010101,0x10101010101,0x101010101010101,0x10101010101,0x101010101010101,0x10101010101,0x101010101010101,0x10101010101,0x0,0x0,0x0,0x0,0x6,0x0,0x10,0x3,0xc400,0x4,0x80000,0x5,0x6200,0xc,0x1,0xd,0x1,0x0,0x0,0x0,0x6,0x0,0x10,0x3,0x7000,0x4,0x80000,0x5,0x3800,0xc,0x1,0xd,0x1,0x0,0x0,0x0,0x7,0x0,0x48,0x3,0x7e00,0x4,0x24000,0x5,0x700,0xb,0x0,0xc,0x1,0xd,0x1,0x0,0x6,0x0,0x1,0x3,0x6200,0x4,0x40000,0x5,0x6200,0xc,0x1,0xd,0x1,0x0,0x0,0x0,0x6,0x0,0x4,0x3,0x18800,0x4,0x20000,0x5,0xc40,0xc,0x1,0xd,0x1,0x0,0x0,0x0,0x7,0x0,0x48,0x3,0x44a00,0x4,0x12000,0x5,0x1e80,0xb,0x2,0xc,0x1,0xd,0x1,0x1010101010101,0x101010101010100,0x101010101010000,0x101010101000001,0x101010100000101,0x101010000010101,0x101000001010101,0x101010101,0x0,0x6,0x0,0x4,0x3,0x18800,0x4,0x80000,0x5,0x3100,0xc,0x1,0xd,0x1,0x0,0x0,0x0,0x7,0x0,0x9,0x3,0x44a00,0x4,0x48000,0x5,0xf40,0xb,0x2,0xc,0x1,0xd,0x1,0x0,0x6,0x0,0x8,0x3,0x6200,0x4,0x40000,0x5,0x6200,0xc,0x1,0xd,0x1,0x0,0x0,0x0,"
    with open(outfile, "w") as outf:
        outf.write(
            '#include <stdint.h>\nalignas(64) uint64_t rn50_backbone_bs{}_data[]={{\n'.format(batchsize))
        outf.write(header)

        for i in range(len(ret)//8):
            val = struct.unpack('Q', ret[i*8:(i+1)*8])[0]
            outf.write(hex(val)+",")
        outf.write("};")


if __name__ == "__main__":
    main()