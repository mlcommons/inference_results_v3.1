{
  "accelerator_frequency": "",
  "accelerator_host_interconnect": "N/A",
  "accelerator_interconnect": "N/A",
  "accelerator_interconnect_topology": "",
  "accelerator_memory_capacity": "N/A",
  "accelerator_memory_configuration": "N/A",
  "accelerator_model_name": "N/A",
  "accelerator_on-chip_memories": "",
  "accelerators_per_node": "0",
  "cooling": "air",
  "division": "closed",
  "framework": "MLCommons reference implementation with CM API, Onnxruntime v1.15.1",
  "host_memory_capacity": "15G",
  "host_memory_configuration": "undefined",
  "host_networking": "Gig Ethernet",
  "host_network_card_count": "1",
  "host_networking_topology": "N/A",
  "host_processor_caches": "L1d cache: 64 KiB (2 instances), L1i cache: 64 KiB (2 instances), L2 cache: 1 MiB (2 instances), L3 cache: 8 MiB (1 instance)",
  "host_processor_core_count": "2",
  "host_processor_frequency": "undefined",
  "host_processor_interconnect": "",
  "host_processor_model_name": "AMD EPYC 7R13 Processor",
  "host_processors_per_node": "1",
  "host_storage_capacity": "220G",
  "host_storage_type": "SSD",
  "hw_notes": "",
  "number_of_nodes": "1",
  "operating_system": "Amzn 2023 (linux-6.1.41-63.114.amzn2023.x86_64-glibc2.34)",
  "other_software_stack": "Python: 3.9.16, GCC-11.3.1",
  "status": "available",
  "submitter": "CTuning",
  "sw_notes": "Powered by MLCommons CM automation language and CK playground. ",
  "system_name": "AWS cloud instance inf2.xlarge",
  "system_type": "edge",
  "system_type_detail": "cloud"
}
